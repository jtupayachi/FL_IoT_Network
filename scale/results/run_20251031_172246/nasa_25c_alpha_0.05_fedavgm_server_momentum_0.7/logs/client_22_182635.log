[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0270fd1-4943-4431-b7f8-8b7b293e2709
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5dd439f2-5f3f-4141-81ba-359cfdd49a0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 521668d3-f7d1-4818-a227-ee2d41e4de95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a549dd1-95ed-48df-9ce6-f13e8b74c69f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9db46d1a-f6d6-4e1b-981c-efb92f6c9607
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1c4732d-5e57-4284-ba2a-6958626924df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc709322-eecf-44c7-abd9-0924a8449fc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7aad3f09-dd9c-4a17-a263-f3794aefddf1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68e8f8c5-d27e-43a3-ae0d-373bcb29c686
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3dcf17f-f494-4986-b559-e46ccb6291d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9dea0563-097f-4161-ba37-37af666d01c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d813c780-3919-47b8-beb7-73e25a2fcb82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fafdbd44-aeb2-4936-805d-4565c72de150
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8848eae9-11e6-4e20-9895-b93ea3b98f49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0885d2d-8860-4d60-93dc-7592178b2e01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7f3df03-a200-4151-8800-65eb371b1dc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dcceec9a-a3fd-47b7-84e6-e6a356f492dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73a57b02-f989-4487-89ad-6f368e654866
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f6a4f7a-8d82-4507-900f-62c82bf9fabd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message efb3535f-f367-445a-96e0-c5abd0cb231a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf2640e2-1705-4a31-a4fa-2c958a13a1f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f84a5c55-a645-43e8-87d6-74e5bfbee557
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0c70691-b236-4b46-b665-557588adf301
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d820f78-a3af-436e-9452-3689486c8d92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee004cdf-f8a5-40db-bd0d-cc07bdb6d1c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be846011-228b-487e-a3a1-c7d67198da5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a0b4139-ab5a-4ff2-9a01-4c536e4cb7d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e336583e-875e-4d22-9f1e-ca57c3acb82c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 367f2a94-2d1d-4ecb-add1-9d7558b202db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 273bd2df-49c9-475c-9b6f-1a19bdacb525
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89613083-fd1f-4ee3-b208-0896e93e80b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 750e0098-4804-45dd-888a-7861bb46644a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfabab41-38a3-4604-bc11-5c6b095b40af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e258df2b-5f5c-45b3-aea1-82a449190123
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f8a6f51-9349-44ee-b92c-2b2718eb9a41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7764cdd-b0d2-4e40-9763-52f3f7083619
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9a9b79f-0764-4e05-a8c0-89259e4faf51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e8182cb-774b-4598-921b-b9620ddee5da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4fb6a7fc-c481-4130-9d2e-8332be935824
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f4cd6de-3318-460d-9037-4607621f1ffe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f1843fa-0761-47bb-aba8-69649a1a591d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 335055d6-cd51-4bb9-887e-a5122d094227
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5bf8876-e79f-45ad-9baf-e2102d321c74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3fecde72-41b2-42ca-8f40-8790641c4570
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63deb337-1c7c-4325-986d-8ebcee26fcaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe0c71a5-e031-4cbb-a4ef-416d3dbd941c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8039c5ec-89e1-40dd-b22d-8eff222479ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ba827db-f320-40c6-8010-17847050518d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76b249c5-8d5b-4ff0-a922-0d7516c5dc11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 783bd302-ee81-444b-a289-d7a02c599126
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 954752da-f300-47fe-adb9-791b14322848
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cbf93969-996f-4910-8b1c-4b205262ca49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a870c92-b253-4b0d-a548-7537f0535c5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 038ef807-99c4-4714-bcee-0730ded6ea78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb57b075-12d1-4739-ab58-3d42610233e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6b5e4ea-43c2-47e3-a697-bb6c45fd58d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 906bab76-62f4-4ef1-ad37-7d6ac46e3d28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6abfda8-03a9-4c45-834f-58ac6bedef01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d7311b8-f3eb-4111-9e94-c33e87c39edb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ebf38c1-407e-418f-8f8a-3da057f51062
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d4db243-410a-4aba-8dfa-e11421c1484f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 597b7c0e-7d35-4b56-a6e3-cb5d0aa50561
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 478e1190-81bf-4631-bb3e-a61dfa5c6574
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec66c887-155c-4160-ad00-bd6ff521d856
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ffa3d3ef-bc43-49e3-b8a7-91fbe94b7c12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0eb387bf-e560-48c6-833c-00aa12bdd208
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f645120b-c56c-40a6-9e1f-b73a304840ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49f7897c-ed8d-41ba-a8e5-1afc0403959f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2980f3d1-1d18-4ade-90ae-70193aaf79de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b16b5ccb-8720-4e94-99f6-16c0342110c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce53a078-9269-45e6-bfe6-5171f993e003
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9f2e55e-471d-40a8-8de5-54d7aa0a0001
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 882be6c2-e006-4246-b83a-d2935250a680
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ba16e09-45d3-4e68-83b0-73b4ba880650
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11ea58a0-9f70-4ec7-92f4-cf668699b347
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad8951dd-e8d0-4747-b612-7f6a1faa365a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b50e26b2-759c-4f3a-98d6-509073f1c4a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5168fef0-cce4-4288-addf-8e40ae9ef7aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bcca8914-002b-4a88-8eb6-1328c39438a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a182a7d-0009-4e41-a1ac-8c4485bc2eb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f978a53e-078e-46b2-b1cc-77469ec37e95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 675e2e39-ef69-45a7-8aa4-372fee149a13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 528e2218-3f2d-4b55-bcdd-62746197bc28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8707d3e-5cbf-4685-9787-6114add481a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0dee93dc-e2a7-4c47-9c82-b912763cefe6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1603f37b-4375-42f7-89a8-8f46883ac617
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7e0feeb-6a43-46ca-99f6-fc7091d39394
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aef3bf1e-9c4b-4887-b035-823c8636849f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7bc98cbc-64fb-4431-8738-c49678931c4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2be67a13-1c5c-4b77-a750-32eddfd31672
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76324d7f-5898-4c35-88db-de49f65684b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43b4a73d-cf52-42ca-a97c-2a8828e930a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 777cf0e7-1a97-41e5-856c-90973a7397bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a272c64c-d32a-4b7f-ac35-a6ecff19704a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0bf468f0-7b76-4f44-b482-26f34ba6f0fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25c60a59-ff02-4e5e-85f9-80a5ebec3fb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 624b83f3-1bb0-4ce6-a461-08a090b877f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83f5feb7-506b-4890-bb4f-ad352da2f0bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05c11b22-99f6-44bb-afb7-5cfcedee5ebb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a7b14cd-dfbb-4bb8-9300-2057455b336f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc295eab-a2ff-4eaa-99fd-4275c2c36bdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c27072bf-32cc-42d3-be9a-347c81295da2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9adfa86-7926-44e8-a9fc-73ba164010d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7a4764f-3434-49a7-9257-9979ae7910b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0dd14727-548b-4068-997b-344d49e9f910
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c033ece-8bbd-43e7-a455-a09f5f67478d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6c7df41-ce86-4953-bf8b-874d0816abc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0ae3ed5-a796-4745-a37c-05c18d511dbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50259aa8-e0b4-4bd4-b36d-2338786adf2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f05c33c8-c4d9-4ecd-9015-cce2c6305fff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb353397-2b11-439f-a2f2-779d422da417
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dbab9240-344d-42b4-98f2-2406122975eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13e1bb52-12a6-48fb-af55-d7d83299fe13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 238b0dd6-1bce-4ef5-a1c0-0ff0131c999a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d6cdc67-3da3-4174-953d-048165f8611a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5ec6138-c573-4efd-8ceb-dc709be3573b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15495958-7804-487b-97a5-cf95f9b3b5f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 769d48ba-7fc2-4aa7-8aa4-c76bc1b94c36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89cc8ab1-3ab2-4717-ae86-3482d312ce5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a91e17f0-1108-446b-957d-dd8d20546302
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6194aa6e-fe5a-49d2-b91b-f509ae8dc845
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bce3722f-d1db-4af6-9c73-1ffb76041a7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70d85a30-a29d-4b0c-9899-1ccca5a94061
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00e913e3-b7f5-4fad-86f0-17f070a51815
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a38b984-5b55-4e66-a719-270ed468074b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d23b115a-3235-4e1c-90c7-7dde8ad8af91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12c89abe-b124-427a-8b29-8c0d6bcae6f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2baa7b29-0fec-48fd-9141-504df5d9d010
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22547648-3201-496e-880e-363e7aae3e15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c283a216-dcf3-4e97-8c36-9325b9929253
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e81cf6b-263f-4058-80e9-90d490511523
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4117946-3997-4aaf-94ac-9ff1211fc358
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6458521-4566-4194-ad5e-f120b79bea09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75a47664-11ac-47d0-92d5-55a97003a643
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9c5ca09-473a-4d3f-9c17-7812cf1137ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8da3ddac-fe70-42bb-a5d6-4b4479e0987b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 530100c1-0052-4e91-a0e6-0fbbdf15d070
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8bb1ee1f-495f-4aab-9ba4-4e1d9db44568
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 959c67a1-1faf-42ff-b5af-cb75b845924c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d0fb36b-abe8-4ff6-bb9c-b399f58dc328
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2dbde775-46ce-419d-bedf-7db0659d9775
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a008808-9998-4cb7-96df-d274387892a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9be5e7b-5282-4c21-815c-cddc11c44266
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34404c42-400c-4b99-91d1-ece44b8560b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message def64eef-428c-4321-8838-3cc73717c2ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f853c23-8084-4769-9f83-fe6332e1ff6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 070785b4-f1de-4c62-8e23-d53100ef3c06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8728ba6f-375d-40f1-b6dc-3550877e8a60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45341d46-ff0d-4476-921f-7d73b5e29f98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1e99308-c20d-406e-a8e3-6624ee0d8629
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb46be88-bdba-44ac-b7a8-c7465bae95d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a10f346-eac2-4eab-b09f-ad236c270e1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d48fd239-591d-44b7-afad-6de5f31c032b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b01c8b2-f54f-476b-953c-39781672ae6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b9f10da-eebe-4e94-a14f-ed62b1cfce17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9cb7f1eb-aadf-40b7-b721-542f99aad13b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7083f68-a406-4e46-b65d-20fa6c4943d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 494a37ee-7b4a-4ef1-8058-c102394627a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0325941-2e1a-4aba-a1ae-b612c39d70ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5cb16036-a6ee-486e-8fc7-6a268beaad74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa061f59-1bdb-409b-bcc7-ee9c0a76700f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2f34772-0a85-42eb-aa9a-2db549599d4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52f4c46d-dbb6-4110-b92a-bee1f7ddaec6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f091f88-b560-46a5-8982-c5302a6692bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a36797b-3e06-4372-b171-d8025488bad5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54fbd7eb-9ee9-498c-8a11-a4b4ce597c6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7966b51-a268-4e84-ad7d-37ab3984b3cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97cb3f25-fb71-46df-9b80-a3e87339dbd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61115d43-9e23-473a-b314-92e2c4f898b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8158fb3-63cf-4ccf-99fe-f69aa255d9e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8784aa25-9ae6-4712-9825-383579227e5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4170063-aff3-4765-ab49-d8bb5f21e5ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6312fa11-2b7c-41da-ae30-557d969b1686
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0b03c06-5ff9-4bc0-b927-84e24fa9c127
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b919c728-afce-482c-bd96-8a4aba484c88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36d2b739-d476-44e3-a399-9f034bbb9b6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 070c0b0a-814e-414b-87a2-a08b924e454c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03648fd8-e86b-49e1-81c8-ad62bf90e250
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd0979c7-d883-4466-8807-3fc05f9eb211
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 600ed141-dba9-499b-a19f-8443ab4704ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7d0b20e-4e89-45e6-89ec-f66bfc6173e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6784307e-3e80-4922-ab6b-2e8cbf388884
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b574193-9d17-45d2-bab7-af16f50f2de5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c847484b-8c83-4a14-bb1e-ea57ce60eeeb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ac38217-2b3d-4db1-b725-b56ca1d08131
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04095c2a-a1d4-4fdc-8e84-160b7feb8b89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28156639-9585-4b48-9761-8e9262502449
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2992c072-d15d-48b6-b6fb-233813ea29ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0371f6dc-4e96-438b-80b9-2727d77b1b63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28e9d4af-dfbc-4c27-a41f-65604360398d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ed0c6ca-bcf2-45e1-ab1e-50d6d95e6a41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b3b32bd-b7a3-437d-a089-8f9b5d765485
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32e221e1-6682-4e7e-88d7-a86f83bb1033
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce0dc4a9-9698-400d-bb7f-e5f4af6815c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e2e5fe6-c04f-4c5f-ba19-0568361b357a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38fe1277-a7f6-49d9-99a8-816261b72e0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c2eaa8f-55e8-445c-8643-33c33b53699e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c2eed41-038a-4ca1-9cee-ff36270ada81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 840da835-823f-4e57-a56d-1c021f5d43ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac87d410-657b-4b93-ae5b-e8c9d5707db3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b65a46d0-fdd9-4178-be6e-727ea5f720c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db7b00e7-2157-4744-866c-49cea317497d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 711a676a-93b8-4b7f-83a3-90d1c3ce6041
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49ceb0bd-bd27-4594-a05b-8a34c2ba576c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb30dffc-96ef-479b-bcfe-42f903b107c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 689e6435-4513-4606-80eb-5a3d2cd5554f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5217f79b-4e87-43e4-a8b9-ca9ce6cc6176
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e93b4c1e-6813-4ee6-ba02-e6fc93e41545
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f31e4072-e4ec-4a7c-b5f6-8ba63f5cb094
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ea49cdb-17ba-4638-8281-729030134465
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c81e5674-9ea1-40c5-b0a1-1e3a02395f7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f8e8bdf-fdfd-4931-9e46-e1e4a22a6f73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3592ba9c-2177-4566-ba86-a16967217bd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 257dba58-ba0c-427a-b69d-d661679175b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5550d4a1-5db7-4683-8223-9c47261ba7c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b28df5b-0350-4a72-a6b4-428c5efc9a1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 611954b3-6837-4f0c-9dd8-f4e5ebda958f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5eab248-4810-4b0c-8733-82cb5a2e5100
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b039e489-6274-427c-8f64-573fe6f9e4c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf5d8034-5347-4dec-8ffa-027db80f620f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e8138f7-4b06-42d7-a845-7ab46c59c12f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b15654c1-4626-41c0-a946-301ba274c95c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e90531d3-aeab-4ef7-b3f0-4c70174bb153
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e6a29d3-acea-44f6-9575-4f713420f791
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 407139ab-4756-4e8a-94c1-547a44d76969
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 797eface-6a30-4826-a37e-e1fd60d9ab21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fbe6aa0f-70aa-4d5c-be80-de058b55ca47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e636f71-133d-4dbd-9cf2-44ac480f84c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d319bee-4646-4071-8504-7e0e7deb4ae0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2771211-49e2-4cdf-8401-a689e0befe56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca0a0bb7-6247-40ce-a63f-ede564b2700a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3be5c5bb-1ba4-450c-9b5b-174fcf530c97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 807e2739-2cf5-4dad-bb56-a6fae81e9e2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82e266f7-edc4-408c-8f7b-7430be048ab3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 984788ac-f9d1-4e38-94a9-626d3a56da7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 341e659d-b95a-4f6c-8ac0-59a3729efa93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a55d0e10-c3eb-43ba-b795-306ca82c4953
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d72bd77e-00e3-4d7a-8a5f-f484337cfa2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3de65ff-fb31-44e2-bdc0-f35fdfd64e5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2792038-67d3-4d70-a66a-845dcd264b85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9033aea7-b8b6-4cb2-a1da-86d601459914
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a0f4112-d369-4b18-b2cd-22009b867d5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc579b97-a21b-48b1-896c-5e9f487de69d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f010e1ac-d555-456a-baa6-6176571890cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d801615-0057-445a-a3e5-eeca2d6db065
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2d734a8-6eb4-4738-a32f-676639c4d23c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17382450-0795-4b6e-8233-06c6e2529df9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29090239-eea9-46ec-a5f6-628b53c37c34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ebe7a5ea-294d-4a5b-acba-c0cc98faa7e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed5f195f-8a97-4850-bfa8-27e197f97190
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48bca766-a18e-4494-a3f4-c366f649753c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1588474-8552-40c5-9c49-f9e3af51b520
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c348a52-3b40-4102-b301-6576384d5619
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76e64fba-43f3-4446-9099-946a17d93069
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3efded78-dcd7-47f8-91cc-b0625b023904
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f16dbb9c-b43b-4478-8c0a-68b1bfc79d1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea87636b-c689-4854-9b84-ac4e9d7ccba6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1972448a-a11c-4c56-b7f8-83ba59154a50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eeef239b-7fcf-449b-ad70-061cb2a5074a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 352ef767-6b87-4298-bbf8-0b6cd484047f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b68d58a8-b18b-4ad4-9125-ebb1004a57f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1e42953-1600-4fb5-9bcb-b5f17bc6df04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41bce048-7e81-4003-8c6f-f21538c9aa7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25f1e0d7-59df-45fc-b7c8-74e63f649272
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 801cc7c1-ccbc-45bc-8af7-091cebcafffb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f5ba1d4-10bf-4be3-a3cd-a03303414ed4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48293be3-8560-49b9-963d-0fb95558d73c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7f7f204-8795-40de-83cc-d836b41e4845
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e92f939d-5178-4b49-9e13-43fc9bee1535
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6c5707b-1eb2-48ea-a70b-92ca066e4200
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51d6b34b-113b-4351-a2b5-7a3dcbf32aeb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1218b236-33f8-44cd-908a-adb6ebfd02b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b137eaeb-d491-4ce4-b672-42e16b4ccbf8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e67be214-1738-4092-95f5-2604b628d9c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ba0e308-1099-4075-830c-16d1942cd9fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74e54f4f-f796-42ee-bd65-08d15c3b0b3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f583114-4a4d-4d4b-888b-c79f7a62f2ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5328485f-991e-4f32-8d35-5ea94a02d28d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3703a9e6-9b12-49f9-bd55-d9a9e0095b6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d490c633-8bdb-4367-ace0-bceff323c471
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1e44526-3055-404a-a8e4-9311f7199845
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19df90ac-e7dd-4242-b993-9cac4d6b35f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98ac551e-c78d-49b8-85b3-30e976e9126d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55555ad4-6502-4d37-b5be-27a923465826
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3228f039-db35-4aa7-adad-ebb0bf7965ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24264ed4-5ee3-4a4f-968e-423d945f2aef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cdeff8e2-0d06-48a3-8c57-cf4d4c1283a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff8b61a9-042a-40b4-9e8f-6c8f470a43d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c96da7e3-8ed5-4f57-9ef0-ca7772333d09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b137b0ca-6c47-4f1d-8100-4a3480036546
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f27e39c6-2501-4144-99ff-dca308946cd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c308001-4e6a-4370-b526-18f17a07554d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bcfd98c7-80b4-452a-b093-94b4059624cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 975d299a-ef14-44fa-a2f4-b02734a0ccc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 081d2a81-dd82-4603-a474-60abbfd87fa8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 856f771e-ebd1-429c-804e-d819dc18b884
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47968564-3fe4-4941-9482-e658f9ddd5f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae3d4064-0309-4d86-a060-ede2a5d7d4ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 769f749e-cdeb-4d8b-9dca-2de9be76bf6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aca22aac-19e8-436e-9712-a56463a906de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d23e59ba-7a78-4698-bc87-48a3368f8171
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3176ad38-3b95-4a86-ae2c-10e874e44273
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2c3a9b4-a7c2-44bf-8292-04ac5793792f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c36463e3-69cd-487b-ac6f-40aaa2c7d5de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad0c1196-03a2-4f40-886d-77ae342ec322
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a6304d3-fbcf-44dd-9cd5-64aa9620dbc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e456eee2-5ec3-4aeb-a5f1-2de2684b7a0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba8812bd-d8d4-4687-b211-75a930df2ad2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3cc913b6-36ff-4b0e-8853-e67261ab0498
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 901ae569-a2b9-47fe-934a-f1b21fb57c09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae7e4d03-1143-4001-b79c-25ecb08aca0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 350e0729-e5ba-429d-bd2d-f78db506f7db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0122e77c-c284-410d-9e93-9451aa146b1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 945be67a-f2c0-4025-ac6f-42efdd67041c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9d5916c-f330-40e1-be56-7a5e9a67e51a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 708b89f8-5faf-424d-9d07-ec887d6352bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02e80940-a8fe-40b1-bcaf-1e36100f63b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c2b2fa1-3c0e-4c03-a03b-52051075e77f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7d2036a-04d8-4a80-98e7-953766769339
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6d5b6c0-e257-4553-b710-bb1a422c7146
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2805742-d8a2-4ebc-95f0-8851ce9584bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5cb1853-15ed-4e22-9d21-f5c7378dce9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4172cc89-4d02-4b86-aec6-13d6c8b0b1c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71452136-818a-4e2f-aa1b-f80e7c01e737
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a345ed3-8b41-435a-b501-23448626f193
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1bae35d-5435-44da-9d51-e88755d9ed15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07427920-782c-4d51-9d63-0382fd38513e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd90e4cd-192b-4775-85c1-d96424a7b2ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 644e2769-057f-4eb2-8213-d45da18efe41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11c9095a-4d68-4bdd-83fb-188c1a598fd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f74adee8-c474-48a5-8353-c8c859ad5fc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 340806bd-64f9-4e26-bdb6-54f548fa09c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1dc1cc07-161e-4a64-aae9-ab7f93b05ed5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71e92682-d423-4f38-a65b-f4766c87bd52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 874b2e8e-e3d2-4a5f-9398-a67b53076f98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b591d794-0ec0-4bbb-bd00-74fd1cb549c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed7391cb-49e8-407f-96ad-afdb95b0ac1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 377e9a60-11ee-4f25-8a93-873cc2e6fe93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a945664-7c76-44ff-8636-dda51cfc7d0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8a0e951-0aef-4395-bd3a-9369e86d8a07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d07fc4bc-9aac-44d8-a5ee-43d8c2453dca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f344254-c756-4f03-a550-12b1ab43c0f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1753d21b-8f58-4424-b2a6-e88b39bc87cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65296145-af76-4045-b78b-4abcda23d71a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d159da63-f8d0-4224-9cd3-4c9007b338c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4193d16-72f5-4946-a581-7c4c83776a13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3def72d-fa2f-4545-a38d-6425a6ed4dbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb9aee10-3657-4464-a9e5-bbf60402737b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e1af986-1def-4164-b819-7eb38ea676e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00a98ebc-6e39-45ec-a11e-33e3a1579303
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bace7bb2-02d8-489f-949f-27532b7fa287
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce6709dd-142c-4832-b21c-eaa0eb85871d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf175363-15c0-47ed-8c3d-69e133f55c63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2bbf1285-4da6-48ef-9a30-38b4fea80877
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5038f4a-f610-470e-9c78-e67bb3d591ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b921d5b8-ef2d-4a55-ac6e-c3bd61a2d9dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 328fda33-618f-4601-bbb6-61666475660f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aaced151-5b25-4d6e-82d8-2ca2ed2bc303
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab9242ef-cdea-45f4-aad0-af3e43c6d6d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd3c9de9-626f-4ffe-a4d0-b8b40b7a46be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b827bc3c-2b7e-4cd8-be13-2ff90a77da23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2fe05453-34df-433a-9c1d-e3f4e0acd945
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48965f9a-bf9f-4ce1-9d7a-f21465312da3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41ce3225-361e-47c0-8da3-43720ff4961e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 237cafb6-83c6-4a6e-9fdc-f5bb866b49af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2be32d96-d2c8-4ebb-8702-31b0e3601578
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4696dd81-85c1-45a3-b7a5-f9f70937f194
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d58eb9a4-9810-49f3-9402-1d201031c8e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1557d13-f087-4730-b456-6aa9e9f4b3e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2bfdb0a7-9d70-4e3f-b8b5-1248a88118ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e516384-d954-4aa2-8a5f-1511520a4d4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f623162-99e2-4d3f-87ce-bb6b861b0d01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0333ffa2-345b-4fb9-b435-8ef407b614b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a93bcead-bb0e-4733-b76a-37d0e0feb9ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83250ce9-db1b-423c-ba3c-c24b684c0d92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd388ece-98fd-461e-9378-40ad9e3b533d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 269973bf-72c5-467c-8027-c6d432546c43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 723c85c0-a4f5-467b-8001-628ccafa9bd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4d63ba8-00a7-4b00-bccb-e291da61b1e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc56477e-75a5-4443-82a6-5841bb96ef19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b703d3a-25b1-4796-a323-3642c9638ac8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db912649-e3d5-4088-aa2a-0861aba190b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1de3baf-2a8d-4dd4-b051-13a375720ce1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73474de6-040b-405e-a02e-4966e6523325
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0125ac1e-3e12-4669-ba58-034679b5fa06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b36f500-936f-4900-9c52-b4407b461270
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 661519a3-d683-4c6c-b5ee-9a323c2113e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92dab344-cea4-42e9-bfe5-953d972f2815
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6063b4a6-fc1a-4782-8252-42a2b1d97ea6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef7f015e-e574-4db9-bbc8-234bd15ca705
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7b9189d-3e8a-4763-b5f9-5b615a07d96c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05d4d6e1-8bd0-4de9-835c-899e2c66c9db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fff32a7d-9a43-45f2-b41d-7a1a3def8e7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f48db73a-8a2c-4c46-8c53-ce55b999e5b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45b54c30-1492-4f5b-9274-ad25b2823cc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8ac307f-c5ef-44c3-8184-8f54ad36eadf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f960ce5-38f7-4fdb-9bf3-f9658273bbef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 464c44d2-5b89-4a3e-930e-315286d915d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa8791b9-6588-4161-8d74-b4d02a3c2574
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9e0076a-c14c-4f85-8aa2-8b129ce8110f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f655568-d5c5-495b-a101-9c88c2461bad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3adcc67-5afb-4e6a-ab19-a9c9fa751943
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0219efb6-e1c4-4bbd-a9ce-822710b6c1da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8618e8e-7c93-4ccb-8989-4d69139e36b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ccaa11f-37b8-41e0-a590-00ecae391510
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 782fa29d-89c9-4ed2-af75-7cf23a2d1293
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30ca7b11-331e-4e80-9ef7-e27fd42c4edb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0eb9481c-332b-4107-aae2-72ed37474cb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e17a9b55-5398-4667-96d2-f82f82d4626b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20fce65d-86f8-464e-965d-bc387cf9adbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67aa94ed-db79-41bb-8b08-b019b4904cb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7ed8412-890e-4b2b-855b-80514557e906
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af9f5d25-2c91-46d2-a4dd-1476dd03ccc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 080ec6a6-41be-47cf-961d-0509d948b70e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4969435a-8fd2-4448-a1da-b09f256ee989
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96f2c04d-be49-4b2e-a87e-1124145ce7f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74eecbda-c966-4f77-b341-4f6be144436d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93526aca-24a7-4606-96eb-0ee0330c8178
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message abf3e6df-8c64-4435-bf9a-b5ba5455cb40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64689335-82cb-48cf-94c1-8f055eeafdf4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67a5ae8f-e3fc-4a9a-8131-e1e4ecb17d22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4cadbf92-9dcb-4eb4-be9d-fede4bc78527
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05527c88-e636-42d3-a4b0-fd5fd638fd30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 395649b8-f55c-405d-b5f7-708bd2ceda5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef6e5549-29e4-44c2-b11b-5e0cebfa9aa1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d28487b-feb2-4df9-b6c0-319af8f7739c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6972a9e-f81c-455b-b797-9d261e1ba9a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34cde8a1-7869-4b42-8346-3bded693f28d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31783865-a521-40fd-8ba8-a4af6a976fad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce83aa41-6db3-441b-bfe8-0091e3ad0740
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02dd1725-0972-4683-acbe-04b98105c0e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7bd292fe-bbee-4d0d-b0da-663778e58f0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bedbb934-d69f-4e17-bd52-fbae90e73e2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce037a6c-2509-4e5e-8a60-076b3d3cb4b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d59dcea-4d93-47cc-9247-eb76c7f01621
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 320b3e0d-67e1-49bd-a3c3-40e4f802b83a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 766106b3-9c5a-4ea1-a1c4-ab8a4cb2bd71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5c7d335-1fb2-41a5-83fb-4e2f90f9f41d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d012a72-923d-4544-9b90-50e856543ca2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e8a37a0-45c4-4499-be1f-48b8adc2f7ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 759f7926-a61f-46e7-b09c-f3c180fd03e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cebb0ae4-5eb8-4e21-a89a-304c85094077
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba1f555d-8101-41c9-a48e-14232a6cc4b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2b0f38f-cbfc-46f4-acc8-1fc8136a9dc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b92235f5-76df-4938-bfe1-281b747eca07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2fbd06c0-c7f8-46ab-8bd3-297812d52dc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a40baa38-acef-4c6f-9e6a-46a83793cc09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a34dc91a-adea-4034-ab25-fd3c4e6bb748
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f4aafe1-cccf-4b47-9e17-58810124a2f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f124433-1040-4576-99fb-99f01f5d45d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f2cf985-ca49-4e17-825f-1dd019e3c4ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 848b1d31-8ec0-4d41-9ccb-41e49189cb99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88c78c55-f0d5-4127-9193-987862395f61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d31426c-828e-4efd-ad1c-e00ecb5e9431
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf45ca0d-642f-4e45-847d-0e4c1470209c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4cf510ce-a267-4dd5-845a-b9fb456df8b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f970646-48a8-4e05-b173-7ef9db48a135
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3e1db66-a534-4219-abec-dbc86efb75f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98469795-7802-45f8-a7ea-aca7a116624a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1bcc5d01-e02f-4171-a6dc-e799227d2465
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4adc6700-8a56-4bf6-b055-ff54a5a044a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0dcc3c8b-9088-4cc4-89c1-51c76958be38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 543cf212-3fc7-4996-856e-69309825b128
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ab18ed8-5563-4090-86c6-9a6e6e8da470
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6d6a51b-9bde-4ed1-8af7-47461bf1d4e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b49f5b0-8876-4b88-8882-0ffbe2c5885f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eda44a87-e965-4329-bd39-256561a0fcf7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90a7148c-41b4-42ee-b636-d7f4ed8f0237
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8688 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_22
Server: localhost:8688
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_22
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_22/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_22/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_22/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_22/test_labels.txt

📊 Raw data loaded:
   Train: X=(3694, 24), y=(3694,)
   Test:  X=(924, 24), y=(924,)

⚠️  Limiting training data: 3694 → 800 samples
⚠️  Limiting test data: 924 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_22 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2435, R²: -0.0140

============================================================
🔄 Round 2 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0754 (↓), lr=0.001000
   • Epoch   2/100: train=0.0844, val=0.0750, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0839, val=0.0750, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0834, val=0.0753, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0831, val=0.0751, patience=4/15, lr=0.001000
   • Epoch  11/100: train=0.0819, val=0.0747, patience=2/15, lr=0.001000
   📉 Epoch 18: LR reduced 0.001000 → 0.000500
   • Epoch  21/100: train=0.0760, val=0.0783, patience=12/15, lr=0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 2 Summary - Client client_22
   Epochs: 24/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0131
   Val:   Loss=0.0748, RMSE=0.2736, R²=0.0046
============================================================


============================================================
🔄 Round 4 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0994, val=0.0886 (↓), lr=0.000500
   📉 Epoch 2: LR reduced 0.000500 → 0.000250
   • Epoch   2/100: train=0.0806, val=0.0885, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0794, val=0.0884, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0792, val=0.0884, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0791, val=0.0885, patience=4/15, lr=0.000250
   📉 Epoch 10: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0788, val=0.0887, patience=10/15, lr=0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 4 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000500 → 0.000125 (2 reductions)
   Train: Loss=0.0799, RMSE=0.2828, R²=-0.0077
   Val:   Loss=0.0886, RMSE=0.2977, R²=-0.0031
============================================================


📊 Round 4 Test Metrics:
   Loss: 0.0996, RMSE: 0.3156, MAE: 0.2637, R²: -0.2437

📊 Round 4 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2464, R²: -0.0532

============================================================
🔄 Round 9 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0799 (↓), lr=0.000125
   📉 Epoch 2: LR reduced 0.000125 → 0.000063
   • Epoch   2/100: train=0.0820, val=0.0795, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0811, val=0.0796, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0810, val=0.0796, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0809, val=0.0796, patience=4/15, lr=0.000063
   📉 Epoch 10: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0805, val=0.0799, patience=10/15, lr=0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 9 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000125 → 0.000031 (2 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0169
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0013
============================================================


============================================================
🔄 Round 10 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0832 (↓), lr=0.000031
   📉 Epoch 2: LR reduced 0.000031 → 0.000016
   ✓ Epoch   2/100: train=0.0827, val=0.0822 (↓), lr=0.000016
   • Epoch   3/100: train=0.0821, val=0.0819, patience=1/15, lr=0.000016
   ✓ Epoch   4/100: train=0.0818, val=0.0817 (↓), lr=0.000016
   • Epoch   5/100: train=0.0817, val=0.0815, patience=1/15, lr=0.000016
   📉 Epoch 10: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0810, val=0.0810, patience=3/15, lr=0.000008
   📉 Epoch 18: LR reduced 0.000008 → 0.000004
   • Epoch  21/100: train=0.0808, val=0.0809, patience=13/15, lr=0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 10 Summary - Client client_22
   Epochs: 23/100 (early stopped)
   LR: 0.000031 → 0.000004 (3 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0021
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0114
============================================================


📊 Round 10 Test Metrics:
   Loss: 0.0798, RMSE: 0.2826, MAE: 0.2410, R²: 0.0029

📊 Round 10 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2440, R²: -0.0281

============================================================
🔄 Round 12 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0898 (↓), lr=0.000004
   • Epoch   2/100: train=0.0803, val=0.0897, patience=1/15, lr=0.000004
   📉 Epoch 3: LR reduced 0.000004 → 0.000002
   • Epoch   3/100: train=0.0802, val=0.0896, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0802, val=0.0895, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0802, val=0.0895, patience=4/15, lr=0.000002
   📉 Epoch 11: LR reduced 0.000002 → 0.000001
   ✓ Epoch  11/100: train=0.0800, val=0.0892 (↓), lr=0.000001
   • Epoch  21/100: train=0.0799, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 12 Summary - Client client_22
   Epochs: 26/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0170
   Val:   Loss=0.0892, RMSE=0.2987, R²=0.0144
============================================================


============================================================
🔄 Round 13 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0791, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0834, val=0.0787, patience=8/15, lr=0.000001
   • Epoch  31/100: train=0.0832, val=0.0784, patience=3/15, lr=0.000001
   • Epoch  41/100: train=0.0830, val=0.0781, patience=13/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 13 Summary - Client client_22
   Epochs: 43/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0091
   Val:   Loss=0.0785, RMSE=0.2801, R²=-0.0611
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2439, R²: -0.0276

📊 Round 13 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2419, R²: -0.0066

📊 Round 13 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2409, R²: 0.0021

============================================================
🔄 Round 16 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 16 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=-0.0086
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0162
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2406, R²: 0.0047

============================================================
🔄 Round 19 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 19 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0107
   Val:   Loss=0.0759, RMSE=0.2754, R²=-0.0022
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0798, RMSE: 0.2824, MAE: 0.2405, R²: 0.0039

============================================================
🔄 Round 20 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0941 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0941, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0941, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0940, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0940, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0939, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0941)

============================================================
📊 Round 20 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=-0.0053
   Val:   Loss=0.0941, RMSE=0.3067, R²=-0.0311
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2405, R²: 0.0035

📊 Round 20 Test Metrics:
   Loss: 0.0798, RMSE: 0.2824, MAE: 0.2405, R²: 0.0037

============================================================
🔄 Round 24 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 24 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0118
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0020
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2405, R²: 0.0041

============================================================
🔄 Round 27 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0949 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0949, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0949, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0949, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0949, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0948, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0949)

============================================================
📊 Round 27 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=-0.0025
   Val:   Loss=0.0949, RMSE=0.3081, R²=-0.0285
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2405, R²: 0.0042

============================================================
🔄 Round 28 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 28 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0164
   Val:   Loss=0.0801, RMSE=0.2831, R²=0.0233
============================================================


============================================================
🔄 Round 29 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 29 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0225
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0452
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2405, R²: 0.0046

📊 Round 29 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2405, R²: 0.0047

============================================================
🔄 Round 33 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 33 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0063
   Val:   Loss=0.0836, RMSE=0.2892, R²=-0.0076
============================================================


============================================================
🔄 Round 34 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 34 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0010
   Val:   Loss=0.0789, RMSE=0.2808, R²=-0.0348
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2405, R²: 0.0049

============================================================
🔄 Round 37 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 37 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0034
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0293
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2405, R²: 0.0049

============================================================
🔄 Round 39 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 39 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0042
   Val:   Loss=0.0778, RMSE=0.2790, R²=-0.0060
============================================================


============================================================
🔄 Round 40 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 40 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0031
   Val:   Loss=0.0777, RMSE=0.2788, R²=-0.0081
============================================================


============================================================
🔄 Round 41 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 41 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0016
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0232
============================================================


============================================================
🔄 Round 43 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 43 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0017
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0104
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2406, R²: 0.0050

📊 Round 43 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2406, R²: 0.0050

============================================================
🔄 Round 50 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 50 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0083
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0196
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2406, R²: 0.0049

📊 Round 50 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2406, R²: 0.0049

============================================================
🔄 Round 55 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 55 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0035
   Val:   Loss=0.0801, RMSE=0.2831, R²=-0.0289
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2406, R²: 0.0049

📊 Round 55 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2406, R²: 0.0049

📊 Round 55 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2406, R²: 0.0049

============================================================
🔄 Round 61 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 61 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2863, R²=-0.0071
   Val:   Loss=0.0785, RMSE=0.2801, R²=0.0217
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2406, R²: 0.0049

📊 Round 61 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2406, R²: 0.0048

============================================================
🔄 Round 70 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 70 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=0.0008
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0173
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2406, R²: 0.0047

📊 Round 70 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2406, R²: 0.0047

============================================================
🔄 Round 74 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 74 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0004
   Val:   Loss=0.0863, RMSE=0.2937, R²=-0.0493
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2406, R²: 0.0047

============================================================
🔄 Round 76 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 76 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=-0.0022
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0057
============================================================


============================================================
🔄 Round 77 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 77 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0073
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0408
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2406, R²: 0.0047

📊 Round 77 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2406, R²: 0.0048

============================================================
🔄 Round 80 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 80 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0022
   Val:   Loss=0.0848, RMSE=0.2911, R²=-0.0042
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2406, R²: 0.0048

============================================================
🔄 Round 82 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 82 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0003
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0038
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2406, R²: 0.0048

============================================================
🔄 Round 83 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 83 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0112
   Val:   Loss=0.0852, RMSE=0.2919, R²=0.0367
============================================================


============================================================
🔄 Round 84 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 84 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=0.0055
   Val:   Loss=0.0906, RMSE=0.3010, R²=-0.0383
============================================================


============================================================
🔄 Round 85 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 85 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=-0.0024
   Val:   Loss=0.0788, RMSE=0.2808, R²=0.0056
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2406, R²: 0.0048

============================================================
🔄 Round 89 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 89 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0092
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0493
============================================================


============================================================
🔄 Round 90 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 90 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0012
   Val:   Loss=0.0766, RMSE=0.2768, R²=0.0034
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2406, R²: 0.0048

============================================================
🔄 Round 91 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 91 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0033
   Val:   Loss=0.0857, RMSE=0.2928, R²=0.0080
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2406, R²: 0.0048

============================================================
🔄 Round 92 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 92 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=-0.0109
   Val:   Loss=0.0882, RMSE=0.2970, R²=0.0304
============================================================


============================================================
🔄 Round 93 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 93 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0025
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0137
============================================================


============================================================
🔄 Round 95 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 95 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=-0.0069
   Val:   Loss=0.0800, RMSE=0.2829, R²=0.0259
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2406, R²: 0.0047

📊 Round 95 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2407, R²: 0.0047

📊 Round 95 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2407, R²: 0.0047

📊 Round 95 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2407, R²: 0.0047

============================================================
🔄 Round 100 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 100 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0034
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0140
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2407, R²: 0.0047

============================================================
🔄 Round 101 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 101 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0018
   Val:   Loss=0.0864, RMSE=0.2940, R²=0.0066
============================================================


============================================================
🔄 Round 103 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 103 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0046
   Val:   Loss=0.0766, RMSE=0.2767, R²=-0.0273
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2407, R²: 0.0047

📊 Round 103 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2407, R²: 0.0047

============================================================
🔄 Round 108 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 108 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0026
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0224
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2407, R²: 0.0047

📊 Round 108 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2407, R²: 0.0047

📊 Round 108 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2407, R²: 0.0047

============================================================
🔄 Round 112 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 112 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0031
   Val:   Loss=0.0864, RMSE=0.2940, R²=-0.0108
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2406, R²: 0.0047

📊 Round 112 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2406, R²: 0.0047

============================================================
🔄 Round 114 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 114 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=-0.0010
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0354
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2406, R²: 0.0048

📊 Round 114 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2406, R²: 0.0048

============================================================
🔄 Round 117 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 117 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=0.0020
   Val:   Loss=0.0901, RMSE=0.3002, R²=-0.0065
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2406, R²: 0.0048

============================================================
🔄 Round 118 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 118 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=-0.0067
   Val:   Loss=0.0870, RMSE=0.2950, R²=0.0248
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2406, R²: 0.0048

📊 Round 118 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2406, R²: 0.0048

============================================================
🔄 Round 121 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 121 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0046
   Val:   Loss=0.0736, RMSE=0.2712, R²=-0.0479
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2406, R²: 0.0048

============================================================
🔄 Round 122 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 122 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0010
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0032
============================================================


============================================================
🔄 Round 123 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 123 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0021
   Val:   Loss=0.0768, RMSE=0.2770, R²=-0.0077
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2406, R²: 0.0048

📊 Round 123 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2406, R²: 0.0048

============================================================
🔄 Round 127 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 127 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0024
   Val:   Loss=0.0791, RMSE=0.2812, R²=0.0102
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2406, R²: 0.0049

📊 Round 127 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2406, R²: 0.0049

📊 Round 127 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2406, R²: 0.0049

📊 Round 127 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2406, R²: 0.0049

============================================================
🔄 Round 133 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 133 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0039
   Val:   Loss=0.0767, RMSE=0.2769, R²=0.0174
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2406, R²: 0.0049

📊 Round 133 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2406, R²: 0.0049

📊 Round 133 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2406, R²: 0.0050

📊 Round 133 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2406, R²: 0.0050

============================================================
🔄 Round 138 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 138 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0001
   Val:   Loss=0.0788, RMSE=0.2806, R²=-0.0001
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2406, R²: 0.0050

============================================================
🔄 Round 141 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 141 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0020
   Val:   Loss=0.0791, RMSE=0.2812, R²=-0.0611
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2406, R²: 0.0051

📊 Round 141 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2406, R²: 0.0051

============================================================
🔄 Round 149 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 149 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0009
   Val:   Loss=0.0889, RMSE=0.2981, R²=-0.0028
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2406, R²: 0.0051

============================================================
🔄 Round 153 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 153 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0011
   Val:   Loss=0.0745, RMSE=0.2729, R²=0.0021
============================================================


============================================================
🔄 Round 154 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 154 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0046
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0171
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2406, R²: 0.0053

============================================================
🔄 Round 155 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 155 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0027
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0103
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2406, R²: 0.0053

📊 Round 155 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2406, R²: 0.0053

============================================================
🔄 Round 158 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 158 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0038
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0040
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2406, R²: 0.0054

============================================================
🔄 Round 162 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 162 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2820, R²=-0.0013
   Val:   Loss=0.0874, RMSE=0.2956, R²=0.0040
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2406, R²: 0.0054

============================================================
🔄 Round 165 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 165 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=-0.0066
   Val:   Loss=0.0889, RMSE=0.2982, R²=0.0236
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2406, R²: 0.0054

📊 Round 165 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2406, R²: 0.0054

📊 Round 165 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2406, R²: 0.0054

📊 Round 165 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2406, R²: 0.0054

============================================================
🔄 Round 169 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 169 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0001
   Val:   Loss=0.0836, RMSE=0.2892, R²=0.0006
============================================================


============================================================
🔄 Round 170 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 170 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0020
   Val:   Loss=0.0783, RMSE=0.2798, R²=-0.0097
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2406, R²: 0.0054

============================================================
🔄 Round 171 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 171 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0027
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0115
============================================================


============================================================
🔄 Round 172 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 172 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0000
   Val:   Loss=0.0770, RMSE=0.2776, R²=-0.0055
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2406, R²: 0.0054

============================================================
🔄 Round 175 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 175 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0019
   Val:   Loss=0.0779, RMSE=0.2791, R²=-0.0102
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2406, R²: 0.0054

📊 Round 175 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2406, R²: 0.0054

📊 Round 175 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2406, R²: 0.0054

📊 Round 175 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2406, R²: 0.0055

📊 Round 175 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2406, R²: 0.0055

📊 Round 175 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2406, R²: 0.0055

============================================================
🔄 Round 182 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 182 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2843, R²=0.0016
   Val:   Loss=0.0822, RMSE=0.2866, R²=-0.0050
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2406, R²: 0.0055

============================================================
🔄 Round 187 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 187 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0007
   Val:   Loss=0.0791, RMSE=0.2813, R²=-0.0004
============================================================


============================================================
🔄 Round 188 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 188 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0002
   Val:   Loss=0.0843, RMSE=0.2904, R²=0.0011
============================================================


============================================================
🔄 Round 189 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 189 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0074
   Val:   Loss=0.0770, RMSE=0.2775, R²=0.0244
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2406, R²: 0.0055

============================================================
🔄 Round 191 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 191 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0020
   Val:   Loss=0.0775, RMSE=0.2784, R²=-0.0112
============================================================


📊 Round 191 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2406, R²: 0.0055

============================================================
🔄 Round 194 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 194 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=0.0090
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0399
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2406, R²: 0.0055

============================================================
🔄 Round 198 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 198 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=0.0010
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0379
============================================================


============================================================
🔄 Round 200 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 200 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0010
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0061
============================================================


============================================================
🔄 Round 202 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 202 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0065
   Val:   Loss=0.0804, RMSE=0.2835, R²=0.0244
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2406, R²: 0.0056

📊 Round 202 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2406, R²: 0.0056

📊 Round 202 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2405, R²: 0.0057

📊 Round 202 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2405, R²: 0.0058

============================================================
🔄 Round 212 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 212 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0070
   Val:   Loss=0.0749, RMSE=0.2737, R²=-0.0302
============================================================


============================================================
🔄 Round 215 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 215 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=0.0029
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0126
============================================================


📊 Round 215 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2405, R²: 0.0059

============================================================
🔄 Round 217 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 217 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=-0.0008
   Val:   Loss=0.0797, RMSE=0.2824, R²=0.0045
============================================================


📊 Round 217 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2405, R²: 0.0059

============================================================
🔄 Round 221 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 221 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0015
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0368
============================================================


📊 Round 221 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2405, R²: 0.0059

📊 Round 221 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2405, R²: 0.0059

📊 Round 221 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2405, R²: 0.0059

============================================================
🔄 Round 228 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 228 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=-0.0052
   Val:   Loss=0.0861, RMSE=0.2935, R²=0.0204
============================================================


============================================================
🔄 Round 229 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 229 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0073
   Val:   Loss=0.0919, RMSE=0.3032, R²=-0.0756
============================================================


📊 Round 229 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2405, R²: 0.0060

📊 Round 229 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2405, R²: 0.0060

============================================================
🔄 Round 232 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 232 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0023
   Val:   Loss=0.0781, RMSE=0.2794, R²=-0.0087
============================================================


📊 Round 232 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2405, R²: 0.0060

============================================================
🔄 Round 233 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0950 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0949, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0949, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0949, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0949, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0949, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0950)

============================================================
📊 Round 233 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0018
   Val:   Loss=0.0950, RMSE=0.3081, R²=-0.0044
============================================================


============================================================
🔄 Round 234 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 234 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0022
   Val:   Loss=0.0775, RMSE=0.2784, R²=0.0085
============================================================


📊 Round 234 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2405, R²: 0.0059

============================================================
🔄 Round 235 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 235 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0038
   Val:   Loss=0.0848, RMSE=0.2913, R²=-0.0188
============================================================


📊 Round 235 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2405, R²: 0.0059

📊 Round 235 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2405, R²: 0.0059

============================================================
🔄 Round 239 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 239 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=-0.0005
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0051
============================================================


============================================================
🔄 Round 241 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 241 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2863, R²=-0.0048
   Val:   Loss=0.0777, RMSE=0.2788, R²=-0.0059
============================================================


📊 Round 241 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2405, R²: 0.0059

============================================================
🔄 Round 242 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 242 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0013
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0041
============================================================


📊 Round 242 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2405, R²: 0.0060

============================================================
🔄 Round 244 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 244 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0076
   Val:   Loss=0.0720, RMSE=0.2684, R²=0.0357
============================================================


📊 Round 244 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2405, R²: 0.0060

📊 Round 244 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2405, R²: 0.0059

📊 Round 244 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2405, R²: 0.0059

============================================================
🔄 Round 247 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 247 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0045
   Val:   Loss=0.0842, RMSE=0.2901, R²=-0.0202
============================================================


============================================================
🔄 Round 249 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0674 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0674, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0674, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0674, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0674, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0674, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0674)

============================================================
📊 Round 249 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0008
   Val:   Loss=0.0674, RMSE=0.2596, R²=0.0001
============================================================


📊 Round 249 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2405, R²: 0.0059

📊 Round 249 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2405, R²: 0.0060

📊 Round 249 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2405, R²: 0.0060

============================================================
🔄 Round 256 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 256 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0028
   Val:   Loss=0.0759, RMSE=0.2755, R²=-0.0185
============================================================


============================================================
🔄 Round 257 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 257 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=-0.0025
   Val:   Loss=0.0785, RMSE=0.2801, R²=0.0023
============================================================


📊 Round 257 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2405, R²: 0.0060

============================================================
🔄 Round 259 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 259 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0029
   Val:   Loss=0.0822, RMSE=0.2867, R²=0.0120
============================================================


📊 Round 259 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2405, R²: 0.0061

============================================================
🔄 Round 260 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 260 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=0.0048
   Val:   Loss=0.0830, RMSE=0.2880, R²=-0.0166
============================================================


============================================================
🔄 Round 261 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 261 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0013
   Val:   Loss=0.0724, RMSE=0.2690, R²=0.0053
============================================================


============================================================
🔄 Round 265 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 265 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0030
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0103
============================================================


📊 Round 265 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2405, R²: 0.0061

📊 Round 265 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2405, R²: 0.0061

============================================================
🔄 Round 269 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 269 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0005
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.0033
============================================================


============================================================
🔄 Round 270 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 270 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0006
   Val:   Loss=0.0802, RMSE=0.2833, R²=-0.0036
============================================================


============================================================
🔄 Round 271 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 271 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0033
   Val:   Loss=0.0828, RMSE=0.2878, R²=0.0140
============================================================


📊 Round 271 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2405, R²: 0.0062

============================================================
🔄 Round 272 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 272 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0006
   Val:   Loss=0.0721, RMSE=0.2684, R²=0.0050
============================================================


============================================================
🔄 Round 273 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 273 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0001
   Val:   Loss=0.0775, RMSE=0.2785, R²=0.0016
============================================================


📊 Round 273 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2405, R²: 0.0062

📊 Round 273 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2405, R²: 0.0062

📊 Round 273 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2405, R²: 0.0062

📊 Round 273 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2405, R²: 0.0062

============================================================
🔄 Round 278 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0679 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0679, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0679, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0679, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0679, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0679, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0679)

============================================================
📊 Round 278 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0001
   Val:   Loss=0.0679, RMSE=0.2606, R²=0.0027
============================================================


============================================================
🔄 Round 281 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 281 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=0.0068
   Val:   Loss=0.0829, RMSE=0.2880, R²=-0.0331
============================================================


📊 Round 281 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2405, R²: 0.0062

============================================================
🔄 Round 282 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 282 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0072
   Val:   Loss=0.0771, RMSE=0.2776, R²=0.0319
============================================================


============================================================
🔄 Round 283 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 283 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0043
   Val:   Loss=0.0817, RMSE=0.2859, R²=0.0190
============================================================


============================================================
🔄 Round 284 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 284 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=-0.0101
   Val:   Loss=0.0866, RMSE=0.2943, R²=0.0369
============================================================


📊 Round 284 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2405, R²: 0.0062

📊 Round 284 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2405, R²: 0.0062

============================================================
🔄 Round 286 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 286 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=-0.0112
   Val:   Loss=0.0749, RMSE=0.2736, R²=0.0392
============================================================


============================================================
🔄 Round 287 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 287 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0128
   Val:   Loss=0.0752, RMSE=0.2741, R²=0.0421
============================================================


📊 Round 287 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2405, R²: 0.0061

============================================================
🔄 Round 289 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0929 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0929, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0930, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0930, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0930, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0931, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 289 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0071
   Val:   Loss=0.0929, RMSE=0.3048, R²=-0.0645
============================================================


============================================================
🔄 Round 292 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 292 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0080
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0314
============================================================


============================================================
🔄 Round 294 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 294 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=-0.0037
   Val:   Loss=0.0829, RMSE=0.2880, R²=0.0169
============================================================


============================================================
🔄 Round 300 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 300 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0070
   Val:   Loss=0.0823, RMSE=0.2868, R²=-0.0162
============================================================


📊 Round 300 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2405, R²: 0.0064

============================================================
🔄 Round 301 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 301 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0065
   Val:   Loss=0.0814, RMSE=0.2854, R²=-0.0298
============================================================


📊 Round 301 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2405, R²: 0.0064

============================================================
🔄 Round 304 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0923, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 304 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0049
   Val:   Loss=0.0923, RMSE=0.3039, R²=-0.0166
============================================================


============================================================
🔄 Round 305 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 305 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0019
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0144
============================================================


📊 Round 305 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2405, R²: 0.0064

📊 Round 305 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2405, R²: 0.0065

📊 Round 305 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2405, R²: 0.0065

📊 Round 305 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2404, R²: 0.0065

📊 Round 305 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2405, R²: 0.0065

============================================================
🔄 Round 313 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 313 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0073
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0224
============================================================


📊 Round 313 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2404, R²: 0.0065

============================================================
🔄 Round 314 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 314 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0016
   Val:   Loss=0.0883, RMSE=0.2972, R²=-0.0042
============================================================


📊 Round 314 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2404, R²: 0.0065

============================================================
🔄 Round 315 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 315 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0024
   Val:   Loss=0.0770, RMSE=0.2775, R²=0.0123
============================================================


📊 Round 315 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2404, R²: 0.0065

============================================================
🔄 Round 319 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 319 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0054
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0211
============================================================


============================================================
🔄 Round 320 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 320 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0062
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0290
============================================================


============================================================
🔄 Round 321 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 321 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0036
   Val:   Loss=0.0911, RMSE=0.3019, R²=-0.0118
============================================================


============================================================
🔄 Round 322 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 322 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0001
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0198
============================================================


📊 Round 322 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2404, R²: 0.0066

============================================================
🔄 Round 324 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 324 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=-0.0033
   Val:   Loss=0.0874, RMSE=0.2956, R²=0.0132
============================================================


📊 Round 324 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2404, R²: 0.0066

============================================================
🔄 Round 325 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 325 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0023
   Val:   Loss=0.0791, RMSE=0.2812, R²=-0.0088
============================================================


📊 Round 325 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2404, R²: 0.0067

📊 Round 325 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2404, R²: 0.0067

============================================================
🔄 Round 331 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 331 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0082
   Val:   Loss=0.0813, RMSE=0.2852, R²=-0.0379
============================================================


📊 Round 331 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2404, R²: 0.0067

============================================================
🔄 Round 332 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 332 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0034
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0208
============================================================


📊 Round 332 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2404, R²: 0.0068

============================================================
🔄 Round 337 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 337 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0009
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0113
============================================================


📊 Round 337 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2404, R²: 0.0067

📊 Round 337 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2404, R²: 0.0067

============================================================
🔄 Round 341 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 341 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0034
   Val:   Loss=0.0776, RMSE=0.2785, R²=-0.0047
============================================================


📊 Round 341 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2404, R²: 0.0067

📊 Round 341 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2404, R²: 0.0066

📊 Round 341 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2404, R²: 0.0066

============================================================
🔄 Round 345 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 345 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0036
   Val:   Loss=0.0851, RMSE=0.2918, R²=0.0086
============================================================


📊 Round 345 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2404, R²: 0.0066

============================================================
🔄 Round 349 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 349 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=-0.0033
   Val:   Loss=0.0875, RMSE=0.2958, R²=0.0046
============================================================


📊 Round 349 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2404, R²: 0.0066

============================================================
🔄 Round 350 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 350 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0017
   Val:   Loss=0.0878, RMSE=0.2964, R²=-0.0090
============================================================


============================================================
🔄 Round 351 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 351 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0024
   Val:   Loss=0.0796, RMSE=0.2822, R²=-0.0124
============================================================


============================================================
🔄 Round 352 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 352 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0005
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0171
============================================================


📊 Round 352 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2404, R²: 0.0066

📊 Round 352 Test Metrics:
   Loss: 0.0796, RMSE: 0.2820, MAE: 0.2404, R²: 0.0066

============================================================
🔄 Round 356 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 356 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0104
   Val:   Loss=0.0873, RMSE=0.2954, R²=-0.0448
============================================================


============================================================
🔄 Round 357 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0955 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0955, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0955, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0955, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0955, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0955, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0955)

============================================================
📊 Round 357 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0067
   Val:   Loss=0.0955, RMSE=0.3090, R²=-0.0204
============================================================


📊 Round 357 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2405, R²: 0.0065

============================================================
🔄 Round 358 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 358 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0018
   Val:   Loss=0.0890, RMSE=0.2984, R²=-0.0035
============================================================


============================================================
🔄 Round 359 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0716 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0716, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0716, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0716, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0716, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0716, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0716)

============================================================
📊 Round 359 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=0.0017
   Val:   Loss=0.0716, RMSE=0.2677, R²=-0.0078
============================================================


============================================================
🔄 Round 363 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 363 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0032
   Val:   Loss=0.0810, RMSE=0.2847, R²=-0.0169
============================================================


============================================================
🔄 Round 365 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 365 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0012
   Val:   Loss=0.0782, RMSE=0.2797, R²=0.0069
============================================================


📊 Round 365 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2404, R²: 0.0065

============================================================
🔄 Round 368 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 368 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0055
   Val:   Loss=0.0846, RMSE=0.2908, R²=0.0222
============================================================


📊 Round 368 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2404, R²: 0.0066

📊 Round 368 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2404, R²: 0.0066

============================================================
🔄 Round 372 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 372 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0038
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0376
============================================================


============================================================
🔄 Round 373 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 373 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0062
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.0259
============================================================


📊 Round 373 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2404, R²: 0.0067

📊 Round 373 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2404, R²: 0.0067

============================================================
🔄 Round 376 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 376 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0058
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.0253
============================================================


============================================================
🔄 Round 377 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 377 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0046
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0117
============================================================


============================================================
🔄 Round 379 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 379 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0006
   Val:   Loss=0.0819, RMSE=0.2863, R²=-0.0079
============================================================


📊 Round 379 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2404, R²: 0.0067

📊 Round 379 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2404, R²: 0.0067

============================================================
🔄 Round 381 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 381 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0021
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0053
============================================================


📊 Round 381 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2404, R²: 0.0067

============================================================
🔄 Round 384 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 384 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=0.0018
   Val:   Loss=0.0915, RMSE=0.3026, R²=-0.0068
============================================================


📊 Round 384 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2404, R²: 0.0067

============================================================
🔄 Round 385 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 385 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0021
   Val:   Loss=0.0782, RMSE=0.2797, R²=0.0121
============================================================


============================================================
🔄 Round 386 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 386 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0040
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0382
============================================================


📊 Round 386 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2404, R²: 0.0067

============================================================
🔄 Round 387 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 387 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0038
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.0282
============================================================


📊 Round 387 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2404, R²: 0.0067

📊 Round 387 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2404, R²: 0.0068

============================================================
🔄 Round 391 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 391 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0058
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0247
============================================================


📊 Round 391 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2404, R²: 0.0068

📊 Round 391 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2404, R²: 0.0068

📊 Round 391 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2404, R²: 0.0068

============================================================
🔄 Round 395 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 395 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0021
   Val:   Loss=0.0783, RMSE=0.2798, R²=0.0084
============================================================


📊 Round 395 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2404, R²: 0.0068

============================================================
🔄 Round 398 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 398 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0011
   Val:   Loss=0.0783, RMSE=0.2798, R²=0.0069
============================================================


📊 Round 398 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2404, R²: 0.0068

📊 Round 398 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2404, R²: 0.0068

============================================================
🔄 Round 400 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 400 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0001
   Val:   Loss=0.0740, RMSE=0.2721, R²=-0.0063
============================================================


============================================================
🔄 Round 401 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 401 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=-0.0001
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0024
============================================================


============================================================
🔄 Round 403 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 403 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0024
   Val:   Loss=0.0792, RMSE=0.2815, R²=-0.0073
============================================================


📊 Round 403 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2404, R²: 0.0069

============================================================
🔄 Round 408 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 408 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0003
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0035
============================================================


📊 Round 408 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2404, R²: 0.0069

============================================================
🔄 Round 410 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 410 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0049
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0157
============================================================


============================================================
🔄 Round 412 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 412 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0055
   Val:   Loss=0.0789, RMSE=0.2809, R²=-0.0384
============================================================


📊 Round 412 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2404, R²: 0.0070

============================================================
🔄 Round 414 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 414 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0006
   Val:   Loss=0.0806, RMSE=0.2838, R²=-0.0001
============================================================


============================================================
🔄 Round 416 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 416 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0061
   Val:   Loss=0.0723, RMSE=0.2689, R²=-0.0280
============================================================


📊 Round 416 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2404, R²: 0.0071

============================================================
🔄 Round 417 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 417 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0016
   Val:   Loss=0.0868, RMSE=0.2945, R²=-0.0039
============================================================


📊 Round 417 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2404, R²: 0.0071

============================================================
🔄 Round 419 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 419 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0012
   Val:   Loss=0.0772, RMSE=0.2779, R²=0.0077
============================================================


============================================================
🔄 Round 422 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 422 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0019
   Val:   Loss=0.0724, RMSE=0.2690, R²=0.0109
============================================================


============================================================
🔄 Round 423 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 423 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0015
   Val:   Loss=0.0779, RMSE=0.2791, R²=0.0090
============================================================


============================================================
🔄 Round 425 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 425 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0021
   Val:   Loss=0.0743, RMSE=0.2725, R²=0.0067
============================================================


📊 Round 425 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2404, R²: 0.0071

============================================================
🔄 Round 426 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 426 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0016
   Val:   Loss=0.0785, RMSE=0.2803, R²=-0.0492
============================================================


📊 Round 426 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2404, R²: 0.0071

============================================================
🔄 Round 427 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 427 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2863, R²=-0.0089
   Val:   Loss=0.0777, RMSE=0.2787, R²=0.0076
============================================================


📊 Round 427 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2404, R²: 0.0071

============================================================
🔄 Round 429 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 429 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0049
   Val:   Loss=0.0835, RMSE=0.2890, R²=0.0205
============================================================


📊 Round 429 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2404, R²: 0.0072

============================================================
🔄 Round 435 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 435 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0070
   Val:   Loss=0.0740, RMSE=0.2720, R²=0.0293
============================================================


============================================================
🔄 Round 436 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 436 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0055
   Val:   Loss=0.0725, RMSE=0.2693, R²=-0.0000
============================================================


📊 Round 436 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2404, R²: 0.0071

============================================================
🔄 Round 437 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 437 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0010
   Val:   Loss=0.0814, RMSE=0.2852, R²=0.0069
============================================================


📊 Round 437 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2404, R²: 0.0072

📊 Round 437 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2404, R²: 0.0072

============================================================
🔄 Round 440 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 440 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0003
   Val:   Loss=0.0786, RMSE=0.2803, R²=0.0043
============================================================


📊 Round 440 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2404, R²: 0.0072

📊 Round 440 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2404, R²: 0.0072

============================================================
🔄 Round 442 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 442 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=0.0027
   Val:   Loss=0.0765, RMSE=0.2766, R²=-0.0120
============================================================


============================================================
🔄 Round 443 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 443 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0009
   Val:   Loss=0.0827, RMSE=0.2875, R²=-0.0013
============================================================


📊 Round 443 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2403, R²: 0.0072

📊 Round 443 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2403, R²: 0.0072

📊 Round 443 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2403, R²: 0.0073

📊 Round 443 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2403, R²: 0.0073

📊 Round 443 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2403, R²: 0.0073

============================================================
🔄 Round 450 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 450 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0075
   Val:   Loss=0.0762, RMSE=0.2760, R²=0.0318
============================================================


📊 Round 450 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2403, R²: 0.0073

============================================================
🔄 Round 455 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 455 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0018
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0095
============================================================


📊 Round 455 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2403, R²: 0.0074

📊 Round 455 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2403, R²: 0.0074

============================================================
🔄 Round 458 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 458 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2856, R²=-0.0014
   Val:   Loss=0.0793, RMSE=0.2817, R²=-0.0010
============================================================


============================================================
🔄 Round 462 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 462 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=-0.0004
   Val:   Loss=0.0765, RMSE=0.2766, R²=0.0020
============================================================


📊 Round 462 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2403, R²: 0.0074

📊 Round 462 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2403, R²: 0.0074

📊 Round 462 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2403, R²: 0.0074

============================================================
🔄 Round 465 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 465 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0003
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0037
============================================================


============================================================
🔄 Round 466 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 466 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0046
   Val:   Loss=0.0899, RMSE=0.2998, R²=-0.0145
============================================================


📊 Round 466 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2403, R²: 0.0074

============================================================
🔄 Round 469 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 469 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0028
   Val:   Loss=0.0775, RMSE=0.2784, R²=0.0139
============================================================


============================================================
🔄 Round 471 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 471 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0010
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0015
============================================================


📊 Round 471 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2403, R²: 0.0074

📊 Round 471 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2403, R²: 0.0074

📊 Round 471 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2403, R²: 0.0074

============================================================
🔄 Round 475 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 475 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0009
   Val:   Loss=0.0776, RMSE=0.2786, R²=-0.0033
============================================================


📊 Round 475 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2403, R²: 0.0075

============================================================
🔄 Round 477 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 477 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0027
   Val:   Loss=0.0807, RMSE=0.2840, R²=-0.0002
============================================================


📊 Round 477 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2403, R²: 0.0075

📊 Round 477 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2403, R²: 0.0075

============================================================
🔄 Round 480 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0699 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0699, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0699, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0699, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0699, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0699, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0699)

============================================================
📊 Round 480 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0009
   Val:   Loss=0.0699, RMSE=0.2644, R²=0.0034
============================================================


📊 Round 480 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2403, R²: 0.0075

============================================================
🔄 Round 482 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 482 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0005
   Val:   Loss=0.0836, RMSE=0.2892, R²=-0.0001
============================================================


📊 Round 482 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2403, R²: 0.0075

============================================================
🔄 Round 484 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 484 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=-0.0031
   Val:   Loss=0.0872, RMSE=0.2953, R²=0.0038
============================================================


📊 Round 484 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2403, R²: 0.0075

============================================================
🔄 Round 485 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 485 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0021
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0368
============================================================


============================================================
🔄 Round 487 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 487 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0065
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0255
============================================================


📊 Round 487 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2403, R²: 0.0075

============================================================
🔄 Round 488 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 488 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0026
   Val:   Loss=0.0768, RMSE=0.2771, R²=0.0105
============================================================


📊 Round 488 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2403, R²: 0.0075

📊 Round 488 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2403, R²: 0.0075

============================================================
🔄 Round 490 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 490 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0066
   Val:   Loss=0.0823, RMSE=0.2870, R²=-0.0245
============================================================


============================================================
🔄 Round 491 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 491 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0012
   Val:   Loss=0.0788, RMSE=0.2806, R²=0.0011
============================================================


============================================================
🔄 Round 493 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 493 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0063
   Val:   Loss=0.0745, RMSE=0.2729, R²=0.0279
============================================================


============================================================
🔄 Round 495 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 495 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0003
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0007
============================================================


📊 Round 495 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2403, R²: 0.0075

============================================================
🔄 Round 496 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 496 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0054
   Val:   Loss=0.0751, RMSE=0.2740, R²=0.0199
============================================================


📊 Round 496 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2403, R²: 0.0075

============================================================
🔄 Round 498 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 498 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0025
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0110
============================================================


📊 Round 498 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2403, R²: 0.0075

============================================================
🔄 Round 499 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 499 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0013
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0028
============================================================


📊 Round 499 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2403, R²: 0.0075

📊 Round 499 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2403, R²: 0.0075

============================================================
🔄 Round 503 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 503 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0029
   Val:   Loss=0.0834, RMSE=0.2888, R²=0.0133
============================================================


📊 Round 503 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2403, R²: 0.0076

============================================================
🔄 Round 507 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 507 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0107
   Val:   Loss=0.0842, RMSE=0.2901, R²=-0.0420
============================================================


📊 Round 507 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2403, R²: 0.0076

============================================================
🔄 Round 508 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 508 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0098
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0555
============================================================


============================================================
🔄 Round 510 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 510 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0046
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0345
============================================================


============================================================
🔄 Round 511 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 511 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0018
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0088
============================================================


============================================================
🔄 Round 512 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0704 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0704, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0704, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0704, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0704, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0705, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0704)

============================================================
📊 Round 512 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0105
   Val:   Loss=0.0704, RMSE=0.2653, R²=0.0302
============================================================


📊 Round 512 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2403, R²: 0.0076

📊 Round 512 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2403, R²: 0.0076

📊 Round 512 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2403, R²: 0.0076

============================================================
🔄 Round 516 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 516 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2813, R²=0.0082
   Val:   Loss=0.0889, RMSE=0.2981, R²=-0.0313
============================================================


📊 Round 516 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2403, R²: 0.0076

============================================================
🔄 Round 517 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0718, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 517 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0023
   Val:   Loss=0.0718, RMSE=0.2679, R²=0.0134
============================================================


📊 Round 517 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2403, R²: 0.0077

📊 Round 517 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2403, R²: 0.0076

📊 Round 517 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2403, R²: 0.0076

📊 Round 517 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2403, R²: 0.0076

📊 Round 517 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2403, R²: 0.0076

📊 Round 517 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2403, R²: 0.0076

📊 Round 517 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2403, R²: 0.0076

============================================================
🔄 Round 526 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 526 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0009
   Val:   Loss=0.0782, RMSE=0.2797, R²=-0.0070
============================================================


============================================================
🔄 Round 527 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 527 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0016
   Val:   Loss=0.0853, RMSE=0.2921, R²=0.0082
============================================================


============================================================
🔄 Round 528 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 528 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0065
   Val:   Loss=0.0790, RMSE=0.2810, R²=0.0291
============================================================


📊 Round 528 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2403, R²: 0.0076

📊 Round 528 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2403, R²: 0.0076

📊 Round 528 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2403, R²: 0.0076

📊 Round 528 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2403, R²: 0.0076

============================================================
🔄 Round 537 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 537 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0018
   Val:   Loss=0.0797, RMSE=0.2824, R²=-0.0047
============================================================


📊 Round 537 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2403, R²: 0.0075

============================================================
🔄 Round 538 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 538 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0020
   Val:   Loss=0.0819, RMSE=0.2861, R²=-0.0067
============================================================


📊 Round 538 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2403, R²: 0.0075

📊 Round 538 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2403, R²: 0.0075

============================================================
🔄 Round 541 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 541 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0004
   Val:   Loss=0.0861, RMSE=0.2934, R²=0.0009
============================================================


📊 Round 541 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2403, R²: 0.0075

📊 Round 541 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2403, R²: 0.0075

📊 Round 541 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2403, R²: 0.0075

📊 Round 541 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2403, R²: 0.0074

📊 Round 541 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2403, R²: 0.0074

📊 Round 541 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2403, R²: 0.0074

============================================================
🔄 Round 549 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 549 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0092
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0405
============================================================


📊 Round 549 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2403, R²: 0.0074

📊 Round 549 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2403, R²: 0.0074

📊 Round 549 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2403, R²: 0.0074

============================================================
🔄 Round 555 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 555 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0059
   Val:   Loss=0.0857, RMSE=0.2927, R²=0.0249
============================================================


📊 Round 555 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2403, R²: 0.0074

📊 Round 555 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2403, R²: 0.0075

============================================================
🔄 Round 558 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 558 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=-0.0055
   Val:   Loss=0.0796, RMSE=0.2822, R²=0.0111
============================================================


📊 Round 558 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2403, R²: 0.0075

============================================================
🔄 Round 562 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 562 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0020
   Val:   Loss=0.0875, RMSE=0.2957, R²=-0.0218
============================================================


📊 Round 562 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2403, R²: 0.0076

📊 Round 562 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2403, R²: 0.0076

📊 Round 562 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2403, R²: 0.0076

============================================================
🔄 Round 572 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 572 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0026
   Val:   Loss=0.0857, RMSE=0.2928, R²=0.0066
============================================================


📊 Round 572 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2403, R²: 0.0076

============================================================
🔄 Round 573 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 573 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0040
   Val:   Loss=0.0780, RMSE=0.2793, R²=0.0151
============================================================


============================================================
🔄 Round 576 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 576 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0088
   Val:   Loss=0.0733, RMSE=0.2708, R²=0.0308
============================================================


❌ Client client_22 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8688 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8688 {grpc_status:14, grpc_message:"Socket closed"}"
>
