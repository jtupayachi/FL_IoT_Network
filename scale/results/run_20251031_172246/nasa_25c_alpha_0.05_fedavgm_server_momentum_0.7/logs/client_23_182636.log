[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 711a5112-fc72-446a-a83f-3bd57ada514c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e7b0343-40df-4d0f-82f2-6f01a9b34138
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f18197e1-bd9e-447b-a717-d4514aa6a716
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d092f7c1-6074-4eba-aaf9-520e34f54584
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8038f2c7-2c30-4fc8-9094-8a21d96c9c55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82ed95ce-b849-4daa-94b8-acfcd8186885
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 458f1ed2-5459-48f9-81d4-57c8aa73a72f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message efb362d5-ed4d-4301-b51c-76756f58a5a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91e10450-bf28-4a5f-b3ee-588c21c69b64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1fbaf38d-6309-4b03-a1e7-cad509c1a478
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c592d790-90ed-4ffc-9809-5208d09863ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 178fb7f9-d609-41e2-9078-625767eb6372
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e2e9935-9eab-4dc8-9002-5f0712602e60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9c972ef-02c7-473b-bb15-a5d409dd5532
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51fb126a-494d-4d18-9728-82740fa57037
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be8cb857-f946-4c49-ae78-2e6b8f34f426
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message abb1c5a5-27f4-464b-bd9d-bef55f90240b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d201278-35b3-4c2d-aa49-352a35832061
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0dc533d2-9817-4e2a-8e91-5d04bbf30ebb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a19e8bea-1c9a-4b31-91dd-11159bb7ea1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1868296d-48e0-4181-8913-ebf1e891c1a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e8a7e50-3beb-4bbe-9b1e-750356614c27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0b014e0-1324-492c-b997-23decd4117d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a95f88f5-fbc7-43bf-9297-47cdc33d788a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8799765b-c1f5-4c2e-b878-dc885950ce5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42c8020a-8c20-4192-89eb-f9a53995f0b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d527fae-22dd-46bd-bb2f-7023d290ea0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96a2c387-4340-438f-9f21-1f078b76f305
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ee35bc6-60c8-4790-bcac-a411a7763bbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3210715a-cb33-445b-8c69-e401d16cb811
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04888cd7-6cf1-4c5e-b3b1-f4d2cffdad26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 069091b7-ec64-4844-b57b-d6afef2c8471
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1238dfdd-685c-4a27-9497-2db76a66ec36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2827c93-1143-4570-9efc-edc6903a244d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4fbfb15-5f4e-4276-8af7-63dc3ede4259
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3828eb1a-17e1-454a-a6a1-3a65a0fe0c91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b3bf3ca-812a-4c71-9128-001eb3de8a6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a56100f-ab70-41ff-80d8-3901cf7aab29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1fd45e35-a8cf-4bd5-a29c-36be6db21b06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 998c0202-515c-48a3-9bad-242fca2c9c31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f302e0c2-07d7-475b-84d2-62ee657ed368
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4561f410-7007-410a-9961-87d1475c55da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36b5e90f-46bb-4f2e-a2d3-ec507072bbbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f172eaf-a846-4294-a8dc-3a00abbce251
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e3aa011-e09a-409f-a58b-4c7b62fd33bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27c41c8a-1e73-49b9-8740-6f45683a6423
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4155b407-6d88-42b0-a494-19cb91b2bd6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf50f0ab-d923-4a2c-a678-d0ed5c1e512e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2dfffee4-b164-4206-9f61-80762bb8e2b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78aac37e-8482-4b63-b780-bb698415a220
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0e48d91-2f3d-411d-b6b7-0753722a9866
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d53b2be-977e-4e14-9248-209e4036405e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 327c0182-4a81-4dd4-85c1-d3bee68178d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a74df75-5f34-4e75-8708-4527f755a6fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ea668b0-5ffb-4ab4-8168-1603235611fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f211e45-767e-415a-8f98-ce78a801dca2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9c0054e-89c8-4612-8e1a-cfcea1faaa91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eee89458-55aa-432d-9142-1caf43e00e66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c93677c-ce55-4727-ac59-bdc8a33fdad3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8d5c5a7-2870-4fbf-9ec4-d8858cb83788
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6b57a60-bd26-485e-af3e-5d6d45aaa952
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4117d9ee-7426-4868-aaba-7baf22104412
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2cfeae7-4a57-413c-af16-d1b422220473
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 406684c6-65c6-4bff-934e-dcc3fe7e9ef0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c0fe524-92fa-41cb-a8c4-7a1a6a5dd798
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bbaaef92-1587-4e6b-acfc-584af15d04dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 627de513-19f7-45b8-8ff9-df51bb1228d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29a19162-e4ff-4d71-b360-e7f611ea08bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f54f9249-34a3-47c7-a5a5-1f226d3f9188
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d9daa63-defd-4207-a08b-9509f2b6fe6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2c2dc82-2b46-4929-81e3-bb2797377b65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2bd9962d-b556-442f-85b9-d8382fef5270
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dab9eb88-efb5-4b52-a674-efbd825f2d31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d8cd36f-179b-49c2-a9a7-6c837d713144
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eeafedf6-2d93-4fb4-929d-ab2c8fdce872
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4dd9102-5773-4877-bea5-ba0616dcb993
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2742838-6054-4f39-9f8c-6f9a72669f59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64ba943b-ca75-44f6-bcb6-fbb87b5a2878
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47b07cd6-bfc2-4425-bd9f-1d07e01d0ec0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4663682-084b-4ddd-a3d9-46607ecc51e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb9733e1-a686-4f3b-8ba5-4b316813abc1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ce087e9-f348-408b-aad3-b7e5295b7806
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e799d3d2-53d4-4185-89ac-71f7a441b301
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed42d329-6ec4-40eb-9acb-bc7858302d88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90db96d1-4cd3-4401-ac3a-123219a9ec51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15b64b63-21bc-4d83-9192-fdf8a43115fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b5316de-71f8-4427-8609-9bf67ac5d1dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 412458f4-c9c0-4191-a77c-7bb2216b54ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 765ad450-c2de-494e-b953-218448132f83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b26bb1cc-53f0-4a47-beaf-a615646208fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb58793f-a5e1-458d-b906-ec8900f7bb19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37216fb0-a11c-4875-9a90-051a2e076131
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3fad90fd-c0d7-4751-923b-e585f60e3ff8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64325ece-ec70-445a-8b09-c322808a4faa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 353e3121-b69e-412b-ab8e-2c3ee904f093
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23fe9058-5835-4810-85d5-035bf3c20d9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b7d4b51-8063-436d-8f17-66b045a75f0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 374e5d28-c201-49fa-87a6-37a3e2f4f6e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e11f5f6f-9511-4a70-a500-7a979d4c6b2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff2e9ba3-666e-48d2-847b-ebbd967c8147
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87ea15ab-d328-43c6-b0fa-f2bf76fac18f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c08eb56-a00a-491a-b63c-c07ed49a7c4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0cf947ea-26e4-4759-adc9-24338513c287
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60f6ce2e-f74f-4373-9db4-98427aaebf91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 776a56e8-eb4a-404a-ac1a-25cbbfa57cd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec1afc4c-0994-4d0f-a69b-5ee01bbf5ac2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4292b7fe-2a2e-49e1-b1e4-03298c7619d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0283a19a-9e84-4bbe-bc9d-3fa2285675a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a2bba1b-cf3e-45af-9f79-cc79334872d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1424c2a3-8230-49b5-a3a3-b8195b4f61a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a143d240-09a5-4ff9-b49c-4fffd59ad839
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a32dcaae-0c94-4a60-ab63-ac7a4c2ac502
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b8fdff3-41c7-4865-b7a4-660d270cea4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a3feced-d81d-483e-b3ab-168ffe8bcc83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ae78246-68eb-476f-9aff-0260eff1e22e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0376040-c3e1-4cff-b19c-68ded4bcb068
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7fcb4de7-c3e5-48d4-891a-c489173fa00e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31caa061-ffbf-4eb7-b9e0-655663b352c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b35b84f-95fc-40f3-9fbf-c55cfae42afb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc48a3fe-3834-4aa9-872e-1794e383ea34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8431f663-e844-477d-8628-3f7ccc0a38c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29891a20-1c78-47bf-8bd5-4de83bce3060
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0699b113-0080-4e39-8f13-ca563088fce3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58470056-2834-490b-bd0a-4ac53a3d7318
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02d781d5-9691-4511-9583-eb75e845919a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d1540bb-2dae-4272-96be-2cf174517a6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3bffc0f-1e1c-4c40-a01f-4afdd24b1c2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 757d5f05-1ba6-4af8-b35c-9bb56e7e46e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ef1ce47-8d35-4e64-9e70-ce32b5142a92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d29eccda-262a-4f51-9d63-edf0fd93d898
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c3ef388-bf12-4cce-a198-922f3ced766e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63f5bfd8-7b06-4654-a305-2adca218c079
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b249fc07-a7e9-4746-b8dc-7255a532461b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60a0a65c-040a-478a-9679-0b873b641989
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c533b1b-da8e-4d93-b554-3057d77e3a96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1978d1a-0a8d-4c62-851c-1a2df4ffb506
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d2d5e47-dd94-480b-bd3f-4fcd85a64c7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26f422f8-5e92-4a7b-8afe-bfc0d931bcb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89e66547-032c-4958-8fde-beeb16e263c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f6faeb4-0e35-4da4-ab9e-8ba609a3db1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message afe77ec8-16a2-46a1-94e8-0f4499a389bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35ad4802-7c79-4000-a43f-683ffd3bee5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d64f2414-c96b-4b89-be02-68191e0fa67a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a4b90eb-ed3d-40f2-818c-6c5156aca9cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a6d9fe3-23c9-4bad-bede-1439b07489bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21a57f12-9c81-4491-b311-ee1feedacb1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5404040a-82ca-47af-91c6-8f4125b64fc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9b64efa-4b94-4dd9-834d-c9ccc5953784
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 492ca164-bd71-415c-845d-68ddb71b78db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aec9fd03-22fd-47a1-8e89-aadad43bdef3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23c26f7b-599d-4b33-a1dc-2d0bcd6ffe48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 992a3cfb-cb28-4abd-9693-ac656b4d153a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6200043a-4336-41df-92e5-100f131e0d39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d04007f7-9305-4ea0-ba67-2b2ec9c8ed50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7234ebf9-1544-486d-b145-97d1b29ea3de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4c7e854-e073-4f65-a72c-eab6d63088ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73a54c91-5c52-4e58-8a52-2c3217de3428
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b45a2ceb-c8e4-4af8-b72d-63a28f64052c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa8fe4e3-9c3f-4e21-a2b6-1c6536062291
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1beeea6-39a2-4878-a43e-54ebfc19f2d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dcfb3393-180a-42eb-8f2a-a9fac8891ea4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2029f5e-7c74-45bd-a312-b09d748c4343
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a09b235b-8687-418e-b58e-7c45c9ed5a4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 881ce728-74f8-4f10-b3af-87e1b0912d66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6fb4aba9-4aab-41ec-9b33-9077089926dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35887cb8-56fb-41ed-94f8-96ffe14acb99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66645d2c-9ba1-4138-a0c3-f891fa658719
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0145bae4-7640-43b4-9167-b2145334b92e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cdc3b106-d1f4-493c-883f-c9c78073c3e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16b16b82-6fc5-4c30-b8a7-11a566b0d71a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ac80984-bf02-4288-ae77-c09362f73a1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dfbd8e5e-cf55-47cd-88cd-fa888283d0ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83be7255-c051-423b-9593-e214be192578
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d4455b2-c7f1-41b9-ab78-10ed554fc712
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e6621fb-ebc1-409c-a54b-60ae0d1813a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9e00fa1-2b2d-412f-a2bd-f98cf7cfb4bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f49a87d7-9e37-411f-881f-819202fdf9b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 343f2b69-f0e0-4ff3-bbe1-127460009869
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a341e0de-e473-4c98-8d52-7d1ced0da0d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9ccd92d-4f47-4d85-90b3-3589e67ed499
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02ad15d6-8ece-44b8-a3e3-77a12dae9768
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b109662b-1407-4f07-b109-f6c3bc15f7c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d345157-80cc-4402-a289-aadd29ef6ae8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a93c534-a3e6-4b03-8b51-dd8102c3bac8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea00afc6-aea5-4d9b-a013-a1dc27977b67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b78e2ce9-80fa-43f2-b028-5ad8c8c0a7ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f819102-3652-47db-98ad-a9d08a2aa362
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ef57f7a-5984-4b9e-a824-968e74da4b7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14cfd90e-fd4d-48c6-8bbc-13f16ac735d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca190c22-ea81-476b-ac8c-a0627ddb9537
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb504000-452a-4b11-ae6d-1cfeee04c3c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3232aa3-1642-4a8d-8551-ff9d77da506e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a52d9e0-bb90-4dc7-b24a-f3d5829e90df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d65bd37-5eba-4d37-9ae9-ac45f6ac4edc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ffe472a4-dd1f-463c-984d-732541344dfd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36c69067-7cfa-4191-952e-856bc44a5724
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62aa0e88-d19a-488d-9b19-a29c6f6a7a20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a2b5683-7d91-4f60-a447-a1f0dcf9ef91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26981df0-dd4b-48b0-a4f2-592523b43f62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab2ea05e-fcc3-45ce-9d02-60f273c50b26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 662920d7-2d27-40ac-93bf-b7d19883c0ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32b4e8dd-edc9-410d-ad1e-89e9d06a7064
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d541c61-2252-458d-ac5a-9e228de6657a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 838fa253-a14a-410d-a6e7-00d3c784d148
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b5acdcc-6126-4ae4-9f45-e3ef335c6c44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2f67f01-220c-436a-8a77-9b44ccd44725
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 773f80a2-6299-4c25-9587-8f990efa460a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9dc33022-4216-4864-a5ac-513622084765
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18d76669-d39d-4888-a9ca-adb9ca9e1f1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa83dbe4-7a73-4f13-866a-bd6fc39a873b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3bb6a09a-dfe4-4a2e-87d9-57dff8edeb7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a0b7a4f-0041-4b6c-93b2-ba7c7448f169
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41d4e75c-4bf4-4dcf-a44f-ab6a1ebc15e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e537776-cdf1-475e-98af-606da3096929
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76b17aff-5562-4f0d-add0-7c9647707b52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5dd36914-f0c7-4dbd-9a4b-0ba593ccc022
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76a7a19e-37b1-4d82-8b83-4a45811ad697
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd009d22-0972-4a61-898f-0445e094bb6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dbe14455-e0f6-4ff1-a1b4-ec0db80d0f23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b42642e-c006-4bdd-87f1-7e480cb015da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7097b358-3672-44b9-b32e-ff627e4b4348
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8fe61ae1-feb9-4e41-9c5b-77b3b48732fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2e3889e-c87e-4ce0-abb2-0c71a2585a70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b42ee3cc-2457-4432-8874-83835b330dae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c3e78ff-a56d-4c40-9dbe-e63017548c33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60f2b371-1c70-4b92-bd89-0509a55555a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0489e11-10bc-491f-978d-60417910f3bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59e0286f-a711-4b10-a831-fe7bed3a626c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 557783b2-db58-4960-82eb-2467b561e8d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75954b5f-af22-4ad2-8d3f-eb02c75a3ab7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7821ac1a-4233-4a81-8f07-c95312aa9fbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11a86f2f-10da-481a-8ef2-5cb77b00e444
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b63beb66-79b4-4b98-b8d1-80f80d9febd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d86ff1f5-828f-4de6-b709-6cfae949e4c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53e7552b-eda3-41f8-ad9c-24cdb0a89127
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ba3081b-5030-49ad-b66a-5b543bb05c60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 270134d0-4d31-4a89-ad13-a014b087dbec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45d45621-8418-491a-bfcc-d2f73c95db93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d10cf251-e5f6-4820-a4ee-1930eac7e713
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03721338-139f-47ca-bf7b-cf91bbe11e7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80d21f1c-2bf1-4666-ae9a-d1a89517e9ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2558e9b5-a255-4a28-8cfd-ae504ea3ecbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd84e8bd-af7c-42d6-a8df-13f21df1eb3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39941559-192a-4594-ad5d-a90bbb77b759
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd396d85-a00c-4b59-b090-1d1365a876b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2da12263-8c57-4022-ace4-35f09bdb758a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5780f9b-f170-4a37-8a4d-4f6ecd75b4ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97ba8015-0417-41b7-bfc7-c3274de15bad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19c1dbce-9d76-4bf5-b557-1d1d1538b0c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b48616eb-0880-49cf-a277-79a351f9fe05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7281772-f2d5-46c0-820c-2e74b553c075
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87c2e64d-66bd-4993-9717-40c84cec8eb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 345b00e0-3602-423e-b8c8-0ea895422366
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c3b5627-26a1-4c08-9626-4a5c0fdd3db7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1681cc71-97e5-4568-8a9d-ed55024d6ece
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2f1a5f0-8e33-40ac-b97b-3e3bead02940
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a29280fc-8b0d-4bb8-99ba-e4f13946057b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec828488-3ce0-4107-941d-b38959e9ae1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6bf306a4-f65c-464e-9c30-7e74f4970f3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8fba6a3-1d55-416b-ab27-5a65e66235bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33f08618-5a4a-475d-853d-41a139716f83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 244b502f-bcb0-44f3-90c6-22359b4519ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07abc27c-f5ae-4481-ab9a-daa9a571d2e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a551510-1f5d-456e-9ab9-e10e9af753c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d81e618-178f-441f-adf7-3706bbcb4bc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d14fb39f-6424-499a-a3b8-5b92be2c0458
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18cce247-8237-43bf-b04f-1e7b3a89ffaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08cd7b02-0ded-4a37-ac16-dbd41cec0c8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba85df58-21c5-4bdd-9a52-051bd5c33596
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52083535-eb61-4530-963d-3ed34da994be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2626f8e8-5b6c-4b14-80f8-a83bb7daba9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3cfa87c8-b1bb-4565-aab0-9ded764c0ef0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d9c698e-bd14-4ce4-9b71-41d236277178
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58c52aa9-c5f7-4701-9f72-914336d4993b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0df0bc1d-c8fc-4873-9cb4-e5410fb78e58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2047bc3c-94d3-408a-baef-0c4b448f4225
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 834224b4-eae1-4eb0-8e8b-ac6a63b12519
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3492d5f-8739-47b8-b42b-b828071debd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec5cdffb-cdda-4048-af15-550ad6c743c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81912dc5-8bda-42da-931f-7c2e5508dbab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98928fbb-c725-4a3d-928e-fc3306c681ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 613be530-d725-4f16-9b39-d973bfa0316c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a8ee63f-cae3-4464-a995-ac4f6c6e847b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a5b8c8c-c86a-4ad4-8d9e-943347d9b206
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41b4f9ff-23d8-4e47-bee9-a9f1903472ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b05d46b-44cf-4649-b5cd-8f7679dedff4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad0c8393-ff4f-4907-bb47-0f35d147d32b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed794ff3-9fd8-41de-af01-f782c7c4cc72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1989904-4ca4-4b67-8370-a5565be74d75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8afe6177-899f-41f0-b098-2db730e946fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1198f5c7-93e6-4b79-81a3-62e731095810
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c78b5aae-b2a7-4419-95ef-cef854b663cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4c48d37-8f1b-4307-824c-be20f4ed8bb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54869d0f-a5aa-4200-b826-7365d4aa09c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad2865c1-1644-487d-b4a5-1ac632e82ed1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10ba9b16-77e3-43b2-94db-5523711d6635
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6714b6da-14a4-4f88-8fc1-54056ab199df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39d6b316-c8d4-4de2-b69f-a8cbb52276fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35491d3a-09e9-4e07-99db-db8f9ac55a07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ced16b99-b458-43c1-b385-ee92d68f0f31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab14e062-4cb1-428f-8628-b0ec4a793f4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0699ec21-2d38-458c-a0e4-e9cf699363d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e65810f-0613-45d5-af05-f8fae3d374e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 497f5692-a8f6-45ba-af2b-1d2a050b55a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2037f6d-1eae-44a2-be41-26d9360906d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d28725e-6d16-44e7-b5ae-54ba31090e70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80dd70f4-14c8-4a66-a853-a543dfe6ede1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3097bd0e-0f60-4538-a1ca-3a3297bf90f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 179cdd7b-16e5-40bf-8450-349956e041d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b15d9c97-66ae-4e76-844e-0acd7b7c7737
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a885265f-0122-42db-9f4f-056a4b1d9507
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2f2eaf2-43ec-4bf1-b3a9-0de585cc6f12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 790b84d9-f33e-4dff-b96b-b2b4b49b150a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa101500-c981-46f5-92d9-4928f35b8c4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb48907a-22cb-445f-a7b4-364fc83d1da2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ad1318e-837a-4ef1-8a7c-a700008e8617
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 155860be-cbfd-46b3-8eea-c21f022120e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a729244d-c081-4a28-8977-b5d0b568f9e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 421e6e60-38e3-438f-88f1-368f3b09136a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6d06230-fe3b-4988-a233-6bddb3c9fe68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7c3350e-9f4c-420a-bb65-d8e1bc588cbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d28a0786-292e-4e37-8a32-0f02b0557dbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30d0071d-dc64-4d35-898f-e2ee32040acd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33310f62-b940-4cbe-aeef-a7a042a0977e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98588d56-07ec-4b11-be16-273451a9cac0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd8618b8-a408-4077-8095-8f9fe62861e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dedbb4df-35a3-4fdd-8982-54f1f6d128a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 309f2042-bf32-4785-953a-f2d1c482e5eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4bf7fe9d-ccc1-4ad7-b22f-1b649c053dae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73d90f62-19bd-4936-90f8-9272998992c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e5b8ea7-4dda-4069-a0c6-5e5f31882e7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ccf3bfc6-3772-4070-bdc7-ca2cfe9c98d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 101b7085-0945-49a0-af47-a86252137128
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4b820c1-567f-4a3d-8c7e-5f39dfa7e336
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d060fac-d16c-499f-93d9-9bbae899aaef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06f2f002-80d3-49c0-8fc4-0d77d096437c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8993ea70-a454-49df-8184-a483d0c41666
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88aa2dac-ee0f-41c9-a594-2ae02a02283c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4bb9af03-3cab-4dd5-bdff-93a351c2afdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40b2c43e-d5e2-4d53-b5b7-54473ba17c41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd568531-824e-4eaa-8e49-ff4ec30492ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44e60c97-5d73-4766-83cd-97e1c701606f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a0b7bee-fc28-4c91-b331-0e4b2f5b132a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80e163fd-492e-4a44-bcca-f317c7c81763
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a6cd7aa-a861-4fd8-905e-6156b390e6b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dea6a9cc-7cc6-4f15-b266-57f9804c68af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c08223ec-ccd4-478a-8917-7c61c6fc261d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ccc60ee3-32bc-4f1a-845b-dc88a88beb89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e7281f9-e762-4f2f-b0ac-f051ad3d97e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1579e6b3-cabd-4871-be7b-a3d3bc1c072b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9bb52fc-aee6-4313-8205-3e0a08f61780
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a0a145c-bfa2-4dd6-a637-987519f59ca2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b5114a0-18dd-4bd9-895c-369c5a65d23a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9fad7634-c060-4237-89a8-cd66338c1eaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7892338a-5e8a-4ae5-89a6-e6fe77ae7a53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ebc1a18-b761-4c35-a50e-ecbe3b74cb1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6297f20f-58fd-4036-9187-5c991d3fb999
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e68c484-f847-44a0-be9f-328827526f26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95f4a9a1-2b02-4c96-9a33-1db3bb58bee5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7de8c43-8e9d-437a-b39a-323d7722390a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message abdf4b56-c144-49b4-aa52-d49755655e84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46b98ea6-564f-4751-8898-923feaa28ac5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfe4945d-7cdc-4aec-8262-488c2d79f03a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d4a560b-a66f-4040-95fb-2d7b8b46682c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00a53fe9-d226-4385-91fe-5a1db1c55648
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d226f97-5cbc-482b-b1d5-1f572380dc9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd753eb1-0354-4cdc-a1d0-ddadf920c7cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8558c60-a099-43f5-8dcc-08630e243b05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55ec246a-b060-4b31-87d3-2654204e44f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8a63a59-88a6-4d2d-8527-4cb3d1977757
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bbb4f282-5101-4fce-ade5-a472423f795c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 012ade63-4f1b-4fd6-8f86-9054bb967e54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 831bcf9c-a3b9-45ad-9e0f-252af346867d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00984445-a2ea-43bd-990b-599de8ba43a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33c76bfd-3881-45fc-9ce4-806ac2137b8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4865d783-4373-439e-b5b5-49a132f258bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60aabbe2-7084-40e2-8836-bf22de208605
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 624f3038-4234-4ea5-9930-4ea4cb705805
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4b2eb9a-6eb5-44a8-bf06-61b7deb77d5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 905ae722-e6cf-4a39-9ee9-e5bfab7bd28a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c442663-2e6e-4ffb-9312-e37c55905db5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58f334aa-ba29-4fc7-b08e-27fb968df627
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9280011-3022-4074-b0bf-dccaff763439
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97de7b07-3765-4f4a-9dda-efe12b7cea24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3294c8c6-4205-422f-a5e4-234e8bf943b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cbba2e4e-1896-48d4-a7b3-0153b4b89109
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05bfd6d8-463c-4240-9f61-78f832bc3933
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ca255f2-c3e3-4da4-9f05-5ed75875f102
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05ea1f2a-ac76-489b-b25c-9ed3052dd9b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d61c3447-e7ab-4367-992a-4c854badb239
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 942d6a52-1138-42f5-9205-300a836b61ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80b9131f-6ddf-47e3-92f5-33ee66b7abc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc3892af-31bc-41ca-9309-4c7f13a2e233
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 642c1735-17c6-4f6b-b462-aa7a541f0939
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc5126da-b3ae-4326-afd8-8489b5e67973
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 961ed60c-2e25-4db7-8193-52b1cd4da923
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ddc20699-e08a-4d21-b9fd-ad030134a912
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d37a0c3-7b9d-4059-9781-4fda3e14ff7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41e415e6-4105-42d0-9fdc-0d755b446747
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92522f80-cbd8-456c-b843-c0bc94a8e8db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 156c8243-d015-4c30-aaf8-e33b7e6b4a03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e38e039f-52dd-48f2-bcad-57c22a43f152
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d77d33e-9d06-4ab1-9e60-8b675f0a37dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f12e5d6-48db-444a-9dd9-1ef0a3b8d5b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 375bf7cc-f25c-4844-a594-707da779d529
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eafcda1c-2ff3-40ea-b16c-c57b6188a8e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9ae9f08-088a-47a4-96ad-98bc85419ecc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13a6907f-8a50-4a42-a563-d7a75bbe1102
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31e670df-2f28-4346-904e-d1d4bb7a0258
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cac17665-8726-4729-87dc-0630afd8ae1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd5b751e-895e-48dc-88e2-02da415027d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48633127-34c6-47e9-a042-cbcc7ea30123
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3e39e57-88cc-40b7-b000-444778190358
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1ad024d-ac8d-4a67-91cb-d3568b72bde3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aea7e110-e48e-4cd8-9a11-e0bec58dfa99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa75ba2f-2322-4466-8add-3a49ed4902a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22afc9ae-9421-4c6f-8792-4de5d31b2b3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa9a8cf1-623f-4eb6-a1fc-e1205d245eba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3e9ab9c-3444-4844-984c-e4ffe580484c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c062359-4fff-4bc8-987a-07ad62151f30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a81ebd21-b874-4c0e-b94f-441189a071c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4edcad2-cdd6-4744-a329-619385d5e473
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8acd3624-7f40-4b56-839c-cd56f9a1d625
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44e31d01-57d3-4f35-99f1-7b00ae9734c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 217f8435-1f39-4b3b-a839-07fd75f8f523
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e0de593-00ce-421d-855a-8255bcaf75df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf662b34-5415-4e6f-bc14-8f5ea9918499
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4e37e1b-2a37-4257-aba0-dab9f0296deb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e4f920f-2b0a-4b43-8680-c0f48e495dce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0971ea8a-8d89-4b40-ad64-4ffa193a172f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aee42708-3d3f-4592-a3ca-414f50b24563
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67ea33f0-b61b-46a9-9145-03a95f6523b2
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8688 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_23
Server: localhost:8688
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_23
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_23/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_23/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_23/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_23/test_labels.txt

📊 Raw data loaded:
   Train: X=(7224, 24), y=(7224,)
   Test:  X=(1806, 24), y=(1806,)

⚠️  Limiting training data: 7224 → 800 samples
⚠️  Limiting test data: 1806 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_23 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2437, R²: -0.0028

============================================================
🔄 Round 4 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0978, val=0.0850 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0844, val=0.0828 (↓), lr=0.001000
   • Epoch   3/100: train=0.0840, val=0.0830, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0838, val=0.0832, patience=2/15, lr=0.001000
   • Epoch   5/100: train=0.0837, val=0.0831, patience=3/15, lr=0.001000
   📉 Epoch 8: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0830, val=0.0832, patience=9/15, lr=0.000500
   📉 Epoch 16: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 4 Summary - Client client_23
   Epochs: 17/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0052
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0244
============================================================


============================================================
🔄 Round 13 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0915 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0822, val=0.0910 (↓), lr=0.000250
   ✓ Epoch   3/100: train=0.0819, val=0.0900 (↓), lr=0.000250
   • Epoch   4/100: train=0.0817, val=0.0902, patience=1/15, lr=0.000250
   • Epoch   5/100: train=0.0816, val=0.0902, patience=2/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0809, val=0.0901, patience=8/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 13 Summary - Client client_23
   Epochs: 18/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=0.0030
   Val:   Loss=0.0900, RMSE=0.3001, R²=-0.0313
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2440, R²: -0.0175

============================================================
🔄 Round 14 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0903 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.0830, val=0.0894 (↓), lr=0.000063
   • Epoch   3/100: train=0.0827, val=0.0891, patience=1/15, lr=0.000063
   • Epoch   4/100: train=0.0825, val=0.0890, patience=2/15, lr=0.000063
   📉 Epoch 5: LR reduced 0.000063 → 0.000031
   • Epoch   5/100: train=0.0825, val=0.0890, patience=3/15, lr=0.000031
   • Epoch  11/100: train=0.0822, val=0.0890, patience=9/15, lr=0.000031
   📉 Epoch 13: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 14 Summary - Client client_23
   Epochs: 17/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0044
   Val:   Loss=0.0894, RMSE=0.2991, R²=-0.0002
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2432, R²: -0.0045

📊 Round 14 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2433, R²: -0.0014

============================================================
🔄 Round 16 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0844 (↓), lr=0.000016
   • Epoch   2/100: train=0.0838, val=0.0844, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0838, val=0.0845, patience=2/15, lr=0.000016
   📉 Epoch 4: LR reduced 0.000016 → 0.000008
   • Epoch   4/100: train=0.0838, val=0.0846, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0837, val=0.0846, patience=4/15, lr=0.000008
   • Epoch  11/100: train=0.0836, val=0.0847, patience=10/15, lr=0.000008
   📉 Epoch 12: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 16 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0014
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0097
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2442, R²: -0.0048

============================================================
🔄 Round 18 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0861 (↓), lr=0.000004
   • Epoch   2/100: train=0.0834, val=0.0861, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0833, val=0.0861, patience=2/15, lr=0.000004
   📉 Epoch 4: LR reduced 0.000004 → 0.000002
   • Epoch   4/100: train=0.0833, val=0.0862, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0833, val=0.0862, patience=4/15, lr=0.000002
   • Epoch  11/100: train=0.0832, val=0.0862, patience=10/15, lr=0.000002
   📉 Epoch 12: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 18 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0133
   Val:   Loss=0.0861, RMSE=0.2935, R²=0.0221
============================================================


============================================================
🔄 Round 19 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 19 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0057
   Val:   Loss=0.0772, RMSE=0.2778, R²=-0.0059
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2448, R²: -0.0081

============================================================
🔄 Round 22 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 22 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0053
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0176
============================================================


============================================================
🔄 Round 23 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 23 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0066
   Val:   Loss=0.0898, RMSE=0.2996, R²=-0.0189
============================================================


============================================================
🔄 Round 24 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 24 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=-0.0054
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0137
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2446, R²: -0.0070

📊 Round 24 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2445, R²: -0.0067

============================================================
🔄 Round 27 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0687 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0687, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0687, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0687, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0686, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0686, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0687)

============================================================
📊 Round 27 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2968, R²=-0.0105
   Val:   Loss=0.0687, RMSE=0.2621, R²=0.0151
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2444, R²: -0.0060

📊 Round 27 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2442, R²: -0.0047

📊 Round 27 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2441, R²: -0.0040

📊 Round 27 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2441, R²: -0.0037

============================================================
🔄 Round 34 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 34 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0037
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0151
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2440, R²: -0.0032

============================================================
🔄 Round 37 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 37 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0055
   Val:   Loss=0.0912, RMSE=0.3021, R²=-0.0043
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2440, R²: -0.0028

📊 Round 37 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2439, R²: -0.0026

============================================================
🔄 Round 40 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 40 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2892, R²=-0.0040
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0001
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2439, R²: -0.0022

============================================================
🔄 Round 42 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 42 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0104
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0180
============================================================


============================================================
🔄 Round 43 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.1031 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.1031, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.1031, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.1031, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.1031, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.1032, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1031)

============================================================
📊 Round 43 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=-0.0065
   Val:   Loss=0.1031, RMSE=0.3211, R²=-0.0030
============================================================


============================================================
🔄 Round 44 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 44 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0036
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0005
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2438, R²: -0.0014

============================================================
🔄 Round 46 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 46 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=-0.0004
   Val:   Loss=0.0757, RMSE=0.2752, R²=-0.0276
============================================================


============================================================
🔄 Round 47 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 47 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0067
   Val:   Loss=0.0856, RMSE=0.2925, R²=0.0133
============================================================


============================================================
🔄 Round 48 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0718, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 48 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0059
   Val:   Loss=0.0718, RMSE=0.2679, R²=0.0075
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2437, R²: -0.0010

============================================================
🔄 Round 51 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 51 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0035
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0019
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2437, R²: -0.0008

============================================================
🔄 Round 52 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 52 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0085
   Val:   Loss=0.0847, RMSE=0.2910, R²=0.0218
============================================================


============================================================
🔄 Round 53 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 53 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0061
   Val:   Loss=0.0737, RMSE=0.2715, R²=0.0069
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2436, R²: -0.0006

📊 Round 53 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2436, R²: -0.0005

============================================================
🔄 Round 58 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 58 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0060
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0348
============================================================


============================================================
🔄 Round 59 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 59 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=0.0018
   Val:   Loss=0.0816, RMSE=0.2856, R²=-0.0248
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2436, R²: -0.0001

============================================================
🔄 Round 61 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 61 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0024
   Val:   Loss=0.0811, RMSE=0.2847, R²=-0.0215
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2435, R²: -0.0000

============================================================
🔄 Round 63 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 63 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0024
   Val:   Loss=0.0914, RMSE=0.3024, R²=-0.0020
============================================================


============================================================
🔄 Round 65 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 65 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0015
   Val:   Loss=0.0860, RMSE=0.2932, R²=-0.0193
============================================================


============================================================
🔄 Round 66 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 66 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=-0.0001
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0128
============================================================


============================================================
🔄 Round 67 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 67 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0048
   Val:   Loss=0.0812, RMSE=0.2850, R²=0.0096
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2435, R²: 0.0005

============================================================
🔄 Round 71 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 71 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0030
   Val:   Loss=0.0885, RMSE=0.2976, R²=-0.0287
============================================================


============================================================
🔄 Round 73 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 73 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=0.0035
   Val:   Loss=0.0764, RMSE=0.2764, R²=-0.0256
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2434, R²: 0.0006

📊 Round 73 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2434, R²: 0.0007

📊 Round 73 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2434, R²: 0.0008

============================================================
🔄 Round 79 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 79 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0152
   Val:   Loss=0.0819, RMSE=0.2861, R²=0.0292
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2434, R²: 0.0008

📊 Round 79 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2434, R²: 0.0009

============================================================
🔄 Round 83 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 83 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0116
   Val:   Loss=0.0832, RMSE=0.2884, R²=0.0366
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2434, R²: 0.0010

📊 Round 83 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2434, R²: 0.0010

📊 Round 83 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2434, R²: 0.0010

📊 Round 83 Test Metrics:
   Loss: 0.0815, RMSE: 0.2856, MAE: 0.2434, R²: 0.0010

============================================================
🔄 Round 90 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 90 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0030
   Val:   Loss=0.0913, RMSE=0.3021, R²=-0.0183
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0815, RMSE: 0.2856, MAE: 0.2434, R²: 0.0012

📊 Round 90 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2434, R²: 0.0012

📊 Round 90 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2433, R²: 0.0013

============================================================
🔄 Round 96 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 96 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0053
   Val:   Loss=0.0749, RMSE=0.2736, R²=0.0099
============================================================


============================================================
🔄 Round 97 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 97 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=0.0008
   Val:   Loss=0.0766, RMSE=0.2768, R²=-0.0119
============================================================


============================================================
🔄 Round 98 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 98 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0016
   Val:   Loss=0.0882, RMSE=0.2969, R²=-0.0022
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2433, R²: 0.0014

============================================================
🔄 Round 99 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 99 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0039
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0226
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2433, R²: 0.0015

📊 Round 99 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2433, R²: 0.0016

============================================================
🔄 Round 106 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 106 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0029
   Val:   Loss=0.0802, RMSE=0.2831, R²=0.0047
============================================================


============================================================
🔄 Round 108 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 108 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=-0.0005
   Val:   Loss=0.0829, RMSE=0.2878, R²=-0.0056
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2433, R²: 0.0017

============================================================
🔄 Round 109 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0934 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0934, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0934, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0934, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0934, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0934, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0934)

============================================================
📊 Round 109 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0062
   Val:   Loss=0.0934, RMSE=0.3055, R²=-0.0316
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2433, R²: 0.0018

============================================================
🔄 Round 112 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 112 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=0.0013
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0360
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2433, R²: 0.0018

============================================================
🔄 Round 115 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 115 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0006
   Val:   Loss=0.0811, RMSE=0.2847, R²=-0.0049
============================================================


============================================================
🔄 Round 116 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 116 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0058
   Val:   Loss=0.0771, RMSE=0.2776, R²=0.0016
============================================================


============================================================
🔄 Round 118 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 118 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0052
   Val:   Loss=0.0889, RMSE=0.2982, R²=-0.0032
============================================================


============================================================
🔄 Round 119 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 119 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0034
   Val:   Loss=0.0920, RMSE=0.3033, R²=-0.0199
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2433, R²: 0.0020

📊 Round 119 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2432, R²: 0.0020

============================================================
🔄 Round 123 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 123 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0015
   Val:   Loss=0.0885, RMSE=0.2974, R²=-0.0042
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2432, R²: 0.0020

📊 Round 123 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2432, R²: 0.0020

📊 Round 123 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2432, R²: 0.0021

============================================================
🔄 Round 126 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 126 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0030
   Val:   Loss=0.0868, RMSE=0.2946, R²=0.0033
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2432, R²: 0.0021

📊 Round 126 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2432, R²: 0.0021

============================================================
🔄 Round 130 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 130 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0034
   Val:   Loss=0.0763, RMSE=0.2762, R²=-0.0002
============================================================


============================================================
🔄 Round 131 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 131 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0010
   Val:   Loss=0.0831, RMSE=0.2882, R²=-0.0127
============================================================


============================================================
🔄 Round 134 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 134 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=-0.0020
   Val:   Loss=0.0825, RMSE=0.2873, R²=0.0004
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2432, R²: 0.0022

📊 Round 134 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2432, R²: 0.0023

📊 Round 134 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2432, R²: 0.0023

============================================================
🔄 Round 139 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 139 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0063
   Val:   Loss=0.0879, RMSE=0.2966, R²=0.0164
============================================================


============================================================
🔄 Round 140 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 140 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=-0.0026
   Val:   Loss=0.0829, RMSE=0.2878, R²=0.0030
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2432, R²: 0.0023

============================================================
🔄 Round 142 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0708 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0708, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0708, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0708, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0708, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0708, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0708)

============================================================
📊 Round 142 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2950, R²=0.0003
   Val:   Loss=0.0708, RMSE=0.2662, R²=-0.0125
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2432, R²: 0.0024

📊 Round 142 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2432, R²: 0.0024

📊 Round 142 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2432, R²: 0.0024

============================================================
🔄 Round 147 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 147 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0078
   Val:   Loss=0.0791, RMSE=0.2813, R²=-0.0724
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2432, R²: 0.0025

📊 Round 147 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2432, R²: 0.0025

📊 Round 147 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2432, R²: 0.0025

============================================================
🔄 Round 153 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 153 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0005
   Val:   Loss=0.0822, RMSE=0.2866, R²=-0.0124
============================================================


============================================================
🔄 Round 154 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 154 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0008
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0112
============================================================


============================================================
🔄 Round 155 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 155 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0036
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0445
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2432, R²: 0.0026

============================================================
🔄 Round 157 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 157 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0035
   Val:   Loss=0.0779, RMSE=0.2790, R²=0.0056
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2432, R²: 0.0026

============================================================
🔄 Round 159 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 159 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=0.0027
   Val:   Loss=0.0889, RMSE=0.2981, R²=-0.0318
============================================================


============================================================
🔄 Round 160 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 160 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0002
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0103
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2432, R²: 0.0026

============================================================
🔄 Round 161 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0950 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0950, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0950, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0950, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0950, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0950, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0950)

============================================================
📊 Round 161 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=-0.0026
   Val:   Loss=0.0950, RMSE=0.3082, R²=-0.0180
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2432, R²: 0.0026

📊 Round 161 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2432, R²: 0.0027

📊 Round 161 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2432, R²: 0.0028

============================================================
🔄 Round 169 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 169 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0022
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0190
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2432, R²: 0.0028

============================================================
🔄 Round 170 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 170 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0024
   Val:   Loss=0.0916, RMSE=0.3027, R²=-0.0008
============================================================


============================================================
🔄 Round 172 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 172 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0031
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0084
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2432, R²: 0.0028

============================================================
🔄 Round 174 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 174 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=0.0003
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0099
============================================================


============================================================
🔄 Round 179 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 179 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0060
   Val:   Loss=0.0782, RMSE=0.2797, R²=0.0079
============================================================


============================================================
🔄 Round 180 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 180 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0055
   Val:   Loss=0.0776, RMSE=0.2785, R²=0.0169
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2432, R²: 0.0029

============================================================
🔄 Round 183 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 183 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0012
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0124
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2432, R²: 0.0030

📊 Round 183 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2432, R²: 0.0030

📊 Round 183 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2432, R²: 0.0030

📊 Round 183 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2432, R²: 0.0030

============================================================
🔄 Round 188 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 188 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0094
   Val:   Loss=0.0788, RMSE=0.2807, R²=0.0306
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2431, R²: 0.0031

📊 Round 188 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2431, R²: 0.0031

============================================================
🔄 Round 195 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 195 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0096
   Val:   Loss=0.0862, RMSE=0.2937, R²=0.0286
============================================================


============================================================
🔄 Round 196 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 196 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0006
   Val:   Loss=0.0763, RMSE=0.2762, R²=-0.0133
============================================================


📊 Round 196 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2431, R²: 0.0031

📊 Round 196 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2431, R²: 0.0031

📊 Round 196 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2431, R²: 0.0032

📊 Round 196 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2431, R²: 0.0032

============================================================
🔄 Round 201 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 201 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0044
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0509
============================================================


============================================================
🔄 Round 204 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 204 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0124
   Val:   Loss=0.0824, RMSE=0.2871, R²=0.0314
============================================================


============================================================
🔄 Round 205 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 205 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0022
   Val:   Loss=0.0899, RMSE=0.2998, R²=0.0018
============================================================


============================================================
🔄 Round 206 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 206 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=0.0051
   Val:   Loss=0.0763, RMSE=0.2762, R²=-0.0528
============================================================


📊 Round 206 Test Metrics:
   Loss: 0.0814, RMSE: 0.2852, MAE: 0.2431, R²: 0.0033

============================================================
🔄 Round 208 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 208 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0042
   Val:   Loss=0.0873, RMSE=0.2954, R²=0.0034
============================================================


📊 Round 208 Test Metrics:
   Loss: 0.0814, RMSE: 0.2852, MAE: 0.2431, R²: 0.0033

============================================================
🔄 Round 209 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 209 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=0.0019
   Val:   Loss=0.0785, RMSE=0.2801, R²=-0.0157
============================================================


📊 Round 209 Test Metrics:
   Loss: 0.0814, RMSE: 0.2852, MAE: 0.2431, R²: 0.0033

📊 Round 209 Test Metrics:
   Loss: 0.0814, RMSE: 0.2852, MAE: 0.2431, R²: 0.0033

📊 Round 209 Test Metrics:
   Loss: 0.0814, RMSE: 0.2852, MAE: 0.2431, R²: 0.0033

============================================================
🔄 Round 214 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 214 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0022
   Val:   Loss=0.0810, RMSE=0.2845, R²=-0.0014
============================================================


📊 Round 214 Test Metrics:
   Loss: 0.0814, RMSE: 0.2852, MAE: 0.2431, R²: 0.0033

============================================================
🔄 Round 215 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 215 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0017
   Val:   Loss=0.0734, RMSE=0.2709, R²=-0.0007
============================================================


📊 Round 215 Test Metrics:
   Loss: 0.0814, RMSE: 0.2852, MAE: 0.2431, R²: 0.0034

📊 Round 215 Test Metrics:
   Loss: 0.0814, RMSE: 0.2852, MAE: 0.2431, R²: 0.0034

============================================================
🔄 Round 218 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 218 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2892, R²=0.0036
   Val:   Loss=0.0845, RMSE=0.2906, R²=-0.0215
============================================================


📊 Round 218 Test Metrics:
   Loss: 0.0814, RMSE: 0.2852, MAE: 0.2431, R²: 0.0034

============================================================
🔄 Round 219 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 219 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=-0.0080
   Val:   Loss=0.0828, RMSE=0.2878, R²=0.0245
============================================================


📊 Round 219 Test Metrics:
   Loss: 0.0814, RMSE: 0.2852, MAE: 0.2431, R²: 0.0034

============================================================
🔄 Round 221 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 221 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0083
   Val:   Loss=0.0832, RMSE=0.2884, R²=0.0257
============================================================


📊 Round 221 Test Metrics:
   Loss: 0.0814, RMSE: 0.2852, MAE: 0.2431, R²: 0.0034

============================================================
🔄 Round 225 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 225 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0076
   Val:   Loss=0.0902, RMSE=0.3004, R²=-0.0441
============================================================


============================================================
🔄 Round 227 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 227 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0088
   Val:   Loss=0.0821, RMSE=0.2864, R²=-0.0309
============================================================


📊 Round 227 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2431, R²: 0.0035

============================================================
🔄 Round 231 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 231 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0021
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0071
============================================================


📊 Round 231 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2431, R²: 0.0036

📊 Round 231 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2431, R²: 0.0036

============================================================
🔄 Round 233 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0722 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 233 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=-0.0033
   Val:   Loss=0.0722, RMSE=0.2687, R²=-0.0014
============================================================


📊 Round 233 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2431, R²: 0.0036

============================================================
🔄 Round 234 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 234 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=-0.0038
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0032
============================================================


📊 Round 234 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2431, R²: 0.0036

📊 Round 234 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2431, R²: 0.0037

📊 Round 234 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2431, R²: 0.0037

============================================================
🔄 Round 239 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 239 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0020
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0012
============================================================


📊 Round 239 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2431, R²: 0.0037

============================================================
🔄 Round 240 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 240 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0021
   Val:   Loss=0.0864, RMSE=0.2940, R²=0.0017
============================================================


📊 Round 240 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2431, R²: 0.0037

============================================================
🔄 Round 244 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 244 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0081
   Val:   Loss=0.0813, RMSE=0.2852, R²=0.0198
============================================================


📊 Round 244 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2431, R²: 0.0038

📊 Round 244 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2431, R²: 0.0038

============================================================
🔄 Round 248 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 248 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0042
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0348
============================================================


============================================================
🔄 Round 250 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 250 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0018
   Val:   Loss=0.0775, RMSE=0.2783, R²=-0.0018
============================================================


📊 Round 250 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2431, R²: 0.0038

============================================================
🔄 Round 252 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 252 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0043
   Val:   Loss=0.0833, RMSE=0.2887, R²=-0.0259
============================================================


============================================================
🔄 Round 253 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 253 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0024
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0050
============================================================


📊 Round 253 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2431, R²: 0.0039

============================================================
🔄 Round 254 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 254 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2877, R²=-0.0037
   Val:   Loss=0.0881, RMSE=0.2968, R²=0.0073
============================================================


📊 Round 254 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2431, R²: 0.0039

============================================================
🔄 Round 256 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 256 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0053
   Val:   Loss=0.0891, RMSE=0.2985, R²=-0.0022
============================================================


📊 Round 256 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2431, R²: 0.0039

📊 Round 256 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2431, R²: 0.0039

📊 Round 256 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2431, R²: 0.0039

============================================================
🔄 Round 262 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 262 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0023
   Val:   Loss=0.0857, RMSE=0.2928, R²=-0.0065
============================================================


============================================================
🔄 Round 263 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 263 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0075
   Val:   Loss=0.0926, RMSE=0.3043, R²=-0.0365
============================================================


📊 Round 263 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2431, R²: 0.0039

📊 Round 263 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2431, R²: 0.0039

============================================================
🔄 Round 265 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 265 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0023
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0223
============================================================


📊 Round 265 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 267 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 267 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0038
   Val:   Loss=0.0850, RMSE=0.2915, R²=0.0022
============================================================


📊 Round 267 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2430, R²: 0.0040

📊 Round 267 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2431, R²: 0.0040

============================================================
🔄 Round 270 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0932 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0932, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0932, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0932, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0932, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0932, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0932)

============================================================
📊 Round 270 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=-0.0019
   Val:   Loss=0.0932, RMSE=0.3053, R²=0.0003
============================================================


============================================================
🔄 Round 272 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 272 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=0.0024
   Val:   Loss=0.0726, RMSE=0.2695, R²=-0.0212
============================================================


📊 Round 272 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2430, R²: 0.0041

📊 Round 272 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2430, R²: 0.0041

============================================================
🔄 Round 274 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 274 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=0.0044
   Val:   Loss=0.0813, RMSE=0.2852, R²=-0.0288
============================================================


📊 Round 274 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2430, R²: 0.0041

============================================================
🔄 Round 276 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 276 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0078
   Val:   Loss=0.0894, RMSE=0.2990, R²=0.0223
============================================================


============================================================
🔄 Round 278 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 278 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0011
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0030
============================================================


📊 Round 278 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2430, R²: 0.0041

============================================================
🔄 Round 280 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 280 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0093
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0265
============================================================


============================================================
🔄 Round 281 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 281 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0054
   Val:   Loss=0.0860, RMSE=0.2932, R²=-0.0474
============================================================


============================================================
🔄 Round 283 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 283 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0053
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0236
============================================================


📊 Round 283 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2430, R²: 0.0042

📊 Round 283 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2430, R²: 0.0042

============================================================
🔄 Round 287 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 287 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0139
   Val:   Loss=0.0902, RMSE=0.3004, R²=0.0363
============================================================


📊 Round 287 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2430, R²: 0.0042

============================================================
🔄 Round 289 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 289 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0025
   Val:   Loss=0.0821, RMSE=0.2866, R²=0.0037
============================================================


============================================================
🔄 Round 290 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0932 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0932, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0932, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0932, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0932, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0932, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0932)

============================================================
📊 Round 290 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0005
   Val:   Loss=0.0932, RMSE=0.3052, R²=-0.0077
============================================================


============================================================
🔄 Round 291 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 291 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0043
   Val:   Loss=0.0854, RMSE=0.2922, R²=0.0046
============================================================


📊 Round 291 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2430, R²: 0.0043

============================================================
🔄 Round 295 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 295 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0060
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0382
============================================================


============================================================
🔄 Round 296 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 296 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0020
   Val:   Loss=0.0793, RMSE=0.2817, R²=-0.0374
============================================================


📊 Round 296 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2430, R²: 0.0043

============================================================
🔄 Round 298 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 298 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=0.0015
   Val:   Loss=0.0727, RMSE=0.2697, R²=-0.0226
============================================================


📊 Round 298 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2430, R²: 0.0043

📊 Round 298 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2430, R²: 0.0043

============================================================
🔄 Round 303 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 303 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0044
   Val:   Loss=0.0913, RMSE=0.3022, R²=-0.0010
============================================================


============================================================
🔄 Round 304 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 304 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0018
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0014
============================================================


📊 Round 304 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2430, R²: 0.0043

============================================================
🔄 Round 308 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 308 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0003
   Val:   Loss=0.0750, RMSE=0.2738, R²=-0.0113
============================================================


============================================================
🔄 Round 310 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 310 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0012
   Val:   Loss=0.0726, RMSE=0.2695, R²=-0.0014
============================================================


============================================================
🔄 Round 313 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 313 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0023
   Val:   Loss=0.0873, RMSE=0.2955, R²=0.0028
============================================================


📊 Round 313 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2430, R²: 0.0044

📊 Round 313 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2430, R²: 0.0044

============================================================
🔄 Round 317 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 317 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0015
   Val:   Loss=0.0874, RMSE=0.2957, R²=-0.0260
============================================================


📊 Round 317 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2430, R²: 0.0044

============================================================
🔄 Round 320 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0941 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0941, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0941, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0941, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0941, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0942, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0941)

============================================================
📊 Round 320 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0023
   Val:   Loss=0.0941, RMSE=0.3068, R²=-0.0156
============================================================


📊 Round 320 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2430, R²: 0.0044

============================================================
🔄 Round 321 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 321 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=0.0003
   Val:   Loss=0.0730, RMSE=0.2701, R²=-0.0258
============================================================


📊 Round 321 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2430, R²: 0.0044

📊 Round 321 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2430, R²: 0.0044

📊 Round 321 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2430, R²: 0.0044

============================================================
🔄 Round 324 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 324 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0043
   Val:   Loss=0.0839, RMSE=0.2896, R²=0.0105
============================================================


============================================================
🔄 Round 326 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 326 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=-0.0040
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0214
============================================================


📊 Round 326 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2430, R²: 0.0045

============================================================
🔄 Round 328 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 328 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=0.0060
   Val:   Loss=0.0885, RMSE=0.2974, R²=-0.0384
============================================================


📊 Round 328 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2430, R²: 0.0045

📊 Round 328 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2430, R²: 0.0045

============================================================
🔄 Round 330 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 330 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2915, R²=-0.0019
   Val:   Loss=0.0792, RMSE=0.2815, R²=-0.0108
============================================================


============================================================
🔄 Round 331 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0923, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 331 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0056
   Val:   Loss=0.0923, RMSE=0.3037, R²=0.0130
============================================================


📊 Round 331 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2430, R²: 0.0045

📊 Round 331 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2430, R²: 0.0045

============================================================
🔄 Round 335 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0929 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0929, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0929, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0929, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0929, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0929, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 335 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0019
   Val:   Loss=0.0929, RMSE=0.3048, R²=-0.0151
============================================================


📊 Round 335 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2430, R²: 0.0046

============================================================
🔄 Round 340 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 340 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0000
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0064
============================================================


============================================================
🔄 Round 342 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 342 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0029
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0006
============================================================


📊 Round 342 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2430, R²: 0.0047

📊 Round 342 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2430, R²: 0.0047

📊 Round 342 Test Metrics:
   Loss: 0.0813, RMSE: 0.2850, MAE: 0.2430, R²: 0.0047

============================================================
🔄 Round 349 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 349 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0051
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0395
============================================================


📊 Round 349 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2430, R²: 0.0048

📊 Round 349 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2430, R²: 0.0048

📊 Round 349 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2430, R²: 0.0049

📊 Round 349 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2430, R²: 0.0049

📊 Round 349 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2430, R²: 0.0049

============================================================
🔄 Round 362 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 362 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0084
   Val:   Loss=0.0818, RMSE=0.2859, R²=-0.0196
============================================================


📊 Round 362 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2430, R²: 0.0049

============================================================
🔄 Round 364 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 364 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=-0.0018
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0014
============================================================


📊 Round 364 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2430, R²: 0.0049

============================================================
🔄 Round 366 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 366 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0053
   Val:   Loss=0.0883, RMSE=0.2972, R²=0.0111
============================================================


📊 Round 366 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2430, R²: 0.0050

============================================================
🔄 Round 368 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 368 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0092
   Val:   Loss=0.0877, RMSE=0.2961, R²=0.0261
============================================================


📊 Round 368 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2430, R²: 0.0050

📊 Round 368 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2430, R²: 0.0050

============================================================
🔄 Round 373 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 373 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0007
   Val:   Loss=0.0866, RMSE=0.2943, R²=-0.0092
============================================================


📊 Round 373 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2430, R²: 0.0050

============================================================
🔄 Round 374 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 374 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0024
   Val:   Loss=0.0848, RMSE=0.2911, R²=0.0019
============================================================


📊 Round 374 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2430, R²: 0.0050

📊 Round 374 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2430, R²: 0.0050

📊 Round 374 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2430, R²: 0.0050

📊 Round 374 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2429, R²: 0.0050

============================================================
🔄 Round 381 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 381 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0059
   Val:   Loss=0.0909, RMSE=0.3015, R²=0.0155
============================================================


📊 Round 381 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2429, R²: 0.0050

============================================================
🔄 Round 383 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 383 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0090
   Val:   Loss=0.0848, RMSE=0.2911, R²=0.0152
============================================================


============================================================
🔄 Round 384 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 384 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0022
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0024
============================================================


📊 Round 384 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2429, R²: 0.0051

============================================================
🔄 Round 389 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 389 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0055
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0174
============================================================


============================================================
🔄 Round 391 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 391 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0019
   Val:   Loss=0.0789, RMSE=0.2808, R²=0.0024
============================================================


============================================================
🔄 Round 392 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 392 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=-0.0017
   Val:   Loss=0.0825, RMSE=0.2871, R²=0.0013
============================================================


============================================================
🔄 Round 393 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0989 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0989, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0989, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0989, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0989, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0989, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0989)

============================================================
📊 Round 393 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0011
   Val:   Loss=0.0989, RMSE=0.3145, R²=-0.0087
============================================================


📊 Round 393 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2429, R²: 0.0051

📊 Round 393 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2429, R²: 0.0051

============================================================
🔄 Round 396 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 396 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0086
   Val:   Loss=0.0857, RMSE=0.2928, R²=-0.0407
============================================================


============================================================
🔄 Round 398 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 398 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0067
   Val:   Loss=0.0891, RMSE=0.2984, R²=-0.0312
============================================================


📊 Round 398 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2429, R²: 0.0051

============================================================
🔄 Round 400 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 400 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=-0.0015
   Val:   Loss=0.0887, RMSE=0.2979, R²=-0.0065
============================================================


📊 Round 400 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2429, R²: 0.0052

============================================================
🔄 Round 404 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 404 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0007
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0051
============================================================


📊 Round 404 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2429, R²: 0.0052

📊 Round 404 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2429, R²: 0.0052

📊 Round 404 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2429, R²: 0.0052

📊 Round 404 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2429, R²: 0.0052

📊 Round 404 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2429, R²: 0.0052

============================================================
🔄 Round 409 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 409 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0046
   Val:   Loss=0.0812, RMSE=0.2849, R²=0.0019
============================================================


============================================================
🔄 Round 410 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 410 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0008
   Val:   Loss=0.0915, RMSE=0.3025, R²=-0.0033
============================================================


============================================================
🔄 Round 412 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 412 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0009
   Val:   Loss=0.0778, RMSE=0.2789, R²=-0.0057
============================================================


📊 Round 412 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2430, R²: 0.0052

============================================================
🔄 Round 419 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 419 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0032
   Val:   Loss=0.0847, RMSE=0.2911, R²=0.0053
============================================================


📊 Round 419 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2430, R²: 0.0052

============================================================
🔄 Round 423 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 423 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=0.0058
   Val:   Loss=0.0901, RMSE=0.3001, R²=-0.0349
============================================================


📊 Round 423 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2430, R²: 0.0052

============================================================
🔄 Round 424 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 424 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0032
   Val:   Loss=0.0797, RMSE=0.2824, R²=-0.0231
============================================================


============================================================
🔄 Round 425 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 425 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0055
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0172
============================================================


============================================================
🔄 Round 428 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 428 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0014
   Val:   Loss=0.0911, RMSE=0.3019, R²=-0.0104
============================================================


📊 Round 428 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2429, R²: 0.0053

📊 Round 428 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2429, R²: 0.0053

📊 Round 428 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2429, R²: 0.0053

📊 Round 428 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2429, R²: 0.0053

📊 Round 428 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2429, R²: 0.0054

============================================================
🔄 Round 437 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 437 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0026
   Val:   Loss=0.0766, RMSE=0.2768, R²=0.0041
============================================================


============================================================
🔄 Round 441 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 441 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0072
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0043
============================================================


============================================================
🔄 Round 443 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 443 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0007
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0095
============================================================


📊 Round 443 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2429, R²: 0.0054

============================================================
🔄 Round 448 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 448 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0037
   Val:   Loss=0.0834, RMSE=0.2889, R²=0.0046
============================================================


📊 Round 448 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2429, R²: 0.0054

📊 Round 448 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2430, R²: 0.0054

📊 Round 448 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2430, R²: 0.0054

📊 Round 448 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2430, R²: 0.0054

============================================================
🔄 Round 455 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 455 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0019
   Val:   Loss=0.0849, RMSE=0.2913, R²=-0.0011
============================================================


📊 Round 455 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0054

============================================================
🔄 Round 459 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 459 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0068
   Val:   Loss=0.0893, RMSE=0.2988, R²=0.0186
============================================================


📊 Round 459 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0054

📊 Round 459 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2430, R²: 0.0054

============================================================
🔄 Round 462 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 462 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0034
   Val:   Loss=0.0853, RMSE=0.2920, R²=-0.0201
============================================================


📊 Round 462 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2429, R²: 0.0054

============================================================
🔄 Round 463 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 463 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0039
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0071
============================================================


📊 Round 463 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2429, R²: 0.0054

============================================================
🔄 Round 464 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 464 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0010
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0154
============================================================


📊 Round 464 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2429, R²: 0.0055

============================================================
🔄 Round 465 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 465 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0019
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0103
============================================================


📊 Round 465 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2429, R²: 0.0055

============================================================
🔄 Round 468 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 468 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0011
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0254
============================================================


📊 Round 468 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2429, R²: 0.0055

📊 Round 468 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2429, R²: 0.0055

============================================================
🔄 Round 472 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 472 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=0.0019
   Val:   Loss=0.0783, RMSE=0.2798, R²=-0.0282
============================================================


============================================================
🔄 Round 473 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 473 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=0.0007
   Val:   Loss=0.0760, RMSE=0.2757, R²=-0.0130
============================================================


============================================================
🔄 Round 474 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 474 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=-0.0021
   Val:   Loss=0.0868, RMSE=0.2946, R²=0.0026
============================================================


📊 Round 474 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2429, R²: 0.0056

📊 Round 474 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2429, R²: 0.0056

============================================================
🔄 Round 478 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 478 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0002
   Val:   Loss=0.0842, RMSE=0.2901, R²=-0.0110
============================================================


============================================================
🔄 Round 479 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 479 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=0.0037
   Val:   Loss=0.0841, RMSE=0.2899, R²=-0.0381
============================================================


📊 Round 479 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2429, R²: 0.0056

📊 Round 479 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2429, R²: 0.0056

📊 Round 479 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2429, R²: 0.0056

============================================================
🔄 Round 490 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 490 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0052
   Val:   Loss=0.0923, RMSE=0.3038, R²=-0.0329
============================================================


============================================================
🔄 Round 493 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 493 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0035
   Val:   Loss=0.0748, RMSE=0.2736, R²=0.0041
============================================================


📊 Round 493 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2429, R²: 0.0057

============================================================
🔄 Round 496 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 496 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0037
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0222
============================================================


📊 Round 496 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2429, R²: 0.0057

============================================================
🔄 Round 498 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 498 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0021
   Val:   Loss=0.0878, RMSE=0.2962, R²=-0.0156
============================================================


📊 Round 498 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2429, R²: 0.0058

============================================================
🔄 Round 500 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 500 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0028
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0031
============================================================


============================================================
🔄 Round 502 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 502 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0058
   Val:   Loss=0.0838, RMSE=0.2894, R²=-0.0359
============================================================


📊 Round 502 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2429, R²: 0.0058

📊 Round 502 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2429, R²: 0.0058

📊 Round 502 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2429, R²: 0.0058

📊 Round 502 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2429, R²: 0.0058

============================================================
🔄 Round 512 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 512 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0003
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0246
============================================================


📊 Round 512 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2429, R²: 0.0058

📊 Round 512 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2429, R²: 0.0058

============================================================
🔄 Round 515 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 515 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0016
   Val:   Loss=0.0750, RMSE=0.2738, R²=-0.0304
============================================================


📊 Round 515 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2429, R²: 0.0058

============================================================
🔄 Round 517 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 517 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0019
   Val:   Loss=0.0907, RMSE=0.3011, R²=-0.0169
============================================================


📊 Round 517 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2429, R²: 0.0058

============================================================
🔄 Round 518 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 518 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0104
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0598
============================================================


📊 Round 518 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2429, R²: 0.0059

============================================================
🔄 Round 521 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 521 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0078
   Val:   Loss=0.0825, RMSE=0.2873, R²=0.0202
============================================================


============================================================
🔄 Round 522 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 522 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0053
   Val:   Loss=0.0819, RMSE=0.2862, R²=0.0154
============================================================


📊 Round 522 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2429, R²: 0.0059

📊 Round 522 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2429, R²: 0.0059

============================================================
🔄 Round 524 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 524 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0035
   Val:   Loss=0.0892, RMSE=0.2987, R²=-0.0188
============================================================


📊 Round 524 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2429, R²: 0.0059

📊 Round 524 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2429, R²: 0.0059

📊 Round 524 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2429, R²: 0.0059

📊 Round 524 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2429, R²: 0.0059

============================================================
🔄 Round 530 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 530 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0015
   Val:   Loss=0.0848, RMSE=0.2911, R²=0.0004
============================================================


📊 Round 530 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2429, R²: 0.0059

============================================================
🔄 Round 531 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 531 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0108
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0558
============================================================


============================================================
🔄 Round 535 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 535 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0005
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0137
============================================================


📊 Round 535 Test Metrics:
   Loss: 0.0811, RMSE: 0.2849, MAE: 0.2429, R²: 0.0059

============================================================
🔄 Round 536 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 536 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0044
   Val:   Loss=0.0855, RMSE=0.2923, R²=-0.0233
============================================================


📊 Round 536 Test Metrics:
   Loss: 0.0811, RMSE: 0.2849, MAE: 0.2429, R²: 0.0060

============================================================
🔄 Round 538 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 538 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0074
   Val:   Loss=0.0866, RMSE=0.2942, R²=0.0149
============================================================


📊 Round 538 Test Metrics:
   Loss: 0.0811, RMSE: 0.2849, MAE: 0.2429, R²: 0.0060

============================================================
🔄 Round 539 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 539 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0021
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0029
============================================================


📊 Round 539 Test Metrics:
   Loss: 0.0811, RMSE: 0.2849, MAE: 0.2429, R²: 0.0060

============================================================
🔄 Round 542 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 542 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0000
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0388
============================================================


📊 Round 542 Test Metrics:
   Loss: 0.0811, RMSE: 0.2849, MAE: 0.2429, R²: 0.0060

📊 Round 542 Test Metrics:
   Loss: 0.0811, RMSE: 0.2849, MAE: 0.2429, R²: 0.0060

============================================================
🔄 Round 544 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 544 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0066
   Val:   Loss=0.0819, RMSE=0.2862, R²=0.0051
============================================================


============================================================
🔄 Round 545 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 545 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0026
   Val:   Loss=0.0822, RMSE=0.2868, R²=-0.0035
============================================================


📊 Round 545 Test Metrics:
   Loss: 0.0811, RMSE: 0.2849, MAE: 0.2428, R²: 0.0060

📊 Round 545 Test Metrics:
   Loss: 0.0811, RMSE: 0.2849, MAE: 0.2428, R²: 0.0060

============================================================
🔄 Round 549 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 549 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2904, R²=0.0034
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0344
============================================================


📊 Round 549 Test Metrics:
   Loss: 0.0811, RMSE: 0.2849, MAE: 0.2428, R²: 0.0061

📊 Round 549 Test Metrics:
   Loss: 0.0811, RMSE: 0.2849, MAE: 0.2428, R²: 0.0061

📊 Round 549 Test Metrics:
   Loss: 0.0811, RMSE: 0.2849, MAE: 0.2428, R²: 0.0061

📊 Round 549 Test Metrics:
   Loss: 0.0811, RMSE: 0.2849, MAE: 0.2428, R²: 0.0061

============================================================
🔄 Round 559 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 559 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=-0.0015
   Val:   Loss=0.0808, RMSE=0.2842, R²=0.0008
============================================================


============================================================
🔄 Round 562 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 562 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0042
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0264
============================================================


📊 Round 562 Test Metrics:
   Loss: 0.0811, RMSE: 0.2849, MAE: 0.2429, R²: 0.0061

📊 Round 562 Test Metrics:
   Loss: 0.0811, RMSE: 0.2849, MAE: 0.2429, R²: 0.0061

📊 Round 562 Test Metrics:
   Loss: 0.0811, RMSE: 0.2849, MAE: 0.2429, R²: 0.0061

============================================================
🔄 Round 566 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 566 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0008
   Val:   Loss=0.0779, RMSE=0.2790, R²=-0.0097
============================================================


============================================================
🔄 Round 568 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 568 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0057
   Val:   Loss=0.0914, RMSE=0.3023, R²=0.0152
============================================================


📊 Round 568 Test Metrics:
   Loss: 0.0811, RMSE: 0.2849, MAE: 0.2429, R²: 0.0061

============================================================
🔄 Round 570 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 570 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0067
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0338
============================================================


============================================================
🔄 Round 571 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 571 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0015
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0048
============================================================


📊 Round 571 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2429, R²: 0.0061

============================================================
🔄 Round 576 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 576 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0039
   Val:   Loss=0.0819, RMSE=0.2861, R²=0.0078
============================================================


❌ Client client_23 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8688 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8688 {grpc_message:"Socket closed", grpc_status:14}"
>
