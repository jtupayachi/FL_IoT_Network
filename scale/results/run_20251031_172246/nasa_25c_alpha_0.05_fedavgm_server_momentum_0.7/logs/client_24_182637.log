[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4921bbe6-e9e0-4e8b-a3a4-e69a7e81c60d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80e9bdb9-f244-440f-87b9-9ec09e8f1c1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f317539d-5db0-4e4b-8779-91d57afd6aec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d64731cc-8034-4e36-b2f8-89f10649a91c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99a6506e-dd4f-444b-bfb1-a94933ce3eec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c20d8a27-2c05-4ecf-9189-d4cf88a1ccec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 330c1751-d270-4bc4-9e1c-0d2e94a0eb4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec6d52dc-4e96-4217-99da-a08106476102
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c48d41c-4d62-48bd-8662-d59d675913c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3b19c4f-f752-4917-be92-172f487a3371
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8000f2ed-0dba-4c70-900f-064f8014b1ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e18adb6-816f-48e2-b7e8-983a9e5af854
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message baa87be7-b616-4445-a8f0-d022247969f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0683d018-3c2d-4060-ba2a-44c649e6b930
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb72e30b-d9d6-4645-9bd3-1599e54ee336
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c4991ee-e1b7-454f-a957-1c485b9a96a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d930598f-a2b8-41d8-8876-3313abb314c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d306fcc7-9433-4fe9-b124-51eeeacddc54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aaff2c10-8743-41e8-9f48-50e100e43e18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d65d58e2-9ce8-4d8f-8302-5ab93683b0eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b314f77-731a-46e9-96e6-5589dff69b1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c379c811-b4da-47b6-8b37-1b45cc3a9648
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5dcf7c0a-b231-4a4c-a652-4e2e3053acd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3753eb7a-8812-4de7-bbfe-29f007c0d0f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 195b4cfc-d5b1-4400-b563-2b131a31c31b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2fa3c594-c7e7-4ace-9d39-285772a2a38a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58a7c673-b1ab-45b1-8784-646f40b5c102
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb32230f-c06a-434f-a536-108c1c515417
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1316bd9b-9aa7-424d-a3eb-582533f8a8c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5cc10a20-6bf5-4f31-ba86-5d2696a49c21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab4968c9-3674-433d-89cd-69f68be6c4fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e5d2329-38d1-4a9f-9ed9-653eb93ce5d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ecadd3d-46ce-4e6f-98c2-3f8ceb5af216
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e443dead-4aba-4f8e-b4bb-f4ce609432d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bff65365-616c-4d14-a8f8-8d6ee6fe7725
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd574682-2266-41f8-b90e-3a190f172aad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2dda095-e191-4ed9-9233-ac5560ea6660
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99cd627b-7fd3-4c5d-a1e2-dfcc6605a9e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b147309-ce21-4185-90cb-5b7416623891
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 122234e3-3ae9-443a-b282-d17f34f5e931
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60f265c0-7cbd-4d30-9e76-1b3e755e3cc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d554626b-add4-4011-9ac3-490d32784762
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e85fcbd-437a-46e4-9771-7cced4bbca2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3d0b881-d08e-45a7-a8cb-a9a94c35c952
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6cd9509-d3c3-4b28-9115-db3bd7fb4eb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8d6ab29-ab33-40eb-a129-082d70793f95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23f1bdc7-8e93-4431-af87-a0766f639f77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2dcc7eec-ba50-4f06-8c07-ae56b6e0c522
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7aa65030-8f75-45f0-a33b-83cd7ae23f31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c0212e5-5146-43a9-9e60-87edbb025bef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59bb51ac-eede-4c67-ad9a-bafd5be59ee5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a81e78c-312e-4e4a-bd01-43538fe35056
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e50015ef-98d7-4d67-8ea7-10b966dab2a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 866a1c56-6c42-470a-95f6-4d61382466e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98312d62-004f-4d73-bd34-c5a59ef5efee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 035462f2-1025-4ea1-8d9f-f2cd77964a91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5fe37cf7-0a2c-4917-97b9-d4c4a0586218
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5202dcf-04cb-4829-98e0-44873f752c54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5abb963-fd63-4a43-ae0c-084dd115e551
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 916f9887-b290-49fe-bad7-2e0451492393
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3be3a39-c374-493d-a0cf-83d6eb0ee916
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9d495d7-967c-4627-a036-34f4e96413a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b82ab555-deb9-4fca-b1ab-4f0bd2a1da29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ed001e2-22a4-49e2-a0b0-7e836a483f94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 488e7d89-09db-4974-8ba8-eba4c873f8e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62a73a62-a272-49b2-bf95-4087aaf1ced1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09e83d61-cfb1-43d8-bf51-76a38332fd2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21c30605-9796-4f2c-9cb7-f9de56a68c64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 930aed8e-3400-4bbf-888a-379da6d32943
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 718496cc-abcd-4fba-9db6-300afb06c380
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4046bf25-4b4d-4b57-a3fd-9ea3fe9d87b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 632b8e85-5751-461e-a22f-cd0c63e7fc58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0c2ff43-b286-4c64-9509-9cae4913e2b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 826296dd-35a3-4f1c-ae4b-fd966944046b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c144004f-37be-42b4-aacd-183f8d590301
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21364a59-7724-4917-8081-7891cf0b3663
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5b3d045-d14a-41d3-97e2-ced1f4c1f51c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1276fe97-298d-48ad-a33f-87731c4c715e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3959d56-7266-4948-af57-91764177e4a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 234cc439-4f95-499a-8b98-788c16d7e5cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f67d308-7fa8-4601-a2bd-0bfd439918f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d3c6e13-66e9-4a93-8481-bf37d026db1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b3d6854-c56b-4c67-b35f-21fc3abb9485
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66a86f52-170b-4f00-bc0f-ebf8ac168f39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d669810-305b-4f99-95e4-e9b27752ff43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a68b6df6-165a-4173-a282-a73f112b10a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0114442a-01eb-4f55-b286-da7fe5e52f65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1488df7c-021e-4b73-9b02-c87989963ff8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e005cba2-9fc5-4484-b441-0e8696070f13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4fe7f8e0-1a3d-4ab6-9fa4-a383cbef1b1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 567f8708-ba6f-4a4e-ba02-fd95e9b23bb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf11f55b-2fe2-4e2a-b970-9c0ac157f32c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c4f84c1-5ade-4aeb-939e-3ed8e2301e4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3fc8c78-75cb-4be5-8278-3880cda5d9dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae62ca17-98fc-4621-a2c3-713157807889
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8964b4ed-a78d-488d-85bb-81c0c1b079c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c57ceeda-f747-4924-83c9-d4c1576649ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75d021d2-d11c-4c0e-9eef-b0eabbc0b604
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e36e3d4-bb85-429d-98e3-25440f706509
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 213387e6-33b7-4103-9603-f2fa6e137748
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 606ff3ab-3d9b-45ae-a9a6-c79f77edfd13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d35dfd2-ea1b-4c98-9d0c-921830c3e11a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26e5d886-d99f-4341-8fd8-cded35fad3ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 010ab11b-e823-4ca7-9ec1-fdc0e35facb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2dcf5e17-2da4-498f-8a20-6efec2447aad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b22d4664-eeda-47f4-aef6-7610070e4a2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3d5d652-3c84-4be2-8c13-ac752762b2a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c365f2b-faa7-4a55-b3ea-a16ea9d3b794
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1cd95e7d-5461-4532-bce7-c17d9e0edecc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3363d7e-a125-426c-ac5b-ac77b58b3985
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c86ed89-cbf5-4c57-89dc-05556cc711af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0867799d-965c-4268-bbcb-162c464210a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a943351-2609-4944-9744-5686bef9f143
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64c183da-ae59-4c81-8b7a-84ed365bea86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c25ba38-b5d1-4dc1-b423-67fbb591739f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a49d2cab-c549-45fe-b182-c767a7f30455
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f86ada55-9973-481b-aaca-38feb21351d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7dc6e546-fcf2-4605-8738-d2e59d9a4d02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96fb9ad0-41d3-411f-bd1d-14e2224c0d5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b7243bc-4be3-4be6-83c6-82f1c6e45ee7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9f1db23-8890-4f09-af4d-187f22e1871d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e46fb12-4b6e-45c1-a492-2381c232490e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0009f851-4341-47ef-ae07-40600c50226f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32e3cbef-3772-468c-ba48-c29b514ee358
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea7ab8cb-4109-443e-ba7f-8596dcf70d6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e51d4da-dbe5-4805-891e-79633fe48055
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e16dd99c-261c-494e-908a-5d4333085653
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5c116ca-71ed-441c-b08a-0f1cd28554ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3dda2037-309b-4064-a2b8-4bd61d07f22c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd2119af-6c3e-49f5-8057-6e646ea4d268
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7fc40203-3c70-49d9-a1f9-90fdcf1359de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18370408-161f-48c0-8ada-9739a6e8a05c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91520b80-4c6b-46f9-ad7c-0c2836030504
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aefcac16-a84f-4bdc-b8a8-564752a9a0c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba6f0b15-343f-4938-b804-820b4f95fddf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0043ec4-fea4-4902-b85d-0a97b27df063
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ff8c2da-c252-4913-a72d-04fe02dcffcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d150103-7f8b-4479-a42a-a2d183ae44ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6664ef31-d5cb-4e77-b686-c1d2ff311985
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 974f4cda-c49f-4f11-a669-daee35f7e4cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79b3cacb-01b2-4ca2-8395-88a178a3b567
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55861cb1-b7f6-4845-b97f-a1e14fa8d6eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb895293-d674-46ea-ba30-ebd91a3e3b61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31d79b7d-5508-457c-9f41-d32af93e827b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63940925-dc3b-49aa-b294-3adf488762d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7db566b9-2606-43cc-b13a-00cf3884a820
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 042e8595-4a1e-40d1-b9a5-7c5ecd5f2b97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea379684-0360-4530-92bf-29ee2cfb70e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79c96677-db45-4417-902b-548300be7796
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c8c0200-dbd9-459a-8c70-da75e38cd5c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 193f8f27-2af5-4100-a70a-9ac2cf13058a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d546322-fc96-4123-938c-77ade8acca9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e34ebbb4-5bf8-462e-827f-d053ecd91ee5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e32a1c15-d584-46b5-82f7-f1943d423fc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c23e12c1-1512-40f5-bab2-ff7893583004
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 482d7e35-2846-4c68-a64d-352393998d50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 655e3aec-04b3-456d-a8d0-161ae2d38eaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2bb56580-d526-4293-af01-2a0984897183
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3fc104ba-6f34-45c3-b964-0f4abc831550
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04ecd66d-f452-45d9-97d6-dc12493cd96c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4cb2b1f7-4e8c-414e-a967-27fe9c1b3bf6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3cbf015e-a984-4b1b-a546-ed3505ee4840
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db4abc7e-e399-4e86-888c-114bf6907ab9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9862a40-d811-4916-9df7-1f1887e1d70b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a961c8a-7a60-4839-a39e-adb23bec1b59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 041990d7-d685-4fd8-a09e-b8e76e9bc200
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9fc5acae-162d-44ec-9f35-ef36c8d7baa8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06661562-4a94-4583-8678-6c9a6bae3ada
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a346f48-550f-44ec-8010-2e18eb135e8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0d2d25a-5a0c-4160-907f-e03b0c7514b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 418e8dad-dccd-4f1f-8d0d-21f3f8e045ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b1e2911-9e3d-476b-903b-b0b0159bb186
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5cfa028d-8ede-4c15-96d6-27693a423040
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c6203a8-f01a-4dc2-b216-d365f7e24a1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff532979-307f-48d3-8d4e-71e47f9c8817
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message def91efc-2bd3-462f-89fd-b4dade92f8c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4280ccc2-15ce-456f-9b68-00a19dc623fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e6440e8-7212-4808-8a1a-8a3259ae72b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b0649c0-e732-440c-b52b-12174c16ed4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ccda26c7-c49a-4d9d-a18e-5e084b9c4412
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1044ee2d-eb93-4737-acef-e949ac7d1eaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a00dae2b-c42c-4aca-b328-ebc0a07b6e9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7cd2f16-324f-4207-ae60-8bfe3a75c53e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b12101b6-f8a8-4fdb-8193-b8ba99f7f23f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c5a82c1-86e8-4c72-8d7d-d3b565075611
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d39e140-3373-42c7-8972-d5e63a0d9bda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7dab2d41-5eba-45b8-be2d-4201417d6e6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d204d4d-f45a-4aa9-b8e4-589eee5a4b34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dffd05c5-acf0-4494-b1d4-634f599071cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f7c78f9-a678-4950-9e50-dfeea96bb3a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 772d181d-1b94-40cb-9ccf-cd56beb6ba0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c81d6079-1a9d-419c-8aeb-b6ccf265e7e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 862a1e74-dcdb-4d76-bff3-08275f69c359
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68aaf1a0-ae97-49f2-8846-29686dc667b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d2e8efe-8637-40a2-9fc4-d03a5a3f2b7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4be2b537-c36e-4b8b-b226-95fc99e7953a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93809265-a1a1-43fb-a557-804ef9825624
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1ae8b38-3e6c-48ed-95e4-02d6ca3dbbcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b619d0af-fe80-4e41-8fc5-e0b41d9eb502
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59598709-b04d-4b6f-8293-12c6231f049c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df0abf32-4bff-49bc-83c3-1245427fc07f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b84a2757-b0d4-4c04-96ce-e85e38c8d2b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de9d29b2-4798-4c51-ab0c-2aa3574092d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd2d052c-f378-4fdb-8761-81c6c4af39bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b76d547b-3a2a-4af1-b6f3-9a39a2b27425
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a9e155e-e8fa-4f97-aca0-925bad884929
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7590966-23c3-4b29-a427-c5f5aca2de7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ba2c64d-8de2-476f-89e7-28990e7471fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a088e7ef-d3f7-4687-ad21-70945c7f7437
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60bd4a84-cf55-4c31-ba40-abd83546372c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a81d0b68-5ba6-4277-a2b6-dfbf6abd7433
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message feb8d111-e123-4315-9f5c-0d6db7ad090b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a334d26d-c8e8-4cb0-ba3b-59dced5716e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93a5c327-e16e-4f68-acd1-aa27bcba7a65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3fd2de4-1d96-49df-a87b-fe913d94429b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47fe7109-ef66-482a-8f2d-edb465f2d80e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2cdf08fb-1bcd-4271-ae26-62e9b605f366
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d49711bc-ffd6-4d34-a787-fc260b5397f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08606725-93a5-4fd9-a50c-0809cb350df8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 020b8c71-26c0-4b1b-b029-f6bd9d8bd9f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d4605f7-4c83-4b78-9d16-b0069a653f9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2bfcfc86-af5a-4ee9-8f93-b987f102eb43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5bb0faf9-5a7f-4f0b-ac61-2941f8005791
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e031a7be-9c05-46ff-afe1-aa61140c764a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7499ecf9-11ff-4b7a-a2d2-938455e818dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a36c998-6429-4f22-a337-44b1b925c4a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f592dfa-6598-4efa-bddb-c2f728bac40a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7990dfb6-2a1b-4156-ad00-1ed42600e444
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56609a9d-1c8e-4e60-9f52-af4f3fe96ea6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10d262f1-42b3-4d1a-a97b-845556e4871a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e57b593-6624-449d-bfc7-2b991a272a19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d7b4f13-e22d-4590-9470-ad95f6e1988b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc1cbf3f-1398-4d38-a3e9-7c34fc204eb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6f7e764-d095-4c43-a0e6-087aa4b8d26d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df7ea200-03d8-4d04-8675-86b5960f4242
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8af3989d-b3a1-409d-b6df-1cb64f0fcc1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 680c09f0-9742-4e5e-910e-677466b1ff85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6ce0d5f-6bdb-4844-8c79-1aa74150c663
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4383ca27-44dc-4cb1-820d-bf30ced6ad57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3f26a0e-51d2-45ad-899c-fa37abb04c2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4d7ca97-3b0c-4e9f-9c6d-f7fc999230cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b274f44d-8b8d-4424-8226-a6b3bf22d272
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0eae2fa0-17b0-4dd0-8a82-07845ad948bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6f8bb98-89ff-44f0-b824-2119cb86d5a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04ed88dc-89eb-4aa2-8821-804d095cb528
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1af50ec-53c4-4496-bc38-49a01c99a430
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc2495eb-470e-48bd-8520-d94a65ee8703
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37a94113-e564-44fa-9b90-27764be413ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3048c82e-b09c-4684-8a4b-b7be6cf97ad1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fdd2eda7-e66d-404a-97ff-b8ee90980dd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26cca886-1d76-46e4-9924-58399532603c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72d14f56-1fd3-477e-af73-d76d9c2a53c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b680525e-82b8-4305-9aae-8b8c8c691c0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 946fe8d2-4a4c-455a-9b7d-9fde6afa57f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39362cd6-8bf7-4e5a-b214-046146dd0528
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3d4757f-0d92-45b3-b476-b03a0d15d115
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64bf5ceb-4533-4c1a-b3b3-3700f755b71a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4bc11a0-f2a5-45d2-bd66-b530459b331e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2122a7a3-fb9a-4b7b-8818-ac2e8a6cc7fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9f53ca9-615d-475b-a2d7-a89ebaf753d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21fed4be-d6e3-4e7b-a89b-f5953dacef03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e08ee526-3287-46f6-a2ca-c76f695241e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73f93ef3-375b-4669-a80c-796fc40e1af9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0564488f-9cfd-481b-820a-59fb14ffc68f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76c6ebc8-dc03-496f-ab36-187dc7659a69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3da0fac-b089-46c0-ab19-5fd12a1bcf53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb911e92-c915-4563-b931-23591cd47131
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d872d42-7fa2-4d46-ae17-781e1cccc953
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8a2b2bb-022e-4c79-9ac1-abeb545c3908
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 241e0496-1f4e-44f6-b617-314d87d14c7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f3b0c25-3a20-49d7-833b-1328e63ac46e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cccbecea-16aa-4b3b-95ae-2c7f4e7987c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c0e1353-91a1-4ad7-bad5-0841e5f4ebc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8bf46cd-5991-4a58-9a1f-1a6ef325d185
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28b15721-cdfb-4814-9f33-b13637b30e90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8f9e252-9809-4491-ac59-0d4238ff84f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb46ee0a-19d5-4c0a-87c8-fe53f9fd6a4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27374e69-6d74-44ae-a91b-55d1d9cb85e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fad2461c-0211-447d-96cb-06cab4cd4497
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09a13ed3-a752-4c2d-8fb7-ec52cdae4b50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44a91f5f-dee5-4789-82e0-04d1f22d2c1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6db4c31-44fe-4d7c-94f1-772441ad8bcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e6f938b-55a0-4f1c-8f39-9fc937c4aaf7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 825a4553-d1b2-4551-9f2d-455e74478534
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0205769-54d3-4fb6-96b4-d15f11467f03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20d6683b-5614-4ec3-8749-5046c5fe08a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b860d835-60bd-423d-b64c-24896961e564
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24e5cd2b-e3ce-4586-8d4c-7289b2c8d9fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87dd6782-c0fa-4997-acd5-da3d88393dd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b91eb456-5039-4896-85c0-e648efbc1b87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a3b20d8-873f-4c42-8c9f-c14e7d433c34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 968f97b1-8d6f-49e0-9ef4-e51a5375f136
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed420973-823d-4e6b-8391-df1502092bbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message feb00607-4869-4db8-8ecf-bba9a63e1d4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2fc41e3d-6728-4e32-8e8a-97d8d4c2d6ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eabc6960-037b-4f88-b73e-d85a664a876a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2e9b6a2-762a-4e6b-b332-38d279896363
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4cf7c8fa-9f9b-40e3-8cca-6db25ac23935
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1972e07a-cbdb-41ca-9a94-e2cf93bdd070
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14a545b0-54aa-48c5-a012-9cda673d9ff2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27b29508-ccc6-445d-a8e1-82d53065e82c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message abd15a9f-8ecd-4315-a48a-1c0dd38036d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d4d07b5-2a46-4e9a-b7f4-c111c27a7e2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c4505c0-df8d-412a-a901-0a4b825d3a62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 459953c3-df3c-4fea-83a7-6bf2a9f38799
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e1eb63c-101b-4aa0-8d9b-d82eef49ab70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f52009e7-1df1-47f1-ba9d-dbb0684505c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5992b9aa-e015-4595-a7e6-c05636582ff8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 428b89e7-51ac-44ff-afd7-2387e8934182
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ecde8202-3366-4df9-ae0d-356a1ce180ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4396db4-7fb2-4113-8f30-28ec9836c4fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0108e759-4d66-4164-95e8-b0e4efcfd922
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 980852f5-9c97-4fed-910c-45e6961102ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63134def-7e35-42fa-a881-c68bf9d35057
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10f69ff7-b9e2-4aee-b659-c40b4a5af603
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b6d70d0-174e-4ee8-97b4-ada9901eda4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11f6f1d7-b9c9-4955-b79d-762a15b2db3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35194fb6-d225-45f6-9331-269ff6169249
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a5f140a-8916-4f5e-ba80-5ca677d229e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bfe81f1c-0bf3-4bdb-9c0d-00fb539fe965
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 231bd422-e14c-4d45-8c1a-8c4555dd8999
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f69c8981-c2b6-42f9-8a86-dcdeed77a32e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6cece4c-21a7-46da-8321-74c015b6dfd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ac9748b-e939-4030-a512-2cf8b80f64ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4b66a91-7c6a-46e9-a00a-67d7ffaa888b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7100a7d5-501a-4fc2-b2fa-35b50512f10f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d574d58-55f5-490d-aee7-b94ab22b5698
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ab412ff-7533-4f63-b548-47489bf1d257
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 862c62ea-e005-4f44-b6c0-283cdf49533a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 328e8106-de43-47da-96b2-006f415e1324
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 809fe4fb-cb28-44b9-8dad-3ac263de8c5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad63ef08-dc32-4145-a3be-3c736f6659f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 809750aa-4bc9-4acf-bc1e-5376c7faec01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7a31090-07ff-472d-a5e4-eb822c4f2fa0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 878c9984-1f41-41b9-bbc2-4a004c6a14c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7afa2f8-0901-48fa-9a3d-f515a20a1e66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b8703db-2fb7-4208-b982-ec7350709b29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f964dae-e680-4abe-bfb9-dc1fbf2ddd50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 978c1491-bbdd-4937-a09a-3e2fda1c28e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50983a59-2e2d-45c3-8fa9-c3482d5e957f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b01168b-5ff3-48ef-ba0b-32b5e70efa75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4bbe499e-fd33-4363-a7ef-559828323d68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3d5aa53-330a-4b0b-bd88-e87d33ee79ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a614700d-98cf-46cf-8d8d-6d88fedb27a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c77f945-bb8d-4777-b0ee-d61ae365893c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3f69d3a-54b4-4472-8e5a-f2808c441a9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6fc1bbf2-defa-42b6-9c12-05cef880499b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31329575-5f09-4f18-9db7-d000f6b37819
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 443b42e6-c873-4bef-8ee3-428a54454a25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e73db27-8bb2-4cce-b32d-d0a77fa4eb15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 905ed130-ae4f-442b-95d9-74eb10e9a2ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 900b0dce-5682-4380-ba53-c04535c13e42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1fa770f8-ff46-4973-b5b0-a098bee5673c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b85e41ba-3252-4e12-9fdf-7505ba6a2867
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13e3cd39-8cb7-4337-bb95-41e06a7bd7b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad58a710-a0fe-4625-9faf-9ba5b709f092
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed84af34-195a-436e-97f2-248cb709e9d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29892643-7406-40a0-bf98-3843fbdca091
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bcab761a-86ff-44d4-9026-d81903938420
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 063c821e-1a61-462c-90c0-008cacc84e95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e30b0ed-bd04-45f8-88d4-364344f86db6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af68f7ba-ea0b-4fd4-bc9c-8ccef68bce91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message edae5a19-425a-46a5-8017-380a5d0f2cce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b54bb28-1432-4e9c-90be-7bced683d621
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd6e0d96-8ccd-429e-835c-74e110ef51b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82a854bd-3980-4185-9bf7-91988bbe9c29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b400d939-dc84-4fd4-a599-9ea0e2e4ac16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03b7bdc0-26be-4205-8e2f-49da5e82d323
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6547c24a-ba9e-4a13-a753-e160794b952a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 537efdb9-31a2-43c8-b8a2-187ce89f1d21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cda333f9-2599-4baf-9501-7b9332dec22a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02880beb-81c8-421f-8375-9cbd6b3f0696
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message facad826-0466-4c8b-89ca-b8e403cc34f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da0e961b-7b7f-4bf0-812d-b88104a5c008
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48bf88f1-df8d-45f6-a72c-047cd77acae2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f52ef28d-7be1-4abf-81ee-b99d5bf26fcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 459f38ec-86c7-4afc-b8be-f75f20a3e206
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c066c42e-ae2e-4663-a6c8-489ebcf5a9b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ac915f1-b982-4b69-90c4-50aa44411030
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00c06209-121d-435a-9f3f-b6637f68ac12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ec04d13-00a5-4865-a423-a52cb149d71d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2505b15d-46e0-421b-a6cf-8a2b68ebf3b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2ad2a63-b67a-465e-ae31-8ce6fba1362a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2293f4c8-3c1a-4952-a07f-b23012bf2dcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 026ba819-9023-4983-8f16-5a33a09a3f12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e6716d5-3c8d-426d-9969-23bab1ec6269
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21613169-076c-42a2-989d-ac6321d6b187
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b889374-ad4f-406f-ab5c-a2edc958a409
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f5030b0-87ba-4cd8-9979-845c400bfe04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63ff20bc-052f-4978-a38e-ada81d9e300a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de9cd5c6-d02a-43d5-ab97-b9a5ba6f7024
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae1a6bbd-10d2-4cb9-aa23-801fbaa7444c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f36241d2-ba8f-42ca-8174-d63a14253a15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 550bc623-26db-4235-8f19-29f13ac5cfdb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b387e39e-c38f-4f50-911f-b96406dec972
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23c982f8-5cbd-4973-845c-b0ecf2246f2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21843a7e-59e4-4f7b-9698-4048b027ce23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c56948e-1be8-4431-bfad-26ae3e0e70ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 099d6aa5-0c91-46f5-b296-8da823a69cd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ab3aa77-f90a-4656-962f-bbe93b68c826
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b2069a0-2954-4252-92e7-d151201e9513
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54d6bd41-6824-4d59-bc72-8d8e617bad1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a11472d4-4f8a-47b6-bc5d-b145f5ea1a2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd2000b9-c4e4-4147-a727-fa5765d22a59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9096d101-60d7-4d56-b781-da5154a25ad8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41218101-126f-4970-88f3-dff9f8b7fae8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b8b81e9-9f06-4811-907a-0719dcf73ced
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f51be580-c5df-4389-beb9-1d760bc63b58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd1fe747-553a-4492-b12d-c26020966d79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d02f28ba-e3d9-4eeb-a011-c3dc95a544a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f019acb-df6d-496a-97c5-6d3d26d14311
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f609585-5695-4587-b73a-9c2c43046c27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 079045fd-f34c-4ecf-8ab1-7f996adb0bda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 607aedc1-6e8f-4873-911f-997d7c66c88b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2133e625-43e7-44b0-9dcc-8ef6907ed37a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b526c723-a552-4825-9b2a-c39930a3f632
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8be02bfe-9e5e-4513-8378-11b80676f789
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ff4fc0c-ed2b-4bcf-a523-6ebbf7c8e4a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c835293-60af-472f-b5c6-263a7a72187f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f131b28-868d-4579-a105-16d1ed61ec1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97f0250b-00f3-4845-a35e-1173688fecd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14904e69-dbaa-4a1c-98da-1f81fdff8069
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1567c05f-705e-404b-8c98-6fd66eab4bd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f406be72-b4f0-474b-a23b-c6a12446b1a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f197e253-25a2-4383-927c-d61586816e9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8188a475-3293-487f-bc9f-cd916e2b2793
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38daef26-2df5-4904-afef-469aa6258e25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48ac1ced-d43d-45bb-821e-62178294500d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3d142d4-dd73-4df5-a071-b69a683a325e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b40a8a7-1ba3-4afd-be2c-9a6b2ca4d77b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11ace3d0-d99b-4693-b286-500bf66b0a4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13d0d52a-3414-42b3-9956-5b65dda01ca8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3d19771-f034-4af0-a888-db8d80cc75d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17a60305-0e25-4fb3-ada1-0ec9aead324e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9889e7b0-2121-48c8-bb80-fa60eeb80c79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69b61c3d-a358-4bbe-95f4-8a0b31df371a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21eda3db-951a-45b2-90b6-61c12cec740f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2c7c7a0-7d15-462d-bd85-bdabef801ff4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0365c0aa-22a2-4b67-a94e-02970645936f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e75f73f8-7d48-4f81-9c95-cb8be64d17c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff8f16cd-3fac-42b5-8d47-82eab52cd5d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24a7ccd8-20d2-4256-a295-0d6acd495360
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52756f7a-e0fa-4a4b-857f-7825d896d2bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b63f0d1-3926-49fb-9ee7-92c1cc679052
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eea8fc3e-d8b1-4b0d-b71e-eda46f9bdbcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8b2fdcf-2b8f-4d18-8ffb-2c41f3199e57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b9fd96e-4c2f-440c-8ea0-03c98f58c596
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b52cc1e0-e2bf-43a6-90d2-616a774cba29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f2fcaac-c5f5-47f5-8ec9-8d8b437311e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7fb8e566-d554-4873-b552-d35a82101a2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5803c7c0-7dc8-4028-bfcc-016f68a98ae1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ae59c4e-cd4a-4188-bb01-c36e9afaaf34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eee53dd5-1f84-463a-b5d2-a1c3a78f8556
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c547514-9a93-499d-9cb4-60b866b6b35f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2a4d0df-45c9-42f4-acbd-4561c5c2b107
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a4d19e5-ce24-4334-95da-55ef4167affc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 239cef51-7a35-43da-9cb6-d4b93c401139
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0779767f-a85e-4df6-8358-abda51ea6e19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 808d4349-fb5e-4e73-b77b-08951ce013ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dcaa7bb3-61cb-45a9-b271-1a203444f1b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 692006c2-9766-4f44-a55c-c4c5bdd61078
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message def343f6-058d-4067-8b97-a1f3b3b88bda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52d5a81a-976d-44d3-a61b-f76ab8362f36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5085bf1-1fa6-4150-b7dc-ebbc4202b5a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2754758-6bd6-4aea-8931-b1fd6db6889f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e2f52a0-3732-4a93-8d62-243fa8bc7e24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc3a5162-a6d2-4fe7-8846-7f4e4f6c0274
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 574c1c57-597b-4779-a746-c1b36c5896af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad62ce5d-b6f5-4ac8-b1b0-0ece7acb99df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95bed893-4cb5-4062-8e7c-cda840a111d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c2cc06a-6a37-422f-a041-138600aeab13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6d5e8ca-f975-4d9c-9462-036defbdb6b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 639818e2-0f3a-4616-85bb-f23e4245377b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c481d6b9-2933-447a-b31a-f8c4803386f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c78376e2-7a02-47f7-9d95-39dec40f2cfa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f58616b-9c59-49b9-9adc-91b7bcbca459
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 255bfadc-2e8c-4e61-a181-bcaddf5e2fd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d6db4ef-345d-4190-9dfe-babad986037e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5b0d52d-ce37-4aa3-b9e4-12ecf83bf69a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fea9abd8-5136-40a1-89f1-b2c7bc338546
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30860bb0-637c-4806-ba82-00a26eef48b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2184092-e6f0-4fe9-977b-8de2cd830c07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a2d1b3e-0a75-4a14-bf5d-c347c6a961b3
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8688 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_24
Server: localhost:8688
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_24
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_24/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_24/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_24/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_24/test_labels.txt

📊 Raw data loaded:
   Train: X=(3897, 24), y=(3897,)
   Test:  X=(975, 24), y=(975,)

⚠️  Limiting training data: 3897 → 800 samples
⚠️  Limiting test data: 975 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_24 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 2 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0929, val=0.0854 (↓), lr=0.001000
   • Epoch   2/100: train=0.0930, val=0.0884, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0937, val=0.0873, patience=2/15, lr=0.001000
   ✓ Epoch   4/100: train=0.0939, val=0.0843 (↓), lr=0.001000
   ✓ Epoch   5/100: train=0.0930, val=0.0834 (↓), lr=0.001000
   • Epoch  11/100: train=0.0910, val=0.0823, patience=2/15, lr=0.001000
   📉 Epoch 19: LR reduced 0.001000 → 0.000500
   • Epoch  21/100: train=0.0842, val=0.0816, patience=1/15, lr=0.000500
   📉 Epoch 27: LR reduced 0.000500 → 0.000250
   • Epoch  31/100: train=0.0783, val=0.0817, patience=11/15, lr=0.000250
   📉 Epoch 35: LR reduced 0.000250 → 0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 2 Summary - Client client_24
   Epochs: 35/100 (early stopped)
   LR: 0.001000 → 0.000125 (3 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0947
   Val:   Loss=0.0809, RMSE=0.2845, R²=-0.0189
============================================================


📊 Round 2 Test Metrics:
   Loss: 0.1471, RMSE: 0.3835, MAE: 0.3128, R²: -0.7996

============================================================
🔄 Round 4 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1185, val=0.0895 (↓), lr=0.000125
   • Epoch   2/100: train=0.0902, val=0.0944, patience=1/15, lr=0.000125
   • Epoch   3/100: train=0.0892, val=0.0902, patience=2/15, lr=0.000125
   • Epoch   4/100: train=0.0889, val=0.0901, patience=3/15, lr=0.000125
   • Epoch   5/100: train=0.0888, val=0.0905, patience=4/15, lr=0.000125
   📉 Epoch 8: LR reduced 0.000125 → 0.000063
   • Epoch  11/100: train=0.0884, val=0.0906, patience=10/15, lr=0.000063
   📉 Epoch 16: LR reduced 0.000063 → 0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 4 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000125 → 0.000031 (2 reductions)
   Train: Loss=0.0893, RMSE=0.2988, R²=0.0063
   Val:   Loss=0.0895, RMSE=0.2991, R²=-0.0081
============================================================


📊 Round 4 Test Metrics:
   Loss: 0.1006, RMSE: 0.3172, MAE: 0.2672, R²: -0.2308

============================================================
🔄 Round 5 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1039, val=0.0991 (↓), lr=0.000031
   ✓ Epoch   2/100: train=0.0977, val=0.0941 (↓), lr=0.000031
   ✓ Epoch   3/100: train=0.0935, val=0.0913 (↓), lr=0.000031
   ✓ Epoch   4/100: train=0.0912, val=0.0900 (↓), lr=0.000031
   ✓ Epoch   5/100: train=0.0900, val=0.0893 (↓), lr=0.000031
   📉 Epoch 8: LR reduced 0.000031 → 0.000016
   • Epoch  11/100: train=0.0886, val=0.0888, patience=6/15, lr=0.000016
   📉 Epoch 16: LR reduced 0.000016 → 0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 5 Summary - Client client_24
   Epochs: 20/100 (early stopped)
   LR: 0.000031 → 0.000008 (2 reductions)
   Train: Loss=0.0900, RMSE=0.2999, R²=0.0037
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0034
============================================================


📊 Round 5 Test Metrics:
   Loss: 0.1087, RMSE: 0.3297, MAE: 0.2746, R²: -0.3303

============================================================
🔄 Round 6 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1134, val=0.1107 (↓), lr=0.000008
   ✓ Epoch   2/100: train=0.1114, val=0.1089 (↓), lr=0.000008
   ✓ Epoch   3/100: train=0.1094, val=0.1073 (↓), lr=0.000008
   📉 Epoch 4: LR reduced 0.000008 → 0.000004
   ✓ Epoch   4/100: train=0.1076, val=0.1059 (↓), lr=0.000004
   ✓ Epoch   5/100: train=0.1063, val=0.1053 (↓), lr=0.000004
   • Epoch  11/100: train=0.1024, val=0.1023, patience=1/15, lr=0.000004
   📉 Epoch 12: LR reduced 0.000004 → 0.000002
   📉 Epoch 20: LR reduced 0.000002 → 0.000001
   • Epoch  21/100: train=0.0996, val=0.1003, patience=3/15, lr=0.000001
   • Epoch  31/100: train=0.0986, val=0.0995, patience=2/15, lr=0.000001
   • Epoch  41/100: train=0.0977, val=0.0988, patience=5/15, lr=0.000001
   • Epoch  51/100: train=0.0968, val=0.0982, patience=7/15, lr=0.000001
   ✓ Epoch  61/100: train=0.0960, val=0.0976 (↓), lr=0.000001
   ✓ Epoch  71/100: train=0.0953, val=0.0970 (↓), lr=0.000001
   • Epoch  81/100: train=0.0946, val=0.0965, patience=10/15, lr=0.000001
   • Epoch  91/100: train=0.0939, val=0.0961, patience=9/15, lr=0.000001

============================================================
📊 Round 6 Summary - Client client_24
   Epochs: 100/100
   LR: 0.000008 → 0.000001 (3 reductions)
   Train: Loss=0.0929, RMSE=0.3048, R²=-0.0461
   Val:   Loss=0.0957, RMSE=0.3094, R²=-0.0130
============================================================


📊 Round 6 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2479, R²: -0.0078

============================================================
🔄 Round 10 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0904, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0904, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0903, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0903, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0902, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0900, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 10 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0907, RMSE=0.3012, R²=0.0037
   Val:   Loss=0.0812, RMSE=0.2849, R²=0.0387
============================================================


📊 Round 10 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2469, R²: 0.0089

============================================================
🔄 Round 11 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 11 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=0.0353
   Val:   Loss=0.0914, RMSE=0.3024, R²=0.0148
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2492, R²: -0.0174

📊 Round 11 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2508, R²: -0.0357

============================================================
🔄 Round 13 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0957 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0956, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0956, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0955, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0955, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0951, patience=1/15, lr=0.000001
   ✓ Epoch  21/100: train=0.0878, val=0.0947 (↓), lr=0.000001
   • Epoch  31/100: train=0.0875, val=0.0943, patience=10/15, lr=0.000001
   • Epoch  41/100: train=0.0872, val=0.0939, patience=7/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0942)

============================================================
📊 Round 13 Summary - Client client_24
   Epochs: 49/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=0.0111
   Val:   Loss=0.0942, RMSE=0.3069, R²=0.0368
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2487, R²: -0.0132

📊 Round 13 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2458, R²: 0.0167

============================================================
🔄 Round 17 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 17 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2966, R²=0.0313
   Val:   Loss=0.0826, RMSE=0.2875, R²=0.0495
============================================================


============================================================
🔄 Round 18 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 18 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=0.0339
   Val:   Loss=0.0848, RMSE=0.2912, R²=0.0305
============================================================


============================================================
🔄 Round 20 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 20 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=0.0253
   Val:   Loss=0.0906, RMSE=0.3010, R²=0.0484
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0802, RMSE: 0.2831, MAE: 0.2450, R²: 0.0192

============================================================
🔄 Round 21 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 21 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=0.0314
   Val:   Loss=0.0892, RMSE=0.2987, R²=0.0239
============================================================


============================================================
🔄 Round 22 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 22 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2966, R²=0.0249
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0530
============================================================


============================================================
🔄 Round 23 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 23 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=0.0347
   Val:   Loss=0.0902, RMSE=0.3004, R²=0.0143
============================================================


============================================================
🔄 Round 24 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0924 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0923, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 24 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=0.0286
   Val:   Loss=0.0924, RMSE=0.3040, R²=0.0373
============================================================


============================================================
🔄 Round 25 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 25 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=0.0340
   Val:   Loss=0.0882, RMSE=0.2969, R²=0.0189
============================================================


============================================================
🔄 Round 27 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 27 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=0.0283
   Val:   Loss=0.0906, RMSE=0.3010, R²=0.0384
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2450, R²: 0.0209

============================================================
🔄 Round 31 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 31 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2964, R²=0.0231
   Val:   Loss=0.0840, RMSE=0.2899, R²=0.0646
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2450, R²: 0.0211

📊 Round 31 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2451, R²: 0.0213

============================================================
🔄 Round 38 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 38 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=0.0370
   Val:   Loss=0.0902, RMSE=0.3004, R²=0.0219
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2451, R²: 0.0214

============================================================
🔄 Round 44 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 44 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=0.0353
   Val:   Loss=0.0835, RMSE=0.2889, R²=0.0288
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2451, R²: 0.0214

============================================================
🔄 Round 45 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 45 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2968, R²=0.0308
   Val:   Loss=0.0821, RMSE=0.2866, R²=0.0449
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2452, R²: 0.0214

📊 Round 45 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2452, R²: 0.0214

============================================================
🔄 Round 50 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 50 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=0.0361
   Val:   Loss=0.0873, RMSE=0.2954, R²=-0.0014
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2452, R²: 0.0214

============================================================
🔄 Round 52 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 52 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=0.0319
   Val:   Loss=0.0848, RMSE=0.2912, R²=0.0451
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2452, R²: 0.0214

============================================================
🔄 Round 54 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 54 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2977, R²=0.0366
   Val:   Loss=0.0797, RMSE=0.2824, R²=0.0208
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2452, R²: 0.0214

============================================================
🔄 Round 59 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0949 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0949, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0949, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0949, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0949, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0949, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0949)

============================================================
📊 Round 59 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0345
   Val:   Loss=0.0949, RMSE=0.3081, R²=0.0389
============================================================


============================================================
🔄 Round 60 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0902, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0902, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0902, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0902, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0902, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0901, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 60 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0900, RMSE=0.2999, R²=0.0441
   Val:   Loss=0.0744, RMSE=0.2727, R²=-0.0193
============================================================


============================================================
🔄 Round 61 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0930 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0930, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0930, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0930, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0930, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0930, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0930)

============================================================
📊 Round 61 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=0.0344
   Val:   Loss=0.0930, RMSE=0.3050, R²=0.0395
============================================================


============================================================
🔄 Round 64 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 64 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2964, R²=0.0378
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0121
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2453, R²: 0.0213

📊 Round 64 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2453, R²: 0.0213

📊 Round 64 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2453, R²: 0.0212

📊 Round 64 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2453, R²: 0.0212

============================================================
🔄 Round 68 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 68 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=0.0379
   Val:   Loss=0.0882, RMSE=0.2970, R²=0.0255
============================================================


============================================================
🔄 Round 69 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0992 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0992, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0992, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0992, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0992, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0991, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0992)

============================================================
📊 Round 69 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=0.0422
   Val:   Loss=0.0992, RMSE=0.3149, R²=0.0120
============================================================


============================================================
🔄 Round 70 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 70 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=0.0370
   Val:   Loss=0.0913, RMSE=0.3021, R²=0.0247
============================================================


============================================================
🔄 Round 72 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 72 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2971, R²=0.0396
   Val:   Loss=0.0809, RMSE=0.2845, R²=0.0120
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2453, R²: 0.0212

============================================================
🔄 Round 75 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 75 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=0.0408
   Val:   Loss=0.0913, RMSE=0.3022, R²=0.0010
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2453, R²: 0.0212

============================================================
🔄 Round 76 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 76 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2959, R²=0.0326
   Val:   Loss=0.0837, RMSE=0.2893, R²=0.0489
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2453, R²: 0.0212

📊 Round 76 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2453, R²: 0.0212

============================================================
🔄 Round 81 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 81 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=0.0349
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0393
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2454, R²: 0.0212

============================================================
🔄 Round 82 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 82 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=0.0418
   Val:   Loss=0.0851, RMSE=0.2918, R²=0.0046
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2454, R²: 0.0212

============================================================
🔄 Round 83 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 83 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=0.0414
   Val:   Loss=0.0914, RMSE=0.3022, R²=0.0155
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2454, R²: 0.0212

📊 Round 83 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2454, R²: 0.0212

============================================================
🔄 Round 86 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0900, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0900, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0900, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0900, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0900, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0900, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 86 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0900, RMSE=0.3000, R²=0.0313
   Val:   Loss=0.0738, RMSE=0.2717, R²=0.0530
============================================================


============================================================
🔄 Round 87 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 87 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=0.0337
   Val:   Loss=0.0862, RMSE=0.2936, R²=0.0268
============================================================


============================================================
🔄 Round 88 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0979 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0979, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0979, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0979, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0979, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0979, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0979)

============================================================
📊 Round 88 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0397
   Val:   Loss=0.0979, RMSE=0.3129, R²=0.0240
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2454, R²: 0.0212

📊 Round 88 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2454, R²: 0.0212

============================================================
🔄 Round 90 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 90 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=0.0360
   Val:   Loss=0.0839, RMSE=0.2896, R²=0.0289
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2454, R²: 0.0212

📊 Round 90 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2454, R²: 0.0212

============================================================
🔄 Round 93 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0901, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0901, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0901, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0901, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0901, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0901, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 93 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0899, RMSE=0.2999, R²=0.0322
   Val:   Loss=0.0741, RMSE=0.2722, R²=0.0564
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2454, R²: 0.0212

============================================================
🔄 Round 94 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 94 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=0.0352
   Val:   Loss=0.0871, RMSE=0.2951, R²=0.0411
============================================================


============================================================
🔄 Round 96 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0892, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 96 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0893, RMSE=0.2988, R²=0.0430
   Val:   Loss=0.0766, RMSE=0.2767, R²=0.0014
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2454, R²: 0.0211

📊 Round 96 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2454, R²: 0.0211

📊 Round 96 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2454, R²: 0.0211

📊 Round 96 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2454, R²: 0.0211

============================================================
🔄 Round 103 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 103 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2937, R²=0.0450
   Val:   Loss=0.0888, RMSE=0.2980, R²=-0.0002
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2454, R²: 0.0211

📊 Round 103 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2454, R²: 0.0211

📊 Round 103 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2454, R²: 0.0211

============================================================
🔄 Round 107 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 107 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=0.0374
   Val:   Loss=0.0865, RMSE=0.2940, R²=0.0211
============================================================


============================================================
🔄 Round 109 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 109 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=0.0407
   Val:   Loss=0.0880, RMSE=0.2967, R²=0.0172
============================================================


============================================================
🔄 Round 110 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 110 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2964, R²=0.0271
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0546
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2454, R²: 0.0211

============================================================
🔄 Round 111 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 111 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=0.0340
   Val:   Loss=0.0885, RMSE=0.2974, R²=0.0342
============================================================


============================================================
🔄 Round 113 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0992 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0992, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0992, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0992, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0992, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0992, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0992)

============================================================
📊 Round 113 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0404
   Val:   Loss=0.0992, RMSE=0.3149, R²=0.0190
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2454, R²: 0.0211

============================================================
🔄 Round 115 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 115 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=0.0370
   Val:   Loss=0.0858, RMSE=0.2929, R²=0.0201
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2454, R²: 0.0211

============================================================
🔄 Round 116 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 116 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=0.0299
   Val:   Loss=0.0847, RMSE=0.2911, R²=0.0615
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2454, R²: 0.0211

============================================================
🔄 Round 122 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 122 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=0.0412
   Val:   Loss=0.0876, RMSE=0.2959, R²=0.0177
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2454, R²: 0.0211

============================================================
🔄 Round 123 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 123 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2954, R²=0.0345
   Val:   Loss=0.0846, RMSE=0.2909, R²=0.0413
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2454, R²: 0.0211

📊 Round 123 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2454, R²: 0.0211

============================================================
🔄 Round 126 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0941 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0941, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0941, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0941, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0941, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0942, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0941)

============================================================
📊 Round 126 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=0.0421
   Val:   Loss=0.0941, RMSE=0.3068, R²=0.0103
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2454, R²: 0.0211

============================================================
🔄 Round 127 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 127 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0387
   Val:   Loss=0.0892, RMSE=0.2987, R²=0.0248
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2454, R²: 0.0211

============================================================
🔄 Round 128 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 128 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2971, R²=0.0334
   Val:   Loss=0.0805, RMSE=0.2836, R²=0.0286
============================================================


============================================================
🔄 Round 129 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0957 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0957, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0957, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0957, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0957, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0957, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0957)

============================================================
📊 Round 129 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=0.0385
   Val:   Loss=0.0957, RMSE=0.3093, R²=0.0243
============================================================


============================================================
🔄 Round 130 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 130 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=0.0440
   Val:   Loss=0.0847, RMSE=0.2910, R²=0.0066
============================================================


============================================================
🔄 Round 131 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 131 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=0.0390
   Val:   Loss=0.0841, RMSE=0.2901, R²=0.0270
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2454, R²: 0.0211

📊 Round 131 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2454, R²: 0.0212

============================================================
🔄 Round 135 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 135 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0359
   Val:   Loss=0.0892, RMSE=0.2987, R²=0.0384
============================================================


============================================================
🔄 Round 136 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 136 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=0.0364
   Val:   Loss=0.0856, RMSE=0.2926, R²=0.0281
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2454, R²: 0.0212

📊 Round 136 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2454, R²: 0.0212

============================================================
🔄 Round 141 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 141 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=0.0381
   Val:   Loss=0.0874, RMSE=0.2956, R²=0.0173
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2454, R²: 0.0212

📊 Round 141 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2454, R²: 0.0212

============================================================
🔄 Round 144 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 144 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=0.0367
   Val:   Loss=0.0847, RMSE=0.2910, R²=0.0296
============================================================


============================================================
🔄 Round 145 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 145 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=0.0353
   Val:   Loss=0.0840, RMSE=0.2899, R²=0.0444
============================================================


============================================================
🔄 Round 146 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 146 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=0.0338
   Val:   Loss=0.0879, RMSE=0.2964, R²=0.0483
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2454, R²: 0.0212

============================================================
🔄 Round 147 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 147 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=0.0419
   Val:   Loss=0.0906, RMSE=0.3010, R²=0.0118
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2454, R²: 0.0213

============================================================
🔄 Round 148 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 148 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=0.0431
   Val:   Loss=0.0863, RMSE=0.2938, R²=0.0078
============================================================


============================================================
🔄 Round 149 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 149 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=0.0339
   Val:   Loss=0.0881, RMSE=0.2968, R²=0.0354
============================================================


============================================================
🔄 Round 151 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 151 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=0.0320
   Val:   Loss=0.0889, RMSE=0.2981, R²=0.0537
============================================================


============================================================
🔄 Round 152 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 152 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=0.0346
   Val:   Loss=0.0818, RMSE=0.2861, R²=0.0345
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2454, R²: 0.0214

📊 Round 152 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2454, R²: 0.0214

============================================================
🔄 Round 154 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 154 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0308
   Val:   Loss=0.0893, RMSE=0.2989, R²=0.0573
============================================================


============================================================
🔄 Round 155 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 155 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=0.0385
   Val:   Loss=0.0873, RMSE=0.2954, R²=0.0294
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2454, R²: 0.0214

📊 Round 155 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2454, R²: 0.0214

============================================================
🔄 Round 157 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 157 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=0.0374
   Val:   Loss=0.0804, RMSE=0.2835, R²=0.0362
============================================================


============================================================
🔄 Round 158 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 158 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2957, R²=0.0393
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0295
============================================================


============================================================
🔄 Round 159 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 159 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=0.0386
   Val:   Loss=0.0904, RMSE=0.3007, R²=0.0280
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2454, R²: 0.0214

📊 Round 159 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2454, R²: 0.0214

📊 Round 159 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2454, R²: 0.0214

============================================================
🔄 Round 164 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 164 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=0.0414
   Val:   Loss=0.0916, RMSE=0.3027, R²=0.0227
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2454, R²: 0.0215

============================================================
🔄 Round 165 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 165 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2977, R²=0.0344
   Val:   Loss=0.0788, RMSE=0.2807, R²=0.0472
============================================================


============================================================
🔄 Round 166 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 166 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=0.0382
   Val:   Loss=0.0865, RMSE=0.2941, R²=0.0252
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2454, R²: 0.0215

============================================================
🔄 Round 167 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 167 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2952, R²=0.0407
   Val:   Loss=0.0848, RMSE=0.2912, R²=0.0232
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2454, R²: 0.0215

============================================================
🔄 Round 171 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 171 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2969, R²=0.0346
   Val:   Loss=0.0806, RMSE=0.2839, R²=0.0496
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2454, R²: 0.0215

📊 Round 171 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2454, R²: 0.0214

============================================================
🔄 Round 173 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 173 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=0.0352
   Val:   Loss=0.0860, RMSE=0.2933, R²=0.0425
============================================================


============================================================
🔄 Round 176 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 176 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2976, R²=0.0359
   Val:   Loss=0.0789, RMSE=0.2810, R²=0.0449
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2455, R²: 0.0215

============================================================
🔄 Round 179 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 179 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2980, R²=0.0351
   Val:   Loss=0.0779, RMSE=0.2791, R²=0.0450
============================================================


============================================================
🔄 Round 180 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0948 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0948, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0948, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0948, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0948, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0948, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0948)

============================================================
📊 Round 180 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0376
   Val:   Loss=0.0948, RMSE=0.3079, R²=0.0133
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2455, R²: 0.0215

============================================================
🔄 Round 181 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0966 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0966, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0966, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0966, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0966, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0966, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0966)

============================================================
📊 Round 181 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0431
   Val:   Loss=0.0966, RMSE=0.3108, R²=0.0088
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2455, R²: 0.0215

============================================================
🔄 Round 182 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 182 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2966, R²=0.0437
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0092
============================================================


============================================================
🔄 Round 183 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 183 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=0.0381
   Val:   Loss=0.0851, RMSE=0.2917, R²=0.0254
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2455, R²: 0.0215

============================================================
🔄 Round 186 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 186 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2978, R²=0.0358
   Val:   Loss=0.0784, RMSE=0.2799, R²=0.0444
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2455, R²: 0.0214

📊 Round 186 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2455, R²: 0.0215

============================================================
🔄 Round 190 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0935 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0935, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0935, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0935, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0935, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0934, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0935)

============================================================
📊 Round 190 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0347
   Val:   Loss=0.0935, RMSE=0.3057, R²=0.0490
============================================================


============================================================
🔄 Round 193 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 193 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=0.0330
   Val:   Loss=0.0868, RMSE=0.2945, R²=0.0565
============================================================


📊 Round 193 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2455, R²: 0.0214

📊 Round 193 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2455, R²: 0.0215

============================================================
🔄 Round 197 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 197 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=0.0403
   Val:   Loss=0.0904, RMSE=0.3007, R²=0.0254
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2455, R²: 0.0215

============================================================
🔄 Round 198 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 198 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2962, R²=0.0369
   Val:   Loss=0.0822, RMSE=0.2866, R²=0.0385
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2455, R²: 0.0215

============================================================
🔄 Round 199 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 199 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=0.0377
   Val:   Loss=0.0837, RMSE=0.2894, R²=0.0372
============================================================


============================================================
🔄 Round 201 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 201 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=0.0385
   Val:   Loss=0.0860, RMSE=0.2932, R²=0.0316
============================================================


📊 Round 201 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2455, R²: 0.0215

============================================================
🔄 Round 203 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 203 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=0.0415
   Val:   Loss=0.0880, RMSE=0.2967, R²=0.0144
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2455, R²: 0.0215

============================================================
🔄 Round 204 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 204 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=0.0400
   Val:   Loss=0.0906, RMSE=0.3010, R²=0.0290
============================================================


📊 Round 204 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2455, R²: 0.0215

============================================================
🔄 Round 205 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 205 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=0.0374
   Val:   Loss=0.0926, RMSE=0.3043, R²=0.0332
============================================================


============================================================
🔄 Round 206 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 206 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=0.0428
   Val:   Loss=0.0870, RMSE=0.2949, R²=0.0054
============================================================


============================================================
🔄 Round 211 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 211 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=0.0387
   Val:   Loss=0.0842, RMSE=0.2901, R²=0.0358
============================================================


============================================================
🔄 Round 212 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 212 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=0.0403
   Val:   Loss=0.0891, RMSE=0.2984, R²=0.0293
============================================================


============================================================
🔄 Round 213 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 213 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2968, R²=0.0332
   Val:   Loss=0.0806, RMSE=0.2839, R²=0.0507
============================================================


📊 Round 213 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2455, R²: 0.0217

============================================================
🔄 Round 218 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 218 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2959, R²=0.0321
   Val:   Loss=0.0828, RMSE=0.2877, R²=0.0561
============================================================


📊 Round 218 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2455, R²: 0.0217

📊 Round 218 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2455, R²: 0.0217

📊 Round 218 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2455, R²: 0.0217

============================================================
🔄 Round 223 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 223 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2952, R²=0.0345
   Val:   Loss=0.0845, RMSE=0.2906, R²=0.0503
============================================================


📊 Round 223 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2455, R²: 0.0217

📊 Round 223 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2455, R²: 0.0217

============================================================
🔄 Round 228 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 228 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=0.0431
   Val:   Loss=0.0907, RMSE=0.3011, R²=0.0100
============================================================


📊 Round 228 Test Metrics:
   Loss: 0.0799, RMSE: 0.2828, MAE: 0.2455, R²: 0.0217

============================================================
🔄 Round 230 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 230 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=0.0409
   Val:   Loss=0.0903, RMSE=0.3004, R²=0.0279
============================================================


============================================================
🔄 Round 231 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 231 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=0.0368
   Val:   Loss=0.0862, RMSE=0.2936, R²=0.0348
============================================================


📊 Round 231 Test Metrics:
   Loss: 0.0799, RMSE: 0.2828, MAE: 0.2455, R²: 0.0217

📊 Round 231 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2455, R²: 0.0217

📊 Round 231 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2455, R²: 0.0217

📊 Round 231 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2455, R²: 0.0217

📊 Round 231 Test Metrics:
   Loss: 0.0799, RMSE: 0.2828, MAE: 0.2455, R²: 0.0217

📊 Round 231 Test Metrics:
   Loss: 0.0799, RMSE: 0.2828, MAE: 0.2455, R²: 0.0217

============================================================
🔄 Round 241 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 241 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0890, RMSE=0.2984, R²=0.0356
   Val:   Loss=0.0767, RMSE=0.2770, R²=0.0339
============================================================


📊 Round 241 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2455, R²: 0.0217

============================================================
🔄 Round 243 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 243 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2980, R²=0.0390
   Val:   Loss=0.0776, RMSE=0.2785, R²=0.0355
============================================================


📊 Round 243 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2455, R²: 0.0217

============================================================
🔄 Round 246 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 246 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2962, R²=0.0358
   Val:   Loss=0.0820, RMSE=0.2863, R²=0.0313
============================================================


============================================================
🔄 Round 248 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 248 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=0.0416
   Val:   Loss=0.0902, RMSE=0.3003, R²=0.0241
============================================================


📊 Round 248 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2455, R²: 0.0217

============================================================
🔄 Round 249 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 249 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=0.0407
   Val:   Loss=0.0901, RMSE=0.3002, R²=-0.0130
============================================================


============================================================
🔄 Round 250 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 250 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=0.0404
   Val:   Loss=0.0865, RMSE=0.2941, R²=0.0278
============================================================


📊 Round 250 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2455, R²: 0.0217

============================================================
🔄 Round 252 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 252 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=0.0424
   Val:   Loss=0.0893, RMSE=0.2989, R²=0.0206
============================================================


📊 Round 252 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2455, R²: 0.0217

============================================================
🔄 Round 253 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 253 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=0.0352
   Val:   Loss=0.0820, RMSE=0.2863, R²=0.0397
============================================================


📊 Round 253 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2455, R²: 0.0217

============================================================
🔄 Round 254 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0897, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0897, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0897, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0897, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0897, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 254 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0895, RMSE=0.2991, R²=0.0407
   Val:   Loss=0.0750, RMSE=0.2738, R²=0.0284
============================================================


📊 Round 254 Test Metrics:
   Loss: 0.0799, RMSE: 0.2828, MAE: 0.2455, R²: 0.0217

============================================================
🔄 Round 256 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 256 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2972, R²=0.0355
   Val:   Loss=0.0795, RMSE=0.2819, R²=0.0505
============================================================


📊 Round 256 Test Metrics:
   Loss: 0.0799, RMSE: 0.2828, MAE: 0.2455, R²: 0.0217

============================================================
🔄 Round 257 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0962 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0962, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0962, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0962, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0962, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0962, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0962)

============================================================
📊 Round 257 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0286
   Val:   Loss=0.0962, RMSE=0.3102, R²=0.0685
============================================================


📊 Round 257 Test Metrics:
   Loss: 0.0799, RMSE: 0.2828, MAE: 0.2455, R²: 0.0217

📊 Round 257 Test Metrics:
   Loss: 0.0799, RMSE: 0.2828, MAE: 0.2455, R²: 0.0217

============================================================
🔄 Round 259 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0942 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0942, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0942, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0942, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0942, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0942, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0942)

============================================================
📊 Round 259 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0408
   Val:   Loss=0.0942, RMSE=0.3069, R²=0.0281
============================================================


📊 Round 259 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2455, R²: 0.0218

📊 Round 259 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2455, R²: 0.0218

📊 Round 259 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2455, R²: 0.0218

============================================================
🔄 Round 268 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0929 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0929, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0929, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0929, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0929, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0929, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 268 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0413
   Val:   Loss=0.0929, RMSE=0.3048, R²=0.0254
============================================================


============================================================
🔄 Round 272 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 272 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=0.0350
   Val:   Loss=0.0872, RMSE=0.2954, R²=0.0531
============================================================


📊 Round 272 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2455, R²: 0.0218

============================================================
🔄 Round 275 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 275 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0433
   Val:   Loss=0.0908, RMSE=0.3013, R²=0.0131
============================================================


📊 Round 275 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2455, R²: 0.0218

📊 Round 275 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2455, R²: 0.0218

📊 Round 275 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2455, R²: 0.0219

============================================================
🔄 Round 279 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 279 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=0.0413
   Val:   Loss=0.0916, RMSE=0.3026, R²=0.0299
============================================================


============================================================
🔄 Round 283 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 283 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=0.0395
   Val:   Loss=0.0848, RMSE=0.2911, R²=0.0098
============================================================


📊 Round 283 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2455, R²: 0.0218

📊 Round 283 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2455, R²: 0.0218

📊 Round 283 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2455, R²: 0.0218

============================================================
🔄 Round 290 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 290 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2940, R²=0.0385
   Val:   Loss=0.0868, RMSE=0.2947, R²=0.0404
============================================================


============================================================
🔄 Round 292 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 292 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=0.0331
   Val:   Loss=0.0864, RMSE=0.2940, R²=0.0616
============================================================


============================================================
🔄 Round 293 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 293 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2923, R²=0.0417
   Val:   Loss=0.0908, RMSE=0.3014, R²=0.0206
============================================================


📊 Round 293 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2455, R²: 0.0219

============================================================
🔄 Round 294 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0963 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0963, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0963, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0963, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0963, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0963, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0963)

============================================================
📊 Round 294 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0445
   Val:   Loss=0.0963, RMSE=0.3103, R²=0.0177
============================================================


📊 Round 294 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2455, R²: 0.0219

📊 Round 294 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2455, R²: 0.0219

📊 Round 294 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2455, R²: 0.0219

📊 Round 294 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2455, R²: 0.0220

============================================================
🔄 Round 300 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 300 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0373
   Val:   Loss=0.0906, RMSE=0.3010, R²=0.0444
============================================================


============================================================
🔄 Round 303 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 303 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0409
   Val:   Loss=0.0926, RMSE=0.3042, R²=0.0316
============================================================


📊 Round 303 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2455, R²: 0.0220

============================================================
🔄 Round 304 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 304 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2982, R²=0.0473
   Val:   Loss=0.0769, RMSE=0.2774, R²=-0.0060
============================================================


📊 Round 304 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2455, R²: 0.0220

============================================================
🔄 Round 306 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0892, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 306 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0891, RMSE=0.2985, R²=0.0370
   Val:   Loss=0.0761, RMSE=0.2759, R²=0.0465
============================================================


📊 Round 306 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2455, R²: 0.0220

============================================================
🔄 Round 307 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 307 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2976, R²=0.0397
   Val:   Loss=0.0783, RMSE=0.2799, R²=0.0294
============================================================


📊 Round 307 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2455, R²: 0.0221

============================================================
🔄 Round 308 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 308 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=0.0345
   Val:   Loss=0.0896, RMSE=0.2994, R²=0.0561
============================================================


============================================================
🔄 Round 309 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 309 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2959, R²=0.0357
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0480
============================================================


📊 Round 309 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2455, R²: 0.0221

📊 Round 309 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2455, R²: 0.0221

============================================================
🔄 Round 312 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 312 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=0.0341
   Val:   Loss=0.0874, RMSE=0.2956, R²=0.0415
============================================================


📊 Round 312 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2455, R²: 0.0221

============================================================
🔄 Round 314 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0895, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0895, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0895, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0895, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0895, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0894, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 314 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0898, RMSE=0.2996, R²=0.0373
   Val:   Loss=0.0735, RMSE=0.2710, R²=0.0457
============================================================


📊 Round 314 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2455, R²: 0.0221

📊 Round 314 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2455, R²: 0.0221

📊 Round 314 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2455, R²: 0.0221

📊 Round 314 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2455, R²: 0.0221

============================================================
🔄 Round 318 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 318 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0415
   Val:   Loss=0.0926, RMSE=0.3043, R²=0.0300
============================================================


============================================================
🔄 Round 319 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0890, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 319 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0890, RMSE=0.2984, R²=0.0396
   Val:   Loss=0.0764, RMSE=0.2765, R²=0.0372
============================================================


📊 Round 319 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2455, R²: 0.0222

📊 Round 319 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2455, R²: 0.0222

============================================================
🔄 Round 322 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0935 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0935, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0935, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0935, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0936, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0937, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0935)

============================================================
📊 Round 322 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=0.0443
   Val:   Loss=0.0935, RMSE=0.3058, R²=-0.0299
============================================================


📊 Round 322 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2455, R²: 0.0222

============================================================
🔄 Round 325 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 325 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=0.0373
   Val:   Loss=0.0824, RMSE=0.2871, R²=0.0448
============================================================


📊 Round 325 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2455, R²: 0.0222

📊 Round 325 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2455, R²: 0.0222

============================================================
🔄 Round 328 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 328 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=0.0404
   Val:   Loss=0.0878, RMSE=0.2962, R²=0.0345
============================================================


📊 Round 328 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2455, R²: 0.0222

============================================================
🔄 Round 330 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 330 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2927, R²=0.0379
   Val:   Loss=0.0899, RMSE=0.2999, R²=0.0439
============================================================


📊 Round 330 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2455, R²: 0.0223

============================================================
🔄 Round 332 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0933 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0933, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0933, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0933, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0933, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0934, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0933)

============================================================
📊 Round 332 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0367
   Val:   Loss=0.0933, RMSE=0.3055, R²=0.0256
============================================================


============================================================
🔄 Round 333 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0927, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 333 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0474
   Val:   Loss=0.0926, RMSE=0.3044, R²=0.0076
============================================================


📊 Round 333 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2455, R²: 0.0223

📊 Round 333 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2455, R²: 0.0223

📊 Round 333 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2455, R²: 0.0222

============================================================
🔄 Round 341 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 341 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=0.0444
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0107
============================================================


📊 Round 341 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2455, R²: 0.0222

📊 Round 341 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2455, R²: 0.0222

============================================================
🔄 Round 345 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0937 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0937, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0937, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0937, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0937, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0937, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0937)

============================================================
📊 Round 345 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0364
   Val:   Loss=0.0937, RMSE=0.3061, R²=0.0417
============================================================


============================================================
🔄 Round 347 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0900, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0900, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0900, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0900, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0900, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0900, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 347 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0897, RMSE=0.2996, R²=0.0346
   Val:   Loss=0.0735, RMSE=0.2711, R²=0.0590
============================================================


============================================================
🔄 Round 348 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 348 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=0.0417
   Val:   Loss=0.0914, RMSE=0.3023, R²=0.0244
============================================================


📊 Round 348 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2455, R²: 0.0222

============================================================
🔄 Round 349 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 349 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=0.0359
   Val:   Loss=0.0888, RMSE=0.2980, R²=0.0475
============================================================


============================================================
🔄 Round 351 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 351 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=0.0380
   Val:   Loss=0.0847, RMSE=0.2911, R²=0.0339
============================================================


============================================================
🔄 Round 353 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 353 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=0.0443
   Val:   Loss=0.0841, RMSE=0.2901, R²=0.0183
============================================================


📊 Round 353 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2455, R²: 0.0221

============================================================
🔄 Round 354 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 354 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0446
   Val:   Loss=0.0926, RMSE=0.3043, R²=0.0196
============================================================


============================================================
🔄 Round 355 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 355 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2961, R²=0.0329
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0463
============================================================


📊 Round 355 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2455, R²: 0.0221

📊 Round 355 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2455, R²: 0.0221

============================================================
🔄 Round 358 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 358 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2966, R²=0.0376
   Val:   Loss=0.0804, RMSE=0.2836, R²=0.0447
============================================================


============================================================
🔄 Round 359 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 359 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2964, R²=0.0398
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0299
============================================================


📊 Round 359 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2455, R²: 0.0221

📊 Round 359 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2455, R²: 0.0221

📊 Round 359 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2455, R²: 0.0221

📊 Round 359 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2455, R²: 0.0221

📊 Round 359 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2455, R²: 0.0221

📊 Round 359 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2455, R²: 0.0221

============================================================
🔄 Round 369 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 369 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=0.0361
   Val:   Loss=0.0859, RMSE=0.2931, R²=0.0533
============================================================


📊 Round 369 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2455, R²: 0.0222

============================================================
🔄 Round 370 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 370 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2937, R²=0.0388
   Val:   Loss=0.0874, RMSE=0.2956, R²=0.0373
============================================================


============================================================
🔄 Round 371 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 371 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0390
   Val:   Loss=0.0883, RMSE=0.2971, R²=0.0388
============================================================


============================================================
🔄 Round 373 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 373 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=0.0375
   Val:   Loss=0.0861, RMSE=0.2934, R²=0.0232
============================================================


📊 Round 373 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2455, R²: 0.0222

============================================================
🔄 Round 374 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 374 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2969, R²=0.0417
   Val:   Loss=0.0798, RMSE=0.2824, R²=0.0036
============================================================


📊 Round 374 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2455, R²: 0.0222

============================================================
🔄 Round 376 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 376 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=0.0395
   Val:   Loss=0.0858, RMSE=0.2929, R²=0.0279
============================================================


============================================================
🔄 Round 377 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 377 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2973, R²=0.0390
   Val:   Loss=0.0788, RMSE=0.2807, R²=0.0323
============================================================


============================================================
🔄 Round 378 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 378 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=0.0431
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0082
============================================================


============================================================
🔄 Round 379 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 379 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=0.0400
   Val:   Loss=0.0829, RMSE=0.2880, R²=0.0357
============================================================


📊 Round 379 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2455, R²: 0.0222

📊 Round 379 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2455, R²: 0.0222

📊 Round 379 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2455, R²: 0.0222

📊 Round 379 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2455, R²: 0.0223

📊 Round 379 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2455, R²: 0.0223

📊 Round 379 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2455, R²: 0.0223

============================================================
🔄 Round 392 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 392 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=0.0414
   Val:   Loss=0.0863, RMSE=0.2939, R²=-0.0043
============================================================


============================================================
🔄 Round 393 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 393 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=0.0423
   Val:   Loss=0.0843, RMSE=0.2904, R²=0.0293
============================================================


📊 Round 393 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2455, R²: 0.0224

📊 Round 393 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2455, R²: 0.0223

📊 Round 393 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2455, R²: 0.0223

📊 Round 393 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2455, R²: 0.0223

============================================================
🔄 Round 397 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 397 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2968, R²=0.0456
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0081
============================================================


============================================================
🔄 Round 400 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 400 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=0.0350
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0599
============================================================


📊 Round 400 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2455, R²: 0.0223

============================================================
🔄 Round 401 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 401 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2952, R²=0.0337
   Val:   Loss=0.0838, RMSE=0.2895, R²=0.0476
============================================================


============================================================
🔄 Round 402 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0895, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0895, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0894, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0894, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0894, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0894, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 402 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0895, RMSE=0.2991, R²=0.0373
   Val:   Loss=0.0744, RMSE=0.2728, R²=0.0517
============================================================


📊 Round 402 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2455, R²: 0.0224

============================================================
🔄 Round 406 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 406 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0420
   Val:   Loss=0.0890, RMSE=0.2983, R²=0.0310
============================================================


============================================================
🔄 Round 407 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 407 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=0.0450
   Val:   Loss=0.0860, RMSE=0.2932, R²=0.0183
============================================================


============================================================
🔄 Round 408 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 408 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0392
   Val:   Loss=0.0880, RMSE=0.2966, R²=0.0405
============================================================


📊 Round 408 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2455, R²: 0.0224

============================================================
🔄 Round 411 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 411 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2973, R²=0.0409
   Val:   Loss=0.0786, RMSE=0.2803, R²=0.0355
============================================================


📊 Round 411 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2455, R²: 0.0225

📊 Round 411 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2455, R²: 0.0225

📊 Round 411 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2455, R²: 0.0226

📊 Round 411 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2455, R²: 0.0226

📊 Round 411 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2455, R²: 0.0226

============================================================
🔄 Round 418 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 418 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2979, R²=0.0406
   Val:   Loss=0.0772, RMSE=0.2779, R²=0.0225
============================================================


============================================================
🔄 Round 420 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 420 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=0.0394
   Val:   Loss=0.0857, RMSE=0.2928, R²=0.0315
============================================================


============================================================
🔄 Round 421 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 421 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=0.0425
   Val:   Loss=0.0827, RMSE=0.2875, R²=0.0282
============================================================


📊 Round 421 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2455, R²: 0.0226

============================================================
🔄 Round 422 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 422 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=0.0330
   Val:   Loss=0.0893, RMSE=0.2988, R²=0.0566
============================================================


============================================================
🔄 Round 427 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 427 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=0.0360
   Val:   Loss=0.0866, RMSE=0.2942, R²=0.0511
============================================================


============================================================
🔄 Round 429 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 429 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2952, R²=0.0348
   Val:   Loss=0.0837, RMSE=0.2893, R²=0.0538
============================================================


📊 Round 429 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2455, R²: 0.0226

============================================================
🔄 Round 431 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 431 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=0.0409
   Val:   Loss=0.0857, RMSE=0.2928, R²=0.0328
============================================================


📊 Round 431 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2455, R²: 0.0227

============================================================
🔄 Round 432 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 432 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2964, R²=0.0353
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0561
============================================================


📊 Round 432 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2455, R²: 0.0227

============================================================
🔄 Round 436 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 436 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2978, R²=0.0398
   Val:   Loss=0.0775, RMSE=0.2784, R²=0.0374
============================================================


============================================================
🔄 Round 437 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 437 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=0.0451
   Val:   Loss=0.0893, RMSE=0.2989, R²=0.0070
============================================================


============================================================
🔄 Round 439 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 439 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=0.0372
   Val:   Loss=0.0846, RMSE=0.2909, R²=0.0314
============================================================


📊 Round 439 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2455, R²: 0.0227

============================================================
🔄 Round 440 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0958 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0958, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0958, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0958, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0958, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0958, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0958)

============================================================
📊 Round 440 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0441
   Val:   Loss=0.0958, RMSE=0.3095, R²=0.0255
============================================================


📊 Round 440 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2455, R²: 0.0227

📊 Round 440 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2455, R²: 0.0228

📊 Round 440 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2454, R²: 0.0228

============================================================
🔄 Round 445 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 445 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=0.0376
   Val:   Loss=0.0869, RMSE=0.2948, R²=0.0492
============================================================


📊 Round 445 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2454, R²: 0.0228

============================================================
🔄 Round 448 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 448 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2967, R²=0.0421
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0181
============================================================


📊 Round 448 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2454, R²: 0.0228

============================================================
🔄 Round 449 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 449 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0380
   Val:   Loss=0.0920, RMSE=0.3034, R²=0.0389
============================================================


📊 Round 449 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2454, R²: 0.0228

============================================================
🔄 Round 450 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 450 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0417
   Val:   Loss=0.0880, RMSE=0.2966, R²=0.0141
============================================================


📊 Round 450 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2454, R²: 0.0229

📊 Round 450 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2454, R²: 0.0229

============================================================
🔄 Round 454 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 454 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0364
   Val:   Loss=0.0920, RMSE=0.3033, R²=0.0532
============================================================


📊 Round 454 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2454, R²: 0.0229

============================================================
🔄 Round 457 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 457 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=0.0390
   Val:   Loss=0.0876, RMSE=0.2959, R²=0.0440
============================================================


📊 Round 457 Test Metrics:
   Loss: 0.0798, RMSE: 0.2826, MAE: 0.2454, R²: 0.0229

============================================================
🔄 Round 461 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 461 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2979, R²=0.0416
   Val:   Loss=0.0772, RMSE=0.2778, R²=0.0289
============================================================


📊 Round 461 Test Metrics:
   Loss: 0.0798, RMSE: 0.2826, MAE: 0.2454, R²: 0.0229

============================================================
🔄 Round 463 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 463 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=0.0418
   Val:   Loss=0.0809, RMSE=0.2845, R²=0.0330
============================================================


============================================================
🔄 Round 465 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 465 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=0.0357
   Val:   Loss=0.0904, RMSE=0.3006, R²=0.0532
============================================================


============================================================
🔄 Round 466 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 466 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2947, R²=0.0313
   Val:   Loss=0.0846, RMSE=0.2909, R²=0.0750
============================================================


============================================================
🔄 Round 467 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 467 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2968, R²=0.0353
   Val:   Loss=0.0797, RMSE=0.2824, R²=0.0613
============================================================


============================================================
🔄 Round 468 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0983 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0983, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0983, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0983, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0983, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0983, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0983)

============================================================
📊 Round 468 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=0.0423
   Val:   Loss=0.0983, RMSE=0.3135, R²=0.0321
============================================================


============================================================
🔄 Round 472 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 472 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=0.0343
   Val:   Loss=0.0792, RMSE=0.2815, R²=0.0645
============================================================


📊 Round 472 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2455, R²: 0.0229

📊 Round 472 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2455, R²: 0.0229

============================================================
🔄 Round 475 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 475 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=0.0415
   Val:   Loss=0.0860, RMSE=0.2932, R²=0.0351
============================================================


📊 Round 475 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2454, R²: 0.0229

============================================================
🔄 Round 476 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 476 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=0.0385
   Val:   Loss=0.0840, RMSE=0.2898, R²=0.0474
============================================================


📊 Round 476 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2454, R²: 0.0229

============================================================
🔄 Round 478 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0963 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0963, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0963, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0963, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0963, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0962, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0963)

============================================================
📊 Round 478 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2897, R²=0.0410
   Val:   Loss=0.0963, RMSE=0.3103, R²=0.0355
============================================================


📊 Round 478 Test Metrics:
   Loss: 0.0798, RMSE: 0.2826, MAE: 0.2454, R²: 0.0229

📊 Round 478 Test Metrics:
   Loss: 0.0798, RMSE: 0.2826, MAE: 0.2454, R²: 0.0230

============================================================
🔄 Round 481 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0950 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0950, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0950, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0950, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0950, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0950, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0950)

============================================================
📊 Round 481 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0384
   Val:   Loss=0.0950, RMSE=0.3082, R²=0.0386
============================================================


📊 Round 481 Test Metrics:
   Loss: 0.0798, RMSE: 0.2826, MAE: 0.2454, R²: 0.0230

============================================================
🔄 Round 483 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 483 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=0.0344
   Val:   Loss=0.0892, RMSE=0.2986, R²=0.0567
============================================================


📊 Round 483 Test Metrics:
   Loss: 0.0798, RMSE: 0.2826, MAE: 0.2454, R²: 0.0230

============================================================
🔄 Round 484 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 484 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2971, R²=0.0467
   Val:   Loss=0.0790, RMSE=0.2810, R²=0.0019
============================================================


📊 Round 484 Test Metrics:
   Loss: 0.0798, RMSE: 0.2826, MAE: 0.2454, R²: 0.0230

============================================================
🔄 Round 486 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 486 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2973, R²=0.0332
   Val:   Loss=0.0786, RMSE=0.2803, R²=0.0574
============================================================


📊 Round 486 Test Metrics:
   Loss: 0.0798, RMSE: 0.2826, MAE: 0.2454, R²: 0.0230

📊 Round 486 Test Metrics:
   Loss: 0.0798, RMSE: 0.2826, MAE: 0.2454, R²: 0.0230

============================================================
🔄 Round 492 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 492 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2969, R²=0.0437
   Val:   Loss=0.0794, RMSE=0.2818, R²=0.0223
============================================================


============================================================
🔄 Round 495 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 495 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=0.0403
   Val:   Loss=0.0887, RMSE=0.2979, R²=0.0383
============================================================


📊 Round 495 Test Metrics:
   Loss: 0.0798, RMSE: 0.2826, MAE: 0.2454, R²: 0.0230

============================================================
🔄 Round 496 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 496 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2972, R²=0.0359
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0601
============================================================


📊 Round 496 Test Metrics:
   Loss: 0.0798, RMSE: 0.2826, MAE: 0.2454, R²: 0.0230

============================================================
🔄 Round 497 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 497 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=0.0379
   Val:   Loss=0.0855, RMSE=0.2924, R²=0.0353
============================================================


📊 Round 497 Test Metrics:
   Loss: 0.0798, RMSE: 0.2826, MAE: 0.2454, R²: 0.0230

📊 Round 497 Test Metrics:
   Loss: 0.0798, RMSE: 0.2826, MAE: 0.2454, R²: 0.0230

📊 Round 497 Test Metrics:
   Loss: 0.0798, RMSE: 0.2826, MAE: 0.2454, R²: 0.0230

📊 Round 497 Test Metrics:
   Loss: 0.0798, RMSE: 0.2826, MAE: 0.2454, R²: 0.0230

============================================================
🔄 Round 506 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 506 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=0.0383
   Val:   Loss=0.0826, RMSE=0.2875, R²=0.0482
============================================================


📊 Round 506 Test Metrics:
   Loss: 0.0798, RMSE: 0.2826, MAE: 0.2454, R²: 0.0230

📊 Round 506 Test Metrics:
   Loss: 0.0798, RMSE: 0.2826, MAE: 0.2454, R²: 0.0230

============================================================
🔄 Round 510 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 510 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=0.0429
   Val:   Loss=0.0865, RMSE=0.2941, R²=0.0296
============================================================


📊 Round 510 Test Metrics:
   Loss: 0.0798, RMSE: 0.2826, MAE: 0.2454, R²: 0.0230

============================================================
🔄 Round 511 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 511 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2967, R²=0.0348
   Val:   Loss=0.0799, RMSE=0.2826, R²=0.0589
============================================================


📊 Round 511 Test Metrics:
   Loss: 0.0798, RMSE: 0.2826, MAE: 0.2454, R²: 0.0230

============================================================
🔄 Round 512 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 512 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=0.0436
   Val:   Loss=0.0860, RMSE=0.2932, R²=0.0259
============================================================


📊 Round 512 Test Metrics:
   Loss: 0.0798, RMSE: 0.2826, MAE: 0.2454, R²: 0.0231

📊 Round 512 Test Metrics:
   Loss: 0.0798, RMSE: 0.2826, MAE: 0.2454, R²: 0.0231

============================================================
🔄 Round 515 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 515 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2952, R²=0.0398
   Val:   Loss=0.0835, RMSE=0.2889, R²=0.0402
============================================================


📊 Round 515 Test Metrics:
   Loss: 0.0798, RMSE: 0.2826, MAE: 0.2454, R²: 0.0231

============================================================
🔄 Round 517 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 517 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=0.0373
   Val:   Loss=0.0827, RMSE=0.2875, R²=0.0531
============================================================


📊 Round 517 Test Metrics:
   Loss: 0.0798, RMSE: 0.2826, MAE: 0.2454, R²: 0.0231

📊 Round 517 Test Metrics:
   Loss: 0.0798, RMSE: 0.2826, MAE: 0.2454, R²: 0.0231

============================================================
🔄 Round 520 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 520 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=0.0396
   Val:   Loss=0.0859, RMSE=0.2932, R²=0.0434
============================================================


📊 Round 520 Test Metrics:
   Loss: 0.0798, RMSE: 0.2826, MAE: 0.2454, R²: 0.0231

📊 Round 520 Test Metrics:
   Loss: 0.0798, RMSE: 0.2826, MAE: 0.2454, R²: 0.0231

📊 Round 520 Test Metrics:
   Loss: 0.0798, RMSE: 0.2826, MAE: 0.2454, R²: 0.0231

📊 Round 520 Test Metrics:
   Loss: 0.0798, RMSE: 0.2826, MAE: 0.2454, R²: 0.0231

============================================================
🔄 Round 525 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 525 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0363
   Val:   Loss=0.0921, RMSE=0.3034, R²=0.0419
============================================================


📊 Round 525 Test Metrics:
   Loss: 0.0798, RMSE: 0.2826, MAE: 0.2454, R²: 0.0231

============================================================
🔄 Round 528 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 528 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=0.0417
   Val:   Loss=0.0852, RMSE=0.2920, R²=0.0332
============================================================


============================================================
🔄 Round 529 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 529 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=0.0441
   Val:   Loss=0.0860, RMSE=0.2933, R²=0.0249
============================================================


📊 Round 529 Test Metrics:
   Loss: 0.0798, RMSE: 0.2826, MAE: 0.2454, R²: 0.0231

============================================================
🔄 Round 530 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 530 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2964, R²=0.0406
   Val:   Loss=0.0806, RMSE=0.2840, R²=0.0321
============================================================


📊 Round 530 Test Metrics:
   Loss: 0.0798, RMSE: 0.2826, MAE: 0.2454, R²: 0.0231

============================================================
🔄 Round 533 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 533 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0476
   Val:   Loss=0.0875, RMSE=0.2958, R²=0.0098
============================================================


============================================================
🔄 Round 534 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 534 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2969, R²=0.0397
   Val:   Loss=0.0792, RMSE=0.2815, R²=0.0415
============================================================


============================================================
🔄 Round 535 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 535 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=0.0406
   Val:   Loss=0.0860, RMSE=0.2932, R²=0.0402
============================================================


============================================================
🔄 Round 536 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 536 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2944, R²=0.0407
   Val:   Loss=0.0853, RMSE=0.2921, R²=0.0317
============================================================


📊 Round 536 Test Metrics:
   Loss: 0.0798, RMSE: 0.2826, MAE: 0.2455, R²: 0.0230

📊 Round 536 Test Metrics:
   Loss: 0.0798, RMSE: 0.2826, MAE: 0.2455, R²: 0.0230

============================================================
🔄 Round 539 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 539 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0481
   Val:   Loss=0.0899, RMSE=0.2998, R²=0.0055
============================================================


============================================================
🔄 Round 541 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 541 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0408
   Val:   Loss=0.0878, RMSE=0.2964, R²=0.0395
============================================================


📊 Round 541 Test Metrics:
   Loss: 0.0798, RMSE: 0.2826, MAE: 0.2455, R²: 0.0230

============================================================
🔄 Round 543 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 543 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=0.0441
   Val:   Loss=0.0864, RMSE=0.2940, R²=0.0249
============================================================


============================================================
🔄 Round 544 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 544 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2964, R²=0.0400
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0429
============================================================


============================================================
🔄 Round 546 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 546 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2952, R²=0.0424
   Val:   Loss=0.0834, RMSE=0.2889, R²=0.0178
============================================================


============================================================
🔄 Round 548 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0967 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0967, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0967, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0967, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0967, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0967, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0967)

============================================================
📊 Round 548 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0398
   Val:   Loss=0.0967, RMSE=0.3109, R²=0.0342
============================================================


📊 Round 548 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2455, R²: 0.0229

============================================================
🔄 Round 553 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 553 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=0.0406
   Val:   Loss=0.0853, RMSE=0.2920, R²=0.0404
============================================================


============================================================
🔄 Round 554 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 554 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0437
   Val:   Loss=0.0916, RMSE=0.3026, R²=0.0285
============================================================


📊 Round 554 Test Metrics:
   Loss: 0.0798, RMSE: 0.2826, MAE: 0.2455, R²: 0.0229

============================================================
🔄 Round 559 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 559 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=0.0438
   Val:   Loss=0.0858, RMSE=0.2930, R²=0.0277
============================================================


📊 Round 559 Test Metrics:
   Loss: 0.0798, RMSE: 0.2826, MAE: 0.2455, R²: 0.0230

📊 Round 559 Test Metrics:
   Loss: 0.0798, RMSE: 0.2826, MAE: 0.2455, R²: 0.0230

============================================================
🔄 Round 561 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 561 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0366
   Val:   Loss=0.0887, RMSE=0.2978, R²=0.0457
============================================================


============================================================
🔄 Round 562 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 562 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=0.0374
   Val:   Loss=0.0872, RMSE=0.2953, R²=0.0466
============================================================


📊 Round 562 Test Metrics:
   Loss: 0.0798, RMSE: 0.2826, MAE: 0.2455, R²: 0.0230

============================================================
🔄 Round 563 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 563 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=0.0421
   Val:   Loss=0.0837, RMSE=0.2893, R²=0.0249
============================================================


📊 Round 563 Test Metrics:
   Loss: 0.0798, RMSE: 0.2826, MAE: 0.2454, R²: 0.0231

============================================================
🔄 Round 564 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0953 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0953, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0953, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0953, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0953, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0953, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0953)

============================================================
📊 Round 564 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=0.0351
   Val:   Loss=0.0953, RMSE=0.3088, R²=0.0557
============================================================


📊 Round 564 Test Metrics:
   Loss: 0.0798, RMSE: 0.2826, MAE: 0.2454, R²: 0.0231

📊 Round 564 Test Metrics:
   Loss: 0.0798, RMSE: 0.2826, MAE: 0.2454, R²: 0.0231

📊 Round 564 Test Metrics:
   Loss: 0.0798, RMSE: 0.2826, MAE: 0.2454, R²: 0.0231

============================================================
🔄 Round 568 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 568 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=0.0422
   Val:   Loss=0.0851, RMSE=0.2917, R²=0.0273
============================================================


============================================================
🔄 Round 571 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0940 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0940, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0940, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0940, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0940, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0940, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0940)

============================================================
📊 Round 571 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=0.0381
   Val:   Loss=0.0940, RMSE=0.3066, R²=0.0485
============================================================


📊 Round 571 Test Metrics:
   Loss: 0.0798, RMSE: 0.2826, MAE: 0.2454, R²: 0.0231

📊 Round 571 Test Metrics:
   Loss: 0.0798, RMSE: 0.2826, MAE: 0.2454, R²: 0.0231

============================================================
🔄 Round 573 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 573 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=0.0401
   Val:   Loss=0.0852, RMSE=0.2919, R²=0.0357
============================================================


📊 Round 573 Test Metrics:
   Loss: 0.0798, RMSE: 0.2826, MAE: 0.2454, R²: 0.0231

❌ Client client_24 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8688 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8688 {grpc_message:"Socket closed", grpc_status:14}"
>
