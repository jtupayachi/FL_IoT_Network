[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 104750b3-94b6-4ac2-aecd-849f211e2a26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 685363a4-8304-413c-98b3-53ed81768c66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80dad516-bd19-4f8e-b633-d8b53648456e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e6d7395-377f-4ea3-a3e1-f65c59e725e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9fdfbc5a-fe3a-478d-85ef-6d03734e8bef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de979395-958e-4dbc-a0de-7282d28cecae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b277e6f4-208b-48b2-a82e-fdb91a300aea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04ae8385-ec17-4300-a0c7-938cebdb1119
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fde43d89-e15c-4d91-b4ff-199bd55ac9c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3389b110-a10a-457d-9d97-c0ab0f5cbc5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35659f06-336e-4e2b-abe7-497d3770260e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d6b06b6-999a-4ad4-9e42-2ca95f7c7b1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eca5e5ee-8569-4e54-8acb-8bd71ee197bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 471c223f-f7f5-499e-99f8-14be15af7482
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88413ee3-c544-4037-ad11-3d68d17d7b2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6cb2b07-bfd0-46c8-8315-e094c066ef14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83bd0f1b-aa42-4ce2-96d7-1559880ee492
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8445672a-72b3-4e98-964c-9c4cadd00d4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c59b7f8a-1c6d-4afd-a53c-1958dcf7abe8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9df299f1-4bcc-4f2a-8bc5-d5ba59d099ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 458b6400-2d53-4ca0-a499-4bd3c9a6d4b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9984efb8-ee4f-4d2f-813f-db53c7415296
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a110f017-5b4d-4ec2-9f7f-0b0792ea611e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 059185fb-1957-45c5-b918-9c0806fcf84f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0add8e71-1d92-436c-a381-a5567008a799
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e770b1e-afaa-4ac1-a7f4-64569870d3f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 520f8d66-8199-41c4-b1bb-c9a83008713c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b37a5c32-ea21-4f96-bd50-7f6c222f61d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 856d8d48-b890-47b9-8ec4-697089eb3be9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05b999c4-9969-4c3f-ad0d-18387db4d6ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 790fc9af-4d9e-4534-bb72-2bd1a436b8b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67eea892-2f92-49ac-aecc-5b33ca845bd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9519bd9c-b46f-443d-8217-7e8005ebfa17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5bace27-e9f0-4d76-9b7e-74cc3b2a9e06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a565fbe-0dd0-4064-abbd-289f60994042
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 723fb594-5d4d-4fb7-95fd-d316ccbdebbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3e2be6f-d7ae-42a4-a47c-37493d623129
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d3b67a9-509e-4db4-96c1-f63dec2bfa2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3ef48f3-df64-4334-abc3-cca3af9fb813
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21d9a759-2c81-4ced-a4f0-7e257a59f0a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba1b84ff-e435-43c4-ba1d-58bc0a7e9f03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1166a80-8c17-4986-8df2-469a6fbb2975
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0715b42b-c2fb-450e-ae77-d7735ef34e9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34eac677-e87c-42c0-98a1-b659a9b5713c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80ca5731-3352-4df8-bddf-cdc1368d8121
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7abd953-9d80-4319-9c3f-a5da05e19a17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3b47250-bc29-4d96-adde-de16e71be6fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 341756a5-a514-44c8-ab70-81bb02174b4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f4ba122-bef9-4047-a511-c08ac634f7e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9835cd58-2b60-4d29-bd09-7f3f7604108d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e292973b-0963-4a19-a9a4-cc947a2dfe74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af917203-fe8a-4e7e-9c52-94a5b035efea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f09adaa8-d4ec-4a3a-9eb4-6c20f5f14fd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb2f4e15-96da-40a0-a096-3bfdafa94d77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 277c21da-7dc1-4012-a752-bf61d6e6c1d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2da2087c-4494-49ba-91bf-333414b01314
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 599fca27-f99c-4103-bf60-4fc78b20632a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59cc5581-dd8e-40cd-98c7-9f0525eacfa3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6cc1916-4f5f-42e8-b308-8a026a1acafd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 967d7763-dfa6-4b25-a62d-44600e57e608
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb085dc1-854c-4f97-a05e-5a5a29e21dd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9da17f9d-385d-472c-9cc5-72108d15ed27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d83e7b59-f013-48e7-9940-240e3bc33e48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de8a0715-2844-44d6-b361-2c971b065281
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ccc31093-475e-4095-9a2c-2d2c3aaaa5b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e771d236-5ad6-4e48-9cee-09e380b9e070
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc9ee871-59fc-480e-87e8-fcc7085089e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7bfc41f8-e592-4b4b-acdc-4bc64af419be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de48cad6-032e-4ada-9466-6f4e71d8be3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b23d8b4-a69a-401b-b9c5-84908b6c69e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message caf411e4-d69b-436c-abac-1281434da3c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47b03176-d91e-4b84-8d19-4dc0d2b27221
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 616ec27a-af02-490f-a056-ce04f7af1af5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1c2bce5-7938-4d59-8bcf-99286584ffd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b83b17c-660b-4479-93b8-be77e2b7c5cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4d69094-7f29-4885-bb5c-7d58769c221d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3805d76-6911-4fa5-a047-845580b60cd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df9a4592-31a1-45a1-8302-2ee6b6420656
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6a70609-c16a-4413-810a-f3320762c07b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 257628d7-ab5d-4de3-a80d-858b1456fca8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8add5a4a-ec73-41bd-8ade-0cf94f0ff1c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84b6f516-e4ff-4031-ab24-2eb67e394074
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3b74bd1-7b50-4986-a0a7-77985eb15333
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1902613b-23db-4d17-9612-44dba572d902
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aef61eeb-5733-4f9c-85ab-6132d6c0bcb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13132f02-2ae3-4854-ad51-292b9ca44da2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f175995-d9d5-4dfe-8d5a-34e09901df71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 118eb537-f2cb-4e5c-8bd5-6a591d1cdf2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1ce5609-ce9a-4f0b-8dc5-79b80547974d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 415b73a6-5df0-4065-a947-4d01d8edd757
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b6e0f3c-853d-46cc-90d4-59a1c96ac7e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9900832b-4f2f-4f74-a828-359f95f71e3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d62ceee6-549c-4886-b5dd-cbf5b026d834
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5730a68-aa6b-409f-b51f-cb2e26992ba1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c94571f-b889-40e9-a7d1-2461564d9bb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1ddc1a8-6a36-4ed6-aae5-875cebc1dd46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71ccaa10-b967-4b43-ab19-2fbbebba8371
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb574cee-ba56-4f2e-8788-a4e02b37af71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e73b96d9-93f9-464a-be2a-309f2163cf0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67cddff5-468b-49c8-80a9-ee7d87422d74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f79e24f-fc83-4647-9d9f-e6a1e30fafb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b465687-5582-4c03-8083-3bc98dd739be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd018f28-2d93-4b93-970f-50583dcf922a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bbdfd897-9b05-48e7-994b-f75fa68b1afc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0af56f47-fb24-4546-a322-056260fa2d41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f265fc4f-e7b5-4e18-9a8b-54ad87866ad2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e837cf4-42ad-4169-8bd4-23b71991f938
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c8d7900-8d6b-4285-8e47-9bccdc974c4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80871fec-af18-46ef-8a6f-e14db6fa01d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16beed32-0154-4f44-b75d-17586c8317d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac147e99-2152-4869-877d-284665d273e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5597c0db-6485-4f2b-a83b-dbede981efb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db05cd73-a6ac-4f7c-95f1-800a65f86cd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a42c55d-5398-4dd2-90f4-ecd624becf8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d65427fd-8b97-40fc-8c8d-1b711e510a94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e989117-7aac-445b-988a-5a6742199ced
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message efe523b5-f76b-4275-a7f0-2616dfc0a1c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 994ccb42-85d2-4c5e-ba17-3bc474a976ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c30943eb-a36b-4bb8-894f-c417b0b70eec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 790e7dd5-2bb9-4580-88b8-58f19a3f2f8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4cf77fe8-d03a-4ee0-a032-55241c5d236d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44950c64-5a7d-4933-b934-1172aa442da5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39565ef3-84f1-4c41-868c-d3028731d679
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cea36522-0324-42d5-9650-736028e4f852
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ce8b633-7e9e-4435-8978-489518e2fc5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fae8ab0f-745a-4505-af01-8e46d321bbac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e49fe94-f3df-418f-8db9-ac32c5974a58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05cbecba-59f3-4845-ba67-db15e2645328
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7a4b4f7-56b2-4635-a9d2-783591fbc6e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f21def1-55b7-4737-96d3-7c106aeba4de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 456d7fca-47f2-4c3e-864d-f7718f321153
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af8de742-181b-4f1a-a118-d44f3b265e63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b63cf0a-d540-481a-ba4e-b79feeb3dd16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 666ef010-32e4-4378-99b5-b7aaa602ea51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20b9d263-7566-448e-a7b2-3ef37baca359
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a67def6d-34cb-438d-93a8-593aca86bd87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89f1e1b4-8636-4bf7-a22a-286eb0a5c1cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c105b19-848a-47c3-867c-2a14ccef0780
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 319e9ea5-bd5b-452a-be33-042bc957debd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aef7fa69-a032-4a20-9d5c-a4c8a06e30d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69fc8338-6181-4a3a-9495-45114d07c431
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f28ffdb-e500-4c5b-a632-07e8cf887f4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2eb15c28-0158-46b8-9f98-e9b4fa08d2b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a39c2ae-6c48-4e5a-9933-321a308f095f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74a70f16-c743-4bc7-88f3-45845dcac504
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2112be5b-5ad7-4ec5-a825-2a1a4e732f3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cdbe208f-b359-4b50-8f02-f71eadcd5a88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f86c4220-e518-4cea-bed5-fb2082d135b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35e7aa95-8b92-44cf-a434-dfa3c9d58ddf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 079ae545-3e63-4b67-a376-1ec618f2390d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1cc1b044-74f1-40ca-b97b-26277564e5e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message affeca61-eb2b-4b4c-883d-84c3c00affd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c406022-c35f-4690-bddc-37c0864153f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06a3c7fa-3526-4b5f-9de3-4a9475daa8ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a3ad23c-e63a-4f7e-99f1-1b588ae2ffd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45f95d96-b8c7-488b-9067-efe607bab458
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ead0126c-8864-4687-85f5-726376f62faa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3648b104-9016-4037-a6a9-ba6251f61eed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ecb2c95-5a03-4ebe-a74d-7c32edf38c78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2baef9f-942f-4508-922d-c5140f604930
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 257f17be-94c4-4990-b1c7-501e3ff32be7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd22851e-ba50-4e6d-97ca-1167cb2ad5a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a0e54f6-e7c3-4fb9-b924-6b20ca2b2c1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83a4df52-f621-405d-9bcf-97cb6d91af19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 246088ac-0255-4ac6-af9d-e6403402b775
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c2c3b84-cd0d-4c9e-8d6e-506c07147b12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fcf7495e-99f1-4ac2-ab34-27b349106964
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd4d8a1b-87eb-4b04-9c58-11f9784e8aad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3c02df1-e855-432b-9045-02d522d563f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68a0be95-f101-4042-8db1-b1888e626772
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 205005aa-c414-42e5-84fc-c202d29d5d0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02cd2c8c-0aa3-4e61-b47f-6c559e23ebe1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4e1788a-8a60-4d44-956e-08aed9091141
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc5807f3-ad8d-4795-b56c-9f2d77f3e7d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4000a86-2f7b-48ac-b550-6691f6d0ef31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51ecab36-4b85-4ffe-9b9e-4369ff116b5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f97d1b2c-9406-4555-8c56-628d108be392
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3527ea69-bd63-4e2d-9551-37e7a08490ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed4dd878-59f3-4888-8dcd-f7d84b4571a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e393a1ca-dfb6-41d3-8f9c-d089cb13498d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04370abb-a713-41f4-92d4-1de0e71aa9f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 436bdb7a-2f4e-4af5-8531-ab19a0420cb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfb88f4b-dc17-42d9-8af3-ca23b3a7eb15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a099ad8-2a65-4683-8065-3a183c2a8b3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed6d1500-3819-4d3c-8a56-07e3fb6f8f5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67d5b147-d8f9-443b-bfe6-88de5e7944bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56f723d5-994c-452e-9b38-c57ef8670ef2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 678365d4-c496-473c-82e7-e7b796f6f33d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bae7efe0-3649-424b-9c71-fb23fea1581a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb877aae-b009-4df2-93df-75c033cf31eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8adb1ce3-1ad2-4540-ad6e-0226da1d123a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message edd00557-18e3-4ffc-8eb3-5fb9abb1e23f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 000e0bfd-3a6e-4d52-88ef-518d9a2b89a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8e8a9bd-0c5e-4ad7-957e-b64cc7fe7e4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1fb02ef-97f7-4a6e-b35b-6b6823996882
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e518e39-de50-4d05-adb6-df2d012dfeb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4478c67-38c5-40e4-b430-444281c29e59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c3a6855-c316-4be0-9241-2ac2e99ce52f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72b02a10-8edf-4971-ac4e-6803b7cbee81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6109c75f-bb0e-4bc5-a07f-4974c228e970
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d9c428c-780a-41a6-934b-513d5d8b2aef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46c6754b-5ca4-45d1-bc2c-8a04b473aeb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8b457e9-3d5e-45ee-a6dc-4a69f0de8794
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5769dfc2-f01c-48f4-8388-d0051b93cd17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3224b4fe-0431-48ab-9db8-389c3363d7c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9ef34a7-83d0-4311-82d6-42c2e47bfbe4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 437e4269-209f-42ce-8e63-ff439bf29903
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed6129d9-a01b-42d6-b0be-a35aabd5b105
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b7073ad-df17-4437-b90a-9c80dbaa2445
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b7f311a-b796-4592-b959-ff463804aef5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a846688a-e160-44b7-ab36-2dbe3f8c51c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c41a9808-ae7b-46c2-a3ef-b35e324ac3d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3989fc0b-6679-4817-9b77-54d85ae5a162
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f04bd63-010c-4673-b618-0c5186f5d4af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3979dfa1-7a1f-409e-811f-192b9e2c9c51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message acf67826-be17-47cc-b737-c6e9f4509293
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71147f95-3eb7-40a8-9474-917b454c07b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b9a602d-53ff-4d63-91fd-1034385e4ff9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 617a9d20-3d48-40cd-87a1-41224125337f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c77e345-cba2-4a5f-9784-f7c60fdd0a32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5899d04c-3231-4215-8dc5-5cfbb193df44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f504ee8-e32e-4f8b-ae67-dddb0edff33c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2cd0efe-fa81-4c5e-8ef1-210e74ed9e2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77fd0838-176e-4c0c-a848-ed8289b09ae6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1454f46d-8f86-4c6d-a1fc-83f4f8e4585e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a54d237-b56f-42f7-bfff-5138bd592bd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c79d197-d8c2-46e2-b88c-ae4f31b6e3b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8001a354-7957-4a33-81d3-aa75867d28df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7f55f64-4063-4bf3-a0d4-b96897e17f21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f8f8f2c-1dc8-4b6f-89b8-4909d1d3062e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6416a05d-5cba-41d0-8562-8f7faee2e170
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f93316d-6b6f-4c67-b06b-1b1fab6561a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0747751f-7b4e-4b8b-90a3-f0ab97202882
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50e9ac76-58eb-4067-84bb-43e1529d03d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74decd7e-40b4-4e25-98d0-5ee96ca51610
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 442002d7-4551-4eec-8f49-c5dc5944de7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 996b6fa1-51a4-44c9-a18a-d5c8c2159b6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d35e011-437b-40a5-a1e2-b690c2af0e0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dfdea699-2842-4b38-a34d-86f5ad8ba691
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ffa006d-a4a7-462a-98ca-f964e3b74d42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46fd3f71-7789-4945-a445-48c52da60979
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22f2914d-33a7-43fa-b36b-ddcdff5e8f6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64c188ad-b3ca-40f9-ac32-45f570066fe8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83d6e17c-1fa1-44cd-8908-ed404c70dc47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7bb6084-b74a-4129-8558-79c988d23353
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae4d06ae-3eb1-40f7-ad96-fe8a87f17c9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6fec5897-3930-4d7f-992c-ba13d67a890c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9fb26d55-c688-4327-a3d3-abb78e680d64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c788da59-7eca-46b3-8735-98873e04398b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b3553bf-0f1a-440c-b75a-ea43df50a61e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b0d92d5-62c5-43aa-9766-d29731187fef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5cc93594-81b2-492c-8690-3c057bc1fd76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0dc2aa79-2962-47a2-a495-230ebfcf3609
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45c05e92-c6fa-43f6-9a35-e3bb0f2a74b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4f5826b-d363-4719-9460-02fe2522e7be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ca14ee6-9b43-44fe-b188-8bea36de0544
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9bc7256f-da8b-43ad-814c-eef53996d145
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8c9ba15-e148-4987-8442-b05f4541aba8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f671d48-b25f-45b6-830a-13dfbad44a75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6d91b59-dc55-4b0a-a25c-f0ce0dbc546f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93db8323-6381-403f-af00-202b27f02d66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67620fb7-a9ed-4d0f-b669-355ea952430e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ee7a233-0aff-4649-b4a8-ee34a8e7932b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c815ee54-51d6-4219-b18e-b996ae39142d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d253241-9562-4659-8496-2556d440614d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bade0193-60eb-4681-9067-c126a0bbcdb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 704f6422-972e-4225-9544-45c0245a147a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0be2fd45-1407-45bb-a4a0-7d706854508f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4900b32e-96d6-4b2f-9ae3-22142d0594d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd7c1cc6-eae4-4e07-8bb8-d098c14dfa9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b602860b-9f45-4274-9930-ff75acba6676
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4aa66987-4550-42f3-acf6-5f82e9a15291
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b09c0005-7e09-4637-bce7-e79e6eae68bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 211fe4be-2af4-48c4-a9cc-e9c761e25959
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1de34f9-432f-473a-b907-193c137ef569
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52a26d83-e8c7-4e2f-901c-4e249acc2054
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b785be89-562b-40fa-a9a4-d2833f43e9a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37a76975-9303-447b-be58-def3e79a1f88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96ceef8c-d22c-49d2-aad4-95eb232daa13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d0445ce-1652-48f5-b076-b9d4e7e9a3c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50c7ac76-dd3d-4adb-8808-9524345b5568
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 059b6e55-e60d-4120-be0d-f3c503f4a092
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67467780-fec0-4c08-afcb-8e279543bb2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69e87bd4-9b0e-41b7-a938-e8e587302cc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06630315-ddbe-4436-84dd-38fc2e517985
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 892662ff-9d00-464e-8c84-aadbcc6f87d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b23cc636-32b0-4e3b-83c5-f2a5ed1ef3ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bfc76026-95d9-4c6d-a582-e3cd5f8b4f39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d6c6a88-f6e5-49bc-a822-04f566cac10a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ecea28b0-2ea5-403c-b187-c58d9b4c5f70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21ad1446-dd2a-4dc3-8605-5d90fc79ae0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db1b49b4-1d47-44a1-b102-f736ea7907c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74d806a9-44fb-4fde-9a51-c8d5df82ff82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8cc11193-99a5-4b44-823e-a5d888ba9617
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 559ed02b-4e55-48ad-9a66-4541a6f76cf6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e3d5b70-6d4c-4ce5-aab2-161c7d41b36a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b23168cf-a16d-4271-a8be-081092329dc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78dd9040-657c-4b81-8a14-2e3e9d9f9da5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f23ae354-5961-4a23-a117-857acfccd0fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f17d03d1-4216-4e66-b2a5-92388e4aa819
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc1d92e7-226b-470f-9cac-0244bf3d8251
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b8ba368-9b4e-47ff-b58d-9495a051dba2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd021f33-107e-4afb-824b-863947468f4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4001184b-decb-4b26-87df-fb1f7fe72027
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52c77c1d-4e37-4f85-a53e-2d8eaa8ec924
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73cfa3e5-1e3c-4f20-875a-a18e4e721367
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e84bcd6-6c5d-41d1-bad0-e62e7033247a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 053b35d3-2ebb-4874-9fd3-cdc250c77de7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1efd250a-af17-4bea-bdab-be995b4c4591
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d8b0a62-a0ab-4c7a-a327-8bc38bfcb980
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c098dca2-ea17-4dda-b0dd-2987e9211052
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e11aa879-560b-4f3c-a0f1-c85b763b45e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ee1d4f1-6f26-426b-8e5b-369416194a17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 241f4f9e-acb2-4f8b-b9ce-84e4852259e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2eb6d8d6-5b3d-429c-92ff-90c4de088d0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49281cc1-babb-437f-8b64-1d9304690d31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0cdcb64-b96d-41cd-b13a-661cb450d66e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 697390ee-21af-4eb3-9d0b-2c5639d96261
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40d7d71d-2bbb-4b37-9ced-9f012c54d9c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31bd0a7c-f3f3-4db5-9cb4-b45a6a0004a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9151961a-6b52-46cf-8a6b-190c1182216e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5df08588-a5aa-4237-83ff-7697d9b08e5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc20dc8e-795b-4902-93aa-f70f7feea16a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 934757f5-0c01-409f-b9b5-34bc788f8298
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4b9ae09-0858-4077-85e6-9a123146fff2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44ed96fb-6fea-4228-b7b6-eb9b23517996
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9340b90a-8185-4a49-bd69-e4a05e6d4401
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8751cea0-6593-410a-9e73-6d5efa90f17b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4422a567-11a0-4cae-b776-4cc436d1f8f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c43c523-c2c8-48b9-96c3-a6af12b036d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69b85930-6034-4d6b-9cf8-e759d9b8c499
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78815202-5c64-4326-8f68-23e7c440a914
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07980e41-ddb2-4e31-bb4c-89093b9177ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15f41b6b-7df0-4669-9d15-c2777bffae58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63687448-e70a-4663-b743-1df41e643e30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c228877-0a32-4300-ac4f-357ed00284a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8784de95-65a0-4407-94d1-5f6375d17c52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2bd5f710-7309-49dd-b6fa-9bcf3f343fc1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae3f6583-83fd-4cd0-b8ac-95a5c509793f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6fa75c12-1243-4079-a853-6316db12a96f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60ae308f-01cc-4c3d-8c51-4c0219393470
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 035eb67e-93f7-417f-ae78-0fffb67b2254
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25172dd3-bdb8-4a63-a8c8-4842b7a118d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20cc5a55-14a9-4a9a-8960-7fd7907ff120
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 042c4c42-e015-44a8-934f-43ccd81f10f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ac701fd-0df7-4a8d-8b3a-0702e4b57936
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11c72093-3514-47b8-9efa-1bafaeed14c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd5e09f5-dc58-4ee9-9efd-da5586b76e1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c174aeba-c844-41e9-8a77-b9a34b678382
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72034d38-6bcc-49f0-9cee-21a26c4e9a1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78e71fc6-7e83-415d-8bdc-8ea7dc6ed6ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06c632e5-dedc-4e2e-b10e-60e021ba7a18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f63151e-889a-488c-a90d-6a5663b0854d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8472d12f-5c0a-4da5-b9b7-dc4f0b3b29d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5491ee6-9101-4f98-b12a-59ac155f873b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a99126be-89eb-425c-8dd5-b9988ece7a68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16c8a5b7-f629-44d7-81da-94ffb47c514b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37c70467-3a55-49f4-8154-875d8cef4b6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75d61e82-81af-46c5-9cbf-24ed3901c5b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45c30a78-359a-4d52-a3b0-c6d500df4288
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f71c035e-0cde-4318-8590-b63de1d86184
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd731600-6564-4c05-bd75-a2db8f598890
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef33bb82-2e17-44b0-8ca5-2846b88976f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef8baa85-597e-43e5-b7d6-590c2f0cfcd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8099a28d-91df-47bc-8e3d-8b320e303366
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd16ff52-c188-406f-9c24-708eb6a9cdf5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66071b4d-6402-4fc4-a5fd-f253ae67ce77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed81ce71-7524-4b99-a06b-cd29bc3ee8db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3d277b3-98b8-4384-ac81-ca0c37174ccf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c83727b5-b211-4a51-bc4c-61c005f1ab6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6b7f032-dc22-45d5-8532-54a91aa3d3ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c33b3451-1176-4961-887c-228c0e52b1df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05d76287-a94d-49ba-b90e-29f4dd110c84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ec5c7c3-8e56-40be-95bc-1b83592d30d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 674de458-203b-413b-8cf4-1adb43be9d22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12f972cb-9661-40a7-a1d5-605880a887fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04809d35-0653-4c37-8990-dbf47adebe7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9e3b868-c3f7-4a0e-a65b-b5e544545dbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d57f746-e851-4292-a4d0-16212f7b6375
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d56f3c5-7bc3-4ced-b898-11dc91b3084a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 154a6838-c223-40be-8989-26736b3fafe6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d734fd5-977a-46ef-aff5-f71d4b96811a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f3392eb-ca0c-493e-9072-40c387d14f89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce8bf9c0-1b28-4d0f-82d9-e7538913af73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1348715-5f0a-49e0-8587-f72f75671939
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 502de952-9c70-427a-a0b0-2e14847efd2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e63c609-145b-44cc-a932-ce3107d995d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bcc7dd2c-14d9-4461-8b78-1d35e2474f8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8290b6c-33b8-467f-bf16-0b3d919fd6f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2723e8b6-5b5c-414b-a03b-284d8c60aa29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c6a85bf-f0bd-499c-87c5-b94cb6e2cbb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 288783ae-e0d1-402d-8c75-dbe1cb7a4e66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df5dcd5c-ac95-44db-b316-32fb853fbabb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55105044-ba66-4651-be5e-3cc0fadd295c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8a6d196-57ec-42a2-96ae-0851cef0a308
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93b0a046-3946-46b5-8c56-2a4034dd1985
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5eb2007a-f071-4e3a-893e-fdf2df495aa7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04b9ecb2-71ae-43c8-8d53-ee89f4c15248
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9b04f8a-095e-4d38-b599-702eddc99f0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da0e9cbc-b70b-4a75-9d8d-c0fc7944aa80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4cfa33c-8ac5-491f-9a2d-0f95b761c418
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a58e7ef-da4e-4307-989c-325239c89eba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1962c690-e1f4-4b1f-b271-2d4bd5665f7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f869fbf0-9c4b-4305-b153-4cdf4ce031b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42bd8e2d-1dee-4a74-8f43-42f62761eb88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78687a5b-1a6b-402a-b46a-95df3d2ac6d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac221c3e-87a2-44d2-bb53-a1551bda6481
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec790642-f978-42c9-b31f-03aaf956dee0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5413e46-0641-4855-aac2-7ac178daf72a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1b737f8-3b22-4e85-af93-9a1b70be74ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54a6c13e-ae4d-4343-86b1-08e6bface803
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c601ea52-c684-4c3f-a8fd-3fbdc5ebfffb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6c71bb0-3bb3-4b1f-93d7-2bab32de6000
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34f355a2-8089-4a43-ab7f-a2e0272aaa71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71396bce-ce6f-4984-94e2-9419e2b33c0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5aa851f4-bbdf-4cc8-b3cf-d9713aab2476
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36e3088e-6f26-42e3-b8ae-9a660e94c65a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5053a91-4988-4bff-876b-6dca4b2fed0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d92c3ada-a2d9-485a-88b0-6d5c03fee679
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9348685d-43c5-44c0-abe2-d8b538ee8f73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d81cb06d-c7b4-41ea-be32-63335a7894a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d2a39e7-dcfb-4ace-9471-6d5bf5f4c7ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0465265e-bbd2-413d-a200-480c068ba9a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe341365-4c51-4a5b-b9af-706d04c39da2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8328b60-f560-4bbd-84b2-7cf79e0579c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0863afe5-97dd-46e5-91cc-317b049d5edf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f5b4bfe-6a07-45a1-920c-89f80e742b43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1203a32-5f0d-4de8-a52b-514ddff44051
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32f62ef8-15e6-447b-b421-12c281b688f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eefb2b3d-62cb-4c5f-b24a-05dba6edef5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b39066c6-7dfd-4ebc-9363-e9347f7cdae3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0edb424-196f-4dbd-8476-5b7ec650726e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0f04bf7-6720-451c-896b-f9e0ea5abbb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38747905-2e2a-469d-bc45-a5b600af3b4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f766af64-f013-487b-ac69-f56f99ada9d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ada4663-b151-4c24-8776-5d4985e2dab1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3320a3c-4aee-4279-913c-efb1c0c6c47c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ad12425-257c-4a1c-aaf4-329f94451332
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b40e145-3fae-4f89-a969-bf8f9f7711ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c632ab8f-e9c5-4aa7-ad48-fd7a69ff18f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c8a9ffe-8f6f-4bae-9c79-1d209b6ac663
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cea216b2-327b-4e65-8373-69adbb6baa56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2b1161f-0393-4c1f-85c3-341f660507fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a44d7911-ef6f-4945-8c64-b987a43c14b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c36dc3f-198c-444a-9698-74027eac32ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8663d302-b503-4299-bc2b-a45cce2ffb85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c81b2cea-1a7d-4112-b3f4-1ec65ef0790a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4668416-0460-4ff1-83b4-bcbbbce13e3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7328a2dc-03b2-4beb-9008-c829aa5a75ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e84b332-afb1-4069-a0be-07c50c054e8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65fed9a1-842e-479a-90bf-eceac318c0b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4b1b34e-9e3d-41ad-9e56-b192b831231f
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8688 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_2
Server: localhost:8688
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_2
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_2/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_2/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_2/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_2/test_labels.txt

📊 Raw data loaded:
   Train: X=(5055, 24), y=(5055,)
   Test:  X=(1264, 24), y=(1264,)

⚠️  Limiting training data: 5055 → 800 samples
⚠️  Limiting test data: 1264 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_2 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 1 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1771, val=0.0837 (↓), lr=0.001000
   • Epoch   2/100: train=0.0882, val=0.0847, patience=1/15, lr=0.001000
   ✓ Epoch   3/100: train=0.0793, val=0.0832 (↓), lr=0.001000
   • Epoch   4/100: train=0.0792, val=0.0831, patience=1/15, lr=0.001000
   • Epoch   5/100: train=0.0794, val=0.0829, patience=2/15, lr=0.001000
   📉 Epoch 11: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0784, val=0.0835, patience=8/15, lr=0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 1 Summary - Client client_2
   Epochs: 18/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0046
   Val:   Loss=0.0832, RMSE=0.2884, R²=0.0119
============================================================


📊 Round 1 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2521, R²: -0.0099

📊 Round 1 Test Metrics:
   Loss: 0.3736, RMSE: 0.6113, MAE: 0.5379, R²: -3.4492

============================================================
🔄 Round 3 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000500 → 0.000250
   ✓ Epoch   1/100: train=0.1572, val=0.0847 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0893, val=0.0746 (↓), lr=0.000250
   • Epoch   3/100: train=0.0809, val=0.0763, patience=1/15, lr=0.000250
   • Epoch   4/100: train=0.0806, val=0.0759, patience=2/15, lr=0.000250
   • Epoch   5/100: train=0.0804, val=0.0755, patience=3/15, lr=0.000250
   📉 Epoch 9: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0801, val=0.0753, patience=9/15, lr=0.000125
   📉 Epoch 17: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 3 Summary - Client client_2
   Epochs: 17/100 (early stopped)
   LR: 0.000500 → 0.000063 (3 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0095
   Val:   Loss=0.0746, RMSE=0.2732, R²=0.0048
============================================================


============================================================
🔄 Round 6 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0947, val=0.0871 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.0871, val=0.0805 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.0834, val=0.0777 (↓), lr=0.000063
   ✓ Epoch   4/100: train=0.0820, val=0.0765 (↓), lr=0.000063
   ✓ Epoch   5/100: train=0.0815, val=0.0759 (↓), lr=0.000063
   📉 Epoch 8: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0808, val=0.0751, patience=4/15, lr=0.000031
   📉 Epoch 16: LR reduced 0.000031 → 0.000016
   • Epoch  21/100: train=0.0806, val=0.0748, patience=3/15, lr=0.000016
   📉 Epoch 24: LR reduced 0.000016 → 0.000008
   • Epoch  31/100: train=0.0805, val=0.0747, patience=13/15, lr=0.000008
   📉 Epoch 32: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 6 Summary - Client client_2
   Epochs: 33/100 (early stopped)
   LR: 0.000063 → 0.000004 (4 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0086
   Val:   Loss=0.0749, RMSE=0.2736, R²=0.0020
============================================================


📊 Round 6 Test Metrics:
   Loss: 0.0870, RMSE: 0.2950, MAE: 0.2545, R²: -0.0360

============================================================
🔄 Round 7 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0807 (↓), lr=0.000004
   • Epoch   2/100: train=0.0805, val=0.0806, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0805, val=0.0806, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0805, val=0.0806, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0805, val=0.0806, patience=4/15, lr=0.000004
   📉 Epoch 7: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0804, val=0.0805, patience=10/15, lr=0.000002
   📉 Epoch 15: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 7 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0073
   Val:   Loss=0.0807, RMSE=0.2840, R²=-0.0064
============================================================


============================================================
🔄 Round 8 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0864, patience=5/15, lr=0.000001
   • Epoch  21/100: train=0.0846, val=0.0855, patience=3/15, lr=0.000001
   ✓ Epoch  31/100: train=0.0842, val=0.0847 (↓), lr=0.000001
   • Epoch  41/100: train=0.0838, val=0.0840, patience=3/15, lr=0.000001
   • Epoch  51/100: train=0.0835, val=0.0833, patience=5/15, lr=0.000001
   • Epoch  61/100: train=0.0832, val=0.0827, patience=7/15, lr=0.000001
   • Epoch  71/100: train=0.0830, val=0.0822, patience=8/15, lr=0.000001
   • Epoch  81/100: train=0.0827, val=0.0816, patience=8/15, lr=0.000001
   • Epoch  91/100: train=0.0825, val=0.0812, patience=8/15, lr=0.000001

============================================================
📊 Round 8 Summary - Client client_2
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=-0.0172
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.1018
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.0868, RMSE: 0.2947, MAE: 0.2544, R²: -0.0339

============================================================
🔄 Round 14 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 14 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0226
   Val:   Loss=0.0779, RMSE=0.2792, R²=-0.0506
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.0876, RMSE: 0.2959, MAE: 0.2554, R²: -0.0429

📊 Round 14 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2547, R²: -0.0350

============================================================
🔄 Round 18 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0883, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0812, val=0.0879, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 18 Summary - Client client_2
   Epochs: 30/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0230
   Val:   Loss=0.0881, RMSE=0.2969, R²=-0.0890
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2547, R²: -0.0347

📊 Round 18 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2547, R²: -0.0345

📊 Round 18 Test Metrics:
   Loss: 0.0869, RMSE: 0.2947, MAE: 0.2546, R²: -0.0343

============================================================
🔄 Round 25 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 25 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0519
   Val:   Loss=0.0779, RMSE=0.2791, R²=-0.0185
============================================================


============================================================
🔄 Round 26 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 26 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=-0.0449
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0431
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0868, RMSE: 0.2947, MAE: 0.2546, R²: -0.0340

============================================================
🔄 Round 27 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 27 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0548
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0046
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0868, RMSE: 0.2947, MAE: 0.2546, R²: -0.0339

============================================================
🔄 Round 28 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0960 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0960, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0959, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0959, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0959, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0958, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0960)

============================================================
📊 Round 28 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=-0.0566
   Val:   Loss=0.0960, RMSE=0.3098, R²=-0.0032
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0868, RMSE: 0.2946, MAE: 0.2546, R²: -0.0338

============================================================
🔄 Round 29 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0910, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0808, val=0.0906, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 29 Summary - Client client_2
   Epochs: 30/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0340
   Val:   Loss=0.0908, RMSE=0.3014, R²=-0.0616
============================================================


============================================================
🔄 Round 31 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 31 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0465
   Val:   Loss=0.0791, RMSE=0.2813, R²=-0.0273
============================================================


============================================================
🔄 Round 33 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 33 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0439
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0293
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0868, RMSE: 0.2945, MAE: 0.2545, R²: -0.0331

============================================================
🔄 Round 36 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 36 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2904, R²=-0.0436
   Val:   Loss=0.0773, RMSE=0.2781, R²=-0.0146
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0868, RMSE: 0.2945, MAE: 0.2545, R²: -0.0330

📊 Round 36 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2545, R²: -0.0330

============================================================
🔄 Round 39 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 39 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0431
   Val:   Loss=0.0766, RMSE=0.2767, R²=-0.0174
============================================================


============================================================
🔄 Round 42 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 42 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0369
   Val:   Loss=0.0766, RMSE=0.2768, R²=-0.0325
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2545, R²: -0.0329

📊 Round 42 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2545, R²: -0.0329

============================================================
🔄 Round 44 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0942 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0941, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0941, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0941, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0941, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0940, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0942)

============================================================
📊 Round 44 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=-0.0358
   Val:   Loss=0.0942, RMSE=0.3069, R²=-0.0348
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2545, R²: -0.0328

📊 Round 44 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2545, R²: -0.0328

📊 Round 44 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2545, R²: -0.0328

============================================================
🔄 Round 49 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 49 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0294
   Val:   Loss=0.0900, RMSE=0.3000, R²=-0.0522
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2545, R²: -0.0328

============================================================
🔄 Round 51 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 51 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0344
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0278
============================================================


============================================================
🔄 Round 52 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 52 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0424
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0030
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2545, R²: -0.0328

============================================================
🔄 Round 56 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0963 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0963, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0963, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0963, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0963, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0962, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0963)

============================================================
📊 Round 56 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=-0.0236
   Val:   Loss=0.0963, RMSE=0.3104, R²=-0.0615
============================================================


============================================================
🔄 Round 57 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 57 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0417
   Val:   Loss=0.0920, RMSE=0.3034, R²=-0.0247
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2546, R²: -0.0329

============================================================
🔄 Round 60 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0939 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0939, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0939, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0939, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0938, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0938, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0939)

============================================================
📊 Round 60 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=-0.0338
   Val:   Loss=0.0939, RMSE=0.3064, R²=-0.0244
============================================================


============================================================
🔄 Round 61 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0652 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0652, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0652, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0652, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0652, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0651, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0652)

============================================================
📊 Round 61 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=-0.0330
   Val:   Loss=0.0652, RMSE=0.2554, R²=-0.0259
============================================================


============================================================
🔄 Round 62 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 62 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0407
   Val:   Loss=0.0775, RMSE=0.2783, R²=0.0066
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2546, R²: -0.0329

============================================================
🔄 Round 64 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 64 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0333
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0214
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2546, R²: -0.0329

============================================================
🔄 Round 67 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 67 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0193
   Val:   Loss=0.0917, RMSE=0.3029, R²=-0.0894
============================================================


============================================================
🔄 Round 68 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 68 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0393
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0039
============================================================


============================================================
🔄 Round 69 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 69 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0367
   Val:   Loss=0.0877, RMSE=0.2962, R²=-0.0104
============================================================


============================================================
🔄 Round 71 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 71 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0282
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0395
============================================================


============================================================
🔄 Round 72 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 72 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=-0.0341
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0159
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2546, R²: -0.0329

============================================================
🔄 Round 73 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 73 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=-0.0278
   Val:   Loss=0.0844, RMSE=0.2906, R²=-0.0419
============================================================


============================================================
🔄 Round 78 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 78 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0221
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0605
============================================================


============================================================
🔄 Round 79 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 79 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2877, R²=-0.0343
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0171
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2546, R²: -0.0329

📊 Round 79 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2546, R²: -0.0329

📊 Round 79 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2546, R²: -0.0329

📊 Round 79 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2546, R²: -0.0329

============================================================
🔄 Round 85 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 85 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0282
   Val:   Loss=0.0833, RMSE=0.2885, R²=-0.0379
============================================================


============================================================
🔄 Round 87 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0928 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0928, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0928, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0927, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 87 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=-0.0272
   Val:   Loss=0.0928, RMSE=0.3046, R²=-0.0364
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2546, R²: -0.0329

📊 Round 87 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2546, R²: -0.0329

📊 Round 87 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2546, R²: -0.0329

============================================================
🔄 Round 94 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 94 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0337
   Val:   Loss=0.0780, RMSE=0.2792, R²=-0.0074
============================================================


============================================================
🔄 Round 95 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 95 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0325
   Val:   Loss=0.0823, RMSE=0.2868, R²=-0.0133
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2546, R²: -0.0330

📊 Round 95 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2546, R²: -0.0330

============================================================
🔄 Round 99 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 99 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0267
   Val:   Loss=0.0833, RMSE=0.2887, R²=-0.0352
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2546, R²: -0.0330

============================================================
🔄 Round 101 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 101 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0375
   Val:   Loss=0.0848, RMSE=0.2912, R²=0.0057
============================================================


============================================================
🔄 Round 102 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 102 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0231
   Val:   Loss=0.0852, RMSE=0.2918, R²=-0.0473
============================================================


============================================================
🔄 Round 104 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 104 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0328
   Val:   Loss=0.0901, RMSE=0.3001, R²=-0.0145
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2546, R²: -0.0330

📊 Round 104 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2547, R²: -0.0330

============================================================
🔄 Round 109 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 109 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0195
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0912
============================================================


============================================================
🔄 Round 113 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 113 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0299
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0204
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2547, R²: -0.0330

📊 Round 113 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2547, R²: -0.0330

============================================================
🔄 Round 116 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 116 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0269
   Val:   Loss=0.0809, RMSE=0.2845, R²=-0.0305
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2547, R²: -0.0330

📊 Round 116 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2547, R²: -0.0329

============================================================
🔄 Round 118 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 118 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0328
   Val:   Loss=0.0773, RMSE=0.2780, R²=-0.0098
============================================================


============================================================
🔄 Round 119 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 119 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=-0.0307
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0151
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2547, R²: -0.0329

============================================================
🔄 Round 120 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 120 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0329
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0077
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2547, R²: -0.0329

============================================================
🔄 Round 124 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 124 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0214
   Val:   Loss=0.0798, RMSE=0.2824, R²=-0.0526
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2547, R²: -0.0329

============================================================
🔄 Round 126 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 126 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0275
   Val:   Loss=0.0760, RMSE=0.2756, R²=-0.0347
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2547, R²: -0.0329

============================================================
🔄 Round 128 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 128 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0311
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0235
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2547, R²: -0.0328

============================================================
🔄 Round 132 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 132 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2863, R²=-0.0214
   Val:   Loss=0.0827, RMSE=0.2875, R²=-0.0533
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2547, R²: -0.0328

📊 Round 132 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2547, R²: -0.0328

============================================================
🔄 Round 135 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 135 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0254
   Val:   Loss=0.0777, RMSE=0.2788, R²=-0.0341
============================================================


============================================================
🔄 Round 137 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 137 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0217
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0511
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2547, R²: -0.0328

📊 Round 137 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2547, R²: -0.0328

============================================================
🔄 Round 143 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0711 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0711, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0711, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0711, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0711, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0710, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0711)

============================================================
📊 Round 143 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0283
   Val:   Loss=0.0711, RMSE=0.2667, R²=-0.0315
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2547, R²: -0.0328

📊 Round 143 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2547, R²: -0.0328

📊 Round 143 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2547, R²: -0.0328

============================================================
🔄 Round 150 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 150 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0261
   Val:   Loss=0.0816, RMSE=0.2856, R²=-0.0324
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2547, R²: -0.0327

============================================================
🔄 Round 152 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 152 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0241
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0436
============================================================


============================================================
🔄 Round 153 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 153 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0269
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0280
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2547, R²: -0.0326

📊 Round 153 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2547, R²: -0.0326

============================================================
🔄 Round 156 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 156 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0203
   Val:   Loss=0.0884, RMSE=0.2973, R²=-0.0889
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2547, R²: -0.0326

============================================================
🔄 Round 158 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 158 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0324
   Val:   Loss=0.0839, RMSE=0.2896, R²=-0.0085
============================================================


============================================================
🔄 Round 159 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 159 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0288
   Val:   Loss=0.0891, RMSE=0.2985, R²=-0.0211
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2547, R²: -0.0326

============================================================
🔄 Round 161 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 161 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0287
   Val:   Loss=0.0889, RMSE=0.2981, R²=-0.0226
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2547, R²: -0.0326

📊 Round 161 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2547, R²: -0.0326

============================================================
🔄 Round 164 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 164 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0237
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0491
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2547, R²: -0.0325

============================================================
🔄 Round 166 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 166 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0183
   Val:   Loss=0.0891, RMSE=0.2986, R²=-0.0788
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2547, R²: -0.0325

============================================================
🔄 Round 167 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 167 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0173
   Val:   Loss=0.0792, RMSE=0.2813, R²=-0.0732
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2547, R²: -0.0325

============================================================
🔄 Round 171 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 171 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0297
   Val:   Loss=0.0880, RMSE=0.2967, R²=-0.0290
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2547, R²: -0.0325

📊 Round 171 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2547, R²: -0.0325

============================================================
🔄 Round 175 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 175 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0268
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0268
============================================================


============================================================
🔄 Round 176 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 176 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0289
   Val:   Loss=0.0733, RMSE=0.2708, R²=-0.0244
============================================================


============================================================
🔄 Round 177 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 177 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0337
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0007
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2547, R²: -0.0325

============================================================
🔄 Round 179 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 179 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0233
   Val:   Loss=0.0738, RMSE=0.2717, R²=-0.0557
============================================================


============================================================
🔄 Round 181 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 181 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0246
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0389
============================================================


============================================================
🔄 Round 182 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 182 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0241
   Val:   Loss=0.0863, RMSE=0.2937, R²=-0.0378
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2547, R²: -0.0325

============================================================
🔄 Round 183 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 183 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0251
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0321
============================================================


============================================================
🔄 Round 185 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 185 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0308
   Val:   Loss=0.0740, RMSE=0.2720, R²=-0.0071
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2547, R²: -0.0324

============================================================
🔄 Round 189 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 189 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0299
   Val:   Loss=0.0826, RMSE=0.2875, R²=-0.0290
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0867, RMSE: 0.2944, MAE: 0.2547, R²: -0.0324

============================================================
🔄 Round 191 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 191 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0152
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0763
============================================================


📊 Round 191 Test Metrics:
   Loss: 0.0867, RMSE: 0.2944, MAE: 0.2547, R²: -0.0324

============================================================
🔄 Round 192 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 192 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0238
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0411
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0867, RMSE: 0.2944, MAE: 0.2547, R²: -0.0324

📊 Round 192 Test Metrics:
   Loss: 0.0867, RMSE: 0.2944, MAE: 0.2547, R²: -0.0324

============================================================
🔄 Round 196 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 196 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0358
   Val:   Loss=0.0786, RMSE=0.2803, R²=0.0073
============================================================


============================================================
🔄 Round 197 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 197 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=-0.0212
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0498
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0867, RMSE: 0.2944, MAE: 0.2547, R²: -0.0324

============================================================
🔄 Round 198 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 198 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0308
   Val:   Loss=0.0785, RMSE=0.2801, R²=-0.0214
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0867, RMSE: 0.2944, MAE: 0.2547, R²: -0.0323

============================================================
🔄 Round 201 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 201 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0203
   Val:   Loss=0.0807, RMSE=0.2842, R²=-0.0503
============================================================


📊 Round 201 Test Metrics:
   Loss: 0.0867, RMSE: 0.2944, MAE: 0.2547, R²: -0.0323

============================================================
🔄 Round 205 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 205 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=-0.0241
   Val:   Loss=0.0826, RMSE=0.2875, R²=-0.0472
============================================================


============================================================
🔄 Round 208 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 208 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0252
   Val:   Loss=0.0836, RMSE=0.2892, R²=-0.0394
============================================================


📊 Round 208 Test Metrics:
   Loss: 0.0867, RMSE: 0.2944, MAE: 0.2547, R²: -0.0322

============================================================
🔄 Round 211 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 211 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0154
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0692
============================================================


============================================================
🔄 Round 212 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 212 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0088
   Val:   Loss=0.0914, RMSE=0.3022, R²=-0.1165
============================================================


============================================================
🔄 Round 213 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 213 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0271
   Val:   Loss=0.0899, RMSE=0.2998, R²=-0.0279
============================================================


📊 Round 213 Test Metrics:
   Loss: 0.0867, RMSE: 0.2944, MAE: 0.2547, R²: -0.0321

============================================================
🔄 Round 216 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 216 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0304
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0107
============================================================


📊 Round 216 Test Metrics:
   Loss: 0.0867, RMSE: 0.2944, MAE: 0.2547, R²: -0.0321

============================================================
🔄 Round 218 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 218 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0283
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0238
============================================================


============================================================
🔄 Round 219 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0698 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0697, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0697, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0697, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0697, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0696, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0698)

============================================================
📊 Round 219 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0303
   Val:   Loss=0.0698, RMSE=0.2641, R²=-0.0064
============================================================


📊 Round 219 Test Metrics:
   Loss: 0.0867, RMSE: 0.2944, MAE: 0.2547, R²: -0.0321

============================================================
🔄 Round 220 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 220 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0194
   Val:   Loss=0.0769, RMSE=0.2772, R²=-0.0584
============================================================


📊 Round 220 Test Metrics:
   Loss: 0.0867, RMSE: 0.2944, MAE: 0.2547, R²: -0.0321

============================================================
🔄 Round 222 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 222 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=-0.0216
   Val:   Loss=0.0859, RMSE=0.2930, R²=-0.0444
============================================================


📊 Round 222 Test Metrics:
   Loss: 0.0867, RMSE: 0.2944, MAE: 0.2547, R²: -0.0320

📊 Round 222 Test Metrics:
   Loss: 0.0867, RMSE: 0.2944, MAE: 0.2547, R²: -0.0320

📊 Round 222 Test Metrics:
   Loss: 0.0867, RMSE: 0.2944, MAE: 0.2547, R²: -0.0320

📊 Round 222 Test Metrics:
   Loss: 0.0867, RMSE: 0.2944, MAE: 0.2547, R²: -0.0320

============================================================
🔄 Round 229 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 229 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0269
   Val:   Loss=0.0763, RMSE=0.2762, R²=-0.0224
============================================================


📊 Round 229 Test Metrics:
   Loss: 0.0867, RMSE: 0.2944, MAE: 0.2547, R²: -0.0320

============================================================
🔄 Round 230 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 230 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0273
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0321
============================================================


📊 Round 230 Test Metrics:
   Loss: 0.0867, RMSE: 0.2944, MAE: 0.2547, R²: -0.0320

📊 Round 230 Test Metrics:
   Loss: 0.0867, RMSE: 0.2944, MAE: 0.2547, R²: -0.0320

============================================================
🔄 Round 237 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 237 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0335
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0185
============================================================


============================================================
🔄 Round 238 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 238 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0303
   Val:   Loss=0.0811, RMSE=0.2849, R²=-0.0088
============================================================


📊 Round 238 Test Metrics:
   Loss: 0.0867, RMSE: 0.2944, MAE: 0.2547, R²: -0.0321

📊 Round 238 Test Metrics:
   Loss: 0.0867, RMSE: 0.2944, MAE: 0.2547, R²: -0.0321

============================================================
🔄 Round 241 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0696 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0696, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0696, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0696, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0697, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0698, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0696)

============================================================
📊 Round 241 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0333
   Val:   Loss=0.0696, RMSE=0.2638, R²=-0.0514
============================================================


📊 Round 241 Test Metrics:
   Loss: 0.0867, RMSE: 0.2944, MAE: 0.2547, R²: -0.0320

============================================================
🔄 Round 244 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 244 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=-0.0279
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0254
============================================================


============================================================
🔄 Round 245 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 245 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0362
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0124
============================================================


============================================================
🔄 Round 246 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 246 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0313
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0049
============================================================


============================================================
🔄 Round 247 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 247 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0293
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0121
============================================================


📊 Round 247 Test Metrics:
   Loss: 0.0867, RMSE: 0.2944, MAE: 0.2547, R²: -0.0320

============================================================
🔄 Round 248 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 248 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=-0.0227
   Val:   Loss=0.0776, RMSE=0.2786, R²=-0.0381
============================================================


📊 Round 248 Test Metrics:
   Loss: 0.0867, RMSE: 0.2944, MAE: 0.2547, R²: -0.0320

============================================================
🔄 Round 251 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0713 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0713, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0713, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0713, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0712, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0711, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 251 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0196
   Val:   Loss=0.0713, RMSE=0.2670, R²=-0.0726
============================================================


============================================================
🔄 Round 254 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 254 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0239
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0324
============================================================


📊 Round 254 Test Metrics:
   Loss: 0.0867, RMSE: 0.2944, MAE: 0.2547, R²: -0.0320

============================================================
🔄 Round 255 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 255 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0327
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0033
============================================================


📊 Round 255 Test Metrics:
   Loss: 0.0867, RMSE: 0.2944, MAE: 0.2547, R²: -0.0320

📊 Round 255 Test Metrics:
   Loss: 0.0867, RMSE: 0.2944, MAE: 0.2547, R²: -0.0320

📊 Round 255 Test Metrics:
   Loss: 0.0867, RMSE: 0.2944, MAE: 0.2547, R²: -0.0320

📊 Round 255 Test Metrics:
   Loss: 0.0867, RMSE: 0.2944, MAE: 0.2547, R²: -0.0319

============================================================
🔄 Round 263 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 263 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0337
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0086
============================================================


============================================================
🔄 Round 264 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 264 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0331
   Val:   Loss=0.0769, RMSE=0.2774, R²=-0.0078
============================================================


============================================================
🔄 Round 265 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 265 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0299
   Val:   Loss=0.0839, RMSE=0.2896, R²=-0.0223
============================================================


📊 Round 265 Test Metrics:
   Loss: 0.0867, RMSE: 0.2944, MAE: 0.2547, R²: -0.0320

📊 Round 265 Test Metrics:
   Loss: 0.0867, RMSE: 0.2944, MAE: 0.2547, R²: -0.0320

📊 Round 265 Test Metrics:
   Loss: 0.0867, RMSE: 0.2944, MAE: 0.2547, R²: -0.0320

📊 Round 265 Test Metrics:
   Loss: 0.0867, RMSE: 0.2944, MAE: 0.2547, R²: -0.0320

📊 Round 265 Test Metrics:
   Loss: 0.0867, RMSE: 0.2944, MAE: 0.2547, R²: -0.0320

📊 Round 265 Test Metrics:
   Loss: 0.0867, RMSE: 0.2944, MAE: 0.2547, R²: -0.0320

📊 Round 265 Test Metrics:
   Loss: 0.0867, RMSE: 0.2944, MAE: 0.2547, R²: -0.0320

============================================================
🔄 Round 277 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 277 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0246
   Val:   Loss=0.0790, RMSE=0.2810, R²=-0.0342
============================================================


📊 Round 277 Test Metrics:
   Loss: 0.0867, RMSE: 0.2944, MAE: 0.2547, R²: -0.0320

============================================================
🔄 Round 279 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 279 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2896, R²=-0.0316
   Val:   Loss=0.0744, RMSE=0.2727, R²=-0.0022
============================================================


📊 Round 279 Test Metrics:
   Loss: 0.0867, RMSE: 0.2944, MAE: 0.2547, R²: -0.0320

============================================================
🔄 Round 280 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 280 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0265
   Val:   Loss=0.0829, RMSE=0.2880, R²=-0.0355
============================================================


============================================================
🔄 Round 281 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 281 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0262
   Val:   Loss=0.0852, RMSE=0.2918, R²=-0.0224
============================================================


📊 Round 281 Test Metrics:
   Loss: 0.0867, RMSE: 0.2944, MAE: 0.2547, R²: -0.0320

============================================================
🔄 Round 282 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 282 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=-0.0256
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0321
============================================================


📊 Round 282 Test Metrics:
   Loss: 0.0867, RMSE: 0.2944, MAE: 0.2547, R²: -0.0320

============================================================
🔄 Round 284 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 284 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0233
   Val:   Loss=0.0866, RMSE=0.2943, R²=-0.0344
============================================================


============================================================
🔄 Round 285 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 285 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0300
   Val:   Loss=0.0890, RMSE=0.2982, R²=-0.0101
============================================================


============================================================
🔄 Round 286 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 286 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0279
   Val:   Loss=0.0773, RMSE=0.2780, R²=-0.0321
============================================================


📊 Round 286 Test Metrics:
   Loss: 0.0867, RMSE: 0.2944, MAE: 0.2547, R²: -0.0320

📊 Round 286 Test Metrics:
   Loss: 0.0867, RMSE: 0.2944, MAE: 0.2547, R²: -0.0320

📊 Round 286 Test Metrics:
   Loss: 0.0867, RMSE: 0.2944, MAE: 0.2547, R²: -0.0319

============================================================
🔄 Round 294 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 294 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0210
   Val:   Loss=0.0796, RMSE=0.2822, R²=-0.0435
============================================================


📊 Round 294 Test Metrics:
   Loss: 0.0867, RMSE: 0.2944, MAE: 0.2547, R²: -0.0319

📊 Round 294 Test Metrics:
   Loss: 0.0867, RMSE: 0.2944, MAE: 0.2547, R²: -0.0319

============================================================
🔄 Round 298 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 298 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=-0.0261
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0324
============================================================


📊 Round 298 Test Metrics:
   Loss: 0.0866, RMSE: 0.2944, MAE: 0.2547, R²: -0.0318

📊 Round 298 Test Metrics:
   Loss: 0.0866, RMSE: 0.2944, MAE: 0.2547, R²: -0.0318

📊 Round 298 Test Metrics:
   Loss: 0.0866, RMSE: 0.2944, MAE: 0.2547, R²: -0.0318

============================================================
🔄 Round 302 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 302 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0289
   Val:   Loss=0.0799, RMSE=0.2826, R²=-0.0111
============================================================


📊 Round 302 Test Metrics:
   Loss: 0.0866, RMSE: 0.2944, MAE: 0.2547, R²: -0.0317

📊 Round 302 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0317

📊 Round 302 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0317

📊 Round 302 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0317

📊 Round 302 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0316

============================================================
🔄 Round 311 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 311 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0295
   Val:   Loss=0.0897, RMSE=0.2994, R²=-0.0123
============================================================


📊 Round 311 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0317

============================================================
🔄 Round 316 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 316 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0246
   Val:   Loss=0.0809, RMSE=0.2845, R²=-0.0300
============================================================


============================================================
🔄 Round 317 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 317 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0200
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0579
============================================================


============================================================
🔄 Round 318 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 318 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0227
   Val:   Loss=0.0731, RMSE=0.2703, R²=-0.0452
============================================================


📊 Round 318 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0316

============================================================
🔄 Round 321 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 321 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0277
   Val:   Loss=0.0783, RMSE=0.2799, R²=-0.0230
============================================================


📊 Round 321 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0316

============================================================
🔄 Round 322 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 322 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0286
   Val:   Loss=0.0753, RMSE=0.2745, R²=-0.0119
============================================================


============================================================
🔄 Round 323 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 323 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0229
   Val:   Loss=0.0775, RMSE=0.2783, R²=-0.0368
============================================================


📊 Round 323 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0316

============================================================
🔄 Round 326 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 326 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0296
   Val:   Loss=0.0781, RMSE=0.2795, R²=-0.0107
============================================================


📊 Round 326 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0315

============================================================
🔄 Round 328 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 328 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0235
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0333
============================================================


📊 Round 328 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0315

📊 Round 328 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0315

📊 Round 328 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0315

============================================================
🔄 Round 335 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 335 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=-0.0246
   Val:   Loss=0.0735, RMSE=0.2711, R²=-0.0335
============================================================


📊 Round 335 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0315

============================================================
🔄 Round 337 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 337 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0098
   Val:   Loss=0.0890, RMSE=0.2983, R²=-0.1290
============================================================


============================================================
🔄 Round 338 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 338 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=-0.0279
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0167
============================================================


============================================================
🔄 Round 339 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0711 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0711, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0711, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0711, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0711, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0711, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0711)

============================================================
📊 Round 339 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0311
   Val:   Loss=0.0711, RMSE=0.2667, R²=-0.0079
============================================================


============================================================
🔄 Round 340 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 340 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0185
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0628
============================================================


============================================================
🔄 Round 341 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 341 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0302
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0080
============================================================


📊 Round 341 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0315

============================================================
🔄 Round 342 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 342 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0225
   Val:   Loss=0.0884, RMSE=0.2973, R²=-0.0686
============================================================


📊 Round 342 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0316

============================================================
🔄 Round 344 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 344 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0254
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0243
============================================================


📊 Round 344 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0316

📊 Round 344 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0316

📊 Round 344 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0316

============================================================
🔄 Round 348 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 348 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0329
   Val:   Loss=0.0860, RMSE=0.2932, R²=0.0008
============================================================


📊 Round 348 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0316

============================================================
🔄 Round 350 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 350 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0168
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0584
============================================================


============================================================
🔄 Round 352 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 352 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0176
   Val:   Loss=0.0880, RMSE=0.2967, R²=-0.0519
============================================================


📊 Round 352 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0316

============================================================
🔄 Round 354 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 354 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0364
   Val:   Loss=0.0875, RMSE=0.2957, R²=0.0085
============================================================


============================================================
🔄 Round 355 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 355 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0297
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0156
============================================================


============================================================
🔄 Round 358 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 358 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0366
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0168
============================================================


📊 Round 358 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0316

============================================================
🔄 Round 360 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 360 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=-0.0184
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0552
============================================================


📊 Round 360 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0317

📊 Round 360 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0317

📊 Round 360 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0317

============================================================
🔄 Round 365 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 365 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0227
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0350
============================================================


============================================================
🔄 Round 367 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 367 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=-0.0193
   Val:   Loss=0.0914, RMSE=0.3023, R²=-0.0676
============================================================


📊 Round 367 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0316

📊 Round 367 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0316

============================================================
🔄 Round 371 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 371 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0252
   Val:   Loss=0.0811, RMSE=0.2847, R²=-0.0224
============================================================


============================================================
🔄 Round 372 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 372 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0228
   Val:   Loss=0.0833, RMSE=0.2887, R²=-0.0320
============================================================


============================================================
🔄 Round 373 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 373 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0231
   Val:   Loss=0.0879, RMSE=0.2965, R²=-0.0382
============================================================


============================================================
🔄 Round 374 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 374 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0263
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0286
============================================================


============================================================
🔄 Round 375 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 375 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0290
   Val:   Loss=0.0891, RMSE=0.2985, R²=-0.0179
============================================================


📊 Round 375 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0316

📊 Round 375 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0316

============================================================
🔄 Round 377 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 377 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0262
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0235
============================================================


📊 Round 377 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0316

============================================================
🔄 Round 379 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 379 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0192
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0455
============================================================


📊 Round 379 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0316

📊 Round 379 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0316

📊 Round 379 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0316

============================================================
🔄 Round 388 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 388 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0236
   Val:   Loss=0.0761, RMSE=0.2758, R²=-0.0317
============================================================


📊 Round 388 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0316

============================================================
🔄 Round 392 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 392 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0265
   Val:   Loss=0.0863, RMSE=0.2937, R²=-0.0202
============================================================


📊 Round 392 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0315

============================================================
🔄 Round 393 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 393 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0263
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0216
============================================================


============================================================
🔄 Round 394 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 394 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0333
   Val:   Loss=0.0838, RMSE=0.2895, R²=0.0068
============================================================


📊 Round 394 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0315

============================================================
🔄 Round 395 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 395 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0269
   Val:   Loss=0.0811, RMSE=0.2849, R²=-0.0183
============================================================


============================================================
🔄 Round 397 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 397 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=-0.0191
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0545
============================================================


============================================================
🔄 Round 398 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 398 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=-0.0318
   Val:   Loss=0.0926, RMSE=0.3043, R²=-0.0066
============================================================


📊 Round 398 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0316

============================================================
🔄 Round 399 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 399 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0287
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0084
============================================================


📊 Round 399 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0315

📊 Round 399 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0315

📊 Round 399 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0315

============================================================
🔄 Round 405 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 405 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0252
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0253
============================================================


============================================================
🔄 Round 406 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 406 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0265
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.0270
============================================================


📊 Round 406 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0314

📊 Round 406 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0314

📊 Round 406 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0314

📊 Round 406 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0314

============================================================
🔄 Round 416 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 416 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0170
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0665
============================================================


============================================================
🔄 Round 418 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 418 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0328
   Val:   Loss=0.0783, RMSE=0.2797, R²=-0.0024
============================================================


📊 Round 418 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0314

============================================================
🔄 Round 419 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 419 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0253
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0245
============================================================


============================================================
🔄 Round 420 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 420 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0241
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0285
============================================================


📊 Round 420 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0314

📊 Round 420 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0313

============================================================
🔄 Round 423 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 423 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0237
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0318
============================================================


============================================================
🔄 Round 424 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 424 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0239
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0292
============================================================


📊 Round 424 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0313

📊 Round 424 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0313

📊 Round 424 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0313

📊 Round 424 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0313

============================================================
🔄 Round 432 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 432 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0230
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0332
============================================================


============================================================
🔄 Round 433 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 433 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0264
   Val:   Loss=0.0753, RMSE=0.2744, R²=-0.0253
============================================================


============================================================
🔄 Round 434 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 434 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0231
   Val:   Loss=0.0809, RMSE=0.2845, R²=-0.0317
============================================================


============================================================
🔄 Round 435 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 435 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0291
   Val:   Loss=0.0784, RMSE=0.2800, R²=-0.0087
============================================================


📊 Round 435 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0313

📊 Round 435 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0313

📊 Round 435 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0313

📊 Round 435 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0313

📊 Round 435 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0313

============================================================
🔄 Round 442 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 442 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0275
   Val:   Loss=0.0784, RMSE=0.2801, R²=-0.0161
============================================================


📊 Round 442 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0313

📊 Round 442 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0313

📊 Round 442 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0313

📊 Round 442 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0313

============================================================
🔄 Round 448 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 448 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0329
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0013
============================================================


📊 Round 448 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0312

============================================================
🔄 Round 451 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 451 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0194
   Val:   Loss=0.0776, RMSE=0.2785, R²=-0.0493
============================================================


📊 Round 451 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0312

============================================================
🔄 Round 453 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 453 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0246
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0324
============================================================


============================================================
🔄 Round 454 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 454 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0192
   Val:   Loss=0.0736, RMSE=0.2713, R²=-0.0661
============================================================


📊 Round 454 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0311

📊 Round 454 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0311

============================================================
🔄 Round 456 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 456 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0325
   Val:   Loss=0.0831, RMSE=0.2882, R²=-0.0004
============================================================


============================================================
🔄 Round 460 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 460 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0224
   Val:   Loss=0.0784, RMSE=0.2800, R²=-0.0372
============================================================


📊 Round 460 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0311

============================================================
🔄 Round 462 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 462 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0196
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0483
============================================================


📊 Round 462 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0311

📊 Round 462 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0311

============================================================
🔄 Round 465 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 465 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=-0.0202
   Val:   Loss=0.0905, RMSE=0.3009, R²=-0.0442
============================================================


📊 Round 465 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0311

============================================================
🔄 Round 467 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 467 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0243
   Val:   Loss=0.0773, RMSE=0.2781, R²=-0.0376
============================================================


📊 Round 467 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0311

============================================================
🔄 Round 469 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 469 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0174
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0536
============================================================


============================================================
🔄 Round 470 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 470 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0289
   Val:   Loss=0.0744, RMSE=0.2728, R²=-0.0071
============================================================


📊 Round 470 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0311

📊 Round 470 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0311

📊 Round 470 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0311

============================================================
🔄 Round 477 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0691 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0691, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0691, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0691, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0692, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0692, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0691)

============================================================
📊 Round 477 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0416
   Val:   Loss=0.0691, RMSE=0.2629, R²=0.0179
============================================================


============================================================
🔄 Round 479 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 479 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=-0.0273
   Val:   Loss=0.0757, RMSE=0.2752, R²=-0.0136
============================================================


============================================================
🔄 Round 480 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 480 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0269
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0327
============================================================


📊 Round 480 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0311

📊 Round 480 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0311

============================================================
🔄 Round 483 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 483 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0278
   Val:   Loss=0.0731, RMSE=0.2704, R²=-0.0111
============================================================


============================================================
🔄 Round 484 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 484 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0224
   Val:   Loss=0.0862, RMSE=0.2937, R²=-0.0495
============================================================


📊 Round 484 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0311

============================================================
🔄 Round 486 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0675 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0675, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0675, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0675, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0675, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0674, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0675)

============================================================
📊 Round 486 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0293
   Val:   Loss=0.0675, RMSE=0.2598, R²=-0.0028
============================================================


📊 Round 486 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0311

============================================================
🔄 Round 488 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 488 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0229
   Val:   Loss=0.0830, RMSE=0.2880, R²=-0.0338
============================================================


============================================================
🔄 Round 489 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 489 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0295
   Val:   Loss=0.0821, RMSE=0.2864, R²=-0.0211
============================================================


============================================================
🔄 Round 491 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 491 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0259
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0216
============================================================


============================================================
🔄 Round 492 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 492 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0245
   Val:   Loss=0.0786, RMSE=0.2803, R²=-0.0255
============================================================


============================================================
🔄 Round 493 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 493 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0288
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0082
============================================================


📊 Round 493 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0311

============================================================
🔄 Round 494 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 494 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0237
   Val:   Loss=0.0807, RMSE=0.2840, R²=-0.0326
============================================================


📊 Round 494 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0311

============================================================
🔄 Round 497 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 497 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0275
   Val:   Loss=0.0895, RMSE=0.2992, R²=-0.0176
============================================================


============================================================
🔄 Round 498 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 498 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0188
   Val:   Loss=0.0795, RMSE=0.2819, R²=-0.0494
============================================================


📊 Round 498 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0311

📊 Round 498 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0311

============================================================
🔄 Round 504 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 504 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0288
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0094
============================================================


============================================================
🔄 Round 505 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 505 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2856, R²=-0.0213
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0377
============================================================


📊 Round 505 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0311

============================================================
🔄 Round 507 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 507 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0201
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0430
============================================================


📊 Round 507 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0311

============================================================
🔄 Round 512 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 512 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0301
   Val:   Loss=0.0873, RMSE=0.2954, R²=-0.0101
============================================================


📊 Round 512 Test Metrics:
   Loss: 0.0866, RMSE: 0.2942, MAE: 0.2547, R²: -0.0310

📊 Round 512 Test Metrics:
   Loss: 0.0866, RMSE: 0.2942, MAE: 0.2547, R²: -0.0310

============================================================
🔄 Round 516 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 516 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0205
   Val:   Loss=0.0772, RMSE=0.2778, R²=-0.0444
============================================================


📊 Round 516 Test Metrics:
   Loss: 0.0866, RMSE: 0.2942, MAE: 0.2547, R²: -0.0310

============================================================
🔄 Round 518 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 518 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0249
   Val:   Loss=0.0784, RMSE=0.2799, R²=-0.0242
============================================================


============================================================
🔄 Round 519 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 519 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0236
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0290
============================================================


============================================================
🔄 Round 520 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 520 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=-0.0202
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0470
============================================================


============================================================
🔄 Round 521 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 521 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0205
   Val:   Loss=0.0784, RMSE=0.2800, R²=-0.0426
============================================================


📊 Round 521 Test Metrics:
   Loss: 0.0866, RMSE: 0.2942, MAE: 0.2547, R²: -0.0310

============================================================
🔄 Round 522 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 522 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0260
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0262
============================================================


📊 Round 522 Test Metrics:
   Loss: 0.0866, RMSE: 0.2942, MAE: 0.2547, R²: -0.0310

============================================================
🔄 Round 524 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 524 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0182
   Val:   Loss=0.0810, RMSE=0.2845, R²=-0.0532
============================================================


📊 Round 524 Test Metrics:
   Loss: 0.0866, RMSE: 0.2942, MAE: 0.2547, R²: -0.0310

============================================================
🔄 Round 525 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 525 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0262
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0321
============================================================


📊 Round 525 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0310

📊 Round 525 Test Metrics:
   Loss: 0.0866, RMSE: 0.2942, MAE: 0.2547, R²: -0.0310

============================================================
🔄 Round 528 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 528 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0217
   Val:   Loss=0.0840, RMSE=0.2899, R²=-0.0360
============================================================


📊 Round 528 Test Metrics:
   Loss: 0.0866, RMSE: 0.2942, MAE: 0.2547, R²: -0.0310

📊 Round 528 Test Metrics:
   Loss: 0.0866, RMSE: 0.2942, MAE: 0.2547, R²: -0.0310

📊 Round 528 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0310

============================================================
🔄 Round 531 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 531 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0249
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0224
============================================================


============================================================
🔄 Round 536 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 536 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0242
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0329
============================================================


📊 Round 536 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0311

============================================================
🔄 Round 538 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 538 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=-0.0323
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0269
============================================================


============================================================
🔄 Round 540 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 540 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0225
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0395
============================================================


📊 Round 540 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0311

============================================================
🔄 Round 543 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 543 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0193
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0468
============================================================


📊 Round 543 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0311

📊 Round 543 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0312

============================================================
🔄 Round 548 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 548 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0381
   Val:   Loss=0.0733, RMSE=0.2707, R²=0.0291
============================================================


📊 Round 548 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0312

📊 Round 548 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0313

============================================================
🔄 Round 552 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 552 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0206
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0383
============================================================


📊 Round 552 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0313

📊 Round 552 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0312

📊 Round 552 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0312

📊 Round 552 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0312

📊 Round 552 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0312

============================================================
🔄 Round 561 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 561 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0288
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0100
============================================================


📊 Round 561 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0311

📊 Round 561 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0311

============================================================
🔄 Round 565 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 565 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=-0.0147
   Val:   Loss=0.0919, RMSE=0.3032, R²=-0.0743
============================================================


📊 Round 565 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0311

============================================================
🔄 Round 567 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 567 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0246
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0256
============================================================


============================================================
🔄 Round 569 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 569 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0262
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0187
============================================================


📊 Round 569 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0311

============================================================
🔄 Round 570 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 570 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0250
   Val:   Loss=0.0734, RMSE=0.2710, R²=-0.0207
============================================================


📊 Round 570 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0311

============================================================
🔄 Round 573 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0717, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0717, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0717, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0716, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 573 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0261
   Val:   Loss=0.0717, RMSE=0.2678, R²=-0.0161
============================================================


============================================================
🔄 Round 575 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 575 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0248
   Val:   Loss=0.0777, RMSE=0.2788, R²=-0.0216
============================================================


📊 Round 575 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2547, R²: -0.0311

❌ Client client_2 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8688 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8688 {grpc_status:14, grpc_message:"Socket closed"}"
>
