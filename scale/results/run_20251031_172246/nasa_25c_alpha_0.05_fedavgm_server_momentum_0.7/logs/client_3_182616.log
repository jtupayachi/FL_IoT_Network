[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d560001-4b56-4178-bce3-634767f5e789
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ab2aee8-1506-42f0-b3ab-5b6ae3ba09c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff73b569-69a3-4b5c-b14c-74685a2d1ead
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69b5ee33-80b2-4359-a374-0203af734443
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f698ca20-83c9-478d-89e0-d645607cb1d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1fcc040a-9b14-4628-849b-cf7feb0c78ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f01ee7db-11e6-4d74-80e7-1d9a32f381a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4eaf192-af7f-4a6f-a5bd-a85072f5a1bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e05279e-511c-44b7-9d50-358052ba2474
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c3cab76-5f86-4067-9f3f-043413d6ff2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d14a5c5e-c1de-432e-9713-1e4bed578461
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 155e34cb-e14c-4241-8b73-1aea3416b7c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46a71ee2-0733-4827-abf5-260c035b233f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53cf68c6-c431-4cc1-a863-4843fa2fcbd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f950b26-55f3-4f80-a9cc-217e1e259141
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4194ab3f-ba84-4939-a981-b04768f70006
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b4aa117-bd7d-4e0d-b5e9-0b83ebd65842
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a724bd89-9be4-40ee-a3c8-7abb66735ca5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 221fd7ed-46e9-4041-8e2f-ebae17fadea8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b008c035-1551-4971-a170-38f5bd6c6bbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a8ffe72-a6b3-4745-950d-bfbc536bb3b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3cba7256-e0dc-46f9-b222-420998772f86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21aefe6e-0c7b-450f-918f-cd448a57a9e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59cefd52-c2ba-4400-a46e-4a1b13f5e27a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f451fac2-0f26-4ec5-8cf9-275703831879
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e33920b-76c8-4a98-82c1-6fea350a08b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 484f494e-6028-4d55-bc6b-91842eff88a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c92aec4-6cbc-45af-92e3-8c4174c91ab8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15cabd26-2d0e-4d51-8465-c7bc00ccf638
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dfd8837f-5711-4c07-9c3f-b0d6bb70d1a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a1d10ca-9911-44dc-98d1-9c32695bbaa8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4c35e44-5967-461b-ad85-8078ba65c425
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cee22f47-67df-429a-9fc7-4209bfd6edde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6a95f65-9cfa-48cf-89e6-916c4b495900
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd66ad1d-63ad-432a-81fd-5006ac23b7fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22cd97b8-8b43-40e3-8834-937de8de8181
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22717b5c-d926-4346-8133-f4a63eb4224b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4403b820-52c2-4082-9d72-a219d02fe5e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db8d6dc2-9522-4988-a5b4-754a694928ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 798651e5-bcc3-45ea-b499-12ca62057b25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d82702c3-af9f-4a65-918a-20ed40e76453
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cabc1d26-48ea-4b9c-85c9-b7e26c66d43f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message abcacd75-7f43-45c3-9a49-1a3a1e77889b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec2a01b5-19aa-4165-8762-99ff1b334f86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a857577d-d2b6-413c-9e52-d7a29bb75a4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38ea1732-6522-46b8-8112-324ab0e4b877
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c49b5b9e-6331-4c85-a1e7-e86328e91300
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fcb9ebb3-929d-446e-b083-4f9452b2e1dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43607bc8-e344-427a-82bf-25e5054bb9ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d536cbea-b352-42fb-be62-17fd17b5e251
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ea6a01a-691c-4955-9ed4-f57d7df95a23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83ae86b8-c44a-459f-bdcf-9630952ecb72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ac8d054-31b6-4f4b-9c64-a703855f968a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1aee9ba4-2e04-44b3-8ce1-09e5f7249103
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3cfd151f-9073-46f0-a7c5-dc6e620b6e60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd475633-fcc1-485f-a002-545cfc19f89f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56e57bd4-79cd-4c44-8470-e24fa5e1c081
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5750070b-f964-4b42-a4e8-302b3955265b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12561b58-3cf5-44b9-98bf-93b219a9322b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a10e5673-7332-45f1-91dd-db02174787bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18eba3e8-9808-4cd4-a831-1e1d6475f971
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0842c8a8-af3b-4af8-ab3b-fdc9ccdab184
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04d93cde-f96d-4a5d-be45-c51a44328831
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9822bca-2874-4d39-a36c-ce65ea0a74d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b0944e4-e7e7-4234-9cb4-e205e937f3d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35c01613-e314-4770-b8c9-c1ccbe26dd7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e8d3641-4765-493a-b582-c353c8217b40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55d40a68-731b-4b5d-8c5f-24fdb7f08233
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 388de35a-b882-4a19-a7c5-f18a45497a60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0bd6b2f-a94f-4f72-95c8-97acc6afe995
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82739f0c-eff8-419e-a116-7041113ba706
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9349488a-7f47-41fa-bc35-fcb787a471e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4df9a07-e02d-4246-b8bf-9e1e5c7c7ed7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb4e496c-5c66-48b9-a822-99d35926b48f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13d46cf4-5637-4aaf-a098-dbceb44cb1a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d018a521-a2d2-4e64-8bbb-edf6389e8b4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d64da3a-4a8b-4786-a7ad-6c0a6c86fc0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e8b9e58-a7e7-4806-9760-4e70ea72496c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16bee864-daec-47a1-9778-173643d67893
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75570246-9cb4-4824-827a-8d0814228774
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message effd3f2e-f208-4faf-a9a9-a7d9ce34f2b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25395b4c-be21-4a44-ab9a-90def61a78bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0176614e-cda5-4eb6-be84-f85c77ebc0cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 736aa43a-a640-4ea3-801b-41bd489090ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 602180a5-0bf5-4110-9c5f-56e317ab193e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bebf805f-e80b-4267-85c9-a635b0a9ee4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32d728b9-772e-4c39-8b91-4733129fd76a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a604889-5fc5-4646-8eed-e969983d5596
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be5403b5-21f2-46fa-95f6-67ce230f3a31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 010d6bc1-7da4-4aac-9a84-35faa172ad09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce68ebfb-3988-4dc1-8e2a-f7a9cfe4c1c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4804401d-295c-4e36-8ff2-9a9a0ad34546
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d40a4c9-1412-4bc7-8365-c5d5e0aa812b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7db3d138-845a-4261-bbbb-a0347a4f0c1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b54496c-8d8e-450a-9bbc-5cf9ada68833
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9fc51590-de16-49e1-9e06-87904855c5e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13d5a566-d7f0-4352-b80a-30a44d07cd45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15056a86-6867-4f8f-a65d-5188d7ca75bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78c36ba2-90e9-4519-9f70-1d58d827660e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0ccd151-369c-4911-9a49-6762575f2b3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd0cd131-6ec9-4f9d-b81e-8d48ecf76b86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e82ade2-bf1a-4452-92de-9339854219a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7217951-95a6-4711-a903-a28acb5af593
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3bdd2828-68b6-460f-90e9-38acfaf3a3ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a4d58fe-d9e9-4ab1-bf74-e91a280c3f54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15da9174-9429-48b2-ae90-7024d9fb80b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39ab382f-36b7-41d6-9a8e-f5fdb0bf79e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc9c25ff-2a6a-4445-b540-3f89d5adb95b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e9927b3-23f5-43cb-ab79-fb531d5efa8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9da20482-b9f9-4c29-8380-ee2da204c3c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 801c6d9b-f91d-4491-ba4c-c0bcb496b830
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2cee37b3-be96-4725-ba2f-8ae86158a3a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2441afc3-dcf7-499c-84f6-3f7e281929ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33d25da3-42f5-4c2b-a4cc-5a8fb7b6f444
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86f7d225-5214-43b5-8ac6-bf1305c2e7de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a002c7e5-ce5d-4ef0-9ebd-76b06ceff1a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f54c609-93a4-48e7-8191-57a88661d542
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3d41abe-ee89-4655-87f0-a37fc94f9aed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c9eaa13-10a4-44e0-b355-886247262a62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c6f86fc-1343-4597-b509-8bf06c57eb12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message afa58950-2ca5-405c-af4b-c65b13c81718
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fba212e0-46bd-4fb1-9ca0-85a06e73dc13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d64bef2-a853-4dda-b466-466f0ff925ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7209d59-579e-46b1-b7b1-edcd82a2a27a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 234cbf31-396c-4115-9565-f5b7787c7eac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52611c27-382d-40dd-9ff5-b4f0ff95bdb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f24c1bf-ab7b-4b22-aaf0-1881945c3c3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b052c39f-e276-4016-a76b-e4ca4a5e0513
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c80f0826-0c55-4d6d-9cd9-09455270041a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d1faa7d-3f85-4b0b-8bbe-8397d9e50978
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2486a9e8-5b1a-443b-a67b-250156a617d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e3aca6a-6b64-4eda-b885-9d810f0b278d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d936cc4-7a9f-4ed1-a3c5-2671ec4e9605
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 775115b4-b0ce-4427-a986-68080ccbeeb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7266ce02-17d3-4d73-81d3-254f2fe41c00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2866485-df2d-408a-b108-24f87ea5960b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ecdc79cb-7bc1-4425-8d63-0a2592c7f467
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8ff3752-fc6d-43f4-963b-ec0a06d14cab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 499a2396-482e-44f8-bf8b-59a031b42ec2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7310fac-2095-4a71-9b06-e1aa72726e63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49ca54f2-7bf5-432b-adbf-b3787f9212cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e397e17-e7ec-497b-87dd-0bd9af906d92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8fab7b7d-3d2b-477d-a303-e2a5431b8225
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10f7a70f-5bf6-4fec-9c4f-7b4b7015220a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5aff94e-59d6-47eb-82cf-80138f2cb807
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9e002d2-c641-473e-8391-93856e116ec9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72800fc7-dc2b-4aa1-a1fb-86a4ac1b3d90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 252e8bde-0333-4757-82ce-4c7b87a7e303
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a67a5f6-41a6-4fd6-ba59-e27eef146fee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66eec577-84f5-42fd-b826-e381ea5856e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bab08cb3-306c-40fd-b06c-dd2b88e09264
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5940f32d-f994-4b5f-a55d-8bc466fbaf71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6365d12a-c120-4db0-85eb-887ac88ed6d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34772d36-235c-4a15-805b-dc42f67df8ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35777f83-b921-4059-b5c8-077c96beb71b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f5fef03-7a2e-4169-bad4-cc04b23acfca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2bf78b40-b1fe-4f4e-a672-c5f4635962f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1bb87e1f-726b-477f-b69f-9176baf34024
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57e2df18-07c8-431f-a02d-f5fa5277da71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b59cd2c-bf53-422e-898f-cd9fb1cd2b4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7958aa5-da82-4242-8b3f-295ac7d89162
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8275e997-448b-45bc-ab8e-4aa666643a09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a5508b5-cd61-49d0-9435-7a112e17042e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d95c1ca1-c808-4347-a99d-0dc8edb73245
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c87871e-b933-4d9e-92e1-41ed4d30b31f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 988e8e9f-c8d8-44a3-b61e-bea099e4e26f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a49fbaec-c2af-4743-96df-d9e20cc73a3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89468c46-3868-4450-a03a-179235c04787
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9777290-65b2-490d-87b4-e81e1ef6fd17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5ed9f77-90a6-4606-8388-1375a428037f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b62da5c-2b99-401f-aa5a-bf8ea3714883
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a816b18-38eb-4c2a-97d7-c9122512aa1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f5a2215-b933-41b0-8df1-923d051d77d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58938680-9e22-4c41-b8c1-a17aeb144543
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d51e05ba-0c8b-4a60-bc80-ae5bf10e94c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b8c1543-87a6-4333-aa51-a13ff8818071
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ab1981e-2d1a-429f-9e4e-ea7d1d9c3926
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f6e4cee-bd99-4a4f-9691-fd54434d68a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f472863-5c1b-4f7a-87dc-e73877479fe4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 544117df-92c1-4b7c-aeae-7626b27a4556
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d79c70f-9364-4a2a-b4b9-22e3890f5bb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5428daa2-f221-4c17-a668-ea50e8cbc76a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee564836-e01f-4d58-b589-0dfdb6e02da2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68514a00-15bf-4d9c-a570-c59d9376e921
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ee3fa24-31e8-4318-a656-428ea5d93a56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57da9a1b-33a8-49cd-be9c-da92af273c2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9a21123-33f2-4d3f-8e2b-061d398a781b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40e33e10-d58f-4d16-ae12-3b9e887a8ae3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7883cc87-f829-43f5-a45d-2100230fc08e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6bb409bb-162c-4d59-8513-0a380f412f7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 718abd8e-b166-408c-b659-61c3cd6200d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ca8f279-5022-4783-b4db-d158026ebc15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e03f0c7-7a76-4950-89c6-c7bfed8fb5fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f23c245-5b09-4c4a-8a58-a13565ad8d76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b97bd99-a1e1-48b6-ab20-090d9a40a45b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9b8d7b1-e00d-4a6c-b56f-5d7d2f572a47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9606d075-275a-4965-9919-cbcefed7b4dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db903686-76c5-4fbb-a8ca-6f1215dd4672
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 344ffccd-2792-413c-a970-4684752c52dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b678fa9c-c933-4a25-bd9a-43b7d4d44a60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d440db1f-a07c-4973-9a68-ff318404d8c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ad13749-2ccf-4062-952b-61ca06ff4563
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d57b2a2-e8d9-4415-866b-3971dec33701
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ec23bb1-3a73-4d12-a6c5-ecb799cb8b6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 984a8f65-3b46-47c3-9bcd-c74006abbb8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be05f3f3-af4e-465e-b420-d1a942e831bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71926890-7a77-411c-9848-b54cf8849c90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3473c171-6587-4afc-ad61-0d24fd0c7d41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a90fdf6-62a9-413d-b2dd-b71fcbfca095
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3334219-57f7-4188-9d33-21c8cc57a384
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3abb4b03-b8ec-4bd8-872a-aceb90d6fd21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88c0cd17-4024-4c37-af92-eca2a3b11fa9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cab74d1b-39d9-4ceb-88bb-70ca17f3a2f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ec5d4bb-3f9a-427e-8374-f6dea026bdba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac92fe0b-8346-484a-8734-5400b9c896be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63865874-52b9-476f-8972-a200cd951c82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86f7f69f-ff47-4950-a85c-9f88c48f9fc1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8fd3993-8359-454c-9342-b4bb69d77e8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52d98415-aec6-43ff-8be7-dc9d14d40cc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f2df27a-ceaf-4720-ae0f-c050245cdd03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55cdd851-a1b7-4228-ac17-922f0aba9d08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38ea81a7-13f1-4a6b-a598-72897ac8aa39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4bab0b24-75fd-4c49-8e8f-1b804d3d833b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d17d396-3b20-4a2c-9d1a-6f8dfc7b9b30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3a1619d-b060-4d04-8f10-0a6191fec649
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 331f0fb8-3c32-40a9-bc9c-2713aab1edfc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2898eeea-cac0-4248-aac4-9fbc58a83486
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eeec3aac-158e-409f-835b-5d29dfc8c2c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53cec29a-4a0f-4b5b-be18-9bba435767b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03beae47-1a2b-4545-ab54-d192cfd6eaf5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08dcfbcb-e7f0-46be-945f-e73b523e35a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94542400-48c2-42f7-aa4a-fd4f154c2ef2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1d4a616-04d8-4304-a868-3ee82296f44a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b837712-d3d1-4c14-bd04-1edb99eebd7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8826054-0737-44a2-9cc4-fc74a48cbe34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b4b8225-50d0-46d2-a0ed-e26defebc596
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4095a4b7-ea6e-44d3-af2e-a190168a1206
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a12f6510-a3ba-4f40-98f6-de03bf758a36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b34a517-51d3-44c9-89aa-c8cec80d0959
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a975a50-062a-4f01-a4c1-fb29322d2c95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7c0f95f-001d-4229-bd50-ee625e6ce84d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 317ea586-31c9-4fe3-b51e-15f3a59e775e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21569b8c-c8b4-4508-b45a-38d095c33392
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a9b5290-e311-484d-ac56-6a63db6e9555
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f93ffeaf-dc21-4369-a607-980ac3281aac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c3de441-3bf0-4f8c-851d-cf762f3995f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b66304f4-50bf-408d-a426-c9fde8b834cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82066147-5e94-4093-912c-8be2861a4bc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba8a88df-9ebf-481c-a8b1-450ba6603484
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ac748da-bf88-4569-ab31-fa22efde71fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2204f812-d61e-4c03-8c4f-107b02c39709
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ce71a7a-a822-4f68-a5ab-829e45dda720
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43f86b04-0143-4c51-a481-6827b50aec8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 746c8b4f-efff-4874-b9f8-e1f2f0b9711f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99d608ee-11ea-4de9-accc-64a88350da64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7145d448-0ee1-4e44-8f17-5254bf65f68b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86015ded-0f57-4829-916e-280e2bddca7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8bc5b3b-4477-4c9a-89a4-40e27f5eeb44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83cf9ece-b82a-4e45-a3bc-87ce88afc4ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27cff2dd-3b63-4ab6-ac6f-a75f839b0068
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c14a20bd-c2ec-4dec-98fd-74ef9a8187a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 604752de-cad6-4c2b-b690-a50bac853170
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e19e9d03-2b9c-4b56-beb3-592758b56b92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60b8645c-a832-4bcb-9277-5495908c6389
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22f1ea73-2b8c-45a8-89fd-ed02828e0a0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3654734e-2e0f-4d6a-8028-2175fd6861a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9da79a90-d921-438f-a326-974a4a4f19ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b9ab8c2-e900-49cf-a1bd-cece3a608645
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ed3a606-8cba-4c0d-a337-7e21dd6b37a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message faa8cd60-6f20-4fc6-9646-d4a15ff7ddae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52b5bb67-5f79-410d-98c2-53f01cf553a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a827fbe7-4edf-4988-951e-f3703f0573df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e154a9a-aa56-43cb-b072-316934a7d197
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 994049be-e8ee-468f-8014-5e25d09ce61e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9016a4be-1053-4402-933c-9a1f2a28f3ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc276506-3e47-4ab6-ab53-affea2d2c752
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d6f06ae-72c3-4eba-bed8-e61c6f4c08b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93ce0c6b-a441-4a5d-ae29-e27bb84fa414
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5a90b86-d82f-4ed6-9b52-0c889957b083
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4d85b73-0cd0-4704-879e-84f25b72e0ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8680015-82a9-4fc9-ba24-c5c97b8d52a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e227da0-5c99-466e-aaf3-f1e24be3f33c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0737c3e-b366-4cf5-a629-e0bf1bdba1a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5bc0a8de-3b78-463d-9e1d-893cf130d44f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f651c2f-6cd5-4974-802e-16aed71d6d50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc9dfe02-1196-4735-b4fd-ea7de321da80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04976c19-7a8e-49c8-9515-0eabd65f85c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b4f3cd6-ee12-4a76-94c1-97a71e99080e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd4e96b7-7392-400d-b86b-56bc580b48d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63ec59e1-031c-4624-8157-e14047ae84f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8910a592-5f13-4fa4-a55f-8d1eeb813eb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 704bff0e-06e5-4f4c-8a53-29288e8eabda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35e9575e-b502-4f35-8231-520a3c6f01fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42f92d2e-adfa-4c59-8166-972f4874a78d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 863bfcb8-f34f-4448-b375-a7586a3d1f90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b65dc13f-156f-42f6-b8f0-289d397c65ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7129346-570a-4371-9dfe-73c86cef79c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2f215b8-5f9a-40ae-956a-d75284ce68ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e8c665e-d614-4b3b-b56c-0952a5a51324
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16a2e7ea-3e8e-4ce3-a2ab-9ecc0a82c1fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b3ab6fc-051d-43fc-adc3-167f21bd52f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33de5ea1-efc5-431f-a389-944395d3d3b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 200fbd4f-9dad-4068-a74b-75323ec3fd1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0ec7a0a-1d59-4f64-9967-89515c4f8b4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05addc49-c792-49c7-a561-ceffa8aa7c3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 861eaf87-8536-463e-a35e-14cd970b7f4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e25abf6-f0e7-44ff-acfd-8594df401b1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 944042da-b712-49d8-a170-7192a8cc5cbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b23a55c-6032-4645-b4fe-7a5143988d29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d0eeb32-9e8b-4cf7-ad8b-4695f22c6fc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a733b8de-0b7b-40fa-9fb6-f86e5f5a9f21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3ecf67e-3923-4b3f-8441-5c3b7bd505f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4dc6861-da57-4170-8606-5d9a711e4ae1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9266ffb1-aac6-46ca-b889-0fd2d0cbdeae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7d5c302-bf68-4d9a-81ab-790c8e0acf1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9707dc89-5676-42ae-b76c-4a6f50b735e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b2bb289-2707-4d34-9f38-b10744d72a5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd6ca44d-a7a5-4ef1-8b69-8a6dc78227df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12d3763f-8505-4a0c-adc1-3210af8414e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e450b36-ecc8-42f5-b21f-1432a2b2b920
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98f3c00b-483f-4bbf-b485-9c33a31692b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 901602a1-58e2-4902-876b-fe40d4fb0965
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 068da101-98af-4334-a274-6cea2745f1c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2db4a718-b3ad-45c2-9536-bebc2edfba0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 798b4585-96e9-48b0-949e-d680e7b408fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e70de536-450f-4c47-a4a3-c93027fe627f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f744bba2-46cf-40e7-b5f3-53695cad10cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72127d40-6469-408f-89e4-aff9c59e3908
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9775846d-cf88-45ef-b798-82bc05a7d538
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88b8207a-a572-45d4-9490-f41c093baf0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6fa6686-4588-4d57-b68c-9489b65fc3b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99057b13-b6f5-43ba-88b2-df3defaf874b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59d0acb4-3f78-4e8c-9607-1ce35dd4f67a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4084dcc-63b6-4c58-a7c1-1f2804f5df7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eae6afb4-acbf-4738-864c-60cd591e2aec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0360a6d7-d938-4fa1-8af7-cb4e2294a425
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79e4f2d3-67c0-4fe4-a9d9-17e3508eb861
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5f7c2e2-eb10-41a7-a283-15208273f0c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54c77bed-249e-4b00-b01b-fb68ba0dff7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12a74561-a6a5-456e-8ce0-2dd7936e1a4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 302bd7d7-03d5-46f9-a08b-4baf0ed03d61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ab1cbd5-5122-42f3-95d5-4eb71b551b61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ff29ba4-316e-4012-ae0b-1855f22ae6d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ca94df5-7de1-4338-90d6-838913288cec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 411c68bf-9d97-475a-9fdd-87cf682d1adc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5666fc3-f3c4-42d5-8afe-41d8920cf155
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc34cfea-ac2a-42b5-b9da-75b9cab555e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 650e0862-f4ba-403f-9c55-8dfc92ae8894
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a25755e-05f1-4d27-bf2b-66538f2408e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49bfadf6-6b66-4c62-8eb2-8595d12048f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ad3d1ed-9c0d-4295-bf88-c5072b18b5ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5728015f-df2d-47a5-af0b-411a286813f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce80f8da-c8b3-47de-b3fa-c286d67857b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f35cfe80-c03c-41dd-9719-b53846f34272
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2f76061-5c75-45da-8137-397fa70b0caf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d2c4b54-f446-46de-9fad-fdf9d9972561
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a873cc8-0070-4831-a3b6-2e35ea13d03a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ebac6574-ebd6-4c07-ae3a-a2db250ea4ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33a67890-1c28-46d1-a4e4-272b9ee6aff0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 149eb29a-43ff-4d2d-86ee-9cf1afdb7d89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74bd5a67-77ab-4fce-bc16-0ffb4603f4e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62aed67f-550b-4721-af38-e664cba19102
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84ef1d8a-e867-48fb-89d0-563ec2463a80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84ce28e1-5e40-4d62-8de9-50596b590e9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5abd4c3-ff91-4975-b36c-b743ecd27c31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d016361-b8be-450b-93b7-5a56b8ae0dcd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be0644e6-f0c4-4c9f-9915-5ce8fb7f24cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9fca4580-65ce-4faa-bbcc-c93128d3f0cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec9125fc-8430-4811-82b9-827914559481
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72eaf61d-ec42-4a9a-b7cb-8fe2991f3eae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13342f52-d309-4ac1-9ca5-41e51ef67cd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1fff995e-ce65-4410-ba31-930a65bb6b24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90c693cc-0993-406c-b98c-d1eb5f8f158b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6e664cc-f52e-41d9-ac31-0831ad3954fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b12d5c94-c5d4-4c1d-83bc-c774f825b57e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc1548df-87e9-4c0c-8560-8894edc05367
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c1cfe20-f3fc-42df-864f-93d60fcd81ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce7d0fcd-6ac2-4ab9-8ccd-57f4472cdd78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3fba8c2e-99fd-4395-aabd-49db14f87422
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b53ebc2e-2870-4df3-a608-b8543af28fbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc779cd4-410b-4060-8375-997d2d696d1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7fd8b1a-b197-4bc0-a3cd-2e7490e27267
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a6d0704-8078-409d-b9f5-20c0d43c2b82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab0da6a0-b2df-4856-a608-f55db5299763
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97102177-a884-460b-915f-620075f8844e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 206b3ce0-9871-4569-a82b-a90840bb29d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d8d511f-545e-499f-a4a9-b052212c7412
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b08a9328-67b3-41e4-ab4c-9b7929f0d0e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a8a9f98-2f7e-4f13-bcb7-f98e78069c42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0873cd1-8b0d-4fdc-8349-6f4fa84c155a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd0a53ba-f94c-4ba5-9f64-c1baaeedc7d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b1fe2d1-bd0e-4636-b973-f75594133642
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aca1a714-57b5-4518-befa-716c5d1e7c00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12b8c31f-0c1c-4026-a64c-f5146bbabdd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a659e6e-9d53-47f5-bd58-fe4fcbd281cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a601d93-9ebd-4cc8-b79a-7f69b93aa6d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0fe1a39-4749-4755-b86b-880ae435c8c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0af59922-e396-4362-93f4-3c33ea3c9c48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7efa9580-6533-4b2a-b65b-1840deca6ca3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f48d661-09e8-4389-8dc8-1f6f8d4afe21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01d9223a-e072-4102-a81d-8f83785dd61c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20814e7e-f55d-4b70-a3fd-76047e8a9db4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e21145d-1c07-4b56-99c4-8b9e56c65d81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b93c5112-c2eb-45e8-8d22-bcc50a1855de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c07e0d6f-a6a0-4650-a3d9-a6eb4a594aa5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ee29ee2-980e-42c0-bb46-6723f81922ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b62ce61f-0bee-422f-9df7-9f720b0a78e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ca1ab08-ce57-47ce-b380-8484313883e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2855d92-f192-4488-bace-5ca60cd9f119
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4dcdcd3-ffac-49fc-8219-99f3fd9d357b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79bd9c81-12b7-4aeb-ac91-fef05b11f105
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e6d763e-5a07-435d-a7ba-c202a9e9eded
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af747194-9a0e-4e66-852e-298165f3c2cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 155626ef-757e-443c-a732-83d8aa5b1eda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be4d8167-6c77-4356-9ae7-8e032e6c5193
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f51e30f-c088-44c6-81ad-0a95bd080bc1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8803874b-9d9d-44d6-abe4-f21160ba64c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a81ca102-ac9d-4824-8cd5-5e76ef3abb21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6373574-48ad-4101-b467-53cf248a307f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42ec84b5-8684-48e2-b1cb-b55c3116b9bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fabe1f4a-29cc-4bf3-86b7-458d61c97bb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 936062f4-188f-4e58-970f-afbacda8f159
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 964a6985-d4fb-49b2-866c-d3a6a2d51f69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 406abcc1-d39e-4927-9558-d890c55a3ea9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6448d2f-43a9-4f21-8055-71c3e0ce0fd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 191b4bb8-bf1f-4d20-98c9-bcbbc6819882
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message adfcc6d9-9be5-42ea-a156-edf1c8fce394
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb5c7f0a-9799-407f-a49d-815987bfe727
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 509f49af-6684-4767-a3b7-f8dc058734f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2727973-c476-4ea8-9bd7-bf404510b2a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1010303a-e663-43ce-bdc2-df7df0bb97fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39676357-ecc7-4829-9d99-569d49a8aa58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e32b5b65-9707-4988-b302-e82aa2d4bcab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e88ccbd-fc40-4ba0-83c3-7a8c7e7860ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a744c5f7-756e-4da4-be75-08a17f663b09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 178f07d4-822a-44b7-b205-5aab32e8892b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7baae8db-b5a3-40d1-a8b9-72ef4fabe8ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ced1d11-815b-4cf3-a386-f229b68d28d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36c70e17-040a-455d-9ca0-827339bf4f0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ce09114-5daf-44e0-a638-f5818e2b3c03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea40e79f-da30-46f2-9ffb-3b0b7a13a42d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ce759b8-b780-4ff4-a318-db78cea94221
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0d67c51-3067-4420-bc5c-1f41ecda7e4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7b65247-21c0-466c-a2dd-54d52178fd91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f638617-71db-4279-9ba7-b18518ea7da5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5bb52d50-2d4b-4e75-bc1b-5d4340479547
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b7130cb-247d-4eea-ade8-d2e9138984a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc3b1bdf-1a3c-4547-993f-ce64f628cebd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75489dd5-2e8a-4f82-a63a-d7a1e22a5290
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7504430-9757-46fd-862c-ffa7992d3497
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8688 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_3
Server: localhost:8688
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_3
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_3/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_3/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_3/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_3/test_labels.txt

📊 Raw data loaded:
   Train: X=(4483, 24), y=(4483,)
   Test:  X=(1121, 24), y=(1121,)

⚠️  Limiting training data: 4483 → 800 samples
⚠️  Limiting test data: 1121 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_3 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 1 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1945, val=0.0814 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0848, val=0.0802 (↓), lr=0.001000
   • Epoch   3/100: train=0.0817, val=0.0812, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0831, val=0.0819, patience=2/15, lr=0.001000
   • Epoch   5/100: train=0.0828, val=0.0813, patience=3/15, lr=0.001000
   📉 Epoch 8: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0809, val=0.0806, patience=9/15, lr=0.000500
   📉 Epoch 16: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 1 Summary - Client client_3
   Epochs: 17/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0035
   Val:   Loss=0.0802, RMSE=0.2831, R²=-0.0005
============================================================


📊 Round 1 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2501, R²: -0.0113

============================================================
🔄 Round 2 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0835 (↓), lr=0.000250
   • Epoch   2/100: train=0.0807, val=0.0837, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0806, val=0.0838, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0805, val=0.0838, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0804, val=0.0839, patience=4/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0801, val=0.0842, patience=10/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 2 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0012
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0044
============================================================


📊 Round 2 Test Metrics:
   Loss: 0.3743, RMSE: 0.6118, MAE: 0.5398, R²: -3.5229

============================================================
🔄 Round 3 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.2999, val=0.1760 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.1480, val=0.0928 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.0944, val=0.0752 (↓), lr=0.000063
   • Epoch   4/100: train=0.0838, val=0.0748, patience=1/15, lr=0.000063
   • Epoch   5/100: train=0.0831, val=0.0753, patience=2/15, lr=0.000063
   📉 Epoch 10: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0829, val=0.0752, patience=8/15, lr=0.000031
   📉 Epoch 18: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 3 Summary - Client client_3
   Epochs: 18/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0373
   Val:   Loss=0.0752, RMSE=0.2742, R²=-0.0089
============================================================


📊 Round 3 Test Metrics:
   Loss: 0.1505, RMSE: 0.3879, MAE: 0.3174, R²: -0.8183

============================================================
🔄 Round 5 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0967, val=0.1003 (↓), lr=0.000016
   ✓ Epoch   2/100: train=0.0934, val=0.0961 (↓), lr=0.000016
   ✓ Epoch   3/100: train=0.0905, val=0.0929 (↓), lr=0.000016
   ✓ Epoch   4/100: train=0.0884, val=0.0905 (↓), lr=0.000016
   ✓ Epoch   5/100: train=0.0869, val=0.0886 (↓), lr=0.000016
   📉 Epoch 8: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0833, val=0.0839, patience=1/15, lr=0.000008
   📉 Epoch 16: LR reduced 0.000008 → 0.000004
   • Epoch  21/100: train=0.0823, val=0.0821, patience=4/15, lr=0.000004
   📉 Epoch 24: LR reduced 0.000004 → 0.000002
   • Epoch  31/100: train=0.0821, val=0.0816, patience=8/15, lr=0.000002
   📉 Epoch 32: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 5 Summary - Client client_3
   Epochs: 38/100 (early stopped)
   LR: 0.000016 → 0.000001 (4 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0021
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0437
============================================================


📊 Round 5 Test Metrics:
   Loss: 0.0841, RMSE: 0.2899, MAE: 0.2494, R²: -0.0158

============================================================
🔄 Round 9 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0936 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0935, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0934, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0934, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0933, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0929, patience=3/15, lr=0.000001
   • Epoch  21/100: train=0.0835, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  31/100: train=0.0829, val=0.0919, patience=3/15, lr=0.000001
   • Epoch  41/100: train=0.0824, val=0.0916, patience=13/15, lr=0.000001
   • Epoch  51/100: train=0.0819, val=0.0913, patience=9/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 9 Summary - Client client_3
   Epochs: 57/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0366
   Val:   Loss=0.0915, RMSE=0.3026, R²=-0.0455
============================================================


📊 Round 9 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2472, R²: 0.0019

============================================================
🔄 Round 11 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 11 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0049
   Val:   Loss=0.0766, RMSE=0.2768, R²=0.0022
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2499, R²: -0.0197

============================================================
🔄 Round 12 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 12 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0197
   Val:   Loss=0.0753, RMSE=0.2745, R²=-0.0213
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.0861, RMSE: 0.2934, MAE: 0.2517, R²: -0.0399

📊 Round 12 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2493, R²: -0.0146

📊 Round 12 Test Metrics:
   Loss: 0.0821, RMSE: 0.2864, MAE: 0.2470, R²: 0.0086

============================================================
🔄 Round 18 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 18 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0195
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0188
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2450, R²: 0.0227

============================================================
🔄 Round 20 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 20 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0114
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0091
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2449, R²: 0.0225

📊 Round 20 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2449, R²: 0.0228

📊 Round 20 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2449, R²: 0.0229

📊 Round 20 Test Metrics:
   Loss: 0.0809, RMSE: 0.2843, MAE: 0.2449, R²: 0.0231

============================================================
🔄 Round 26 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 26 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0107
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0138
============================================================


============================================================
🔄 Round 27 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0694 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0694, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0694, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0694, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0694, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0693, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0694)

============================================================
📊 Round 27 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0127
   Val:   Loss=0.0694, RMSE=0.2634, R²=-0.0000
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2449, R²: 0.0233

============================================================
🔄 Round 34 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 34 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0081
   Val:   Loss=0.0744, RMSE=0.2727, R²=0.0333
============================================================


============================================================
🔄 Round 35 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 35 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0150
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0060
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2449, R²: 0.0236

📊 Round 35 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2450, R²: 0.0236

📊 Round 35 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2450, R²: 0.0236

📊 Round 35 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2450, R²: 0.0236

📊 Round 35 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2450, R²: 0.0236

============================================================
🔄 Round 42 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 42 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0110
   Val:   Loss=0.0727, RMSE=0.2697, R²=0.0203
============================================================


============================================================
🔄 Round 43 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 43 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0158
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0043
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2451, R²: 0.0235

============================================================
🔄 Round 46 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 46 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0118
   Val:   Loss=0.0875, RMSE=0.2958, R²=0.0003
============================================================


============================================================
🔄 Round 48 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 48 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0067
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0399
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2451, R²: 0.0233

📊 Round 48 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2451, R²: 0.0233

============================================================
🔄 Round 51 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 51 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=0.0077
   Val:   Loss=0.0917, RMSE=0.3028, R²=0.0277
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2451, R²: 0.0232

📊 Round 51 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2452, R²: 0.0230

📊 Round 51 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2452, R²: 0.0230

📊 Round 51 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2452, R²: 0.0229

============================================================
🔄 Round 61 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0698 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0698, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0698, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0698, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0698, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0698, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0698)

============================================================
📊 Round 61 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0077
   Val:   Loss=0.0698, RMSE=0.2641, R²=0.0400
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2452, R²: 0.0229

============================================================
🔄 Round 62 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 62 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0095
   Val:   Loss=0.0791, RMSE=0.2813, R²=0.0259
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2452, R²: 0.0229

📊 Round 62 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2452, R²: 0.0228

📊 Round 62 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2452, R²: 0.0228

============================================================
🔄 Round 65 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 65 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0099
   Val:   Loss=0.0799, RMSE=0.2826, R²=0.0260
============================================================


============================================================
🔄 Round 66 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 66 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0056
   Val:   Loss=0.0750, RMSE=0.2738, R²=0.0466
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2453, R²: 0.0227

📊 Round 66 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2453, R²: 0.0227

============================================================
🔄 Round 68 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 68 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0111
   Val:   Loss=0.0805, RMSE=0.2838, R²=0.0246
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2453, R²: 0.0226

📊 Round 68 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2453, R²: 0.0226

📊 Round 68 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2453, R²: 0.0225

📊 Round 68 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2453, R²: 0.0225

============================================================
🔄 Round 73 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 73 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0166
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0014
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2453, R²: 0.0225

📊 Round 73 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2453, R²: 0.0224

============================================================
🔄 Round 76 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 76 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0111
   Val:   Loss=0.0751, RMSE=0.2741, R²=0.0224
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2453, R²: 0.0224

📊 Round 76 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2453, R²: 0.0224

============================================================
🔄 Round 78 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 78 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0089
   Val:   Loss=0.0783, RMSE=0.2799, R²=0.0322
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2453, R²: 0.0224

============================================================
🔄 Round 81 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 81 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0161
   Val:   Loss=0.0790, RMSE=0.2811, R²=0.0045
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2453, R²: 0.0224

============================================================
🔄 Round 84 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 84 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2835, R²=0.0134
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0009
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2453, R²: 0.0223

============================================================
🔄 Round 85 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 85 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0053
   Val:   Loss=0.0819, RMSE=0.2862, R²=0.0414
============================================================


============================================================
🔄 Round 86 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 86 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0100
   Val:   Loss=0.0902, RMSE=0.3003, R²=0.0059
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2453, R²: 0.0223

============================================================
🔄 Round 87 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 87 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0146
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0110
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2453, R²: 0.0223

============================================================
🔄 Round 88 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 88 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0159
   Val:   Loss=0.0839, RMSE=0.2897, R²=0.0061
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2453, R²: 0.0223

============================================================
🔄 Round 89 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 89 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=0.0156
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0039
============================================================


============================================================
🔄 Round 90 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 90 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2849, R²=0.0151
   Val:   Loss=0.0756, RMSE=0.2750, R²=-0.0110
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2454, R²: 0.0220

============================================================
🔄 Round 99 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0974 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0974, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0974, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0974, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0974, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0975, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0974)

============================================================
📊 Round 99 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2751, R²=0.0118
   Val:   Loss=0.0974, RMSE=0.3122, R²=0.0159
============================================================


============================================================
🔄 Round 101 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 101 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2776, R²=0.0072
   Val:   Loss=0.0920, RMSE=0.3032, R²=0.0171
============================================================


============================================================
🔄 Round 103 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 103 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=0.0156
   Val:   Loss=0.0869, RMSE=0.2948, R²=0.0022
============================================================


============================================================
🔄 Round 105 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 105 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0152
   Val:   Loss=0.0825, RMSE=0.2873, R²=0.0050
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0810, RMSE: 0.2845, MAE: 0.2454, R²: 0.0219

============================================================
🔄 Round 106 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 106 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0110
   Val:   Loss=0.0839, RMSE=0.2896, R²=0.0230
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0810, RMSE: 0.2845, MAE: 0.2454, R²: 0.0219

============================================================
🔄 Round 107 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 107 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2783, R²=0.0233
   Val:   Loss=0.0903, RMSE=0.3005, R²=-0.0201
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0810, RMSE: 0.2845, MAE: 0.2454, R²: 0.0219

============================================================
🔄 Round 108 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 108 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0100
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0243
============================================================


============================================================
🔄 Round 109 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 109 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0164
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0009
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0810, RMSE: 0.2845, MAE: 0.2454, R²: 0.0218

============================================================
🔄 Round 110 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0679 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0679, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0679, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0679, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0679, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0679, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0679)

============================================================
📊 Round 110 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0070
   Val:   Loss=0.0679, RMSE=0.2606, R²=0.0324
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0810, RMSE: 0.2845, MAE: 0.2454, R²: 0.0218

============================================================
🔄 Round 111 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 111 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0137
   Val:   Loss=0.0842, RMSE=0.2902, R²=0.0138
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0810, RMSE: 0.2845, MAE: 0.2454, R²: 0.0218

============================================================
🔄 Round 112 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0653 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0653, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0653, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0653, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0653, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0654, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0653)

============================================================
📊 Round 112 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0170
   Val:   Loss=0.0653, RMSE=0.2555, R²=-0.0250
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0810, RMSE: 0.2845, MAE: 0.2454, R²: 0.0218

============================================================
🔄 Round 114 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 114 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0158
   Val:   Loss=0.0753, RMSE=0.2745, R²=0.0015
============================================================


============================================================
🔄 Round 115 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 115 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0134
   Val:   Loss=0.0799, RMSE=0.2826, R²=0.0126
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0810, RMSE: 0.2845, MAE: 0.2454, R²: 0.0218

📊 Round 115 Test Metrics:
   Loss: 0.0810, RMSE: 0.2845, MAE: 0.2454, R²: 0.0218

============================================================
🔄 Round 117 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 117 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0098
   Val:   Loss=0.0746, RMSE=0.2731, R²=0.0295
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0810, RMSE: 0.2845, MAE: 0.2454, R²: 0.0218

============================================================
🔄 Round 118 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 118 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0109
   Val:   Loss=0.0764, RMSE=0.2764, R²=0.0103
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0810, RMSE: 0.2845, MAE: 0.2455, R²: 0.0217

============================================================
🔄 Round 120 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0719, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0719, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 120 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0113
   Val:   Loss=0.0720, RMSE=0.2682, R²=0.0252
============================================================


============================================================
🔄 Round 121 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 121 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0139
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0617
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0810, RMSE: 0.2845, MAE: 0.2455, R²: 0.0217

📊 Round 121 Test Metrics:
   Loss: 0.0810, RMSE: 0.2845, MAE: 0.2455, R²: 0.0217

📊 Round 121 Test Metrics:
   Loss: 0.0810, RMSE: 0.2845, MAE: 0.2455, R²: 0.0217

📊 Round 121 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2455, R²: 0.0216

📊 Round 121 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2455, R²: 0.0216

============================================================
🔄 Round 131 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 131 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0063
   Val:   Loss=0.0857, RMSE=0.2928, R²=0.0335
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2455, R²: 0.0216

📊 Round 131 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2455, R²: 0.0216

============================================================
🔄 Round 134 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 134 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0155
   Val:   Loss=0.0856, RMSE=0.2926, R²=0.0016
============================================================


============================================================
🔄 Round 135 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 135 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0106
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0100
============================================================


============================================================
🔄 Round 136 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 136 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=0.0053
   Val:   Loss=0.0847, RMSE=0.2910, R²=0.0329
============================================================


============================================================
🔄 Round 138 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 138 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0198
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0149
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2455, R²: 0.0216

============================================================
🔄 Round 140 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 140 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2850, R²=0.0095
   Val:   Loss=0.0751, RMSE=0.2741, R²=0.0244
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2455, R²: 0.0216

============================================================
🔄 Round 141 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 141 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2806, R²=0.0144
   Val:   Loss=0.0851, RMSE=0.2917, R²=0.0122
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2455, R²: 0.0216

============================================================
🔄 Round 145 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 145 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0195
   Val:   Loss=0.0790, RMSE=0.2810, R²=-0.0308
============================================================


============================================================
🔄 Round 146 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 146 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0189
   Val:   Loss=0.0726, RMSE=0.2695, R²=-0.0169
============================================================


============================================================
🔄 Round 148 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0717, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0717, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0717, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0717, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 148 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0094
   Val:   Loss=0.0717, RMSE=0.2677, R²=0.0343
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2455, R²: 0.0216

============================================================
🔄 Round 149 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 149 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=0.0225
   Val:   Loss=0.0868, RMSE=0.2947, R²=-0.0177
============================================================


============================================================
🔄 Round 151 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 151 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0148
   Val:   Loss=0.0748, RMSE=0.2735, R²=0.0022
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0810, RMSE: 0.2845, MAE: 0.2455, R²: 0.0217

📊 Round 151 Test Metrics:
   Loss: 0.0810, RMSE: 0.2845, MAE: 0.2455, R²: 0.0217

============================================================
🔄 Round 156 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 156 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0183
   Val:   Loss=0.0762, RMSE=0.2760, R²=-0.0040
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0810, RMSE: 0.2845, MAE: 0.2455, R²: 0.0217

============================================================
🔄 Round 158 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 158 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2785, R²=0.0144
   Val:   Loss=0.0898, RMSE=0.2997, R²=0.0128
============================================================


============================================================
🔄 Round 160 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 160 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0166
   Val:   Loss=0.0755, RMSE=0.2747, R²=0.0037
============================================================


============================================================
🔄 Round 161 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 161 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0092
   Val:   Loss=0.0796, RMSE=0.2822, R²=0.0142
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0810, RMSE: 0.2845, MAE: 0.2455, R²: 0.0217

============================================================
🔄 Round 164 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 164 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0134
   Val:   Loss=0.0797, RMSE=0.2824, R²=0.0117
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2455, R²: 0.0216

============================================================
🔄 Round 165 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 165 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0139
   Val:   Loss=0.0737, RMSE=0.2715, R²=0.0139
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2455, R²: 0.0216

📊 Round 165 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2455, R²: 0.0216

📊 Round 165 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2455, R²: 0.0216

============================================================
🔄 Round 171 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 171 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0147
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0100
============================================================


============================================================
🔄 Round 173 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 173 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0197
   Val:   Loss=0.0829, RMSE=0.2880, R²=-0.0081
============================================================


============================================================
🔄 Round 179 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 179 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=0.0172
   Val:   Loss=0.0831, RMSE=0.2882, R²=0.0015
============================================================


============================================================
🔄 Round 180 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 180 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0171
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0033
============================================================


============================================================
🔄 Round 181 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 181 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0188
   Val:   Loss=0.0782, RMSE=0.2797, R²=-0.0050
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2455, R²: 0.0215

📊 Round 181 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2455, R²: 0.0215

============================================================
🔄 Round 184 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 184 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0204
   Val:   Loss=0.0768, RMSE=0.2772, R²=-0.0133
============================================================


============================================================
🔄 Round 185 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 185 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0173
   Val:   Loss=0.0822, RMSE=0.2867, R²=0.0018
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2455, R²: 0.0214

============================================================
🔄 Round 186 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0691 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0691, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0691, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0691, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0691, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0691, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0691)

============================================================
📊 Round 186 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2877, R²=0.0067
   Val:   Loss=0.0691, RMSE=0.2628, R²=0.0456
============================================================


============================================================
🔄 Round 188 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 188 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0106
   Val:   Loss=0.0783, RMSE=0.2798, R²=0.0269
============================================================


============================================================
🔄 Round 192 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 192 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0104
   Val:   Loss=0.0778, RMSE=0.2789, R²=0.0019
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2455, R²: 0.0214

📊 Round 192 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2455, R²: 0.0214

============================================================
🔄 Round 196 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 196 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0090
   Val:   Loss=0.0788, RMSE=0.2807, R²=0.0245
============================================================


📊 Round 196 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2455, R²: 0.0214

============================================================
🔄 Round 199 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 199 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0141
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0149
============================================================


============================================================
🔄 Round 200 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 200 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0176
   Val:   Loss=0.0755, RMSE=0.2747, R²=-0.0007
============================================================


============================================================
🔄 Round 201 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 201 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0155
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0074
============================================================


============================================================
🔄 Round 204 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0951 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0951, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0951, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0952, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0952, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0952, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0951)

============================================================
📊 Round 204 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2761, R²=0.0174
   Val:   Loss=0.0951, RMSE=0.3085, R²=-0.0004
============================================================


📊 Round 204 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2455, R²: 0.0213

📊 Round 204 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2455, R²: 0.0213

============================================================
🔄 Round 206 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 206 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0128
   Val:   Loss=0.0861, RMSE=0.2934, R²=0.0196
============================================================


============================================================
🔄 Round 207 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 207 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0152
   Val:   Loss=0.0753, RMSE=0.2744, R²=0.0078
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2455, R²: 0.0213

📊 Round 207 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2455, R²: 0.0214

============================================================
🔄 Round 210 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 210 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0068
   Val:   Loss=0.0771, RMSE=0.2777, R²=0.0445
============================================================


============================================================
🔄 Round 213 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 213 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0194
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0060
============================================================


📊 Round 213 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2455, R²: 0.0214

============================================================
🔄 Round 214 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 214 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0260
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0309
============================================================


============================================================
🔄 Round 215 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 215 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=0.0181
   Val:   Loss=0.0827, RMSE=0.2875, R²=-0.0196
============================================================


📊 Round 215 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2455, R²: 0.0214

============================================================
🔄 Round 219 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 219 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0135
   Val:   Loss=0.0761, RMSE=0.2759, R²=0.0002
============================================================


============================================================
🔄 Round 222 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 222 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0193
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0241
============================================================


============================================================
🔄 Round 223 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 223 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0163
   Val:   Loss=0.0797, RMSE=0.2824, R²=0.0049
============================================================


============================================================
🔄 Round 224 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 224 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0132
   Val:   Loss=0.0806, RMSE=0.2839, R²=0.0190
============================================================


📊 Round 224 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2455, R²: 0.0214

============================================================
🔄 Round 225 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 225 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0133
   Val:   Loss=0.0766, RMSE=0.2768, R²=0.0155
============================================================


📊 Round 225 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2455, R²: 0.0214

📊 Round 225 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2455, R²: 0.0214

============================================================
🔄 Round 228 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 228 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0159
   Val:   Loss=0.0807, RMSE=0.2840, R²=0.0066
============================================================


============================================================
🔄 Round 230 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 230 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0132
   Val:   Loss=0.0798, RMSE=0.2825, R²=0.0173
============================================================


📊 Round 230 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0213

📊 Round 230 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0213

============================================================
🔄 Round 236 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 236 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0121
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0202
============================================================


📊 Round 236 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0213

============================================================
🔄 Round 238 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 238 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=0.0141
   Val:   Loss=0.0871, RMSE=0.2952, R²=0.0114
============================================================


============================================================
🔄 Round 239 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 239 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0127
   Val:   Loss=0.0832, RMSE=0.2885, R²=0.0131
============================================================


📊 Round 239 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0212

============================================================
🔄 Round 240 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 240 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0180
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0112
============================================================


📊 Round 240 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0212

============================================================
🔄 Round 243 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 243 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0169
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0021
============================================================


📊 Round 243 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0212

============================================================
🔄 Round 246 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 246 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0157
   Val:   Loss=0.0827, RMSE=0.2875, R²=-0.0213
============================================================


📊 Round 246 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0212

📊 Round 246 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0211

============================================================
🔄 Round 249 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 249 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0195
   Val:   Loss=0.0827, RMSE=0.2877, R²=-0.0065
============================================================


📊 Round 249 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0211

📊 Round 249 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0211

============================================================
🔄 Round 252 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0679 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0679, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0679, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0679, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0679, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0679, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0679)

============================================================
📊 Round 252 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0043
   Val:   Loss=0.0679, RMSE=0.2605, R²=0.0514
============================================================


============================================================
🔄 Round 253 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 253 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2829, R²=0.0094
   Val:   Loss=0.0797, RMSE=0.2824, R²=0.0345
============================================================


📊 Round 253 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0211

============================================================
🔄 Round 255 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 255 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0213
   Val:   Loss=0.0860, RMSE=0.2932, R²=-0.0114
============================================================


============================================================
🔄 Round 260 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 260 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2850, R²=0.0151
   Val:   Loss=0.0749, RMSE=0.2737, R²=-0.0028
============================================================


📊 Round 260 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0211

============================================================
🔄 Round 264 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0708 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0708, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0708, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0708, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0708, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0708, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0708)

============================================================
📊 Round 264 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0172
   Val:   Loss=0.0708, RMSE=0.2660, R²=-0.0204
============================================================


============================================================
🔄 Round 268 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 268 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0076
   Val:   Loss=0.0840, RMSE=0.2898, R²=0.0396
============================================================


============================================================
🔄 Round 269 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 269 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0053
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0338
============================================================


============================================================
🔄 Round 272 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 272 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0127
   Val:   Loss=0.0737, RMSE=0.2715, R²=0.0221
============================================================


============================================================
🔄 Round 274 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 274 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0101
   Val:   Loss=0.0809, RMSE=0.2843, R²=0.0314
============================================================


📊 Round 274 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0211

📊 Round 274 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0211

============================================================
🔄 Round 276 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 276 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0033
   Val:   Loss=0.0786, RMSE=0.2803, R²=0.0354
============================================================


============================================================
🔄 Round 278 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 278 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=0.0130
   Val:   Loss=0.0829, RMSE=0.2878, R²=0.0160
============================================================


📊 Round 278 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0211

============================================================
🔄 Round 280 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 280 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0145
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0139
============================================================


📊 Round 280 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0211

============================================================
🔄 Round 282 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 282 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0163
   Val:   Loss=0.0785, RMSE=0.2801, R²=0.0068
============================================================


📊 Round 282 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0211

📊 Round 282 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0211

📊 Round 282 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0211

============================================================
🔄 Round 285 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 285 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0180
   Val:   Loss=0.0733, RMSE=0.2708, R²=-0.0228
============================================================


============================================================
🔄 Round 287 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 287 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0158
   Val:   Loss=0.0823, RMSE=0.2868, R²=0.0046
============================================================


============================================================
🔄 Round 289 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 289 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0183
   Val:   Loss=0.0802, RMSE=0.2833, R²=-0.0006
============================================================


============================================================
🔄 Round 291 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0719 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0719, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0719, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0719, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0719)

============================================================
📊 Round 291 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0232
   Val:   Loss=0.0719, RMSE=0.2681, R²=-0.0341
============================================================


📊 Round 291 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0211

📊 Round 291 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0211

============================================================
🔄 Round 295 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 295 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=0.0128
   Val:   Loss=0.0773, RMSE=0.2781, R²=0.0176
============================================================


📊 Round 295 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0211

============================================================
🔄 Round 296 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 296 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0132
   Val:   Loss=0.0760, RMSE=0.2757, R²=-0.0008
============================================================


============================================================
🔄 Round 299 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 299 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2792, R²=0.0234
   Val:   Loss=0.0880, RMSE=0.2967, R²=-0.0178
============================================================


📊 Round 299 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0212

============================================================
🔄 Round 301 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 301 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0081
   Val:   Loss=0.0830, RMSE=0.2881, R²=0.0357
============================================================


============================================================
🔄 Round 303 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 303 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0201
   Val:   Loss=0.0728, RMSE=0.2697, R²=-0.0104
============================================================


📊 Round 303 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0212

============================================================
🔄 Round 306 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 306 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0129
   Val:   Loss=0.0839, RMSE=0.2896, R²=0.0195
============================================================


📊 Round 306 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0212

============================================================
🔄 Round 307 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 307 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0140
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0097
============================================================


📊 Round 307 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0212

============================================================
🔄 Round 309 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 309 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0242
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0320
============================================================


============================================================
🔄 Round 310 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 310 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0184
   Val:   Loss=0.0807, RMSE=0.2840, R²=-0.0024
============================================================


📊 Round 310 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0213

📊 Round 310 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0212

============================================================
🔄 Round 313 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 313 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0215
   Val:   Loss=0.0908, RMSE=0.3014, R²=-0.0102
============================================================


📊 Round 313 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0212

============================================================
🔄 Round 314 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 314 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0088
   Val:   Loss=0.0730, RMSE=0.2703, R²=0.0371
============================================================


📊 Round 314 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0212

============================================================
🔄 Round 315 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 315 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0170
   Val:   Loss=0.0829, RMSE=0.2878, R²=0.0006
============================================================


📊 Round 315 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0213

============================================================
🔄 Round 316 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 316 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0210
   Val:   Loss=0.0772, RMSE=0.2779, R²=-0.0131
============================================================


============================================================
🔄 Round 322 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 322 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0133
   Val:   Loss=0.0767, RMSE=0.2769, R²=0.0169
============================================================


📊 Round 322 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0213

📊 Round 322 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0213

============================================================
🔄 Round 331 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 331 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0106
   Val:   Loss=0.0769, RMSE=0.2773, R²=0.0219
============================================================


📊 Round 331 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0213

============================================================
🔄 Round 334 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 334 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0190
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0276
============================================================


============================================================
🔄 Round 337 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 337 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0184
   Val:   Loss=0.0754, RMSE=0.2747, R²=-0.0059
============================================================


============================================================
🔄 Round 338 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 338 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0143
   Val:   Loss=0.0751, RMSE=0.2741, R²=-0.0023
============================================================


📊 Round 338 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0212

============================================================
🔄 Round 340 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 340 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0125
   Val:   Loss=0.0803, RMSE=0.2833, R²=0.0055
============================================================


============================================================
🔄 Round 342 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 342 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2849, R²=0.0196
   Val:   Loss=0.0752, RMSE=0.2743, R²=-0.0062
============================================================


============================================================
🔄 Round 343 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 343 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0112
   Val:   Loss=0.0823, RMSE=0.2870, R²=0.0283
============================================================


📊 Round 343 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0211

============================================================
🔄 Round 344 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 344 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0122
   Val:   Loss=0.0741, RMSE=0.2722, R²=0.0255
============================================================


📊 Round 344 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0211

📊 Round 344 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0211

============================================================
🔄 Round 348 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 348 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0105
   Val:   Loss=0.0838, RMSE=0.2895, R²=0.0289
============================================================


📊 Round 348 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0210

============================================================
🔄 Round 352 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 352 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0091
   Val:   Loss=0.0787, RMSE=0.2806, R²=0.0219
============================================================


📊 Round 352 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0210

📊 Round 352 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0210

============================================================
🔄 Round 354 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 354 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0092
   Val:   Loss=0.0721, RMSE=0.2686, R²=0.0372
============================================================


📊 Round 354 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0210

============================================================
🔄 Round 355 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 355 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0126
   Val:   Loss=0.0750, RMSE=0.2739, R²=0.0205
============================================================


📊 Round 355 Test Metrics:
   Loss: 0.0810, RMSE: 0.2847, MAE: 0.2456, R²: 0.0209

============================================================
🔄 Round 359 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 359 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0177
   Val:   Loss=0.0746, RMSE=0.2731, R²=0.0004
============================================================


📊 Round 359 Test Metrics:
   Loss: 0.0810, RMSE: 0.2847, MAE: 0.2456, R²: 0.0209

📊 Round 359 Test Metrics:
   Loss: 0.0810, RMSE: 0.2847, MAE: 0.2456, R²: 0.0209

📊 Round 359 Test Metrics:
   Loss: 0.0810, RMSE: 0.2847, MAE: 0.2456, R²: 0.0209

📊 Round 359 Test Metrics:
   Loss: 0.0810, RMSE: 0.2847, MAE: 0.2456, R²: 0.0209

============================================================
🔄 Round 364 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 364 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0180
   Val:   Loss=0.0788, RMSE=0.2807, R²=0.0017
============================================================


============================================================
🔄 Round 365 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 365 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0131
   Val:   Loss=0.0739, RMSE=0.2718, R²=0.0038
============================================================


============================================================
🔄 Round 367 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 367 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0197
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0056
============================================================


📊 Round 367 Test Metrics:
   Loss: 0.0810, RMSE: 0.2847, MAE: 0.2456, R²: 0.0209

============================================================
🔄 Round 369 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 369 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2774, R²=0.0215
   Val:   Loss=0.0920, RMSE=0.3033, R²=-0.0198
============================================================


============================================================
🔄 Round 371 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 371 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2836, R²=0.0199
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0109
============================================================


============================================================
🔄 Round 372 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0718, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 372 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0142
   Val:   Loss=0.0718, RMSE=0.2679, R²=0.0178
============================================================


============================================================
🔄 Round 375 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 375 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0190
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0041
============================================================


📊 Round 375 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0210

============================================================
🔄 Round 377 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 377 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0157
   Val:   Loss=0.0833, RMSE=0.2886, R²=0.0031
============================================================


📊 Round 377 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0210

============================================================
🔄 Round 380 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 380 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2803, R²=0.0131
   Val:   Loss=0.0856, RMSE=0.2926, R²=0.0054
============================================================


============================================================
🔄 Round 382 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 382 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0131
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0217
============================================================


📊 Round 382 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0210

📊 Round 382 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0210

============================================================
🔄 Round 386 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 386 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0154
   Val:   Loss=0.0855, RMSE=0.2924, R²=0.0126
============================================================


📊 Round 386 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0210

📊 Round 386 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0211

============================================================
🔄 Round 391 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 391 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0205
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0056
============================================================


============================================================
🔄 Round 393 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0710 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0710, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0711, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0711, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0711, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0711, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0710)

============================================================
📊 Round 393 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0119
   Val:   Loss=0.0710, RMSE=0.2665, R²=-0.0034
============================================================


============================================================
🔄 Round 394 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 394 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0202
   Val:   Loss=0.0888, RMSE=0.2980, R²=-0.0323
============================================================


============================================================
🔄 Round 396 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 396 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0083
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0388
============================================================


============================================================
🔄 Round 397 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 397 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0073
   Val:   Loss=0.0806, RMSE=0.2839, R²=0.0421
============================================================


📊 Round 397 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0211

📊 Round 397 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0211

============================================================
🔄 Round 399 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 399 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0195
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0105
============================================================


📊 Round 399 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0210

📊 Round 399 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0211

============================================================
🔄 Round 404 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 404 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=0.0137
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0022
============================================================


📊 Round 404 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0211

============================================================
🔄 Round 406 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 406 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0125
   Val:   Loss=0.0766, RMSE=0.2768, R²=0.0223
============================================================


📊 Round 406 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0211

📊 Round 406 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0211

📊 Round 406 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0211

============================================================
🔄 Round 411 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 411 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2803, R²=0.0277
   Val:   Loss=0.0855, RMSE=0.2925, R²=-0.0341
============================================================


📊 Round 411 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0211

📊 Round 411 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0212

============================================================
🔄 Round 415 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 415 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0118
   Val:   Loss=0.0833, RMSE=0.2887, R²=0.0131
============================================================


============================================================
🔄 Round 416 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 416 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0180
   Val:   Loss=0.0768, RMSE=0.2772, R²=0.0003
============================================================


📊 Round 416 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0212

📊 Round 416 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0213

============================================================
🔄 Round 419 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 419 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0133
   Val:   Loss=0.0759, RMSE=0.2755, R²=0.0231
============================================================


📊 Round 419 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0213

📊 Round 419 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0213

📊 Round 419 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0213

============================================================
🔄 Round 427 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 427 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0161
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.0105
============================================================


============================================================
🔄 Round 428 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 428 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0156
   Val:   Loss=0.0856, RMSE=0.2926, R²=0.0015
============================================================


📊 Round 428 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0212

============================================================
🔄 Round 429 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 429 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0206
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0066
============================================================


============================================================
🔄 Round 430 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 430 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=0.0087
   Val:   Loss=0.0790, RMSE=0.2811, R²=0.0253
============================================================


============================================================
🔄 Round 431 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 431 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0153
   Val:   Loss=0.0739, RMSE=0.2719, R²=0.0108
============================================================


============================================================
🔄 Round 432 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 432 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0185
   Val:   Loss=0.0776, RMSE=0.2785, R²=-0.0019
============================================================


📊 Round 432 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0213

============================================================
🔄 Round 435 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 435 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=0.0183
   Val:   Loss=0.0742, RMSE=0.2723, R²=-0.0019
============================================================


📊 Round 435 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0212

============================================================
🔄 Round 438 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 438 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0153
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0126
============================================================


============================================================
🔄 Round 440 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 440 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0159
   Val:   Loss=0.0809, RMSE=0.2845, R²=0.0124
============================================================


============================================================
🔄 Round 441 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0719 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0719, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0719, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0719, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0719)

============================================================
📊 Round 441 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0133
   Val:   Loss=0.0719, RMSE=0.2681, R²=0.0238
============================================================


============================================================
🔄 Round 442 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 442 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=0.0167
   Val:   Loss=0.0790, RMSE=0.2810, R²=0.0056
============================================================


============================================================
🔄 Round 443 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 443 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0093
   Val:   Loss=0.0772, RMSE=0.2778, R²=0.0397
============================================================


============================================================
🔄 Round 446 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0722 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 446 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0170
   Val:   Loss=0.0722, RMSE=0.2687, R²=0.0071
============================================================


📊 Round 446 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0213

============================================================
🔄 Round 449 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 449 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0084
   Val:   Loss=0.0889, RMSE=0.2982, R²=0.0338
============================================================


============================================================
🔄 Round 450 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 450 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=0.0164
   Val:   Loss=0.0843, RMSE=0.2904, R²=0.0045
============================================================


============================================================
🔄 Round 451 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0950 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0950, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0950, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0950, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0950, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0950, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0950)

============================================================
📊 Round 451 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2759, R²=0.0144
   Val:   Loss=0.0950, RMSE=0.3083, R²=0.0183
============================================================


============================================================
🔄 Round 452 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 452 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0129
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0234
============================================================


============================================================
🔄 Round 454 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0931 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0931, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0931, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0931, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0931, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0931, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0931)

============================================================
📊 Round 454 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=0.0157
   Val:   Loss=0.0931, RMSE=0.3051, R²=0.0144
============================================================


📊 Round 454 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0214

📊 Round 454 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0214

📊 Round 454 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0214

============================================================
🔄 Round 459 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 459 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0092
   Val:   Loss=0.0783, RMSE=0.2798, R²=0.0299
============================================================


============================================================
🔄 Round 462 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 462 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0212
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0210
============================================================


📊 Round 462 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0214

============================================================
🔄 Round 463 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 463 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0104
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0222
============================================================


📊 Round 463 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0214

============================================================
🔄 Round 465 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 465 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0127
   Val:   Loss=0.0767, RMSE=0.2770, R²=0.0269
============================================================


📊 Round 465 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0214

============================================================
🔄 Round 466 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 466 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0175
   Val:   Loss=0.0782, RMSE=0.2797, R²=0.0070
============================================================


📊 Round 466 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0214

📊 Round 466 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0213

📊 Round 466 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0213

📊 Round 466 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0213

============================================================
🔄 Round 475 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 475 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0144
   Val:   Loss=0.0778, RMSE=0.2789, R²=0.0186
============================================================


📊 Round 475 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0213

============================================================
🔄 Round 480 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 480 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0158
   Val:   Loss=0.0853, RMSE=0.2921, R²=0.0138
============================================================


📊 Round 480 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0214

============================================================
🔄 Round 486 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 486 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0065
   Val:   Loss=0.0768, RMSE=0.2772, R²=0.0275
============================================================


============================================================
🔄 Round 487 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 487 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0075
   Val:   Loss=0.0870, RMSE=0.2949, R²=0.0095
============================================================


📊 Round 487 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0214

============================================================
🔄 Round 490 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 490 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0173
   Val:   Loss=0.0759, RMSE=0.2755, R²=0.0047
============================================================


📊 Round 490 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0214

============================================================
🔄 Round 491 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0719 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0719, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0719, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0719, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0719)

============================================================
📊 Round 491 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0092
   Val:   Loss=0.0719, RMSE=0.2681, R²=0.0411
============================================================


============================================================
🔄 Round 492 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 492 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0138
   Val:   Loss=0.0783, RMSE=0.2798, R²=0.0168
============================================================


📊 Round 492 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0213

============================================================
🔄 Round 493 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 493 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0206
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0172
============================================================


============================================================
🔄 Round 494 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 494 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0102
   Val:   Loss=0.0788, RMSE=0.2807, R²=0.0216
============================================================


============================================================
🔄 Round 497 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 497 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0140
   Val:   Loss=0.0864, RMSE=0.2940, R²=0.0206
============================================================


============================================================
🔄 Round 498 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 498 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0209
   Val:   Loss=0.0844, RMSE=0.2906, R²=-0.0219
============================================================


============================================================
🔄 Round 499 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 499 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0135
   Val:   Loss=0.0788, RMSE=0.2807, R²=0.0230
============================================================


============================================================
🔄 Round 503 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 503 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0188
   Val:   Loss=0.0767, RMSE=0.2770, R²=0.0008
============================================================


============================================================
🔄 Round 504 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 504 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0068
   Val:   Loss=0.0797, RMSE=0.2824, R²=0.0485
============================================================


============================================================
🔄 Round 505 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 505 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0143
   Val:   Loss=0.0808, RMSE=0.2842, R²=0.0113
============================================================


============================================================
🔄 Round 506 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 506 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0097
   Val:   Loss=0.0830, RMSE=0.2882, R²=0.0211
============================================================


📊 Round 506 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0214

============================================================
🔄 Round 508 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 508 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0148
   Val:   Loss=0.0819, RMSE=0.2862, R²=0.0132
============================================================


📊 Round 508 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0214

📊 Round 508 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0214

============================================================
🔄 Round 513 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 513 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2810, R²=0.0138
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0274
============================================================


📊 Round 513 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0214

============================================================
🔄 Round 516 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 516 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0194
   Val:   Loss=0.0732, RMSE=0.2706, R²=-0.0060
============================================================


============================================================
🔄 Round 521 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0939 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0939, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0939, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0939, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0939, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0939, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0939)

============================================================
📊 Round 521 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2764, R²=0.0123
   Val:   Loss=0.0939, RMSE=0.3064, R²=0.0259
============================================================


============================================================
🔄 Round 523 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 523 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0197
   Val:   Loss=0.0900, RMSE=0.3001, R²=0.0008
============================================================


📊 Round 523 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0214

📊 Round 523 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0213

============================================================
🔄 Round 526 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 526 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2822, R²=0.0153
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0156
============================================================


============================================================
🔄 Round 527 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 527 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0130
   Val:   Loss=0.0910, RMSE=0.3016, R²=0.0097
============================================================


============================================================
🔄 Round 530 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 530 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0202
   Val:   Loss=0.0778, RMSE=0.2790, R²=-0.0045
============================================================


📊 Round 530 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0213

📊 Round 530 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0213

============================================================
🔄 Round 532 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 532 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2792, R²=0.0177
   Val:   Loss=0.0878, RMSE=0.2963, R²=0.0068
============================================================


📊 Round 532 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0213

📊 Round 532 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0213

============================================================
🔄 Round 535 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 535 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2843, R²=0.0102
   Val:   Loss=0.0761, RMSE=0.2758, R²=0.0221
============================================================


============================================================
🔄 Round 536 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 536 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0182
   Val:   Loss=0.0869, RMSE=0.2947, R²=-0.0383
============================================================


📊 Round 536 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0213

============================================================
🔄 Round 537 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 537 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2776, R²=0.0166
   Val:   Loss=0.0914, RMSE=0.3023, R²=0.0122
============================================================


📊 Round 537 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0213

============================================================
🔄 Round 539 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 539 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0225
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0119
============================================================


============================================================
🔄 Round 540 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 540 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0083
   Val:   Loss=0.0765, RMSE=0.2767, R²=0.0428
============================================================


📊 Round 540 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0212

============================================================
🔄 Round 545 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 545 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0155
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0126
============================================================


📊 Round 545 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0212

============================================================
🔄 Round 546 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 546 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0175
   Val:   Loss=0.0771, RMSE=0.2777, R²=-0.0022
============================================================


📊 Round 546 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0212

============================================================
🔄 Round 548 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 548 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0174
   Val:   Loss=0.0783, RMSE=0.2798, R²=-0.0006
============================================================


============================================================
🔄 Round 549 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 549 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0168
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0224
============================================================


📊 Round 549 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0212

============================================================
🔄 Round 551 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0722 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 551 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0153
   Val:   Loss=0.0722, RMSE=0.2688, R²=0.0138
============================================================


📊 Round 551 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0212

============================================================
🔄 Round 552 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 552 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0181
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0021
============================================================


📊 Round 552 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0212

📊 Round 552 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0212

============================================================
🔄 Round 555 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 555 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0246
   Val:   Loss=0.0888, RMSE=0.2980, R²=-0.0180
============================================================


============================================================
🔄 Round 557 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 557 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0161
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0133
============================================================


============================================================
🔄 Round 558 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 558 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2836, R²=0.0149
   Val:   Loss=0.0777, RMSE=0.2787, R²=0.0185
============================================================


📊 Round 558 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0212

============================================================
🔄 Round 559 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 559 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2783, R²=0.0152
   Val:   Loss=0.0896, RMSE=0.2994, R²=0.0023
============================================================


📊 Round 559 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0213

📊 Round 559 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0213

============================================================
🔄 Round 562 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 562 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0157
   Val:   Loss=0.0820, RMSE=0.2863, R²=0.0147
============================================================


📊 Round 562 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0213

============================================================
🔄 Round 567 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 567 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0159
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0107
============================================================


============================================================
🔄 Round 568 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 568 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0250
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0222
============================================================


📊 Round 568 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0214

📊 Round 568 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0214

============================================================
🔄 Round 571 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 571 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0125
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0152
============================================================


📊 Round 571 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0213

📊 Round 571 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0213

============================================================
🔄 Round 574 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 574 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0157
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0155
============================================================


============================================================
🔄 Round 575 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 575 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0196
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0190
============================================================


📊 Round 575 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: 0.0214

============================================================
🔄 Round 576 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 576 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0199
   Val:   Loss=0.0759, RMSE=0.2755, R²=-0.0029
============================================================


❌ Client client_3 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8688 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8688 {grpc_status:14, grpc_message:"Socket closed"}"
>
