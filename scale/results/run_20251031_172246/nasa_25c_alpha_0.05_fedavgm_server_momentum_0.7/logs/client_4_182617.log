[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1bb0d8bd-c243-4895-9484-f34790294a1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ed645f8-1682-445c-a417-c88dcd85b518
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f446eae-4eff-4f62-8546-b4c91a8ecef3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a009e7b5-e601-4fa4-9aa1-5139524db9e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1bc008be-266d-4282-8565-3656aeb71045
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d5392f4-08b2-49ee-abdc-e22b319468d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16e3eda3-855a-464b-99b5-54a8014d5511
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 541d532c-51a9-43b2-afda-e7cd96a9345e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7658b05d-bfc1-45c4-b6f7-5b4dcbe6a45c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88601706-46e0-4bb5-a723-9b962e09947f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac87ae1b-6a4d-464c-b479-f63973ed42ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21366413-e939-43b8-8988-7e0d35251574
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1fe600bc-2bdd-4b31-95f9-8dbbdf7730e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b14c0db7-64bf-424c-ac37-506115320017
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b01f25b9-0cac-46e0-ab04-d2ba5b5c74e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91bb2bc6-09a6-4dd7-9725-fbdf04928159
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message abba137a-47a1-494c-8ad4-4ac52f054d04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 296aa180-cc44-4fc7-839b-3a683978d4c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8df71b0-54e0-43e0-b92c-0e857c509683
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47faa2c0-cbc7-4563-a03f-37ea0572527b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 484dc2c4-5ff4-4995-b35c-f919c1aac717
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d567fb61-cee6-404a-b50b-d54e23bf7dae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b4b7c41-372c-4074-af4d-873a394fe2b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c463f035-dc5c-4ec5-8064-c24c053bfd9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e856a6b9-4fcb-47d5-97a8-b36b09f45309
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4449974e-046e-465d-8e97-bf9849385c12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bda77f8d-fd34-4d3a-8130-1abd7087cb1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a73719a-65c4-4eaf-a815-aa6f64e699f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 620c6c4f-72c6-403d-96b3-b0f1d9d710a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85efd68c-e740-42c3-900e-642caa252cd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65fc34bb-239c-4199-9d53-2715ad379ab2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18a08cdf-5a18-41d3-912e-8a8dea4c55f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2261db9c-1afb-4745-9bca-ee27b3e190d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c667b212-b5b5-437b-a86a-8e4ed4d85a0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 331f6d40-94d4-49e1-9f6f-964e635896a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d4a7923-1b05-4677-89e3-08630c44d615
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6443b64-a1bd-4f4a-870a-f4a0c58304a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f4850ae-6d46-4733-92ba-0b2dc468454c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2df9c19-d3ea-4a8f-bd87-b6b19ac5d10d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50cc0f8d-74dd-42fc-bcd9-8ed64f549267
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63de4375-aa9c-47c5-b186-bd5fcf2e9d1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0eaa6c3-deae-4ab7-8c54-57aad809798c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc1af49b-009c-4c37-93de-f33559e59233
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb04df14-d377-4505-ac2b-66265d6d3c8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de36b584-8e5c-4834-bdff-02b8828fe673
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92ce7ae8-3d81-461e-90d1-f46387dfe377
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05ea5811-61d5-4a81-b5fc-ce61ef9a5c7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91ff0499-8e4d-445c-98ea-136ad2978bc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55650185-c14f-4d0b-be95-b739324f2d07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b84ce8b-6fba-475f-bf61-08a702cc2a68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2976ab7e-938a-4c6f-8748-1606572d05de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 573aeba0-cb6b-4717-a06b-1a1ac558f7aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b637bb6-feaf-4db6-8da2-b99d6fa56654
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 647dd3ba-02c1-4e52-9671-cd27a6fe3b71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a827643a-79c1-4b07-9adf-e8fc8119878d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07b9ff9c-2c41-4f9f-92b5-b29a8e406c56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de0eb4c9-787c-49f9-b6b9-1ae11fc0eb1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68e323ad-28e3-4ca5-9dbb-25d3feb1f2d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2b261ea-2103-489e-accd-d970ba21889e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c69947d-187f-4688-8896-f03cb09b9d78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36173560-4220-4c9d-995b-acf9f887a8dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b17e67c8-aaaf-46b0-be64-53cec2c069ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07615d4b-3f18-44aa-ac86-c3f2878b2a76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6b866e0-ea4a-4f6d-bb89-ca3129f32c58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af93e201-0eac-43ef-ad89-0f06226e86a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b482ceb-04b8-4882-8365-df98ea467a7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b49406c7-2538-44d9-8977-ec135c17bc7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09b5c4b7-999d-40be-8553-3ebe2988b3a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23bfa6ed-6507-4c54-8e59-4c0dbb083a6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6993dcd-2f03-490e-bd9f-a778ceaf5b3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae6d7086-9d24-4b8b-bd7d-026361e3bb58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22233463-dbbb-43c5-8aef-fe697784bbe2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26d59abc-1e88-4ac6-af2b-6122a15570bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8dcf3be5-63bd-4c07-bfae-c6576883c2c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 866fdfc0-d91b-4195-8d61-bc850ceae8bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8301b124-6d27-4827-b5c0-5b37d087cf0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ed95313-e2da-48c7-9ebd-dc6752bbfc75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1c917fc-c595-4500-bf7b-434dff6d37f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b038dab2-191d-4bf9-8924-ee5c5f474d6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5990cc3-12f2-4b21-86ed-8ad2ecf110cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e33debee-01de-4baa-b2e2-305c4f381e7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b357c15-f733-4de5-9188-ad6e15380410
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b016dbcd-9abb-4bb0-8649-72decf09ab52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21996161-c32e-4845-a82d-a12d8ba8ad0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89df9f53-eb1b-4d59-8201-4f82f045975f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2857629a-b8ba-42ca-a15f-bebb0658e707
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f196f025-9a53-4e5b-b52a-bf2945d489c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10b5b33d-0366-4e64-99e2-424633001773
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4b447aa-b680-4db5-bb0d-59508b64fb0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd9f280e-603b-4086-bfeb-c6f487c3f551
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0c55512-1633-49d0-8948-c83f3dbece2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3bd0d9e6-9738-4d15-9925-6adecf87091c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7be311ef-58e4-4ad6-8839-24e9127be9cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26adaeb5-c7dc-4653-8047-b2714b18e533
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9a9bd90-6ab1-4ef7-a0f7-2e10a1fbf9cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56345d9a-e790-48a4-9c94-3a9da6c6b974
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ddb54e34-060f-4668-a098-4ecb231572cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3908524-c2f8-4bdd-bc0a-2ed54d89d396
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50cd5fce-67e8-4c8c-9ca1-f7599082a076
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 780f1c6c-95c6-4620-9e43-c33bc572f5bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5b5fd88-e261-40d2-b48b-d08f727ad122
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97b43cda-d4f8-435b-af16-aa39437369fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f2857cc-352c-4ddc-b392-3ed7a34c80a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb72fbbd-a5e7-4970-ba48-2fed7c47a2fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 535e3d54-4046-4c95-99a2-1c7d8b10ec6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 092b979d-ea52-4a23-90f9-1f84c5fa698c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1dcca9e5-0801-42be-85b4-25c0a4adefa1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2d4f298-8d4c-4872-80a1-48eade11aa2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55ca4f8d-2054-424e-b7ec-cf38b874a2a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 600ef3a8-e895-4128-9ddb-718ca357fb77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f98767c-54f7-4509-a8d3-c765833ee25f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71f36b79-4466-4ceb-aded-ce2949ccce6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d4c1234-fd26-4b85-aea6-45bd240cda08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47f44731-7eb5-402d-8a53-383bb457bfc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da9cf87f-6aef-4c82-b1e9-fca7c8d07dc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b9e96a2-6137-4b6d-9770-319fc9fad960
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e41f211b-f2fa-44a2-8b43-899fbd476657
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f52d7a4-8628-49fa-80b3-ae5c92f0a61a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b863383-7c39-4a2e-a628-86d90eb37542
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72cc64a4-3780-4f3b-be3b-b9e03a5d3444
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4306097a-1182-49eb-9190-35e31b9e9bd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27fcb97c-9621-45d6-ba23-1e461953b36a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c4d0920-3a31-45b1-9218-5562841708c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a868ea99-8a06-4f86-961f-464cea7e5ca5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a9850b9-7ef3-4283-a423-2922574f18fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5186d97-48ef-4281-b245-856b410289e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c75174a-d405-45a1-ae75-d9990944beba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd4667f6-1941-4abc-9605-5f6d7eb81549
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9287f335-e819-42dc-bce0-1b1958451bcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74f98275-1a9b-4062-8673-c49578088448
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad719ccf-7180-4b5c-ac63-74064cde02bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21c37245-a034-4ee9-b4b5-aa313b864b36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 676e5c01-918c-4bef-91ed-bde55f7577fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f4d977d-7108-437f-8115-326f6195a2a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b551f41c-1f38-49d4-b2f3-58bd78dbda4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79f40abf-1b03-4a74-84f9-f10a2c80c136
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0c8d3d0-70cf-48ae-a051-2d4fccef79b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d78e14ce-96e1-453d-a9f3-b6d127354a14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8a0e2dd-e9bc-4ae5-9f65-8bf279509c36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 584fa14e-dd20-4b57-93ae-95ef4835e85a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc50e961-54a1-445c-8ac0-6a387fa14307
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69b941cf-0450-4604-8c53-510bd9e454f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16887141-c7ba-4588-873f-486c7678735f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message befffbd1-3ce4-4e74-aa3d-e6e151ddbccd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a883fe6-c5c0-4baf-9023-515a7a0e2d98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c098cdf-95a3-4353-a472-409ef796b606
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d564e523-ba5e-4368-a6fc-5134485132c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4183f098-2188-451b-84e8-1db675d195c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 995be74d-26d2-4e79-ae3f-04aa5f59cd0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19acff64-ee08-4525-897c-10df1f673486
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47454ebd-bbe9-4f46-86c3-d0790c53f7f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1bf81dbc-b3a5-4cc0-8f16-772dc8e0e2a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4429ef68-8624-4c7d-932e-b6c5f0a8cee0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76c81445-b001-4f54-9085-fd1746897097
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 396bbfd2-7d15-4eb5-9069-b2606a4a62df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b5f5d62-d08f-417a-b1a0-1ad92daa1821
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a712a777-2e1b-444e-a4dd-faf309cc2ef0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 972fbfe8-21de-4b94-9548-f0f86821c557
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message edd0bc37-e83f-4fb3-b8f7-f9e5d3ed6527
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91eca37c-33ff-40ed-b94d-a6936f600ada
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f9030e9-daae-4398-b76e-8a332946b256
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c8b1cd7-3a6b-4bff-982e-5d32d91bb3d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71c648bc-4f11-48ef-b534-5dabc0e7db4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4142593b-7984-4579-ae32-50138439e422
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a8a7cdd-d058-45de-a519-f592bdbcbbf6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e65cee2-aac9-4c27-a590-b9004e922546
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a90b70d-bfd5-423f-af14-a9e5dd845a2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d3c70ba-3e83-411c-b692-6e88bf3f9684
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06b3a81f-effd-4267-ab48-dada9c219d1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6a6a74d-2375-4d21-b1a4-a57064368523
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 383eb385-010d-4de2-acb6-d36c7dabe615
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27349e9e-a49d-4143-8661-1fd8cf3c6f31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e92f3b65-548c-4c5e-aa89-0411094c1363
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ecc5277d-f670-4d87-b4f9-129c9654d91f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e60627e5-87d4-4a8f-95f4-46138b288813
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 360f42ee-9bdd-4aab-a117-ffb70393c061
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb9af0ed-aa16-451b-b8c7-ffa50b07ed7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61890854-aef2-4430-8a9b-23f502d4f6da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd0e0325-efaa-4a8c-a5f2-16e7c6005a60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82c85ce6-409f-47a9-989a-b571bf688f51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1fbfe225-6948-46a7-b3aa-6a49d5171e9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d960e8b-3b2c-4738-a781-b78b791ef5c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14b3c84a-78bb-4b23-8c3d-de6818b1ed14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9626dd5f-a676-4ec1-a6e9-284e4b55151d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5cd94b8e-b79a-44e9-aa4c-a1c4d32a69a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b299e4cd-de85-4434-9e81-598da8d0ac26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a223f4d9-1c01-4553-a77a-c5fd0fb82d3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f6a1f4e-cec2-4043-b93d-824fe1d1b6ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df0e80e7-d485-4985-bbc5-f95d29273538
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79dbe40d-9f3c-4a49-b417-75a8ef51cf79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e79c629d-ede6-434b-8705-fd8645c86d06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c183eb3-0fcf-4de4-adba-7e8f4c55d9a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27a02515-1cc5-4600-b26c-ddb66c77ee1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d8b8424-9067-4cef-a87a-607f36d96df9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8deb39f-ecc5-4bb4-bde6-36824ecfeb43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cce6341d-f106-4bba-8b4a-cd9765cd848d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 441f9b76-a2ce-43b3-aed6-1afabd79058f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f664ddfd-fbd0-4f65-be75-a0f1dbf3e8a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20b9ea6e-4c3a-4088-b241-3161c48ec90a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68521c14-46fc-4111-87be-bb2b06a91ba1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee2d543f-019f-4ea1-8aca-c74eacd35b78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c03dbd36-0e2c-436c-b1e3-28b22ceb099f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8600e824-69a3-4556-9cd7-3dbae10af016
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a671e7ff-17aa-4ae0-87ee-34703c134474
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a10ef3d7-aea1-40a0-ac79-b3beb71727ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52a913e7-4b28-4721-8269-3f82c1a720b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3de5912-9a70-4cf3-a1b4-e7b888e86c97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ab60db6-5c1f-4bfd-9f73-fa28ee0c1f00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 732b2d3c-fa2a-4ad2-8819-d987f1f7d740
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c39abfd4-5fc2-4c92-9873-9fc0da01df9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf374d20-3c60-4c49-b63b-9c4bcbc657c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f52c244a-4bb8-45d8-b408-3260243dc94b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07d58e02-986a-4318-bba6-f70288cb97a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b86b37b7-69a7-4bce-9b68-5811ecd3b499
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30d3fb51-f42a-4b2e-ae36-b57bb007f832
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d9a9948-2f70-4591-9818-1146e4e98bc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef7270e6-9858-4e0d-b0e4-84104dfbe72a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4892018-0b86-468a-8e2c-52fbe157ba82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e5c84a7-23bb-4252-ac66-c7a669dedabe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f0927f9-94e0-4fc9-ace5-162b0bfec8d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c20b5f3-ca6a-4bb5-a264-b24bd959f71c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ade6d5bc-e07b-42f2-83a7-0f47ddfea66f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ef0e97f-d18f-4e3f-a7b3-d63d8959cf1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a51ea0a-b437-4555-80e3-e3119df0c6a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 589704a4-590a-48ed-b7b6-fcaca6180f29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9001c986-8658-4231-b138-cf09ceee7c4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9f54b3b-3bf9-4e9d-80fb-d191a04706b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c748aa2b-d492-4b5f-ab90-64680b3f9b54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2369925b-002a-4ad8-885e-8d905f0e42d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e570bb25-e14a-4700-b5c0-8e297ba65aa8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7eb1c1b1-2e39-40e5-855f-e25c4f5e0369
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a331377-ed51-4db2-8aa6-6bfde95699c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69c1a383-2d6f-467f-a828-52b090dd2597
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1906a1cd-2a35-4032-8df9-8c4957b5e66f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7cf5732a-54ef-4ac5-8735-2d8c93dd1431
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 217dbdff-bc03-4e7a-a1d9-262583712048
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ff3d20f-cbbc-4df2-8d49-0d7531910253
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05552f6d-5160-42bc-ae73-76a31f99c8bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 456c09cc-5a73-4c88-8435-35b1913a7b82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eddbd687-41b5-49b8-84a0-dcde032e2825
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f01d3f2-f82a-46fc-94ee-74caed7f0495
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71cd83df-8cb7-496a-95b1-f2d0be6ccee9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ddce377-8e15-43f9-8b5c-9b6de94ccac8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a07cc031-09b4-4eca-a02e-8a98fd8057df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8b8ffc7-389a-4e66-905a-7160d94b14ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cdd9aa51-e9cc-47a8-8c3b-319f8b47fdff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30e60a0e-262a-4275-8a95-ad726646d0ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0bc2c30e-7874-4f44-9850-a1a6b7279f71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20617d88-b31c-40a4-95e9-84993ab4b14b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d50f8153-d485-4736-b387-3e76aac33d6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c92dcab4-0807-4947-9a3c-53c4ac2b05a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da989177-8684-4446-9f55-810fefcc70c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9a5a0d1-fbf6-4297-bde5-630d4850bf3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11838263-9e35-453c-b93f-97ebd0465147
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb3995cd-9d83-4b84-98ce-838ca68b959e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36d8ecac-049b-4427-8634-6d26f6000d0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc6d3340-8679-4259-ad58-a35fcf27e6f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 302af922-cbaa-42c3-82dd-3366f3ae2159
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2347e51-7215-4880-ac65-adcdc82b9aa2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 272a0844-3fb4-4df0-a595-f144ebda2aa9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d7f41bf-c55e-410e-8f45-1b59391602cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8924ac31-d10f-46e9-8b44-985394ca1252
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ac0a198-5260-429e-9fca-e9c63eb1ae48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 585d2536-d6e6-4e16-991e-28ba00f90af8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0fc2ae4b-d0bd-4f7c-ba40-f65796bd4f07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12f16d0b-c6dc-4bd9-8a71-b3a9d25ba162
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d587c9e-e154-4347-b063-72e34a395170
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31d35a6a-eb41-496d-8c36-aee010f5236d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 353777b0-7aca-4fb0-afe1-d2311e5ab3d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4cb5356d-a59f-4f2d-8947-bec4b9727f08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c337f9ad-0a7a-4e12-a846-5027e3ddfac8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a05aac38-fb0b-4265-9167-01021cf22e01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a5e8a7f-664c-45f4-90cb-ea9d03d0d692
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f76651e9-c8b2-44db-9d0e-08f0405efba2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d63b2835-1a16-47bc-b0a1-81c0e41c6068
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f69fd554-00ea-4efb-8132-43b7d6436f81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f46aa08f-5996-46bb-ab7e-b9a454b37241
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27b27c3d-a09b-4bf4-bdbe-822f3ce9fc86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80d4619e-7362-49a6-8f02-b277977dfdc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60bd4318-0afe-4dd5-a65c-93c6d0359db9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e993989-07ee-48be-a6e3-e433d40bf03e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e075f60b-f473-4a59-b143-6a212ef5417e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43c4b58d-baa3-4f61-9b44-8ff9c2b499a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2493dbc-bd17-47d5-9eb6-bc39521e3942
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d53d1012-9879-45bc-be3a-e2d19f36f70c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d96b9ea-6e97-42e6-b405-73b4323e3273
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85720826-bd53-4045-a06c-d5efec61b5f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71f9a588-fc70-4999-a19c-94549d9acf8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b22ee89-04f3-40f4-bdb2-1918203d543d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b78fb96-cdc7-4b2a-aa5b-dc41213929fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7b95b5e-4956-4f9f-b73d-7d5d695a76a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ef4f200-07e0-4774-9e79-8c87dd749708
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9ba7e6f-602c-4663-8d29-c9c9c3352a17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2db076c2-8d4e-4400-9a1b-877fa12c62d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15d08d31-c3b1-4cf5-9b2e-52597cccbb2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7e3f533-26f0-45c6-a53d-1418e0ed8c78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8822e2c0-386b-4d69-89e0-8e1e40474d48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ded8337-9ab4-42c4-8de1-c769b81b778d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f35b33c3-6b13-464a-bb2d-8e7e22eac92a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46d28f91-8e28-4f02-899c-173a6545b5c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d4c9797-602e-4362-bfc2-e93f993a867d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91466ab4-cece-408b-b6ef-0d53e26fb503
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09a4f5d9-b888-4529-ad9e-5552bcd97dba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e300bab-6924-4894-9b01-441408134821
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23ccfd6f-703c-42b8-8c65-76e052828dda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d151ee80-08fe-47e8-9ed8-918d80e2c09c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41d3b7bf-90a3-4d2f-85ab-ecd4d7c52e91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a831a13-ef52-4e32-9f56-6f0b65a674fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 907586cb-17c3-494c-b920-abc8884fc69d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f46874ba-2e4b-44f4-b49d-b79f61f5abbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7cda1b61-afc3-4bd3-888e-2d647aa7f953
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e9409aa-c2c0-423f-9fe2-4d0cf7385573
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8740b6cd-65ac-4db6-90d3-1ab136778402
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92299517-e065-4790-8b04-fe9eafa65e7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c130332-095f-43e4-af89-22dab8189930
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1305c6e-f3a5-4e04-988e-91ad01886fdb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 484eee2f-6cdc-4733-b94d-4c0d35922984
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e6ac485-9b99-4180-b997-1548a7c28c67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18d9c220-1dcc-4ed9-ba6c-2893c39a1f77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 068dc0ca-5182-4ded-8416-fefb1c9d7648
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8d8515f-5a88-498c-a0d9-488987315b33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ffbd35c1-5946-41db-96ed-0d27753ab98d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50f81fe6-8953-4f7a-94e7-640630ae6e1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0ca5405-92e0-4c1d-aa2c-b021ef5ac42c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d687aa4-3b1e-40c8-97c4-0ee188cd0410
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fdfc2f4c-1534-4ff6-9916-6eb63fd618dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 915f0868-0c46-4e13-9d1d-c83c0a5e7204
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8dd511b3-2d0e-4fa3-b82a-52fa571ff7d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a674fdba-672c-4fff-a0cd-a34f4dd33792
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c1ee081-6256-4727-ba89-fe6ec8f1d0e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b155171-e3f7-4d57-ad89-17ed5f317667
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34cb44f8-60a1-465b-97b5-c724e914011c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a102657b-4708-4ef3-ab10-bc8b5512e7ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07e51203-07df-40fc-ad7c-4224026bcc61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4ccee8b-3dd0-4869-b593-bbf9258186b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1363bd1e-76c4-4442-b4d8-2ab23ad127bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b2bca29-736f-4069-8687-8cd3b6baa8e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00f680eb-f0cb-40b2-ac77-095147f2454f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0e75fc6-45d0-491a-ad57-978d2bab254c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2235f39f-1b4b-473d-89a5-9c4a5840afc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6bf7952-485d-4383-b109-d427709df1e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f6d0522-912d-476f-a115-ef5dcdebd506
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f81a2884-0351-4f9e-b1ca-cfc8efc1c563
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55e310e7-ede4-457c-934a-b787b6bcf8a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 058a406b-f8f1-439b-a6b3-37e4bb9dd899
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f284e067-960e-4f27-8f4a-f6873e5489fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f566dc5-8052-40d3-9234-ccbfc1a32a5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6da6b3b-9448-47ea-82cd-5d2a4ec00e82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db987d40-78e8-4d20-a0f2-d01802fe2ae3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b48a2f3-f147-4209-baa4-54b6fec5f89d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f33d9bb9-6749-4771-bacc-fadc74e9b258
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e768387e-1360-4f38-902d-5433692807d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6724bd56-f936-46f1-81d6-5bd26e036492
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc87cf05-da0f-4030-bfe6-e9df160650b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f90d023-2a64-478b-9a63-81efa9d6d951
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 452d4761-4ac0-4025-9c05-fa23b19e7a68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21077c9e-7fab-4f47-b359-8d40508c1a25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4699674b-72c7-4237-af8c-e88845151f4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e47ed08-a8f3-4c63-8523-3840512530d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28ed979c-15e8-4c43-bb33-a0a1e9c08090
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e134ce1-cd75-4071-bc34-1177c671e51a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2575f294-bb33-40b5-b17a-c8d1ba77a2b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c1820fa-f181-4c61-b07e-bc94024f8d81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f0a8ce0-fcb9-4326-942d-4e4ad6a58553
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6aafc22d-e7e2-4d95-a4c0-9e5290d22fb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65481094-f23d-4402-8cf1-a78520a7d7f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90906951-6077-4a5a-a0c4-393f7979b91e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b08343ea-04c8-45b1-8101-2f37b9335044
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8abeed25-e968-4085-9b76-2a3664cd8b2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7006921-648a-4f5b-b910-c05af74facf6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 739ff36c-1281-4d85-9c1f-4f3fa0dfff7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bcf7132c-70a0-40b8-b758-c2bb0f52a0a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2de50c7-5ca4-485b-94f0-bf2d92b9b52d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c08bba8-a9ac-4ac9-96c1-c6dffb843949
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 247efd87-bfc6-4ab8-89c5-8d1ee29d2dfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 358ab778-a5ea-499b-868c-ab097f615fc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8bc97f7-27ea-4813-917b-0409d5036fc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25c5c51d-e853-4c2c-9da7-6f97ff1933eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17d8433a-3642-4060-a9e5-7bc4e3f96347
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e4d4710-83d4-4090-8bd2-545a21027bb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b60c71e2-5ebe-49b6-a68b-3a56b5727b12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2202e71e-9282-4418-88de-6ac8003d719b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b168e881-369a-424a-b055-ccd40ca34a8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c17cb6c-b10c-41cc-a9d0-87f1ee849b13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f69502c-6439-4828-a475-283ef89941ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ef1a1f4-eef6-46ff-816b-7a6142ace749
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d310cb6-732f-4b76-bb34-32de0e74ea0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3b4db4e-3e63-47b3-bea0-d0afe6a0ea88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d82a97ff-d4f8-4f13-a798-8478621126f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 126c9881-c33d-4bf1-8d14-3e3d2066e94e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37c7a4a6-e38e-4bcf-80e9-0ece09297a53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8e79a7a-9afc-4ad2-b4a2-dcf976764c29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16cc0167-1c6a-44ac-af09-b8bfb5119068
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1dc9e30-5b20-4f57-be0d-f974e8aeea8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 087b40d4-943c-47ce-9cfd-70db811eb322
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07a6ef68-27f2-4a25-80d7-e0ab27ce7c8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2c44a78-c9a8-450d-ab8d-a6530f20aeb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 940d8309-8950-47b8-b52c-595fa8b2b8b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c62e13bc-adb1-4701-8d48-089c1ffb07cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0a40f51-7aec-4ad8-b9f2-f821508e058b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84016f85-7323-4bd1-be0d-302f7bf384f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e577f92c-1436-4043-b52c-593e0577cd55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97cfaa21-5614-4588-a712-54bb5cc1f863
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 585f6547-cd3d-42e0-b06c-e096185b6c5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71cca46a-2ffc-41a2-b1ad-016ecc43e3ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 111b4f6e-1e2f-454a-9703-7e1f9603296b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0dad4134-8571-4404-bd64-4f19a80700a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62914983-0dc9-4480-94f0-aa4ebf4ed58b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e16ae018-4ad7-47dd-bb11-008dcb88b652
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5c1c176-bf33-4eb5-945c-412465235b43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ddd907fd-6555-4fad-8576-4d3296e36ef5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eda9776b-661c-45ac-a754-fbb00d10d009
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f2ef242-1b43-451b-b1ef-ef6d46abe417
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7680ce3d-38f7-4085-90ec-0652cd07135d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7535d02-4d7c-415c-b977-5f1c9d95bad8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 323f26ef-8cc6-47bb-b2e4-67d435d6772e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c32d796-dddc-4645-a517-f86fda156d98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f65ee405-7b4d-4415-8720-6e14cbb91fae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73a47db1-114b-4904-bdd9-2bf46558f428
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5438924-64f6-40ea-af13-6fad01df48b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3eb62466-83e6-482f-979b-d8710e2a781f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8421404-c3cd-4def-8980-dade7acaa106
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a34ced3-3119-49b1-8b3c-0d7845e80fda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd49b93d-0df1-4491-bd8f-d5624cd787c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c9febaf-f807-413d-bb29-efc17b2a8869
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1904ac8-89c2-4e60-b6f3-b1339db9dad3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fab1b602-f676-4494-b37d-38428018796d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 172bdaa3-c6d3-45ff-a553-c19ddfbc1d0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21c2cefc-7a80-49bc-813c-2a547f7f7b22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23dd5ec9-d8ff-46cf-a6fb-cc803dce5093
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36d8e89b-a570-47d0-9418-a894795be8a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac8e9555-6bce-49f1-a3aa-6afd2f68d4e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d7bccd3-216b-4c45-b5a0-ead00a25ba16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e8171a7-b4c6-4fd8-8d2f-5bffc509c9a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa41c47a-7355-4d7f-a897-5212cbc45f83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e6c5ef4-07e3-4af9-bad0-fff9aad76eeb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e912138-107e-46fd-86a3-bc3b2582c177
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06068163-637d-48c3-8a20-8ba4585467d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a003cd2f-b27e-4a30-acf3-cc015953a75f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 341567c2-54ef-414f-88a0-2504eea4e875
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a3d47da-e683-4e18-9bfd-70b8c2da503c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b50b81a1-e973-45ee-9c50-07b208558494
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c930aa09-7943-4b20-95a7-5299f9bcfc25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e49ae4f5-349d-40a9-9ef0-d24b4260cbe5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f8a0e13-fc8c-4e91-b2ac-c3ffdcf7ca04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 939bf67d-093c-4c78-9c02-272c2f1b1f8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce59ab38-5634-4312-b22b-4463238b2568
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd30da7e-48d6-47c8-a8fe-bce9b5ec519c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf9ea229-1461-4e3d-b1fb-1ae0b127adcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7bb052f1-ce96-4477-a23c-f12fcd5edf7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9af8e9ae-d5e7-41d1-a2c3-b203d02ce52a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee8f8565-60b5-4568-b6b2-04d2438f4afb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41c5a213-51dd-4aef-a80e-05e6b1c5876f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b4a85f9-5e10-42da-97a6-86fc0a589c2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 069f5787-01ba-4e10-a6e4-93c64c20deae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5289141e-6caa-4723-a665-c62d167943b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25fdba53-a4e4-4ec6-8f50-9d83abe07bb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0abd258e-73f6-419d-8084-7b701f6a29f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8a06067-ba61-4afc-afa3-502901cd2823
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8688 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_4
Server: localhost:8688
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_4
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_4/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_4/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_4/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_4/test_labels.txt

📊 Raw data loaded:
   Train: X=(5467, 24), y=(5467,)
   Test:  X=(1367, 24), y=(1367,)

⚠️  Limiting training data: 5467 → 800 samples
⚠️  Limiting test data: 1367 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_4 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 1 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1996, val=0.0921 (↓), lr=0.001000
   • Epoch   2/100: train=0.0863, val=0.1041, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0879, val=0.0939, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0848, val=0.0926, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0832, val=0.0937, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0824, val=0.0928, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 1 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0132
   Val:   Loss=0.0921, RMSE=0.3035, R²=-0.0113
============================================================


📊 Round 1 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2523, R²: -0.0031

============================================================
🔄 Round 2 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0859 (↓), lr=0.000250
   • Epoch   2/100: train=0.0849, val=0.0858, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0844, val=0.0861, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0843, val=0.0863, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0842, val=0.0864, patience=4/15, lr=0.000250
   📉 Epoch 8: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0838, val=0.0869, patience=10/15, lr=0.000125
   📉 Epoch 16: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 2 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=0.0005
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0405
============================================================


============================================================
🔄 Round 3 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.3006, val=0.2123 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.1534, val=0.1154 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.0991, val=0.0867 (↓), lr=0.000063
   ✓ Epoch   4/100: train=0.0867, val=0.0810 (↓), lr=0.000063
   ✓ Epoch   5/100: train=0.0852, val=0.0803 (↓), lr=0.000063
   • Epoch  11/100: train=0.0850, val=0.0804, patience=6/15, lr=0.000063
   📉 Epoch 12: LR reduced 0.000063 → 0.000031
   📉 Epoch 20: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 3 Summary - Client client_4
   Epochs: 20/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0852, RMSE=0.2920, R²=0.0020
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0042
============================================================


📊 Round 3 Test Metrics:
   Loss: 0.1581, RMSE: 0.3977, MAE: 0.3289, R²: -0.8732

============================================================
🔄 Round 4 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1482, val=0.1648 (↓), lr=0.000016
   ✓ Epoch   2/100: train=0.1324, val=0.1468 (↓), lr=0.000016
   ✓ Epoch   3/100: train=0.1188, val=0.1333 (↓), lr=0.000016
   ✓ Epoch   4/100: train=0.1090, val=0.1233 (↓), lr=0.000016
   ✓ Epoch   5/100: train=0.1019, val=0.1157 (↓), lr=0.000016
   📉 Epoch 8: LR reduced 0.000016 → 0.000008
   ✓ Epoch  11/100: train=0.0866, val=0.0987 (↓), lr=0.000008
   📉 Epoch 16: LR reduced 0.000008 → 0.000004
   • Epoch  21/100: train=0.0835, val=0.0939, patience=2/15, lr=0.000004
   📉 Epoch 24: LR reduced 0.000004 → 0.000002
   • Epoch  31/100: train=0.0829, val=0.0928, patience=5/15, lr=0.000002
   📉 Epoch 32: LR reduced 0.000002 → 0.000001
   • Epoch  41/100: train=0.0827, val=0.0925, patience=7/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0927)

============================================================
📊 Round 4 Summary - Client client_4
   Epochs: 49/100 (early stopped)
   LR: 0.000016 → 0.000001 (4 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0038
   Val:   Loss=0.0927, RMSE=0.3044, R²=-0.0270
============================================================


📊 Round 4 Test Metrics:
   Loss: 0.1072, RMSE: 0.3274, MAE: 0.2704, R²: -0.2696

📊 Round 4 Test Metrics:
   Loss: 0.0852, RMSE: 0.2919, MAE: 0.2517, R²: -0.0096

============================================================
🔄 Round 7 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 7 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2966, R²=-0.0114
   Val:   Loss=0.0771, RMSE=0.2777, R²=-0.0457
============================================================


📊 Round 7 Test Metrics:
   Loss: 0.0907, RMSE: 0.3012, MAE: 0.2597, R²: -0.0747

============================================================
🔄 Round 9 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0918, val=0.0931 (↓), lr=0.000001
   • Epoch   2/100: train=0.0917, val=0.0930, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0916, val=0.0928, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0915, val=0.0927, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0914, val=0.0926, patience=4/15, lr=0.000001
   ✓ Epoch  11/100: train=0.0910, val=0.0920 (↓), lr=0.000001
   • Epoch  21/100: train=0.0903, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  31/100: train=0.0897, val=0.0903, patience=1/15, lr=0.000001
   • Epoch  41/100: train=0.0892, val=0.0896, patience=3/15, lr=0.000001
   • Epoch  51/100: train=0.0888, val=0.0890, patience=5/15, lr=0.000001
   • Epoch  61/100: train=0.0883, val=0.0884, patience=6/15, lr=0.000001
   • Epoch  71/100: train=0.0880, val=0.0879, patience=7/15, lr=0.000001
   • Epoch  81/100: train=0.0876, val=0.0874, patience=7/15, lr=0.000001
   • Epoch  91/100: train=0.0873, val=0.0869, patience=6/15, lr=0.000001

============================================================
📊 Round 9 Summary - Client client_4
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2954, R²=-0.0286
   Val:   Loss=0.0866, RMSE=0.2942, R²=-0.0509
============================================================


📊 Round 9 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2499, R²: 0.0165

============================================================
🔄 Round 16 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 16 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0030
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0076
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2496, R²: 0.0197

============================================================
🔄 Round 19 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 19 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=0.0038
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0333
============================================================


============================================================
🔄 Round 20 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 20 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0074
   Val:   Loss=0.0861, RMSE=0.2934, R²=0.0051
============================================================


============================================================
🔄 Round 22 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 22 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0018
   Val:   Loss=0.0908, RMSE=0.3013, R²=-0.0140
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2497, R²: 0.0188

📊 Round 22 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2497, R²: 0.0191

📊 Round 22 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2496, R²: 0.0194

📊 Round 22 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2496, R²: 0.0197

📊 Round 22 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2496, R²: 0.0200

============================================================
🔄 Round 28 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 28 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=-0.0079
   Val:   Loss=0.0872, RMSE=0.2953, R²=0.0196
============================================================


============================================================
🔄 Round 30 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 30 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2920, R²=0.0023
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0187
============================================================


============================================================
🔄 Round 31 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 31 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0030
   Val:   Loss=0.0848, RMSE=0.2913, R²=0.0046
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2494, R²: 0.0213

============================================================
🔄 Round 33 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 33 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0021
   Val:   Loss=0.0835, RMSE=0.2890, R²=0.0028
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2493, R²: 0.0220

============================================================
🔄 Round 35 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 35 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0018
   Val:   Loss=0.0852, RMSE=0.2919, R²=0.0069
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2493, R²: 0.0222

============================================================
🔄 Round 36 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0933 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0933, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0933, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0933, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0933, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0933, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0933)

============================================================
📊 Round 36 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=0.0021
   Val:   Loss=0.0933, RMSE=0.3055, R²=-0.0062
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2492, R²: 0.0227

============================================================
🔄 Round 39 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0939 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0939, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0939, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0939, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0939, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0939, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0939)

============================================================
📊 Round 39 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0087
   Val:   Loss=0.0939, RMSE=0.3064, R²=0.0263
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2492, R²: 0.0228

============================================================
🔄 Round 41 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 41 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=0.0034
   Val:   Loss=0.0797, RMSE=0.2824, R²=-0.0077
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2492, R²: 0.0230

============================================================
🔄 Round 42 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 42 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0002
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0030
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2492, R²: 0.0232

📊 Round 42 Test Metrics:
   Loss: 0.0825, RMSE: 0.2871, MAE: 0.2492, R²: 0.0233

📊 Round 42 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2491, R²: 0.0235

============================================================
🔄 Round 46 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0934 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0934, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0934, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0934, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0934, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0935, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0934)

============================================================
📊 Round 46 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0014
   Val:   Loss=0.0934, RMSE=0.3056, R²=-0.0002
============================================================


============================================================
🔄 Round 47 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 47 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=0.0085
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0282
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2491, R²: 0.0237

============================================================
🔄 Round 48 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 48 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0040
   Val:   Loss=0.0888, RMSE=0.2980, R²=-0.0117
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2491, R²: 0.0237

📊 Round 48 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2491, R²: 0.0238

📊 Round 48 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2491, R²: 0.0239

📊 Round 48 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2491, R²: 0.0240

📊 Round 48 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: 0.0241

============================================================
🔄 Round 55 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 55 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0027
   Val:   Loss=0.0886, RMSE=0.2977, R²=-0.0013
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: 0.0241

============================================================
🔄 Round 58 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 58 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0058
   Val:   Loss=0.0848, RMSE=0.2913, R²=0.0370
============================================================


============================================================
🔄 Round 59 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 59 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0036
   Val:   Loss=0.0893, RMSE=0.2988, R²=0.0016
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2490, R²: 0.0243

============================================================
🔄 Round 62 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0933 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0933, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0933, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0933, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0932, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0932, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0933)

============================================================
📊 Round 62 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0058
   Val:   Loss=0.0933, RMSE=0.3054, R²=-0.0064
============================================================


============================================================
🔄 Round 64 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 64 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0081
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0151
============================================================


============================================================
🔄 Round 65 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 65 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=0.0019
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0103
============================================================


============================================================
🔄 Round 66 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 66 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0007
   Val:   Loss=0.0875, RMSE=0.2958, R²=0.0116
============================================================


============================================================
🔄 Round 68 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 68 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0064
   Val:   Loss=0.0859, RMSE=0.2931, R²=0.0287
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0823, RMSE: 0.2870, MAE: 0.2490, R²: 0.0245

============================================================
🔄 Round 70 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 70 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0001
   Val:   Loss=0.0858, RMSE=0.2929, R²=0.0176
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0823, RMSE: 0.2870, MAE: 0.2489, R²: 0.0246

============================================================
🔄 Round 73 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 73 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0069
   Val:   Loss=0.0885, RMSE=0.2975, R²=-0.0138
============================================================


============================================================
🔄 Round 74 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 74 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=0.0058
   Val:   Loss=0.0815, RMSE=0.2856, R²=-0.0054
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2489, R²: 0.0246

============================================================
🔄 Round 75 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 75 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0034
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0055
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2489, R²: 0.0247

📊 Round 75 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2489, R²: 0.0247

============================================================
🔄 Round 78 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 78 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0057
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0073
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2489, R²: 0.0247

============================================================
🔄 Round 80 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 80 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0076
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0187
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2489, R²: 0.0247

============================================================
🔄 Round 82 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 82 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=-0.0003
   Val:   Loss=0.0843, RMSE=0.2903, R²=0.0203
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2489, R²: 0.0247

============================================================
🔄 Round 85 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 85 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0066
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0245
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2489, R²: 0.0248

📊 Round 85 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2489, R²: 0.0248

📊 Round 85 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2489, R²: 0.0248

============================================================
🔄 Round 90 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 90 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0128
   Val:   Loss=0.0879, RMSE=0.2965, R²=-0.0447
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2489, R²: 0.0248

============================================================
🔄 Round 91 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0718, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 91 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2954, R²=0.0068
   Val:   Loss=0.0718, RMSE=0.2680, R²=-0.0110
============================================================


============================================================
🔄 Round 92 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 92 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0055
   Val:   Loss=0.0867, RMSE=0.2945, R²=0.0309
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2489, R²: 0.0249

📊 Round 92 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2489, R²: 0.0249

============================================================
🔄 Round 95 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 95 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0060
   Val:   Loss=0.0839, RMSE=0.2896, R²=0.0427
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2489, R²: 0.0249

============================================================
🔄 Round 99 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 99 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0014
   Val:   Loss=0.0898, RMSE=0.2996, R²=0.0145
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2489, R²: 0.0249

============================================================
🔄 Round 100 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 100 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0121
   Val:   Loss=0.0915, RMSE=0.3025, R²=-0.0276
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2489, R²: 0.0249

============================================================
🔄 Round 102 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 102 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0034
   Val:   Loss=0.0872, RMSE=0.2954, R²=0.0037
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2489, R²: 0.0250

============================================================
🔄 Round 104 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 104 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0119
   Val:   Loss=0.0766, RMSE=0.2768, R²=-0.0337
============================================================


============================================================
🔄 Round 105 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 105 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0037
   Val:   Loss=0.0801, RMSE=0.2831, R²=0.0374
============================================================


============================================================
🔄 Round 106 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 106 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0018
   Val:   Loss=0.0872, RMSE=0.2953, R²=0.0145
============================================================


============================================================
🔄 Round 107 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 107 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0082
   Val:   Loss=0.0849, RMSE=0.2913, R²=-0.0120
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2489, R²: 0.0250

============================================================
🔄 Round 109 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 109 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0044
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0343
============================================================


============================================================
🔄 Round 111 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 111 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=0.0054
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0016
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2489, R²: 0.0250

📊 Round 111 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2489, R²: 0.0250

============================================================
🔄 Round 113 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 113 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0090
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0334
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2489, R²: 0.0251

📊 Round 113 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2489, R²: 0.0251

============================================================
🔄 Round 116 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 116 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0022
   Val:   Loss=0.0846, RMSE=0.2908, R²=0.0238
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2489, R²: 0.0251

============================================================
🔄 Round 117 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 117 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0099
   Val:   Loss=0.0907, RMSE=0.3011, R²=-0.0163
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2489, R²: 0.0251

============================================================
🔄 Round 118 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 118 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0014
   Val:   Loss=0.0877, RMSE=0.2962, R²=0.0142
============================================================


============================================================
🔄 Round 121 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 121 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0035
   Val:   Loss=0.0862, RMSE=0.2936, R²=0.0075
============================================================


============================================================
🔄 Round 123 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0939 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0939, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0939, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0939, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0939, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0939, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0939)

============================================================
📊 Round 123 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0043
   Val:   Loss=0.0939, RMSE=0.3065, R²=-0.0029
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2488, R²: 0.0251

📊 Round 123 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2488, R²: 0.0251

📊 Round 123 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2489, R²: 0.0251

============================================================
🔄 Round 129 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 129 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0068
   Val:   Loss=0.0912, RMSE=0.3020, R²=-0.0129
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2489, R²: 0.0251

============================================================
🔄 Round 131 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 131 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0025
   Val:   Loss=0.0838, RMSE=0.2895, R²=0.0004
============================================================


============================================================
🔄 Round 132 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 132 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=0.0057
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0006
============================================================


============================================================
🔄 Round 134 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 134 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=0.0031
   Val:   Loss=0.0884, RMSE=0.2973, R²=-0.0062
============================================================


============================================================
🔄 Round 135 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 135 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=0.0075
   Val:   Loss=0.0781, RMSE=0.2796, R²=-0.0402
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2489, R²: 0.0251

📊 Round 135 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2489, R²: 0.0251

============================================================
🔄 Round 137 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 137 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=0.0033
   Val:   Loss=0.0840, RMSE=0.2898, R²=0.0057
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2489, R²: 0.0251

============================================================
🔄 Round 138 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 138 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0012
   Val:   Loss=0.0908, RMSE=0.3013, R²=0.0233
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2489, R²: 0.0252

============================================================
🔄 Round 140 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 140 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0074
   Val:   Loss=0.0906, RMSE=0.3010, R²=-0.0100
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2488, R²: 0.0252

📊 Round 140 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2489, R²: 0.0252

============================================================
🔄 Round 143 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 143 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0005
   Val:   Loss=0.0765, RMSE=0.2766, R²=-0.0091
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2488, R²: 0.0252

📊 Round 143 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2489, R²: 0.0252

============================================================
🔄 Round 146 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 146 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=0.0006
   Val:   Loss=0.0827, RMSE=0.2875, R²=0.0027
============================================================


============================================================
🔄 Round 149 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 149 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0083
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0363
============================================================


============================================================
🔄 Round 150 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 150 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0044
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0049
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2489, R²: 0.0252

============================================================
🔄 Round 156 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 156 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0059
   Val:   Loss=0.0891, RMSE=0.2985, R²=-0.0005
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2489, R²: 0.0252

============================================================
🔄 Round 157 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 157 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0093
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0171
============================================================


============================================================
🔄 Round 159 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 159 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0018
   Val:   Loss=0.0793, RMSE=0.2815, R²=0.0169
============================================================


============================================================
🔄 Round 161 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 161 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0059
   Val:   Loss=0.0851, RMSE=0.2918, R²=-0.0002
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2489, R²: 0.0252

📊 Round 161 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2489, R²: 0.0252

📊 Round 161 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2489, R²: 0.0252

📊 Round 161 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2489, R²: 0.0252

============================================================
🔄 Round 166 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 166 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0027
   Val:   Loss=0.0867, RMSE=0.2944, R²=0.0107
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2489, R²: 0.0252

📊 Round 166 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2489, R²: 0.0252

📊 Round 166 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2489, R²: 0.0252

============================================================
🔄 Round 171 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 171 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0043
   Val:   Loss=0.0863, RMSE=0.2937, R²=0.0010
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2489, R²: 0.0252

📊 Round 171 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2489, R²: 0.0252

============================================================
🔄 Round 174 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 174 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0066
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0066
============================================================


============================================================
🔄 Round 177 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 177 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0046
   Val:   Loss=0.0918, RMSE=0.3030, R²=-0.0152
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2489, R²: 0.0252

📊 Round 177 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2489, R²: 0.0252

============================================================
🔄 Round 180 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 180 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=0.0104
   Val:   Loss=0.0867, RMSE=0.2945, R²=-0.0240
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2489, R²: 0.0252

============================================================
🔄 Round 183 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 183 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=0.0044
   Val:   Loss=0.0748, RMSE=0.2734, R²=0.0024
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2489, R²: 0.0253

============================================================
🔄 Round 187 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 187 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0089
   Val:   Loss=0.0915, RMSE=0.3025, R²=-0.0109
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2489, R²: 0.0253

📊 Round 187 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2489, R²: 0.0253

📊 Round 187 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2489, R²: 0.0253

============================================================
🔄 Round 192 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 192 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2920, R²=0.0018
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0137
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2489, R²: 0.0253

📊 Round 192 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2489, R²: 0.0253

📊 Round 192 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2489, R²: 0.0253

============================================================
🔄 Round 195 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 195 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0005
   Val:   Loss=0.0819, RMSE=0.2862, R²=0.0183
============================================================


📊 Round 195 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2489, R²: 0.0253

============================================================
🔄 Round 197 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 197 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=0.0058
   Val:   Loss=0.0732, RMSE=0.2705, R²=-0.0019
============================================================


============================================================
🔄 Round 198 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 198 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=0.0036
   Val:   Loss=0.0798, RMSE=0.2824, R²=0.0040
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2489, R²: 0.0253

============================================================
🔄 Round 202 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 202 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=0.0038
   Val:   Loss=0.0788, RMSE=0.2806, R²=0.0012
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2489, R²: 0.0253

============================================================
🔄 Round 204 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 204 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=0.0061
   Val:   Loss=0.0749, RMSE=0.2736, R²=-0.0006
============================================================


============================================================
🔄 Round 205 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0949 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0949, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0949, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0949, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0949, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0949, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0949)

============================================================
📊 Round 205 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0067
   Val:   Loss=0.0949, RMSE=0.3081, R²=0.0366
============================================================


📊 Round 205 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2489, R²: 0.0253

📊 Round 205 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2489, R²: 0.0253

📊 Round 205 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2489, R²: 0.0253

============================================================
🔄 Round 211 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 211 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0011
   Val:   Loss=0.0900, RMSE=0.3000, R²=0.0167
============================================================


============================================================
🔄 Round 212 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 212 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0043
   Val:   Loss=0.0839, RMSE=0.2896, R²=0.0021
============================================================


📊 Round 212 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2489, R²: 0.0253

============================================================
🔄 Round 215 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 215 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0079
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0091
============================================================


📊 Round 215 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2489, R²: 0.0253

============================================================
🔄 Round 217 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 217 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0091
   Val:   Loss=0.0875, RMSE=0.2959, R²=-0.0227
============================================================


📊 Round 217 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2489, R²: 0.0253

============================================================
🔄 Round 218 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 218 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0031
   Val:   Loss=0.0896, RMSE=0.2993, R²=0.0032
============================================================


📊 Round 218 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2489, R²: 0.0253

============================================================
🔄 Round 220 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 220 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=0.0022
   Val:   Loss=0.0776, RMSE=0.2786, R²=0.0133
============================================================


📊 Round 220 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2489, R²: 0.0253

============================================================
🔄 Round 224 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 224 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=0.0083
   Val:   Loss=0.0855, RMSE=0.2925, R²=-0.0181
============================================================


📊 Round 224 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2489, R²: 0.0253

📊 Round 224 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2489, R²: 0.0253

============================================================
🔄 Round 226 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 226 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0000
   Val:   Loss=0.0849, RMSE=0.2914, R²=0.0195
============================================================


📊 Round 226 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2489, R²: 0.0253

============================================================
🔄 Round 228 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 228 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0066
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0028
============================================================


📊 Round 228 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2489, R²: 0.0253

============================================================
🔄 Round 232 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 232 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0035
   Val:   Loss=0.0804, RMSE=0.2835, R²=0.0065
============================================================


📊 Round 232 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2489, R²: 0.0253

============================================================
🔄 Round 233 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 233 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0055
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0019
============================================================


📊 Round 233 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2489, R²: 0.0253

📊 Round 233 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2489, R²: 0.0254

============================================================
🔄 Round 237 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 237 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=0.0073
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0096
============================================================


============================================================
🔄 Round 238 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 238 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=0.0007
   Val:   Loss=0.0774, RMSE=0.2783, R²=0.0168
============================================================


============================================================
🔄 Round 240 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 240 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0023
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0153
============================================================


📊 Round 240 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2489, R²: 0.0254

📊 Round 240 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2489, R²: 0.0254

============================================================
🔄 Round 243 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 243 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0048
   Val:   Loss=0.0806, RMSE=0.2839, R²=0.0028
============================================================


============================================================
🔄 Round 245 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 245 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0027
   Val:   Loss=0.0819, RMSE=0.2863, R²=0.0324
============================================================


📊 Round 245 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2489, R²: 0.0254

============================================================
🔄 Round 246 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 246 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0030
   Val:   Loss=0.0848, RMSE=0.2913, R²=-0.0016
============================================================


📊 Round 246 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2489, R²: 0.0254

📊 Round 246 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2489, R²: 0.0254

============================================================
🔄 Round 248 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 248 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0087
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0095
============================================================


============================================================
🔄 Round 254 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 254 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0090
   Val:   Loss=0.0912, RMSE=0.3021, R²=-0.0115
============================================================


============================================================
🔄 Round 255 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 255 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0023
   Val:   Loss=0.0859, RMSE=0.2930, R²=0.0138
============================================================


============================================================
🔄 Round 257 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 257 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0028
   Val:   Loss=0.0818, RMSE=0.2861, R²=-0.0014
============================================================


============================================================
🔄 Round 260 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 260 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0028
   Val:   Loss=0.0832, RMSE=0.2885, R²=0.0251
============================================================


📊 Round 260 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2489, R²: 0.0254

============================================================
🔄 Round 261 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 261 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0080
   Val:   Loss=0.0823, RMSE=0.2870, R²=-0.0078
============================================================


============================================================
🔄 Round 262 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 262 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0067
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0248
============================================================


============================================================
🔄 Round 263 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 263 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0037
   Val:   Loss=0.0892, RMSE=0.2987, R²=0.0315
============================================================


📊 Round 263 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2489, R²: 0.0254

============================================================
🔄 Round 267 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 267 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2871, R²=0.0054
   Val:   Loss=0.0906, RMSE=0.3010, R²=-0.0116
============================================================


📊 Round 267 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2489, R²: 0.0255

============================================================
🔄 Round 268 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 268 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0104
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0222
============================================================


📊 Round 268 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2489, R²: 0.0255

============================================================
🔄 Round 275 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 275 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=0.0094
   Val:   Loss=0.0777, RMSE=0.2787, R²=-0.0159
============================================================


📊 Round 275 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2489, R²: 0.0255

============================================================
🔄 Round 276 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 276 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0043
   Val:   Loss=0.0834, RMSE=0.2888, R²=0.0071
============================================================


📊 Round 276 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2489, R²: 0.0255

============================================================
🔄 Round 277 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 277 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=0.0085
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0144
============================================================


============================================================
🔄 Round 278 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 278 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0115
   Val:   Loss=0.0883, RMSE=0.2972, R²=-0.0204
============================================================


============================================================
🔄 Round 279 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 279 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0011
   Val:   Loss=0.0890, RMSE=0.2984, R²=0.0198
============================================================


============================================================
🔄 Round 280 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 280 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2892, R²=0.0046
   Val:   Loss=0.0857, RMSE=0.2928, R²=0.0073
============================================================


📊 Round 280 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2489, R²: 0.0255

📊 Round 280 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2489, R²: 0.0255

============================================================
🔄 Round 282 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 282 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0003
   Val:   Loss=0.0890, RMSE=0.2984, R²=0.0166
============================================================


📊 Round 282 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2489, R²: 0.0255

============================================================
🔄 Round 285 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 285 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0067
   Val:   Loss=0.0828, RMSE=0.2877, R²=0.0460
============================================================


📊 Round 285 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2489, R²: 0.0255

============================================================
🔄 Round 286 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 286 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=0.0035
   Val:   Loss=0.0742, RMSE=0.2723, R²=0.0074
============================================================


📊 Round 286 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2488, R²: 0.0255

📊 Round 286 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2489, R²: 0.0255

============================================================
🔄 Round 291 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 291 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=-0.0006
   Val:   Loss=0.0770, RMSE=0.2775, R²=0.0275
============================================================


📊 Round 291 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2489, R²: 0.0255

============================================================
🔄 Round 292 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 292 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=-0.0022
   Val:   Loss=0.0736, RMSE=0.2713, R²=0.0258
============================================================


📊 Round 292 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2489, R²: 0.0255

============================================================
🔄 Round 293 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 293 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0047
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0064
============================================================


📊 Round 293 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2489, R²: 0.0255

============================================================
🔄 Round 295 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 295 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0005
   Val:   Loss=0.0905, RMSE=0.3008, R²=0.0093
============================================================


📊 Round 295 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2489, R²: 0.0255

📊 Round 295 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2489, R²: 0.0255

============================================================
🔄 Round 298 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 298 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0039
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0091
============================================================


============================================================
🔄 Round 299 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 299 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0055
   Val:   Loss=0.0866, RMSE=0.2943, R²=0.0036
============================================================


📊 Round 299 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2489, R²: 0.0255

============================================================
🔄 Round 301 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 301 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0037
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0382
============================================================


============================================================
🔄 Round 302 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 302 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0039
   Val:   Loss=0.0863, RMSE=0.2938, R²=0.0104
============================================================


============================================================
🔄 Round 304 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 304 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0032
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0121
============================================================


📊 Round 304 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2489, R²: 0.0255

============================================================
🔄 Round 305 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 305 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=-0.0017
   Val:   Loss=0.0809, RMSE=0.2845, R²=0.0190
============================================================


📊 Round 305 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2489, R²: 0.0255

============================================================
🔄 Round 307 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 307 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=0.0113
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0200
============================================================


📊 Round 307 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2489, R²: 0.0255

============================================================
🔄 Round 309 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 309 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0031
   Val:   Loss=0.0835, RMSE=0.2890, R²=0.0074
============================================================


📊 Round 309 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2489, R²: 0.0255

============================================================
🔄 Round 312 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 312 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0097
   Val:   Loss=0.0849, RMSE=0.2915, R²=-0.0140
============================================================


📊 Round 312 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2489, R²: 0.0255

============================================================
🔄 Round 313 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 313 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0064
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0019
============================================================


============================================================
🔄 Round 314 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 314 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0083
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0075
============================================================


📊 Round 314 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2489, R²: 0.0255

📊 Round 314 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2489, R²: 0.0255

📊 Round 314 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2489, R²: 0.0255

============================================================
🔄 Round 321 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 321 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=0.0075
   Val:   Loss=0.0782, RMSE=0.2796, R²=-0.0053
============================================================


📊 Round 321 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2489, R²: 0.0255

📊 Round 321 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2489, R²: 0.0255

============================================================
🔄 Round 323 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 323 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2892, R²=0.0041
   Val:   Loss=0.0857, RMSE=0.2927, R²=0.0046
============================================================


============================================================
🔄 Round 324 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 324 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0078
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0058
============================================================


============================================================
🔄 Round 327 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 327 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0041
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0090
============================================================


📊 Round 327 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2489, R²: 0.0255

📊 Round 327 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2489, R²: 0.0255

📊 Round 327 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2489, R²: 0.0255

📊 Round 327 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2489, R²: 0.0255

============================================================
🔄 Round 338 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 338 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=0.0071
   Val:   Loss=0.0745, RMSE=0.2730, R²=-0.0074
============================================================


📊 Round 338 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2489, R²: 0.0256

📊 Round 338 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2489, R²: 0.0256

============================================================
🔄 Round 342 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 342 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0022
   Val:   Loss=0.0876, RMSE=0.2959, R²=0.0157
============================================================


============================================================
🔄 Round 344 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0940 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0940, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0940, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0940, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0940, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0940, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0940)

============================================================
📊 Round 344 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0039
   Val:   Loss=0.0940, RMSE=0.3066, R²=0.0083
============================================================


============================================================
🔄 Round 345 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 345 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0054
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0062
============================================================


📊 Round 345 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2489, R²: 0.0256

============================================================
🔄 Round 347 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 347 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0000
   Val:   Loss=0.0868, RMSE=0.2947, R²=0.0231
============================================================


============================================================
🔄 Round 348 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 348 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=0.0025
   Val:   Loss=0.0766, RMSE=0.2767, R²=-0.0020
============================================================


============================================================
🔄 Round 349 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 349 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0046
   Val:   Loss=0.0822, RMSE=0.2866, R²=-0.0238
============================================================


📊 Round 349 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2489, R²: 0.0256

📊 Round 349 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2489, R²: 0.0256

============================================================
🔄 Round 354 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 354 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0053
   Val:   Loss=0.0815, RMSE=0.2856, R²=0.0036
============================================================


============================================================
🔄 Round 355 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 355 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0063
   Val:   Loss=0.0869, RMSE=0.2948, R²=0.0022
============================================================


📊 Round 355 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2489, R²: 0.0256

============================================================
🔄 Round 358 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 358 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0119
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0401
============================================================


📊 Round 358 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2488, R²: 0.0257

============================================================
🔄 Round 362 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 362 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0052
   Val:   Loss=0.0847, RMSE=0.2910, R²=0.0051
============================================================


============================================================
🔄 Round 363 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0922, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0922, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0922, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 363 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0003
   Val:   Loss=0.0923, RMSE=0.3037, R²=0.0231
============================================================


============================================================
🔄 Round 365 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 365 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0024
   Val:   Loss=0.0797, RMSE=0.2824, R²=0.0114
============================================================


📊 Round 365 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2488, R²: 0.0257

============================================================
🔄 Round 366 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 366 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0092
   Val:   Loss=0.0823, RMSE=0.2868, R²=-0.0278
============================================================


📊 Round 366 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2488, R²: 0.0257

============================================================
🔄 Round 368 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 368 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0032
   Val:   Loss=0.0886, RMSE=0.2976, R²=-0.0216
============================================================


📊 Round 368 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2488, R²: 0.0257

📊 Round 368 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2489, R²: 0.0257

============================================================
🔄 Round 370 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 370 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0018
   Val:   Loss=0.0846, RMSE=0.2909, R²=0.0297
============================================================


============================================================
🔄 Round 372 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 372 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0082
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0059
============================================================


📊 Round 372 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2489, R²: 0.0257

📊 Round 372 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2489, R²: 0.0257

📊 Round 372 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2489, R²: 0.0257

============================================================
🔄 Round 378 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 378 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0012
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0214
============================================================


📊 Round 378 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2488, R²: 0.0257

============================================================
🔄 Round 381 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 381 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0103
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0251
============================================================


📊 Round 381 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2488, R²: 0.0257

============================================================
🔄 Round 384 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 384 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0140
   Val:   Loss=0.0904, RMSE=0.3006, R²=-0.0275
============================================================


📊 Round 384 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2488, R²: 0.0257

============================================================
🔄 Round 389 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 389 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=0.0049
   Val:   Loss=0.0883, RMSE=0.2972, R²=0.0080
============================================================


📊 Round 389 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2489, R²: 0.0257

============================================================
🔄 Round 392 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 392 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0009
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0317
============================================================


📊 Round 392 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2489, R²: 0.0257

============================================================
🔄 Round 398 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 398 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0035
   Val:   Loss=0.0889, RMSE=0.2982, R²=0.0072
============================================================


📊 Round 398 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2489, R²: 0.0257

============================================================
🔄 Round 399 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 399 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0001
   Val:   Loss=0.0770, RMSE=0.2775, R²=0.0235
============================================================


📊 Round 399 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2489, R²: 0.0257

📊 Round 399 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2489, R²: 0.0257

============================================================
🔄 Round 409 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 409 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=0.0024
   Val:   Loss=0.0811, RMSE=0.2847, R²=-0.0012
============================================================


============================================================
🔄 Round 410 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 410 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0089
   Val:   Loss=0.0781, RMSE=0.2796, R²=-0.0127
============================================================


📊 Round 410 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2489, R²: 0.0257

📊 Round 410 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2489, R²: 0.0257

📊 Round 410 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2489, R²: 0.0257

============================================================
🔄 Round 414 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 414 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0013
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0188
============================================================


📊 Round 414 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2489, R²: 0.0257

============================================================
🔄 Round 415 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 415 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=0.0013
   Val:   Loss=0.0733, RMSE=0.2708, R²=0.0245
============================================================


📊 Round 415 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2489, R²: 0.0257

📊 Round 415 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2489, R²: 0.0257

============================================================
🔄 Round 418 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 418 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0089
   Val:   Loss=0.0839, RMSE=0.2896, R²=-0.0089
============================================================


============================================================
🔄 Round 421 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 421 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0096
   Val:   Loss=0.0857, RMSE=0.2928, R²=-0.0102
============================================================


📊 Round 421 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2489, R²: 0.0257

============================================================
🔄 Round 422 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 422 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=0.0070
   Val:   Loss=0.0790, RMSE=0.2810, R²=-0.0206
============================================================


============================================================
🔄 Round 424 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 424 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0028
   Val:   Loss=0.0889, RMSE=0.2982, R²=0.0139
============================================================


📊 Round 424 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2489, R²: 0.0258

============================================================
🔄 Round 428 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 428 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0056
   Val:   Loss=0.0876, RMSE=0.2960, R²=0.0268
============================================================


📊 Round 428 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2489, R²: 0.0258

📊 Round 428 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2489, R²: 0.0258

============================================================
🔄 Round 430 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 430 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0014
   Val:   Loss=0.0886, RMSE=0.2976, R²=0.0314
============================================================


============================================================
🔄 Round 432 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 432 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0060
   Val:   Loss=0.0819, RMSE=0.2861, R²=0.0038
============================================================


📊 Round 432 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2489, R²: 0.0258

============================================================
🔄 Round 434 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 434 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0091
   Val:   Loss=0.0865, RMSE=0.2940, R²=-0.0120
============================================================


📊 Round 434 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2489, R²: 0.0258

============================================================
🔄 Round 436 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 436 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0019
   Val:   Loss=0.0911, RMSE=0.3018, R²=0.0098
============================================================


📊 Round 436 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2489, R²: 0.0258

============================================================
🔄 Round 438 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 438 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=0.0114
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0180
============================================================


📊 Round 438 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2489, R²: 0.0258

📊 Round 438 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2489, R²: 0.0258

📊 Round 438 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2489, R²: 0.0258

============================================================
🔄 Round 445 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 445 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0048
   Val:   Loss=0.0824, RMSE=0.2871, R²=0.0086
============================================================


============================================================
🔄 Round 446 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 446 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=0.0029
   Val:   Loss=0.0883, RMSE=0.2971, R²=0.0163
============================================================


============================================================
🔄 Round 447 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 447 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0038
   Val:   Loss=0.0856, RMSE=0.2926, R²=0.0121
============================================================


📊 Round 447 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2489, R²: 0.0258

📊 Round 447 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2489, R²: 0.0258

============================================================
🔄 Round 449 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 449 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=0.0071
   Val:   Loss=0.0733, RMSE=0.2708, R²=-0.0052
============================================================


📊 Round 449 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2489, R²: 0.0258

📊 Round 449 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2489, R²: 0.0258

============================================================
🔄 Round 454 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0964 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0964, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0964, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0964, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0964, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0964, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0964)

============================================================
📊 Round 454 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0030
   Val:   Loss=0.0964, RMSE=0.3106, R²=0.0131
============================================================


📊 Round 454 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2489, R²: 0.0258

============================================================
🔄 Round 455 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 455 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0090
   Val:   Loss=0.0749, RMSE=0.2737, R²=0.0682
============================================================


📊 Round 455 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2489, R²: 0.0258

============================================================
🔄 Round 457 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 457 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0041
   Val:   Loss=0.0865, RMSE=0.2940, R²=0.0102
============================================================


============================================================
🔄 Round 458 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 458 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0043
   Val:   Loss=0.0926, RMSE=0.3043, R²=0.0087
============================================================


============================================================
🔄 Round 459 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 459 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0041
   Val:   Loss=0.0847, RMSE=0.2910, R²=0.0114
============================================================


📊 Round 459 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2489, R²: 0.0258

📊 Round 459 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2489, R²: 0.0258

============================================================
🔄 Round 461 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 461 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0002
   Val:   Loss=0.0881, RMSE=0.2969, R²=0.0120
============================================================


============================================================
🔄 Round 462 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0719 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0719, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0719, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0719, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0719)

============================================================
📊 Round 462 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=0.0071
   Val:   Loss=0.0719, RMSE=0.2682, R²=-0.0012
============================================================


📊 Round 462 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2489, R²: 0.0258

📊 Round 462 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2489, R²: 0.0258

📊 Round 462 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2489, R²: 0.0258

============================================================
🔄 Round 469 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 469 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0059
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0043
============================================================


============================================================
🔄 Round 470 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 470 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0088
   Val:   Loss=0.0781, RMSE=0.2794, R²=-0.0078
============================================================


📊 Round 470 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2489, R²: 0.0259

============================================================
🔄 Round 471 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 471 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0023
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0184
============================================================


📊 Round 471 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2489, R²: 0.0259

============================================================
🔄 Round 473 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 473 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0077
   Val:   Loss=0.0872, RMSE=0.2952, R²=-0.0026
============================================================


============================================================
🔄 Round 476 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 476 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0032
   Val:   Loss=0.0840, RMSE=0.2899, R²=0.0084
============================================================


============================================================
🔄 Round 477 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 477 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=0.0075
   Val:   Loss=0.0779, RMSE=0.2791, R²=-0.0053
============================================================


============================================================
🔄 Round 480 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 480 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=0.0044
   Val:   Loss=0.0755, RMSE=0.2747, R²=0.0057
============================================================


📊 Round 480 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2489, R²: 0.0259

📊 Round 480 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2489, R²: 0.0259

📊 Round 480 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2489, R²: 0.0259

============================================================
🔄 Round 489 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 489 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0127
   Val:   Loss=0.0834, RMSE=0.2889, R²=-0.0242
============================================================


============================================================
🔄 Round 490 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 490 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0001
   Val:   Loss=0.0873, RMSE=0.2955, R²=0.0277
============================================================


📊 Round 490 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2489, R²: 0.0259

============================================================
🔄 Round 492 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 492 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0055
   Val:   Loss=0.0841, RMSE=0.2901, R²=-0.0020
============================================================


📊 Round 492 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2489, R²: 0.0259

============================================================
🔄 Round 494 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 494 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=0.0033
   Val:   Loss=0.0806, RMSE=0.2838, R²=0.0163
============================================================


📊 Round 494 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2489, R²: 0.0259

📊 Round 494 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2489, R²: 0.0259

============================================================
🔄 Round 498 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 498 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0017
   Val:   Loss=0.0863, RMSE=0.2939, R²=0.0211
============================================================


📊 Round 498 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2489, R²: 0.0259

============================================================
🔄 Round 499 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 499 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=0.0152
   Val:   Loss=0.0898, RMSE=0.2997, R²=-0.0406
============================================================


📊 Round 499 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2489, R²: 0.0259

============================================================
🔄 Round 501 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 501 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0014
   Val:   Loss=0.0897, RMSE=0.2995, R²=0.0131
============================================================


============================================================
🔄 Round 502 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 502 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0047
   Val:   Loss=0.0881, RMSE=0.2968, R²=0.0083
============================================================


📊 Round 502 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2489, R²: 0.0259

📊 Round 502 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2489, R²: 0.0259

============================================================
🔄 Round 506 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 506 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0024
   Val:   Loss=0.0840, RMSE=0.2898, R²=0.0378
============================================================


📊 Round 506 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2489, R²: 0.0260

============================================================
🔄 Round 508 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 508 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0018
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0159
============================================================


📊 Round 508 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2489, R²: 0.0260

📊 Round 508 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2489, R²: 0.0260

============================================================
🔄 Round 510 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 510 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0025
   Val:   Loss=0.0837, RMSE=0.2893, R²=0.0088
============================================================


📊 Round 510 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2489, R²: 0.0260

📊 Round 510 Test Metrics:
   Loss: 0.0822, RMSE: 0.2868, MAE: 0.2489, R²: 0.0260

============================================================
🔄 Round 517 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 517 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0017
   Val:   Loss=0.0871, RMSE=0.2951, R²=0.0217
============================================================


============================================================
🔄 Round 520 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 520 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0099
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0103
============================================================


============================================================
🔄 Round 522 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 522 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=0.0064
   Val:   Loss=0.0743, RMSE=0.2725, R²=-0.0083
============================================================


============================================================
🔄 Round 523 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 523 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0106
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0159
============================================================


============================================================
🔄 Round 525 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 525 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=0.0133
   Val:   Loss=0.0782, RMSE=0.2797, R²=-0.0272
============================================================


============================================================
🔄 Round 528 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 528 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0104
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0108
============================================================


📊 Round 528 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2489, R²: 0.0260

📊 Round 528 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2489, R²: 0.0260

📊 Round 528 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2489, R²: 0.0260

📊 Round 528 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2489, R²: 0.0260

============================================================
🔄 Round 532 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 532 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0016
   Val:   Loss=0.0818, RMSE=0.2861, R²=0.0209
============================================================


📊 Round 532 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2489, R²: 0.0260

============================================================
🔄 Round 533 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 533 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2927, R²=0.0021
   Val:   Loss=0.0773, RMSE=0.2781, R²=0.0134
============================================================


============================================================
🔄 Round 534 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 534 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=0.0108
   Val:   Loss=0.0733, RMSE=0.2708, R²=-0.0190
============================================================


📊 Round 534 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2489, R²: 0.0261

============================================================
🔄 Round 535 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0965 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0965, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0965, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0965, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0965, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0965, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0965)

============================================================
📊 Round 535 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2843, R²=0.0060
   Val:   Loss=0.0965, RMSE=0.3107, R²=0.0043
============================================================


============================================================
🔄 Round 538 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 538 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0066
   Val:   Loss=0.0840, RMSE=0.2897, R²=-0.0022
============================================================


📊 Round 538 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2488, R²: 0.0261

============================================================
🔄 Round 541 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 541 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2937, R²=0.0068
   Val:   Loss=0.0749, RMSE=0.2738, R²=-0.0106
============================================================


============================================================
🔄 Round 542 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 542 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0059
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0073
============================================================


============================================================
🔄 Round 543 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0929 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0929, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0929, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0929, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0929, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0929, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 543 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=0.0136
   Val:   Loss=0.0929, RMSE=0.3048, R²=-0.0215
============================================================


============================================================
🔄 Round 546 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 546 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0086
   Val:   Loss=0.0896, RMSE=0.2993, R²=-0.0086
============================================================


============================================================
🔄 Round 548 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 548 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0042
   Val:   Loss=0.0842, RMSE=0.2901, R²=0.0141
============================================================


============================================================
🔄 Round 549 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 549 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0083
   Val:   Loss=0.0758, RMSE=0.2753, R²=-0.0033
============================================================


📊 Round 549 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2488, R²: 0.0262

============================================================
🔄 Round 553 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 553 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0089
   Val:   Loss=0.0886, RMSE=0.2976, R²=-0.0051
============================================================


📊 Round 553 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2488, R²: 0.0262

============================================================
🔄 Round 556 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 556 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2935, R²=0.0074
   Val:   Loss=0.0752, RMSE=0.2742, R²=0.0009
============================================================


📊 Round 556 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2488, R²: 0.0262

============================================================
🔄 Round 557 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 557 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0098
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0136
============================================================


============================================================
🔄 Round 559 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 559 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0009
   Val:   Loss=0.0842, RMSE=0.2902, R²=0.0251
============================================================


📊 Round 559 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2488, R²: 0.0262

============================================================
🔄 Round 564 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 564 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0089
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0169
============================================================


📊 Round 564 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2488, R²: 0.0262

============================================================
🔄 Round 566 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 566 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=0.0115
   Val:   Loss=0.0764, RMSE=0.2763, R²=-0.0203
============================================================


============================================================
🔄 Round 568 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 568 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0095
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0145
============================================================


📊 Round 568 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2488, R²: 0.0262

📊 Round 568 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2488, R²: 0.0262

============================================================
🔄 Round 572 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 572 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0100
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0098
============================================================


📊 Round 572 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2488, R²: 0.0261

============================================================
🔄 Round 576 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 576 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0110
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0121
============================================================


❌ Client client_4 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8688 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 945, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8688 {grpc_status:14, grpc_message:"Socket closed"}"
>
