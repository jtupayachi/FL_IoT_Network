[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0db4ec58-642e-49a7-b0b3-a467f91871eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf190e92-2dfd-4bfb-817e-3ca55894c5bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7bdca93-1b80-49c9-ad2a-323f24b83910
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5fd61599-3286-4637-b204-4c787f676a03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2bf4768-d00d-4119-bbb4-2e42cb7347d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11d8da9f-e91f-4d49-88e9-6460827528ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53933479-dab2-4f49-af4b-12c8bb5c3026
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c4a1007-a55e-4a1f-ab69-cb3da40c391e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0795442-8612-4de8-8738-d61799be6f1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66c0f473-2204-49c4-a751-1a69c8edec9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ec8591e-d137-4878-9db2-e4a4b7d25a46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aaa84481-2fb8-4de0-8ba8-0dec516ea248
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23021279-e035-4790-8149-887afa6b7fe1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cdc7d9ab-fcdd-4fca-955a-8c18349986bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a74ca977-6904-4d96-abcc-695c9f0f4673
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b77539a-555b-4d4c-b356-d579acf4e5f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a31f0c0-9a39-4172-979d-2ff7667a13be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6208fbca-b7de-4bfa-adcd-3b287fc39726
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d14a0164-49b3-4615-ba9c-1aee40f2d3d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab5594a7-064b-4472-b2ab-1b3d0fd5ba75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72f84a8f-6e19-476f-abc2-dab7eb11dcf4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e411c059-903e-43d6-ae88-fb8489d2cd2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c4c962a-7c5a-45b7-91d7-96f5b90ee7aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9be245a6-caf2-4e55-85c7-74a1755caa45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89bc979a-a91e-4845-a9af-1220eaa0689b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ec89d43-37ce-498a-9279-f307059210b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53bc3ccd-eb3e-4dd5-86ae-722f88a7a1b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db377808-f3f7-487e-bfd9-d93676ecf782
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f9e916a-530f-44a5-8d15-d06f1ff55c26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43ce11a3-9488-46db-abd2-177e07a53cc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef4138dd-7d74-45f3-bbed-869c97a9cc17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20b49013-ba2a-481d-baaf-079258d1da89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f883b88-6a91-4e6f-af1d-bd8cf69749a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c521b461-66c0-4384-94ce-f688b3ad1e31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d7c173e-d129-4925-b5cc-26a4303b3440
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca21fc60-c7b2-4d98-8d1d-3817fbb77e51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f01aef77-deef-49f3-8767-5d23d8dd120c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df313b62-01df-4d26-b981-d1fefe77b593
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f98eefad-84a1-4718-8eea-da3fb92b9dbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46881f41-13bc-41e2-9e1a-4211f3507e8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9bc9c3be-44fb-4ce7-a0fb-0824aba6cec0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9001fb6f-84e6-49b8-b782-d16ec70fb0ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f2bf4dd-74e4-43a3-aa5c-d114cc14d9e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 504578f1-0afb-46f5-a099-18e1376b2105
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 830c2c9f-ae4a-4cb9-8feb-0a099521bf2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e90fb2b-50c1-4bff-b12b-4b7bc75a1d8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0eaeff74-9cf6-4d85-9fd2-d09fe5427761
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35a75851-478d-4301-a811-597bf8c824df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70948ed7-cd80-43f8-b6d0-9f20eb6d6a81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14476683-d36d-4bf0-961f-2df46504dfd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6edb8c3-aff5-48f9-bf2d-49545c6b193c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c3fe0e3-94b5-4a39-b779-65c1857b5cd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01553cbf-58fb-4df0-83e3-e0e046fa1944
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce975d68-2110-4b91-b211-ea89dc0d8a1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1eac661-943d-41b9-a51c-382c38ec6997
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 066d9e23-5fcd-497b-a60b-fe3c5f40becd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2db635f-4cef-4deb-b990-83ba39e1e2a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ad176b2-ac56-40d2-8c0c-784a07ddd753
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f21a313-5154-4b68-a3c4-a5a997493a7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 039b2c8a-acf4-43b8-ad4f-a6f946b83c16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea7b5da9-1182-4aa1-9227-d77a06674b91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e9469f0-d194-408a-9a35-3ead7e6e4912
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0efc505e-4621-4f29-a3c7-eec441006cdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a295a8e-4ce7-40ab-92d4-6d317db3b732
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70fb3bc1-6a0d-4517-bf07-102cdb61c26d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81cf58d9-2b25-42b5-8ec0-18c8fab3bd9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b18fb84b-e6e4-40ab-8a06-969092ac1a04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df7a6422-52b4-4a54-acb9-9f82573917ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1824ae81-6e27-4821-a518-d6778b822282
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9aeacc8c-95ad-490a-9e4f-84d7878df69c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a55fa92-3b8a-4e28-b4d4-1c2d2a28f7bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d855137-fda2-4f35-ad93-b4a0cc2c47b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b07593bf-4d9e-4931-8805-16e816ec5fa2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1b93ce8-b6d3-4066-9067-04ed1fc142b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44d42245-c465-42a4-a0f6-ef9bcd67f3cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 681a18d2-54b7-407a-b28f-9cea2ed9d2ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b64f7315-8899-4565-b409-8c774e44a7ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7819d306-235c-4cdc-9881-cec7b40e996a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c31d9f5d-2e91-4d4d-92cc-a73449ef9d0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64644e89-7450-4d56-9209-f575131ddac8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce79540f-7dd6-49fa-90f9-30c49943e484
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef0a250c-73e1-45bb-9dc1-5ac4ec5a54a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f729b6f-84db-42ae-89cd-d0f402d2acd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a258216e-3a24-4a32-98e9-8e8d0f5eb41b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d82fc65-d0b2-4028-beca-7a72b1598c12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c65bf2e-1af5-4b2a-9d28-8500bfe35a97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cdd12a92-8918-4088-9022-11b7b2d42f9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 309cadd2-9e2f-4075-8814-7ef8a688db50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31f7f459-61ef-49ef-aa30-b77458af079a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87f29720-495a-4c67-8668-3a448733dbc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f5cdde4-6d01-457b-bfa6-40b5ac7c2d7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b6a9282-cb7e-419b-8bf1-aa4f63ac0870
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c80c562-63bb-4f58-be34-f63f2b781173
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95c03275-a55d-4082-bc50-38574cd469db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7b911aa-7e57-48c1-a991-9f1a8918c417
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6bdce373-56da-40c1-b591-0cff5be42f3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 738bdf4d-bdfb-485f-bcf6-0346a21abc55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae89d184-6983-431e-8176-6b9ca1dc6a70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6bb4dd64-d970-44de-9091-089124f64699
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb59cf3b-010f-4f4c-bc7d-8ebb83dd8fb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message effb4682-bf5d-45b2-b427-e5dbaee2de9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 468ced91-6d50-4719-9a6c-fd5c75c6575b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d87ad95-0d37-421d-8d15-ee19011977fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 831306c9-2753-4857-8cb4-e62d44365c0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86d7c949-37f4-4d4f-8890-3e8072138444
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75b9a15a-0daa-4a1e-a9c8-4bb4fa7eaffb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2852f178-5164-4eeb-bf6b-3440fa23fc94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b737a3d-816a-47d3-9952-79cec4dcefe2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3fc51974-f596-4fb9-b867-a5c28133ff34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message adb1ab7c-79f4-42f5-9bf4-b3b4347e1355
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44ac7aab-178a-481f-8db1-ae9ff815055d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f00b9f8c-0a47-4028-ad34-fcee4226d44a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf44a0be-cd92-4018-840b-f0b28a5a338d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21630df7-8b44-4077-8d20-7922ffb9ffd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c47b802c-ccfc-46aa-988f-626a2fbf0a13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7fa273b7-1347-49a9-a488-c4403f57fdfc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be9d199e-32c0-4da7-864a-bcd1217a2718
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b0dda7d-1ab0-4c66-8f7c-2a2500504d1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0bdb46e9-f625-40e8-8f3b-93333c4a3d2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5beeb98-27c1-4955-b55b-cd83e5608180
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7a9e955-6f62-4179-8b5a-c2fc1c8b47ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bbdd76ca-9147-4812-aab9-1bc77398d83f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec224668-a00f-40e5-80be-d5ff73e0986c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe1b8abc-999a-4210-96da-f9bf66acf20e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf913e5d-6a24-4e45-b54b-d5f4d4be0d92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a73e0e43-af2d-4298-b9a9-980fe3762de4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3671b2b0-b5ee-40fe-aa4f-5aa87b44cb9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8ae8fd3-1df6-45fa-b654-505eb3899a94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff702dfd-c79c-4126-a84f-7992561634d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a58af58-308d-4405-bd93-b6c1fd693b3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 773f8fc9-71c4-418b-946e-bb36d2fd269a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf95a57f-acbe-4e00-9578-416cfc468c9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01711839-5b9d-40e4-b9a8-87288ebb1717
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d427442f-a614-453f-98a2-4c63b16b4fd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b14ef14-1f4b-4f29-9c94-52534956bd54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3286ec67-89fa-4f36-ac5f-e115348c79b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a369a487-e1fe-4a6b-977a-bc7cc8399a1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d6dec17-ae41-45ff-8c69-0422b00a6138
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4793abf-10e2-4668-9f21-29920416f75d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b976867f-b3ff-4f4c-aa79-a2587be49648
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58482629-b168-4556-b396-864b1df5d436
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03adb77e-2561-463b-a971-f69ef8e5f125
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4ac3a6a-494b-484b-a61d-de3c8df12106
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5f629da-a734-4746-87a5-e9de67edc75c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1a720a6-241a-42a8-a3fd-9cc391e3d3ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f00df4ff-4599-4b6d-a59d-891f06171713
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 268b6bb6-d9c2-408d-b566-44691377e851
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f17131d9-bbeb-48e7-85e8-c5a12e180900
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1c5a126-1f02-4d8a-b1d4-bd925bfbfb6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc9453b1-d356-4901-b6a3-38dedb648f4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f913994f-e801-42be-a757-6f4e9bebd305
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1920fec-25a7-4564-8dd9-53ce1784c313
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b4820e5-ef27-4ff6-9f71-0d5c7ab6ade6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 140938ee-4551-4c40-8fe8-a4fb244a4ef2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4972458a-5638-4b29-969e-46b6f1f0e0c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d28d88ef-6001-41c9-8e94-935d6dfca100
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6aa14c7d-d5ce-4a6c-9799-14cc4ccbbfb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2fc1e74c-5a2a-48f0-8817-c36cfadaed38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 196b5fa1-d321-4cf4-8120-d865c690a440
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b888acff-5ae8-4393-beb0-ca4d9b960b5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20294f92-a94c-4ab9-b678-9304b9190811
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3ea07e1-b334-4f5f-810e-e487d000fab1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2cbcfe9-43d8-4c44-96f5-69c8b9fa88aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1f20035-f4c9-4d20-915a-bb3d692b5dee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 399b265c-bf81-4d9c-a2b1-72bcc93adabe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eae7bc5d-7138-467c-bc3d-c91f6943e847
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6dfb1b9-d942-444b-8538-dfd1f2faca4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 588c35eb-ee44-45fa-be6f-08d3450e48d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c9892f3-f116-4558-b9b4-e5ac618b25a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78581a0d-d9bc-4648-b4ae-80f66b8b6466
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2edff637-7a5c-42a1-b5aa-dc6a05fa4243
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c845e98f-3a02-4343-a721-dcb746339c37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 479a1f5f-564c-41dd-aa4c-4b539989ac68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76b0b51c-d85f-43d1-bc18-0875b8f22374
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66054ebd-47c8-44f6-90f2-72580744a22a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1644bb25-9a03-4113-b536-7fcfa48266e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff20cd9e-5678-4587-b391-4351af6f0d9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6538928-3e08-41de-9b42-abb3e2fdf5d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c90ca71-7b9a-4af1-b0e9-bbf7333fdf06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 717a59d0-b47b-4b75-8550-bd0f785da9c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2d25356-559d-4d2f-b13b-51d038c088fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8dc2799-71fa-4704-8edb-6352b94988e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 666e40ae-fd9b-4669-96b9-ceede162186b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd6cee31-5230-44b0-b6e3-7a5035616fe7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 324f6b25-b559-4a6f-87f9-42a0bacc9139
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65bdb5eb-3302-4f47-b4b8-e3cf014697e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63cfa743-d85b-4a05-9205-0aeadee3c8ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f656e9ac-85dc-44dd-9ea4-3a6aff757a7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 208bbb2a-81ca-4057-bc7b-ef82e9f7ce31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7fe17b0-46ae-4ad2-9a13-a6f3ca742538
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc8984e4-661c-44cb-8519-d34af3f552ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7eacc10-3762-4a53-b136-3ad6d2bd5b63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc3612ca-221e-4fb2-95e3-7f6fada7eaf8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb78f4c6-1c35-4d4b-ac34-3683bd83e41d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4537d425-3f6c-4bb2-8504-bf2e447d663f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28bb0725-1fc5-499d-9ee2-a8e0e68d67f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf704c3d-b0af-4245-a9f4-db70bc3db2fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7a5d7e1-8b0a-4b9b-ae2e-ef33d2abf5a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 185c4e43-e031-4b3c-bff2-d5f69282ab98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07f3fa73-f780-4f88-80ea-01714a21f828
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 658f7774-55da-4aeb-8e9b-8d6fdd6add7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b72cb96-9f95-49ac-899d-b126a40c6001
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d8e44f1-5e9a-4904-93bc-ea187bae912a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6126681c-bb2d-4f94-a352-053858123f95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55a16ae6-1582-4037-a10a-564f63eaad62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b94dfaae-07d8-49bb-97b8-2246685a3249
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8f5939e-0e21-43ab-9eb9-68e6d94e3500
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec9296b7-bf86-445a-a202-2c491412c077
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c672b2b-8a69-45eb-879f-39da938c2899
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 812f74b2-cfff-443c-a554-cb3648a39624
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f91babf5-5ac4-437c-92b4-f5be28335785
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df75e9c9-ed14-4d56-ad54-23f06afd130c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 922f47a7-850a-4061-9c72-078496d83cc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39661733-1859-4652-92da-219f715e175e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb123d7b-ebd4-4738-897c-e39f4d44385e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51263568-8205-4a01-9945-a1e49df28b86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71675236-e753-4190-9b87-89cfd7d156ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36d8c9b3-b740-4dda-8c42-76200fd8970e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd1d552c-9425-4512-8339-57c911fa8eb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea1bc488-674c-4750-ae4b-ba566f5a99d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 633c6e4a-9335-4a5c-8a7c-0957dcd67165
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8032500c-1ab1-4d34-8c9a-201fec75cd6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message badfe4b0-6292-47b8-a77d-434cc3bab16c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ff2caee-76fd-4390-975e-259b15cda67c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a3b09bf-8fa9-4cbb-8492-1eb990266221
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae869b4a-2af3-41a8-84e3-519cb3d19d0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9120fd4b-2f3f-4be0-a15d-649fc89a0075
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62121fde-7b3f-4ba2-812c-d8d1f9cd2c68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7802353-f449-4316-b982-bbfb5ef8332b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 578ab7ce-4b77-4946-b953-743558a8df08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6bb6203-3be8-4382-b41d-64e77301a253
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8a3a78e-8fcb-4711-8ac7-183240c71731
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7413e6d-552d-44ba-8944-f554a3a73b29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3dead66c-1a47-4738-8da8-a7012b09f133
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce5724a6-8560-4206-b282-578aa05e1e15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9417d560-53c0-433b-8fb6-fbfcadc355bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message baafbe20-b0e8-4f98-8887-2c9cf46d6f54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dff1d7db-bb0f-4d7a-bc38-4701c7151cae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd111d8b-b960-4238-b1cd-addcf58ec609
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b919589-93ae-45fc-88ec-563cde53e59a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ebd5289-20d2-4ccb-b55d-e169148a9fff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a006b4bd-9787-4e2f-8b44-b0e1936336b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0881490-adaa-4c9a-b3e6-f8f0547ccfe6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d7d934f-2418-4ff9-8da2-527bfb871782
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4d43907-25e7-4d59-92aa-f7a3f222c137
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d334d14-cda9-4702-a9ee-5d745bbf8010
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52612dab-f2b5-45a3-b118-27177078bbc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e517c99f-6bd4-42c9-85f6-e37eac635fd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b2d21fe-5625-4eb0-b204-8d1e45e23f06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e71ea1a-e7f1-4c50-a414-92d600d281d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b2c6d63-1333-4399-b528-8fb0e8994baf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6186ece-d152-4c37-893d-9616d157e7ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bfd74af7-236b-4742-b8bb-a4f8bf08b19c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f09c182-9cd5-46c3-87a3-0d5a7279026f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1fb39c2c-4d28-42a9-8dd5-18dc24eedc6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12f2d2ae-4882-4c63-a356-28d0b932a07e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c07c1308-9311-4fe3-8d26-615b187dfcb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 267f1148-54c0-4edb-97f3-d8ea46c49978
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c624da5-0c2d-49e7-959d-94bf5ccd42e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fff7f2f2-f2b1-4006-8fd5-16cd2a9f2c8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab573288-419f-4813-bfc8-829635b704fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 991694eb-9f23-4fdb-9cde-33d50b2ed8b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e5e42b7-d169-42b8-9f02-dd97e35eccb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e182ddc-1562-4b1b-a1ed-782254ee5337
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79884337-7f55-412d-8f9a-9a01f043c52b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f927325-82cd-4c76-99e8-48c10ffea903
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f11adebc-db54-465d-b0a3-3223c392c326
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 613a99b2-77be-44bb-9115-b3edd1c83681
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 334a4089-f846-4e51-80d6-578a6630d987
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3ed5324-029c-4b9f-977f-c88f68b5a4ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d441c2e-0081-4e40-9b6d-53fd36984ebc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c4bf58b-562f-4636-91d1-5d72bb37a5d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb5b9e17-4211-46e8-b89b-ac40ec4f4472
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3af7a018-1a09-4ab5-b29e-02a57d682a16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b46aa33-758e-495b-881e-d4b003426e29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2488e7c5-f599-44c2-8fb3-c5aa1e705eb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c3447d4-5ecc-45ae-9e07-31eb4771458f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d1bc90b-578d-4757-8445-049e79c284d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7eb647e7-e04e-4948-a120-e7a68fe251a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8fae824d-2da6-4dc3-8d5b-5373217f453c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72e461d1-2cd6-4bce-b85b-a401f0740775
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d30edb4d-62e3-4620-9328-8ba1e5ac8fbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7afe0285-e5af-4ec9-b5ba-1bc34385f753
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ef3c19e-aca1-46ce-a8c6-45fa6026d673
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7519b4a5-6ed3-4a3b-8ef0-2d3664427e84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message add85203-d130-4f1c-bfd3-9336fd1cc6cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cfc15cf0-ac51-4b5b-a285-5231124348cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ea38835-d049-43e9-9390-ccaacccc808b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fec9c91e-3d3e-41dd-9128-f7765cf1607a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b42ca8b4-66a4-422a-a827-9b26f2f7f6e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2422a191-427b-4b68-a50d-74b0d38d3d08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b6e10cb-9cc1-495b-aca0-155a1de23819
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2adb93d-c3c6-4453-8bdc-64bd4ae4ec90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f74bbfc-5224-4ed6-ba7b-36a4a2912b74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1be94536-38ad-45ce-9600-21a63698de82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d793e343-456b-40bf-be3e-44700a423ee8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aac63ff8-d607-47da-b593-5f6d2ad6c89b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4b8604c-a3fb-4c65-83df-e8b62b3f3a99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79e90dac-def8-4b53-bc17-1027dbdcb2de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9879603e-2eaa-4a52-835f-e684ef4d1abc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81eab41e-4c38-40f3-89cc-bf8065551fa2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2496ce23-7da0-41f8-aa93-ccdee0a3bd0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb66f6f7-5719-4224-90da-5e73c16f431a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c399001c-461d-46ac-9eff-704383efd6d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e367f9f-45a6-4b3f-b9a0-adb567a0a6ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f21f620-4b6a-4bb8-8297-3da8cf52e9e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a5eb9f1-8fbd-4c4a-8381-50c215409c54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e22863a2-54ac-40ad-9f14-23c2804df33a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca121869-dc68-4aaf-9760-b19d125805f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac5881b4-9181-4ca2-ada4-0be2751cbe6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00c77ced-419c-4bff-8bb7-3c6986e18c42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63334f9d-91fd-456a-84a8-f90f95ef5bed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02877502-13a1-46e9-844a-3ce502c24b62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bafb69f4-b50e-405c-b1d4-4eb948724bf6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aabe8908-3529-49d9-80aa-18729854f924
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b4c38e9-c689-4095-9a81-00caf071db29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e13c300-95f6-4fb8-b38f-3ec84efc605a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d78ba022-6a76-47c7-a5c0-16a664243bba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dfd49d7b-c735-4a10-8b3b-b7c7bbd0a107
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4555b31d-4377-49d5-941b-241889bec6da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c661c387-bdec-42a7-ab32-01489cf195d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98bd8e59-ac58-48ea-93d2-df2022895052
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5c9a5ac-9990-40ea-a8a5-527404434c0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fdaf92f3-84ab-4cc6-a532-555963a7d06b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95f1c57d-5771-443c-a435-c52ae82518f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eef66588-6bf7-4166-9af4-556f24d87189
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d707833f-6a43-40bb-bf09-10ba40792a26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3140820e-0bab-41d1-8cc7-75e676560e5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 234b3c78-b37d-4bad-8398-c076fa1be4b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ef1c46b-ce38-4db4-8e39-34b8de29b6ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16e1fb47-2cfd-41c6-92d7-500e7a357271
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16517141-f8fe-44e0-b0bb-d27eabbed738
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 975717fa-e507-4a60-8f37-1179cf35f016
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6ba08c8-b346-46cc-b4e5-de58a0dc5050
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfcd92dd-2c9c-4e96-ab33-2a954c32bb40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2ac1eb7-0d94-477d-996c-6b8f89bd412e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d6bef8e-18cd-4194-8a0f-a490857273af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9dd7eb88-43d5-4c2e-a336-d80921720afd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bbb65a38-da17-42c0-a91e-98dcb0b717d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75a83d4d-791f-45b8-af0f-f7d7ff38db44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 653dba5c-d191-497d-a13f-c03c7c440982
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76a2283a-410d-417f-b15c-35f390ae3118
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d259aede-c613-4ec0-9799-ef429af1edf8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c666edc-1618-4218-8b99-f0ceccd55a91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ade6b3d3-1f9c-44ff-bf3a-124cb71886f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e34aae5-687d-4cde-9f83-ca5fecda04aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b72d79a5-acd1-4ac7-a483-ce47addcab4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0103a8b8-92e7-4d17-8f14-7ad09470994a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c3027df-0c99-45eb-be24-4cea030ba2e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e70f643-ca4b-438b-a5e7-3ed2b78e58b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 146469f0-591d-43ac-9aa9-af2f39f6175f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc489109-72b8-4974-93f9-275fb4530276
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b34332e9-fdce-4197-8496-57b6f65123da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5326e1c-2183-4c33-98fd-5f6b89d31301
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ed43133-53aa-45f1-81c5-ef87dd2960d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb095d02-ef3a-4672-bd0d-71e6bf31aa1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96f4acec-c6d8-40ec-b158-7298aa94773d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8634a24d-b4a8-4994-bacb-9bac2c96339e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8277c215-00e5-485d-9f2a-22f832414708
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67757c36-b119-4b8a-9273-3081f0125237
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9557816d-5949-4633-9fda-4ec13427351b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d4cf824-a705-483b-96d6-e7663a31c1d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d8c5c02-331a-4640-8460-e838690e49e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a0fe7de-941f-490b-83c3-a76b0e79389b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5536f05-def4-4064-936b-b2fcd0450bec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7bdf1df-6c5d-464e-bc58-837d104675c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84f80cb6-3a61-4a1b-ac2c-879c1bfbfca9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e26b96d0-684a-4c0f-9fe7-07e2d8401b48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 813764c1-6003-4424-9100-851e04c36f87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db4804d5-3c72-4197-a01e-e00c5113aa11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 023b1327-8c89-4e6d-8929-a073dc117c11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 084e6c11-845a-4e2b-b8d7-f7db62962e32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7ac8c14-3023-4eea-99f1-d57a05214b27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 185fbec7-703c-4a55-ab31-d75a13d38680
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b76e9207-ec8f-482e-ac07-1c13ea279034
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 636b8584-44af-40a5-a5c0-83aefb5fcd68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f9697b0-9c1c-47c9-8a81-7aa745896830
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8532b35-4bc5-475d-9f55-2ddae6e97a3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79d80d37-1e32-442d-8596-c0bc1fedfb1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00e15170-66d5-4c54-b609-d2c2e3689eea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3bd7b00-7ce5-4825-83d0-9dd2a28797b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 567e8a8a-4647-4fcb-811e-40a54d41f53a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da6afcae-8fa4-48d7-b0a8-f07822e9fd5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c9ffaab-2db0-481f-8fad-3160af53b091
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2122bc4-33a2-4682-b732-cdd0f2b64561
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88f05ae0-171a-4506-af05-7e95d737e330
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20fe37d2-aa05-4eff-a2be-63c1fdb46f8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be1e908c-6d7f-411f-af77-452206adccdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9379888c-75c6-4c49-8c7c-5e5c917c9637
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dac06eb8-d749-40ed-baf6-013345479462
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f819cb6-0def-4980-a5b7-f15c7589adb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5cd03407-9f75-47e2-8340-cc0966330db6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa9ac40d-7bcd-4812-b8ce-1074a0a1f699
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 604663ea-f0ae-40cc-a110-cce44f7e8379
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fcd6d5d3-0850-4f08-9563-9b6208b662b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 488fee50-0541-463f-8fec-372a9840e9fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29280540-4167-4684-b6dc-4cbbee2e7fd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6923fa5-a266-4c10-8c0f-8367d79b4c2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a34c4c5-5bf5-41e9-9f2e-3f39624492ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a881924-8f2e-4494-99fa-e9b339fd75c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21fc0a6d-e5e0-4878-bafb-2dcb5d4cd9bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 338fa1e7-15a7-4517-80e2-07195b5b021a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a43e9e22-f03c-46b1-978e-b69b9a2d95c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c00c35bb-a227-42a0-ab93-5ba8b3e55853
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1b75d16-5113-4e64-b0f8-1a989ee12f9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ecabb270-4b64-4748-9984-98ee3c9a8a4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b61163d6-4dc0-4da2-9cc2-8bafb8b29587
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5993874a-56b8-41ea-b55c-95394db9090d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68f7377d-c43a-4aa9-a1ca-0c2d4d686b74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7fe2080-4ede-434b-8806-3c8dc0a1be47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7caa36ec-ddf8-42c9-a10b-abcc9e9d400b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e949e6a-6376-469e-9c8f-dd421a644d36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6c51246-8aef-4aed-80f1-c09f0d0f3a3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 892dcfaf-ca55-459d-96c0-facaebaf7bed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf0fa130-77ce-4cd0-99e9-88ce857a1ae9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2a62a7d-d347-4cba-a460-8ac7ac05fcce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74771249-27e9-4fcb-95a9-d78700fdc6e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41379ced-e05a-4582-a10e-93f133c21f11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6bbaa588-5061-4ddb-a828-7bb7fcb55385
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de772f35-1579-4dea-b1cb-cb81894e1fcd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ae0b776-bb54-4bd1-bf0e-0e5d651aef88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2577ed6-6382-4954-9f03-caf36416bc4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aba5f560-8c4a-4a10-a817-555d3cc8a72f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae55da21-0f3d-4357-84d8-374d61a97ec9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec7e184b-7466-44ae-bce9-72a087846257
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03ed31f2-aeea-4673-a1c9-d3e509d0cefe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87381244-30cc-45a8-ac71-6b27e4ffbe4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d0987c8-6b2a-4c77-83b4-699a2025f275
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc1430db-20f3-48c2-b640-9bcbd9658165
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5860ec4-adf0-44df-9677-b1a6381b9f6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b680ddb3-924c-4dc3-8785-24c1f07e99c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 457d7215-91a7-4629-bd9d-c8daac0ae4f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c97b2487-e8f0-4ce9-9eea-639ee5a5d299
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73556c5c-41eb-4f76-a567-431e63defd92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a8d8315-63b0-4bea-a564-711fd9fc6f37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91fb9d5d-ebdf-471c-8eaf-99a2e014f6c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1fcfcd26-6ca5-4bbb-a522-0a79c0ae0d47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d38d91e-0b25-4f10-aadc-771a2e96bef8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c643279-ab31-4410-b70b-f5968c6a1b36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d77a57d9-02d9-4de5-bb77-1a2d9d27a107
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc7516e6-5b22-48f1-9c4c-81f0b7eea7a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9aab6b3e-bf49-4a27-b2f8-5acb9a13d652
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cec65060-7661-4fee-8711-42ec748eb430
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1fcc1d2-f9a4-4aeb-8376-be8bb50ce668
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c70e427-43d2-4351-9ba0-eb1bc22c1abb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c4f4173-9371-4fe5-aa7c-fb65be85094c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38bec8fe-bbb7-4d67-9521-5573c4ddb347
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52020d55-4dd7-4308-ad2b-777a9a2bc8fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8831ef5-1037-4446-b078-f327a4a378f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66451b0a-6dc0-48e4-bee1-9dbbd138fa9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a985ce90-c26b-4567-a091-dea842c36b21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57cc201d-97e5-44e8-95c4-5c266fe47b2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab9b728d-bea6-4ad5-911f-b1abab98f392
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df1fff5c-f967-40b9-9e89-50eb68da3760
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d58225e0-77b4-4780-8dd8-83dfef726e18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7badfbca-b8ad-429a-92b5-95fd456255ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4dffe707-1427-4191-a053-762ecbde020f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03cd6f02-5f59-48af-a708-5a542c92125e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41ac6f50-9fd8-4bfc-bb16-f43b40e6dfb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79e26e3a-21de-49e7-bd89-b16ddd8eb7d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 615126b3-91de-4a8a-8ce2-94c6f2bcffcd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea32d29e-5660-4639-9740-e91dbc958f12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d872602b-7298-46e9-8a8a-ce186fbde1af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac2fc738-0b0d-4f96-9265-00d1a2a9f7c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa27cf1c-93a9-486c-8cbf-3216b565c471
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed948219-1e7b-4920-b93e-a100117329d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0a3ccd5-dcc0-46cb-99a2-c75648af8452
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4774cc33-3e9f-4ef7-85c9-43ac16560438
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 154d51ec-eedf-4256-8fb8-46f115d3cb9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87324bfe-ec21-42b2-a974-8177a3596355
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a9c9065-0674-40a1-8151-766a2b390ea2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5590a77-43ac-4f53-8f3d-5d4d8cc8eb9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dde3bcb4-057e-42b6-be82-fcdf3760f74f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa5409c5-1cc9-43bc-ad65-c03808d20466
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8688 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_5
Server: localhost:8688
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_5
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_5/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_5/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_5/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_5/test_labels.txt

📊 Raw data loaded:
   Train: X=(5354, 24), y=(5354,)
   Test:  X=(1339, 24), y=(1339,)

⚠️  Limiting training data: 5354 → 800 samples
⚠️  Limiting test data: 1339 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_5 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0909, RMSE: 0.3014, MAE: 0.2609, R²: -0.0086

============================================================
🔄 Round 3 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1447, val=0.0937 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0850, val=0.0801 (↓), lr=0.001000
   ✓ Epoch   3/100: train=0.0826, val=0.0791 (↓), lr=0.001000
   • Epoch   4/100: train=0.0818, val=0.0790, patience=1/15, lr=0.001000
   • Epoch   5/100: train=0.0819, val=0.0790, patience=2/15, lr=0.001000
   📉 Epoch 10: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0812, val=0.0791, patience=8/15, lr=0.000500
   📉 Epoch 18: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 3 Summary - Client client_5
   Epochs: 18/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0005
   Val:   Loss=0.0791, RMSE=0.2812, R²=0.0046
============================================================


📊 Round 3 Test Metrics:
   Loss: 0.0925, RMSE: 0.3042, MAE: 0.2650, R²: -0.0270

📊 Round 3 Test Metrics:
   Loss: 0.0967, RMSE: 0.3110, MAE: 0.2697, R²: -0.0732

============================================================
🔄 Round 9 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0736 (↓), lr=0.000250
   • Epoch   2/100: train=0.0834, val=0.0739, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0829, val=0.0739, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0826, val=0.0740, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0824, val=0.0741, patience=4/15, lr=0.000250
   📉 Epoch 8: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0815, val=0.0748, patience=10/15, lr=0.000125
   📉 Epoch 16: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 9 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0008
   Val:   Loss=0.0736, RMSE=0.2713, R²=-0.0035
============================================================


============================================================
🔄 Round 12 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0890 (↓), lr=0.000063
   • Epoch   2/100: train=0.0804, val=0.0890, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0799, val=0.0892, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0797, val=0.0894, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0796, val=0.0895, patience=4/15, lr=0.000063
   📉 Epoch 8: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0793, val=0.0896, patience=10/15, lr=0.000031
   📉 Epoch 16: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 12 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0255
   Val:   Loss=0.0890, RMSE=0.2984, R²=0.0162
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.0944, RMSE: 0.3072, MAE: 0.2638, R²: -0.0476

📊 Round 12 Test Metrics:
   Loss: 0.0917, RMSE: 0.3029, MAE: 0.2617, R²: -0.0181

============================================================
🔄 Round 15 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0804 (↓), lr=0.000016
   • Epoch   2/100: train=0.0832, val=0.0802, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0831, val=0.0801, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0830, val=0.0800, patience=3/15, lr=0.000016
   ✓ Epoch   5/100: train=0.0829, val=0.0799 (↓), lr=0.000016
   📉 Epoch 8: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0827, val=0.0796, patience=6/15, lr=0.000008
   📉 Epoch 16: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 15 Summary - Client client_5
   Epochs: 20/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0066
   Val:   Loss=0.0799, RMSE=0.2826, R²=-0.0196
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.0913, RMSE: 0.3022, MAE: 0.2617, R²: -0.0135

📊 Round 15 Test Metrics:
   Loss: 0.0914, RMSE: 0.3023, MAE: 0.2624, R²: -0.0144

============================================================
🔄 Round 18 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0828 (↓), lr=0.000004
   • Epoch   2/100: train=0.0821, val=0.0828, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0820, val=0.0828, patience=2/15, lr=0.000004
   📉 Epoch 4: LR reduced 0.000004 → 0.000002
   • Epoch   4/100: train=0.0820, val=0.0829, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0820, val=0.0829, patience=4/15, lr=0.000002
   • Epoch  11/100: train=0.0819, val=0.0830, patience=10/15, lr=0.000002
   📉 Epoch 12: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 18 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0152
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0102
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0916, RMSE: 0.3026, MAE: 0.2628, R²: -0.0163

📊 Round 18 Test Metrics:
   Loss: 0.0916, RMSE: 0.3027, MAE: 0.2630, R²: -0.0169

📊 Round 18 Test Metrics:
   Loss: 0.0916, RMSE: 0.3027, MAE: 0.2629, R²: -0.0167

📊 Round 18 Test Metrics:
   Loss: 0.0916, RMSE: 0.3026, MAE: 0.2629, R²: -0.0165

============================================================
🔄 Round 23 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 23 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0277
   Val:   Loss=0.0772, RMSE=0.2778, R²=0.0135
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0915, RMSE: 0.3026, MAE: 0.2629, R²: -0.0161

📊 Round 23 Test Metrics:
   Loss: 0.0915, RMSE: 0.3025, MAE: 0.2628, R²: -0.0159

============================================================
🔄 Round 28 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 28 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0100
   Val:   Loss=0.0742, RMSE=0.2725, R²=-0.0197
============================================================


============================================================
🔄 Round 30 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 30 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0155
   Val:   Loss=0.0812, RMSE=0.2849, R²=0.0011
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0914, RMSE: 0.3024, MAE: 0.2626, R²: -0.0147

📊 Round 30 Test Metrics:
   Loss: 0.0914, RMSE: 0.3023, MAE: 0.2626, R²: -0.0145

============================================================
🔄 Round 34 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 34 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0057
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0424
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0914, RMSE: 0.3023, MAE: 0.2624, R²: -0.0140

📊 Round 34 Test Metrics:
   Loss: 0.0913, RMSE: 0.3022, MAE: 0.2624, R²: -0.0139

============================================================
🔄 Round 36 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 36 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0118
   Val:   Loss=0.0847, RMSE=0.2911, R²=-0.0009
============================================================


============================================================
🔄 Round 40 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 40 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0105
   Val:   Loss=0.0810, RMSE=0.2847, R²=-0.0043
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0913, RMSE: 0.3022, MAE: 0.2623, R²: -0.0134

📊 Round 40 Test Metrics:
   Loss: 0.0913, RMSE: 0.3021, MAE: 0.2623, R²: -0.0133

📊 Round 40 Test Metrics:
   Loss: 0.0913, RMSE: 0.3021, MAE: 0.2622, R²: -0.0131

============================================================
🔄 Round 45 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 45 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0058
   Val:   Loss=0.0887, RMSE=0.2977, R²=-0.0210
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0913, RMSE: 0.3021, MAE: 0.2622, R²: -0.0130

📊 Round 45 Test Metrics:
   Loss: 0.0913, RMSE: 0.3021, MAE: 0.2622, R²: -0.0130

============================================================
🔄 Round 47 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 47 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0093
   Val:   Loss=0.0815, RMSE=0.2856, R²=-0.0059
============================================================


============================================================
🔄 Round 48 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 48 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0031
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0317
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0913, RMSE: 0.3021, MAE: 0.2621, R²: -0.0129

============================================================
🔄 Round 52 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 52 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0081
   Val:   Loss=0.0805, RMSE=0.2836, R²=-0.0109
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0912, RMSE: 0.3021, MAE: 0.2621, R²: -0.0127

📊 Round 52 Test Metrics:
   Loss: 0.0912, RMSE: 0.3021, MAE: 0.2621, R²: -0.0127

============================================================
🔄 Round 54 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 54 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0131
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0337
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0912, RMSE: 0.3021, MAE: 0.2621, R²: -0.0127

📊 Round 54 Test Metrics:
   Loss: 0.0912, RMSE: 0.3020, MAE: 0.2621, R²: -0.0126

📊 Round 54 Test Metrics:
   Loss: 0.0912, RMSE: 0.3020, MAE: 0.2621, R²: -0.0126

============================================================
🔄 Round 57 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 57 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0070
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0161
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0912, RMSE: 0.3020, MAE: 0.2621, R²: -0.0126

============================================================
🔄 Round 60 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 60 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0116
   Val:   Loss=0.0833, RMSE=0.2885, R²=0.0037
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0912, RMSE: 0.3020, MAE: 0.2620, R²: -0.0125

============================================================
🔄 Round 61 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 61 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0083
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0064
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0912, RMSE: 0.3020, MAE: 0.2620, R²: -0.0125

📊 Round 61 Test Metrics:
   Loss: 0.0912, RMSE: 0.3020, MAE: 0.2620, R²: -0.0125

📊 Round 61 Test Metrics:
   Loss: 0.0912, RMSE: 0.3020, MAE: 0.2620, R²: -0.0124

============================================================
🔄 Round 66 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 66 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0065
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0131
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0912, RMSE: 0.3020, MAE: 0.2620, R²: -0.0124

============================================================
🔄 Round 67 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 67 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0003
   Val:   Loss=0.0763, RMSE=0.2762, R²=-0.0552
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0912, RMSE: 0.3020, MAE: 0.2620, R²: -0.0124

============================================================
🔄 Round 68 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 68 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0085
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0178
============================================================


============================================================
🔄 Round 69 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 69 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0070
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0197
============================================================


============================================================
🔄 Round 71 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 71 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0043
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0224
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0912, RMSE: 0.3020, MAE: 0.2620, R²: -0.0123

============================================================
🔄 Round 72 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 72 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=-0.0115
   Val:   Loss=0.0750, RMSE=0.2739, R²=0.0066
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0912, RMSE: 0.3020, MAE: 0.2620, R²: -0.0123

============================================================
🔄 Round 73 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 73 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0024
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0383
============================================================


============================================================
🔄 Round 76 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 76 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0055
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0160
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0912, RMSE: 0.3020, MAE: 0.2619, R²: -0.0123

============================================================
🔄 Round 77 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 77 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0125
   Val:   Loss=0.0826, RMSE=0.2874, R²=0.0119
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0912, RMSE: 0.3020, MAE: 0.2619, R²: -0.0123

📊 Round 77 Test Metrics:
   Loss: 0.0912, RMSE: 0.3020, MAE: 0.2619, R²: -0.0123

============================================================
🔄 Round 80 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 80 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0048
   Val:   Loss=0.0767, RMSE=0.2769, R²=-0.0192
============================================================


============================================================
🔄 Round 81 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 81 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0078
   Val:   Loss=0.0767, RMSE=0.2770, R²=-0.0118
============================================================


============================================================
🔄 Round 85 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 85 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0021
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0278
============================================================


============================================================
🔄 Round 86 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 86 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0037
   Val:   Loss=0.0842, RMSE=0.2901, R²=-0.0304
============================================================


============================================================
🔄 Round 87 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0695 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0695, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0695, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0695, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0695, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0695, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0695)

============================================================
📊 Round 87 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0087
   Val:   Loss=0.0695, RMSE=0.2636, R²=-0.0032
============================================================


============================================================
🔄 Round 89 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 89 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0107
   Val:   Loss=0.0791, RMSE=0.2812, R²=0.0070
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0912, RMSE: 0.3020, MAE: 0.2619, R²: -0.0121

============================================================
🔄 Round 90 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 90 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0055
   Val:   Loss=0.0818, RMSE=0.2861, R²=-0.0157
============================================================


============================================================
🔄 Round 93 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 93 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0078
   Val:   Loss=0.0746, RMSE=0.2731, R²=-0.0071
============================================================


============================================================
🔄 Round 94 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 94 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0057
   Val:   Loss=0.0790, RMSE=0.2810, R²=-0.0134
============================================================


============================================================
🔄 Round 96 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 96 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=-0.0069
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0132
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0912, RMSE: 0.3020, MAE: 0.2619, R²: -0.0121

📊 Round 96 Test Metrics:
   Loss: 0.0912, RMSE: 0.3020, MAE: 0.2619, R²: -0.0121

============================================================
🔄 Round 102 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 102 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0061
   Val:   Loss=0.0770, RMSE=0.2774, R²=-0.0122
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0912, RMSE: 0.3020, MAE: 0.2619, R²: -0.0121

============================================================
🔄 Round 104 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 104 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0110
   Val:   Loss=0.0800, RMSE=0.2829, R²=0.0081
============================================================


============================================================
🔄 Round 105 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 105 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0086
   Val:   Loss=0.0777, RMSE=0.2788, R²=-0.0007
============================================================


============================================================
🔄 Round 106 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 106 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=-0.0088
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0068
============================================================


============================================================
🔄 Round 107 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 107 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0079
   Val:   Loss=0.0859, RMSE=0.2932, R²=-0.0038
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0912, RMSE: 0.3020, MAE: 0.2619, R²: -0.0120

📊 Round 107 Test Metrics:
   Loss: 0.0912, RMSE: 0.3020, MAE: 0.2619, R²: -0.0120

📊 Round 107 Test Metrics:
   Loss: 0.0912, RMSE: 0.3020, MAE: 0.2619, R²: -0.0120

📊 Round 107 Test Metrics:
   Loss: 0.0912, RMSE: 0.3020, MAE: 0.2618, R²: -0.0120

============================================================
🔄 Round 113 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0984 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0984, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0984, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0984, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0984, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0984, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0984)

============================================================
📊 Round 113 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2790, R²=-0.0017
   Val:   Loss=0.0984, RMSE=0.3137, R²=-0.0260
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0912, RMSE: 0.3020, MAE: 0.2618, R²: -0.0120

📊 Round 113 Test Metrics:
   Loss: 0.0912, RMSE: 0.3019, MAE: 0.2618, R²: -0.0120

📊 Round 113 Test Metrics:
   Loss: 0.0912, RMSE: 0.3019, MAE: 0.2618, R²: -0.0120

============================================================
🔄 Round 117 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 117 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0014
   Val:   Loss=0.0796, RMSE=0.2822, R²=-0.0337
============================================================


============================================================
🔄 Round 118 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 118 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0096
   Val:   Loss=0.0740, RMSE=0.2720, R²=0.0051
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0912, RMSE: 0.3019, MAE: 0.2618, R²: -0.0119

============================================================
🔄 Round 120 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 120 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0053
   Val:   Loss=0.0720, RMSE=0.2684, R²=-0.0223
============================================================


============================================================
🔄 Round 121 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 121 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0106
   Val:   Loss=0.0779, RMSE=0.2791, R²=0.0082
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0912, RMSE: 0.3019, MAE: 0.2618, R²: -0.0119

============================================================
🔄 Round 122 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 122 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0004
   Val:   Loss=0.0873, RMSE=0.2954, R²=-0.0453
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0912, RMSE: 0.3019, MAE: 0.2618, R²: -0.0119

============================================================
🔄 Round 125 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 125 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0085
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0001
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0912, RMSE: 0.3019, MAE: 0.2618, R²: -0.0119

📊 Round 125 Test Metrics:
   Loss: 0.0912, RMSE: 0.3019, MAE: 0.2618, R²: -0.0119

============================================================
🔄 Round 128 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0725, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 128 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0072
   Val:   Loss=0.0725, RMSE=0.2693, R²=-0.0078
============================================================


============================================================
🔄 Round 129 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 129 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0127
   Val:   Loss=0.0839, RMSE=0.2896, R²=0.0110
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0912, RMSE: 0.3019, MAE: 0.2618, R²: -0.0119

============================================================
🔄 Round 130 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 130 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0084
   Val:   Loss=0.0723, RMSE=0.2689, R²=0.0013
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0912, RMSE: 0.3019, MAE: 0.2618, R²: -0.0119

📊 Round 130 Test Metrics:
   Loss: 0.0912, RMSE: 0.3019, MAE: 0.2618, R²: -0.0119

============================================================
🔄 Round 132 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 132 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0072
   Val:   Loss=0.0786, RMSE=0.2803, R²=-0.0045
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0912, RMSE: 0.3019, MAE: 0.2618, R²: -0.0119

============================================================
🔄 Round 133 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 133 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0096
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0038
============================================================


============================================================
🔄 Round 134 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 134 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0135
   Val:   Loss=0.0788, RMSE=0.2808, R²=0.0181
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0912, RMSE: 0.3019, MAE: 0.2618, R²: -0.0118

============================================================
🔄 Round 139 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 139 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0056
   Val:   Loss=0.0887, RMSE=0.2979, R²=-0.0194
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0912, RMSE: 0.3019, MAE: 0.2618, R²: -0.0118

============================================================
🔄 Round 142 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 142 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0068
   Val:   Loss=0.0721, RMSE=0.2685, R²=-0.0120
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0912, RMSE: 0.3019, MAE: 0.2618, R²: -0.0118

============================================================
🔄 Round 145 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 145 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0131
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0196
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0912, RMSE: 0.3019, MAE: 0.2618, R²: -0.0118

============================================================
🔄 Round 147 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 147 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=0.0001
   Val:   Loss=0.0885, RMSE=0.2975, R²=-0.0399
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0912, RMSE: 0.3019, MAE: 0.2618, R²: -0.0118

📊 Round 147 Test Metrics:
   Loss: 0.0912, RMSE: 0.3019, MAE: 0.2618, R²: -0.0118

📊 Round 147 Test Metrics:
   Loss: 0.0912, RMSE: 0.3019, MAE: 0.2618, R²: -0.0118

📊 Round 147 Test Metrics:
   Loss: 0.0912, RMSE: 0.3019, MAE: 0.2618, R²: -0.0118

📊 Round 147 Test Metrics:
   Loss: 0.0912, RMSE: 0.3019, MAE: 0.2618, R²: -0.0117

📊 Round 147 Test Metrics:
   Loss: 0.0912, RMSE: 0.3019, MAE: 0.2618, R²: -0.0117

============================================================
🔄 Round 153 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 153 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0106
   Val:   Loss=0.0761, RMSE=0.2758, R²=0.0091
============================================================


============================================================
🔄 Round 154 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 154 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0027
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0208
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0912, RMSE: 0.3019, MAE: 0.2618, R²: -0.0117

============================================================
🔄 Round 158 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 158 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=-0.0116
   Val:   Loss=0.0745, RMSE=0.2729, R²=0.0155
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0911, RMSE: 0.3019, MAE: 0.2618, R²: -0.0117

📊 Round 158 Test Metrics:
   Loss: 0.0911, RMSE: 0.3019, MAE: 0.2618, R²: -0.0117

============================================================
🔄 Round 160 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 160 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0014
   Val:   Loss=0.0859, RMSE=0.2932, R²=-0.0279
============================================================


============================================================
🔄 Round 162 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 162 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0109
   Val:   Loss=0.0759, RMSE=0.2754, R²=0.0027
============================================================


============================================================
🔄 Round 163 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 163 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0036
   Val:   Loss=0.0729, RMSE=0.2701, R²=-0.0199
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0911, RMSE: 0.3019, MAE: 0.2618, R²: -0.0117

📊 Round 163 Test Metrics:
   Loss: 0.0911, RMSE: 0.3019, MAE: 0.2618, R²: -0.0117

============================================================
🔄 Round 166 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 166 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0059
   Val:   Loss=0.0885, RMSE=0.2974, R²=-0.0545
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0911, RMSE: 0.3019, MAE: 0.2618, R²: -0.0117

📊 Round 166 Test Metrics:
   Loss: 0.0911, RMSE: 0.3019, MAE: 0.2618, R²: -0.0117

📊 Round 166 Test Metrics:
   Loss: 0.0911, RMSE: 0.3019, MAE: 0.2618, R²: -0.0116

============================================================
🔄 Round 174 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 174 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=-0.0017
   Val:   Loss=0.0731, RMSE=0.2703, R²=-0.0285
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0911, RMSE: 0.3019, MAE: 0.2618, R²: -0.0116

============================================================
🔄 Round 177 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 177 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0053
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0138
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0911, RMSE: 0.3019, MAE: 0.2618, R²: -0.0116

📊 Round 177 Test Metrics:
   Loss: 0.0911, RMSE: 0.3019, MAE: 0.2618, R²: -0.0116

============================================================
🔄 Round 181 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 181 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0065
   Val:   Loss=0.0765, RMSE=0.2767, R²=-0.0108
============================================================


============================================================
🔄 Round 184 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 184 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0039
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0250
============================================================


============================================================
🔄 Round 188 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 188 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0107
   Val:   Loss=0.0849, RMSE=0.2913, R²=-0.0023
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0911, RMSE: 0.3019, MAE: 0.2618, R²: -0.0116

📊 Round 188 Test Metrics:
   Loss: 0.0911, RMSE: 0.3019, MAE: 0.2617, R²: -0.0116

============================================================
🔄 Round 191 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 191 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=-0.0097
   Val:   Loss=0.0755, RMSE=0.2748, R²=0.0102
============================================================


============================================================
🔄 Round 193 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 193 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0099
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0092
============================================================


📊 Round 193 Test Metrics:
   Loss: 0.0911, RMSE: 0.3019, MAE: 0.2617, R²: -0.0116

============================================================
🔄 Round 195 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0710 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0710, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0710, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0710, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0710, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0710, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0710)

============================================================
📊 Round 195 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0089
   Val:   Loss=0.0710, RMSE=0.2664, R²=0.0058
============================================================


📊 Round 195 Test Metrics:
   Loss: 0.0911, RMSE: 0.3019, MAE: 0.2617, R²: -0.0115

============================================================
🔄 Round 198 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 198 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0072
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0012
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0911, RMSE: 0.3019, MAE: 0.2617, R²: -0.0115

============================================================
🔄 Round 199 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 199 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0024
   Val:   Loss=0.0781, RMSE=0.2795, R²=-0.0223
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0911, RMSE: 0.3019, MAE: 0.2617, R²: -0.0115

============================================================
🔄 Round 200 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 200 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0021
   Val:   Loss=0.0891, RMSE=0.2986, R²=-0.0215
============================================================


============================================================
🔄 Round 202 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 202 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0069
   Val:   Loss=0.0794, RMSE=0.2817, R²=-0.0246
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0911, RMSE: 0.3019, MAE: 0.2617, R²: -0.0115

============================================================
🔄 Round 207 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 207 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0069
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0244
============================================================


============================================================
🔄 Round 208 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 208 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0081
   Val:   Loss=0.0807, RMSE=0.2842, R²=-0.0091
============================================================


📊 Round 208 Test Metrics:
   Loss: 0.0911, RMSE: 0.3019, MAE: 0.2617, R²: -0.0115

============================================================
🔄 Round 210 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0922 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0922, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0922, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0922, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0922, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0922, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0922)

============================================================
📊 Round 210 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=0.0008
   Val:   Loss=0.0922, RMSE=0.3036, R²=-0.0291
============================================================


============================================================
🔄 Round 212 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 212 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2871, R²=-0.0037
   Val:   Loss=0.0794, RMSE=0.2817, R²=-0.0146
============================================================


📊 Round 212 Test Metrics:
   Loss: 0.0911, RMSE: 0.3019, MAE: 0.2617, R²: -0.0114

📊 Round 212 Test Metrics:
   Loss: 0.0911, RMSE: 0.3019, MAE: 0.2617, R²: -0.0114

============================================================
🔄 Round 214 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 214 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0009
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0352
============================================================


📊 Round 214 Test Metrics:
   Loss: 0.0911, RMSE: 0.3019, MAE: 0.2617, R²: -0.0114

📊 Round 214 Test Metrics:
   Loss: 0.0911, RMSE: 0.3019, MAE: 0.2617, R²: -0.0114

============================================================
🔄 Round 220 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 220 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0062
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0041
============================================================


📊 Round 220 Test Metrics:
   Loss: 0.0911, RMSE: 0.3019, MAE: 0.2617, R²: -0.0114

============================================================
🔄 Round 222 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 222 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0076
   Val:   Loss=0.0855, RMSE=0.2924, R²=0.0015
============================================================


============================================================
🔄 Round 223 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 223 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0049
   Val:   Loss=0.0792, RMSE=0.2815, R²=-0.0092
============================================================


============================================================
🔄 Round 224 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 224 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0085
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0064
============================================================


============================================================
🔄 Round 225 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 225 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0048
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0101
============================================================


============================================================
🔄 Round 227 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 227 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0026
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0186
============================================================


📊 Round 227 Test Metrics:
   Loss: 0.0911, RMSE: 0.3019, MAE: 0.2617, R²: -0.0114

============================================================
🔄 Round 229 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 229 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=0.0006
   Val:   Loss=0.0866, RMSE=0.2943, R²=-0.0296
============================================================


📊 Round 229 Test Metrics:
   Loss: 0.0911, RMSE: 0.3019, MAE: 0.2617, R²: -0.0114

📊 Round 229 Test Metrics:
   Loss: 0.0911, RMSE: 0.3019, MAE: 0.2617, R²: -0.0114

============================================================
🔄 Round 231 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 231 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0130
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0218
============================================================


📊 Round 231 Test Metrics:
   Loss: 0.0911, RMSE: 0.3019, MAE: 0.2617, R²: -0.0114

============================================================
🔄 Round 235 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 235 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0077
   Val:   Loss=0.0751, RMSE=0.2741, R²=-0.0029
============================================================


📊 Round 235 Test Metrics:
   Loss: 0.0911, RMSE: 0.3019, MAE: 0.2617, R²: -0.0114

============================================================
🔄 Round 236 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 236 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0118
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0195
============================================================


📊 Round 236 Test Metrics:
   Loss: 0.0911, RMSE: 0.3019, MAE: 0.2617, R²: -0.0114

============================================================
🔄 Round 237 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 237 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0047
   Val:   Loss=0.0823, RMSE=0.2870, R²=-0.0212
============================================================


📊 Round 237 Test Metrics:
   Loss: 0.0911, RMSE: 0.3019, MAE: 0.2617, R²: -0.0114

============================================================
🔄 Round 239 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0943 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0943, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0943, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0943, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0943, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0943, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0943)

============================================================
📊 Round 239 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=-0.0031
   Val:   Loss=0.0943, RMSE=0.3071, R²=-0.0223
============================================================


============================================================
🔄 Round 242 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 242 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0093
   Val:   Loss=0.0851, RMSE=0.2917, R²=0.0045
============================================================


============================================================
🔄 Round 243 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 243 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0045
   Val:   Loss=0.0781, RMSE=0.2795, R²=-0.0097
============================================================


📊 Round 243 Test Metrics:
   Loss: 0.0911, RMSE: 0.3019, MAE: 0.2617, R²: -0.0113

============================================================
🔄 Round 245 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 245 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0110
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0162
============================================================


📊 Round 245 Test Metrics:
   Loss: 0.0911, RMSE: 0.3019, MAE: 0.2617, R²: -0.0113

📊 Round 245 Test Metrics:
   Loss: 0.0911, RMSE: 0.3019, MAE: 0.2617, R²: -0.0113

📊 Round 245 Test Metrics:
   Loss: 0.0911, RMSE: 0.3019, MAE: 0.2617, R²: -0.0113

📊 Round 245 Test Metrics:
   Loss: 0.0911, RMSE: 0.3019, MAE: 0.2617, R²: -0.0113

============================================================
🔄 Round 249 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 249 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0019
   Val:   Loss=0.0775, RMSE=0.2783, R²=-0.0458
============================================================


📊 Round 249 Test Metrics:
   Loss: 0.0911, RMSE: 0.3019, MAE: 0.2617, R²: -0.0113

============================================================
🔄 Round 251 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0718, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 251 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0130
   Val:   Loss=0.0718, RMSE=0.2680, R²=0.0287
============================================================


📊 Round 251 Test Metrics:
   Loss: 0.0911, RMSE: 0.3019, MAE: 0.2617, R²: -0.0113

📊 Round 251 Test Metrics:
   Loss: 0.0911, RMSE: 0.3018, MAE: 0.2617, R²: -0.0113

📊 Round 251 Test Metrics:
   Loss: 0.0911, RMSE: 0.3018, MAE: 0.2617, R²: -0.0113

============================================================
🔄 Round 254 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 254 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0114
   Val:   Loss=0.0765, RMSE=0.2767, R²=0.0198
============================================================


📊 Round 254 Test Metrics:
   Loss: 0.0911, RMSE: 0.3018, MAE: 0.2617, R²: -0.0113

📊 Round 254 Test Metrics:
   Loss: 0.0911, RMSE: 0.3018, MAE: 0.2617, R²: -0.0113

📊 Round 254 Test Metrics:
   Loss: 0.0911, RMSE: 0.3018, MAE: 0.2617, R²: -0.0113

============================================================
🔄 Round 257 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 257 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0020
   Val:   Loss=0.0798, RMSE=0.2826, R²=-0.0197
============================================================


============================================================
🔄 Round 258 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 258 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0137
   Val:   Loss=0.0861, RMSE=0.2935, R²=0.0020
============================================================


📊 Round 258 Test Metrics:
   Loss: 0.0911, RMSE: 0.3018, MAE: 0.2617, R²: -0.0113

============================================================
🔄 Round 260 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 260 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=-0.0051
   Val:   Loss=0.0906, RMSE=0.3010, R²=-0.0094
============================================================


📊 Round 260 Test Metrics:
   Loss: 0.0911, RMSE: 0.3018, MAE: 0.2617, R²: -0.0113

============================================================
🔄 Round 263 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 263 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0013
   Val:   Loss=0.0762, RMSE=0.2760, R²=-0.0304
============================================================


📊 Round 263 Test Metrics:
   Loss: 0.0911, RMSE: 0.3018, MAE: 0.2617, R²: -0.0113

📊 Round 263 Test Metrics:
   Loss: 0.0911, RMSE: 0.3018, MAE: 0.2617, R²: -0.0113

============================================================
🔄 Round 266 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 266 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0080
   Val:   Loss=0.0860, RMSE=0.2933, R²=0.0046
============================================================


📊 Round 266 Test Metrics:
   Loss: 0.0911, RMSE: 0.3018, MAE: 0.2617, R²: -0.0113

============================================================
🔄 Round 269 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 269 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0110
   Val:   Loss=0.0810, RMSE=0.2845, R²=0.0137
============================================================


📊 Round 269 Test Metrics:
   Loss: 0.0911, RMSE: 0.3018, MAE: 0.2617, R²: -0.0113

============================================================
🔄 Round 270 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 270 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0010
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0224
============================================================


📊 Round 270 Test Metrics:
   Loss: 0.0911, RMSE: 0.3018, MAE: 0.2617, R²: -0.0113

============================================================
🔄 Round 271 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 271 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=-0.0118
   Val:   Loss=0.0909, RMSE=0.3015, R²=0.0170
============================================================


============================================================
🔄 Round 273 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 273 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0012
   Val:   Loss=0.0802, RMSE=0.2833, R²=-0.0305
============================================================


📊 Round 273 Test Metrics:
   Loss: 0.0911, RMSE: 0.3018, MAE: 0.2617, R²: -0.0112

📊 Round 273 Test Metrics:
   Loss: 0.0911, RMSE: 0.3018, MAE: 0.2617, R²: -0.0112

📊 Round 273 Test Metrics:
   Loss: 0.0911, RMSE: 0.3018, MAE: 0.2617, R²: -0.0112

============================================================
🔄 Round 277 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 277 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0088
   Val:   Loss=0.0826, RMSE=0.2874, R²=0.0074
============================================================


============================================================
🔄 Round 278 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 278 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0046
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0078
============================================================


📊 Round 278 Test Metrics:
   Loss: 0.0911, RMSE: 0.3018, MAE: 0.2617, R²: -0.0112

============================================================
🔄 Round 280 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 280 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0084
   Val:   Loss=0.0808, RMSE=0.2842, R²=0.0073
============================================================


============================================================
🔄 Round 281 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 281 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0126
   Val:   Loss=0.0858, RMSE=0.2929, R²=0.0218
============================================================


📊 Round 281 Test Metrics:
   Loss: 0.0911, RMSE: 0.3018, MAE: 0.2617, R²: -0.0112

============================================================
🔄 Round 287 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 287 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0027
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0254
============================================================


📊 Round 287 Test Metrics:
   Loss: 0.0911, RMSE: 0.3018, MAE: 0.2617, R²: -0.0112

📊 Round 287 Test Metrics:
   Loss: 0.0911, RMSE: 0.3018, MAE: 0.2617, R²: -0.0112

============================================================
🔄 Round 290 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 290 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0082
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0047
============================================================


============================================================
🔄 Round 291 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 291 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0079
   Val:   Loss=0.0811, RMSE=0.2847, R²=-0.0058
============================================================


============================================================
🔄 Round 293 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 293 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0054
   Val:   Loss=0.0795, RMSE=0.2819, R²=-0.0039
============================================================


============================================================
🔄 Round 294 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 294 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0104
   Val:   Loss=0.0819, RMSE=0.2862, R²=0.0150
============================================================


📊 Round 294 Test Metrics:
   Loss: 0.0911, RMSE: 0.3018, MAE: 0.2617, R²: -0.0112

============================================================
🔄 Round 297 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0927 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0927, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0927, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0927, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0928, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0927)

============================================================
📊 Round 297 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=-0.0084
   Val:   Loss=0.0927, RMSE=0.3045, R²=-0.0236
============================================================


📊 Round 297 Test Metrics:
   Loss: 0.0911, RMSE: 0.3018, MAE: 0.2617, R²: -0.0111

📊 Round 297 Test Metrics:
   Loss: 0.0911, RMSE: 0.3018, MAE: 0.2617, R²: -0.0111

============================================================
🔄 Round 302 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 302 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0046
   Val:   Loss=0.0888, RMSE=0.2981, R²=-0.0072
============================================================


📊 Round 302 Test Metrics:
   Loss: 0.0911, RMSE: 0.3018, MAE: 0.2617, R²: -0.0111

============================================================
🔄 Round 303 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 303 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0061
   Val:   Loss=0.0878, RMSE=0.2962, R²=-0.0016
============================================================


📊 Round 303 Test Metrics:
   Loss: 0.0911, RMSE: 0.3018, MAE: 0.2617, R²: -0.0111

============================================================
🔄 Round 306 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 306 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0056
   Val:   Loss=0.0764, RMSE=0.2764, R²=-0.0024
============================================================


📊 Round 306 Test Metrics:
   Loss: 0.0911, RMSE: 0.3018, MAE: 0.2617, R²: -0.0111

============================================================
🔄 Round 308 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 308 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0002
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0245
============================================================


============================================================
🔄 Round 309 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 309 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0005
   Val:   Loss=0.0911, RMSE=0.3019, R²=-0.0391
============================================================


============================================================
🔄 Round 311 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 311 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0029
   Val:   Loss=0.0754, RMSE=0.2746, R²=-0.0179
============================================================


============================================================
🔄 Round 312 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 312 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0030
   Val:   Loss=0.0734, RMSE=0.2708, R²=-0.0149
============================================================


📊 Round 312 Test Metrics:
   Loss: 0.0911, RMSE: 0.3018, MAE: 0.2617, R²: -0.0111

============================================================
🔄 Round 313 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 313 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0040
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0637
============================================================


📊 Round 313 Test Metrics:
   Loss: 0.0911, RMSE: 0.3018, MAE: 0.2617, R²: -0.0111

============================================================
🔄 Round 314 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 314 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0068
   Val:   Loss=0.0800, RMSE=0.2829, R²=-0.0171
============================================================


📊 Round 314 Test Metrics:
   Loss: 0.0911, RMSE: 0.3018, MAE: 0.2617, R²: -0.0111

============================================================
🔄 Round 317 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 317 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0050
   Val:   Loss=0.0790, RMSE=0.2810, R²=-0.0049
============================================================


📊 Round 317 Test Metrics:
   Loss: 0.0911, RMSE: 0.3018, MAE: 0.2617, R²: -0.0111

============================================================
🔄 Round 318 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 318 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0063
   Val:   Loss=0.0838, RMSE=0.2894, R²=0.0007
============================================================


📊 Round 318 Test Metrics:
   Loss: 0.0911, RMSE: 0.3018, MAE: 0.2617, R²: -0.0111

============================================================
🔄 Round 320 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 320 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0070
   Val:   Loss=0.0758, RMSE=0.2753, R²=-0.0049
============================================================


📊 Round 320 Test Metrics:
   Loss: 0.0911, RMSE: 0.3018, MAE: 0.2617, R²: -0.0110

============================================================
🔄 Round 323 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 323 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0080
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0071
============================================================


📊 Round 323 Test Metrics:
   Loss: 0.0911, RMSE: 0.3018, MAE: 0.2617, R²: -0.0110

============================================================
🔄 Round 326 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 326 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2857, R²=0.0015
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0334
============================================================


📊 Round 326 Test Metrics:
   Loss: 0.0911, RMSE: 0.3018, MAE: 0.2617, R²: -0.0110

📊 Round 326 Test Metrics:
   Loss: 0.0911, RMSE: 0.3018, MAE: 0.2617, R²: -0.0110

============================================================
🔄 Round 329 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 329 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0116
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0159
============================================================


📊 Round 329 Test Metrics:
   Loss: 0.0911, RMSE: 0.3018, MAE: 0.2617, R²: -0.0110

============================================================
🔄 Round 330 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 330 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=-0.0041
   Val:   Loss=0.0846, RMSE=0.2908, R²=-0.0108
============================================================


📊 Round 330 Test Metrics:
   Loss: 0.0911, RMSE: 0.3018, MAE: 0.2617, R²: -0.0110

============================================================
🔄 Round 331 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 331 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0079
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.0077
============================================================


📊 Round 331 Test Metrics:
   Loss: 0.0911, RMSE: 0.3018, MAE: 0.2617, R²: -0.0110

============================================================
🔄 Round 334 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 334 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0036
   Val:   Loss=0.0793, RMSE=0.2817, R²=-0.0105
============================================================


📊 Round 334 Test Metrics:
   Loss: 0.0911, RMSE: 0.3018, MAE: 0.2617, R²: -0.0110

============================================================
🔄 Round 336 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 336 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0042
   Val:   Loss=0.0884, RMSE=0.2973, R²=-0.0219
============================================================


📊 Round 336 Test Metrics:
   Loss: 0.0911, RMSE: 0.3018, MAE: 0.2617, R²: -0.0110

============================================================
🔄 Round 337 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 337 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0001
   Val:   Loss=0.0836, RMSE=0.2892, R²=-0.0243
============================================================


============================================================
🔄 Round 338 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 338 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0027
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0132
============================================================


📊 Round 338 Test Metrics:
   Loss: 0.0911, RMSE: 0.3018, MAE: 0.2617, R²: -0.0110

📊 Round 338 Test Metrics:
   Loss: 0.0911, RMSE: 0.3018, MAE: 0.2617, R²: -0.0110

============================================================
🔄 Round 341 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0687 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0687, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0687, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0687, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0687, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0688, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0687)

============================================================
📊 Round 341 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0053
   Val:   Loss=0.0687, RMSE=0.2622, R²=-0.0027
============================================================


📊 Round 341 Test Metrics:
   Loss: 0.0911, RMSE: 0.3018, MAE: 0.2617, R²: -0.0110

📊 Round 341 Test Metrics:
   Loss: 0.0911, RMSE: 0.3018, MAE: 0.2617, R²: -0.0110

============================================================
🔄 Round 343 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0690 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0690, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0690, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0690, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0690, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0690, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0690)

============================================================
📊 Round 343 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0071
   Val:   Loss=0.0690, RMSE=0.2627, R²=0.0052
============================================================


📊 Round 343 Test Metrics:
   Loss: 0.0911, RMSE: 0.3018, MAE: 0.2617, R²: -0.0110

============================================================
🔄 Round 346 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 346 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0043
   Val:   Loss=0.0724, RMSE=0.2691, R²=-0.0085
============================================================


📊 Round 346 Test Metrics:
   Loss: 0.0911, RMSE: 0.3018, MAE: 0.2617, R²: -0.0110

============================================================
🔄 Round 349 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 349 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0045
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0068
============================================================


============================================================
🔄 Round 351 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 351 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0030
   Val:   Loss=0.0895, RMSE=0.2991, R²=-0.0108
============================================================


📊 Round 351 Test Metrics:
   Loss: 0.0911, RMSE: 0.3018, MAE: 0.2617, R²: -0.0109

============================================================
🔄 Round 353 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0985 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0985, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0985, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0985, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0985, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0985, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0985)

============================================================
📊 Round 353 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2785, R²=-0.0018
   Val:   Loss=0.0985, RMSE=0.3139, R²=-0.0261
============================================================


📊 Round 353 Test Metrics:
   Loss: 0.0911, RMSE: 0.3018, MAE: 0.2616, R²: -0.0109

📊 Round 353 Test Metrics:
   Loss: 0.0911, RMSE: 0.3018, MAE: 0.2616, R²: -0.0109

============================================================
🔄 Round 355 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 355 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0036
   Val:   Loss=0.0775, RMSE=0.2784, R²=-0.0206
============================================================


============================================================
🔄 Round 356 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 356 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0022
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0143
============================================================


📊 Round 356 Test Metrics:
   Loss: 0.0911, RMSE: 0.3018, MAE: 0.2616, R²: -0.0110

============================================================
🔄 Round 359 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 359 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0055
   Val:   Loss=0.0755, RMSE=0.2749, R²=-0.0057
============================================================


📊 Round 359 Test Metrics:
   Loss: 0.0911, RMSE: 0.3018, MAE: 0.2616, R²: -0.0110

============================================================
🔄 Round 360 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 360 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0001
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0245
============================================================


============================================================
🔄 Round 362 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 362 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0015
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0180
============================================================


============================================================
🔄 Round 365 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 365 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0060
   Val:   Loss=0.0836, RMSE=0.2892, R²=-0.0077
============================================================


============================================================
🔄 Round 366 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 366 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0032
   Val:   Loss=0.0847, RMSE=0.2911, R²=-0.0266
============================================================


📊 Round 366 Test Metrics:
   Loss: 0.0911, RMSE: 0.3018, MAE: 0.2616, R²: -0.0110

📊 Round 366 Test Metrics:
   Loss: 0.0911, RMSE: 0.3018, MAE: 0.2616, R²: -0.0109

📊 Round 366 Test Metrics:
   Loss: 0.0911, RMSE: 0.3018, MAE: 0.2616, R²: -0.0109

📊 Round 366 Test Metrics:
   Loss: 0.0911, RMSE: 0.3018, MAE: 0.2616, R²: -0.0109

============================================================
🔄 Round 372 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 372 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=-0.0008
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0191
============================================================


📊 Round 372 Test Metrics:
   Loss: 0.0911, RMSE: 0.3018, MAE: 0.2616, R²: -0.0109

============================================================
🔄 Round 375 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 375 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0052
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0060
============================================================


============================================================
🔄 Round 376 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 376 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0060
   Val:   Loss=0.0785, RMSE=0.2801, R²=0.0017
============================================================


📊 Round 376 Test Metrics:
   Loss: 0.0911, RMSE: 0.3018, MAE: 0.2616, R²: -0.0109

📊 Round 376 Test Metrics:
   Loss: 0.0911, RMSE: 0.3018, MAE: 0.2616, R²: -0.0109

============================================================
🔄 Round 378 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 378 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0049
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0070
============================================================


📊 Round 378 Test Metrics:
   Loss: 0.0911, RMSE: 0.3018, MAE: 0.2616, R²: -0.0109

============================================================
🔄 Round 379 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 379 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2813, R²=-0.0077
   Val:   Loss=0.0921, RMSE=0.3034, R²=-0.0180
============================================================


============================================================
🔄 Round 380 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 380 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0023
   Val:   Loss=0.0789, RMSE=0.2809, R²=-0.0360
============================================================


📊 Round 380 Test Metrics:
   Loss: 0.0911, RMSE: 0.3018, MAE: 0.2616, R²: -0.0109

📊 Round 380 Test Metrics:
   Loss: 0.0911, RMSE: 0.3018, MAE: 0.2616, R²: -0.0109

📊 Round 380 Test Metrics:
   Loss: 0.0911, RMSE: 0.3018, MAE: 0.2616, R²: -0.0109

============================================================
🔄 Round 384 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 384 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0063
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0127
============================================================


📊 Round 384 Test Metrics:
   Loss: 0.0911, RMSE: 0.3018, MAE: 0.2616, R²: -0.0109

============================================================
🔄 Round 385 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 385 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0070
   Val:   Loss=0.0887, RMSE=0.2978, R²=0.0044
============================================================


📊 Round 385 Test Metrics:
   Loss: 0.0911, RMSE: 0.3018, MAE: 0.2616, R²: -0.0109

============================================================
🔄 Round 386 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 386 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0090
   Val:   Loss=0.0833, RMSE=0.2885, R²=0.0121
============================================================


📊 Round 386 Test Metrics:
   Loss: 0.0911, RMSE: 0.3018, MAE: 0.2616, R²: -0.0109

📊 Round 386 Test Metrics:
   Loss: 0.0911, RMSE: 0.3018, MAE: 0.2616, R²: -0.0109

============================================================
🔄 Round 388 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 388 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0067
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0494
============================================================


============================================================
🔄 Round 390 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 390 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=-0.0037
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0073
============================================================


📊 Round 390 Test Metrics:
   Loss: 0.0911, RMSE: 0.3018, MAE: 0.2616, R²: -0.0109

============================================================
🔄 Round 391 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 391 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0031
   Val:   Loss=0.0769, RMSE=0.2774, R²=-0.0105
============================================================


📊 Round 391 Test Metrics:
   Loss: 0.0911, RMSE: 0.3018, MAE: 0.2616, R²: -0.0109

============================================================
🔄 Round 393 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 393 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0034
   Val:   Loss=0.0761, RMSE=0.2758, R²=-0.0090
============================================================


📊 Round 393 Test Metrics:
   Loss: 0.0911, RMSE: 0.3018, MAE: 0.2616, R²: -0.0109

============================================================
🔄 Round 394 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 394 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0064
   Val:   Loss=0.0800, RMSE=0.2829, R²=0.0017
============================================================


📊 Round 394 Test Metrics:
   Loss: 0.0911, RMSE: 0.3018, MAE: 0.2616, R²: -0.0109

📊 Round 394 Test Metrics:
   Loss: 0.0911, RMSE: 0.3018, MAE: 0.2616, R²: -0.0109

============================================================
🔄 Round 398 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 398 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0104
   Val:   Loss=0.0757, RMSE=0.2751, R²=0.0211
============================================================


📊 Round 398 Test Metrics:
   Loss: 0.0911, RMSE: 0.3018, MAE: 0.2616, R²: -0.0109

============================================================
🔄 Round 399 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 399 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2856, R²=0.0026
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0361
============================================================


============================================================
🔄 Round 402 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 402 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0082
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0076
============================================================


============================================================
🔄 Round 403 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 403 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0052
   Val:   Loss=0.0770, RMSE=0.2775, R²=-0.0008
============================================================


📊 Round 403 Test Metrics:
   Loss: 0.0911, RMSE: 0.3018, MAE: 0.2616, R²: -0.0108

============================================================
🔄 Round 404 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 404 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0014
   Val:   Loss=0.0789, RMSE=0.2808, R²=-0.0287
============================================================


📊 Round 404 Test Metrics:
   Loss: 0.0911, RMSE: 0.3018, MAE: 0.2616, R²: -0.0108

📊 Round 404 Test Metrics:
   Loss: 0.0911, RMSE: 0.3018, MAE: 0.2616, R²: -0.0108

============================================================
🔄 Round 407 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0698 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0699, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0699, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0699, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0699, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0701, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0698)

============================================================
📊 Round 407 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0083
   Val:   Loss=0.0698, RMSE=0.2643, R²=-0.0613
============================================================


============================================================
🔄 Round 411 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 411 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0081
   Val:   Loss=0.0826, RMSE=0.2873, R²=-0.0031
============================================================


📊 Round 411 Test Metrics:
   Loss: 0.0911, RMSE: 0.3018, MAE: 0.2616, R²: -0.0108

📊 Round 411 Test Metrics:
   Loss: 0.0911, RMSE: 0.3018, MAE: 0.2616, R²: -0.0108

============================================================
🔄 Round 414 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 414 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0057
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.0098
============================================================


📊 Round 414 Test Metrics:
   Loss: 0.0911, RMSE: 0.3018, MAE: 0.2616, R²: -0.0108

============================================================
🔄 Round 417 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 417 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0034
   Val:   Loss=0.0744, RMSE=0.2727, R²=-0.0268
============================================================


📊 Round 417 Test Metrics:
   Loss: 0.0911, RMSE: 0.3018, MAE: 0.2616, R²: -0.0108

============================================================
🔄 Round 418 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0955 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0955, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0955, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0955, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0955, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0956, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0955)

============================================================
📊 Round 418 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2797, R²=-0.0046
   Val:   Loss=0.0955, RMSE=0.3091, R²=-0.0058
============================================================


============================================================
🔄 Round 420 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 420 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0039
   Val:   Loss=0.0874, RMSE=0.2957, R²=-0.0051
============================================================


📊 Round 420 Test Metrics:
   Loss: 0.0911, RMSE: 0.3018, MAE: 0.2617, R²: -0.0108

============================================================
🔄 Round 422 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 422 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0063
   Val:   Loss=0.0760, RMSE=0.2758, R²=-0.0089
============================================================


📊 Round 422 Test Metrics:
   Loss: 0.0911, RMSE: 0.3018, MAE: 0.2617, R²: -0.0108

📊 Round 422 Test Metrics:
   Loss: 0.0911, RMSE: 0.3018, MAE: 0.2617, R²: -0.0108

============================================================
🔄 Round 425 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 425 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=-0.0041
   Val:   Loss=0.0826, RMSE=0.2875, R²=-0.0044
============================================================


============================================================
🔄 Round 426 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 426 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=-0.0032
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0086
============================================================


============================================================
🔄 Round 427 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 427 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0062
   Val:   Loss=0.0775, RMSE=0.2784, R²=0.0044
============================================================


============================================================
🔄 Round 429 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 429 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0041
   Val:   Loss=0.0748, RMSE=0.2736, R²=-0.0091
============================================================


============================================================
🔄 Round 430 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 430 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0017
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0311
============================================================


============================================================
🔄 Round 431 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 431 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=-0.0010
   Val:   Loss=0.0913, RMSE=0.3022, R²=-0.0166
============================================================


📊 Round 431 Test Metrics:
   Loss: 0.0911, RMSE: 0.3018, MAE: 0.2616, R²: -0.0107

============================================================
🔄 Round 433 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 433 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0072
   Val:   Loss=0.0783, RMSE=0.2799, R²=0.0086
============================================================


============================================================
🔄 Round 434 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 434 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0013
   Val:   Loss=0.0773, RMSE=0.2780, R²=-0.0310
============================================================


============================================================
🔄 Round 436 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 436 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0033
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0362
============================================================


============================================================
🔄 Round 437 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 437 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0086
   Val:   Loss=0.0886, RMSE=0.2976, R²=0.0044
============================================================


============================================================
🔄 Round 438 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 438 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=-0.0063
   Val:   Loss=0.0900, RMSE=0.3000, R²=-0.0001
============================================================


============================================================
🔄 Round 446 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 446 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0006
   Val:   Loss=0.0790, RMSE=0.2810, R²=-0.0201
============================================================


============================================================
🔄 Round 447 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0717, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0717, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0717, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0717, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 447 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0061
   Val:   Loss=0.0717, RMSE=0.2678, R²=0.0056
============================================================


📊 Round 447 Test Metrics:
   Loss: 0.0911, RMSE: 0.3018, MAE: 0.2617, R²: -0.0107

📊 Round 447 Test Metrics:
   Loss: 0.0911, RMSE: 0.3018, MAE: 0.2617, R²: -0.0107

📊 Round 447 Test Metrics:
   Loss: 0.0911, RMSE: 0.3018, MAE: 0.2617, R²: -0.0106

📊 Round 447 Test Metrics:
   Loss: 0.0911, RMSE: 0.3018, MAE: 0.2617, R²: -0.0106

============================================================
🔄 Round 456 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 456 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0084
   Val:   Loss=0.0888, RMSE=0.2981, R²=-0.0573
============================================================


📊 Round 456 Test Metrics:
   Loss: 0.0911, RMSE: 0.3017, MAE: 0.2617, R²: -0.0106

📊 Round 456 Test Metrics:
   Loss: 0.0911, RMSE: 0.3017, MAE: 0.2617, R²: -0.0106

============================================================
🔄 Round 460 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0717, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0717, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0717, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0717, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 460 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0021
   Val:   Loss=0.0717, RMSE=0.2677, R²=-0.0278
============================================================


📊 Round 460 Test Metrics:
   Loss: 0.0911, RMSE: 0.3017, MAE: 0.2617, R²: -0.0106

📊 Round 460 Test Metrics:
   Loss: 0.0911, RMSE: 0.3017, MAE: 0.2617, R²: -0.0106

📊 Round 460 Test Metrics:
   Loss: 0.0911, RMSE: 0.3017, MAE: 0.2617, R²: -0.0106

📊 Round 460 Test Metrics:
   Loss: 0.0911, RMSE: 0.3017, MAE: 0.2617, R²: -0.0106

📊 Round 460 Test Metrics:
   Loss: 0.0911, RMSE: 0.3017, MAE: 0.2617, R²: -0.0106

============================================================
🔄 Round 471 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 471 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0049
   Val:   Loss=0.0785, RMSE=0.2801, R²=0.0003
============================================================


📊 Round 471 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2617, R²: -0.0106

📊 Round 471 Test Metrics:
   Loss: 0.0911, RMSE: 0.3017, MAE: 0.2616, R²: -0.0106

📊 Round 471 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2617, R²: -0.0106

📊 Round 471 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2617, R²: -0.0106

============================================================
🔄 Round 483 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 483 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=0.0005
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0204
============================================================


============================================================
🔄 Round 486 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 486 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0123
   Val:   Loss=0.0816, RMSE=0.2856, R²=0.0188
============================================================


============================================================
🔄 Round 487 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 487 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0044
   Val:   Loss=0.0743, RMSE=0.2726, R²=-0.0037
============================================================


📊 Round 487 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2617, R²: -0.0106

============================================================
🔄 Round 488 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 488 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0074
   Val:   Loss=0.0856, RMSE=0.2926, R²=0.0070
============================================================


📊 Round 488 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2617, R²: -0.0106

📊 Round 488 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2617, R²: -0.0106

📊 Round 488 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2617, R²: -0.0106

📊 Round 488 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2617, R²: -0.0106

📊 Round 488 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2616, R²: -0.0106

============================================================
🔄 Round 493 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 493 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=-0.0113
   Val:   Loss=0.0813, RMSE=0.2852, R²=0.0015
============================================================


📊 Round 493 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2616, R²: -0.0105

============================================================
🔄 Round 497 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 497 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0058
   Val:   Loss=0.0830, RMSE=0.2882, R²=0.0013
============================================================


📊 Round 497 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2616, R²: -0.0105

============================================================
🔄 Round 500 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 500 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0014
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0260
============================================================


📊 Round 500 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2616, R²: -0.0105

============================================================
🔄 Round 507 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 507 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2878, R²=-0.0024
   Val:   Loss=0.0769, RMSE=0.2774, R²=-0.0098
============================================================


============================================================
🔄 Round 508 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0706 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0706, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0706, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0706, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0706, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0706, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0706)

============================================================
📊 Round 508 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0068
   Val:   Loss=0.0706, RMSE=0.2658, R²=0.0103
============================================================


📊 Round 508 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2617, R²: -0.0105

📊 Round 508 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2617, R²: -0.0105

============================================================
🔄 Round 515 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 515 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0001
   Val:   Loss=0.0791, RMSE=0.2812, R²=-0.0192
============================================================


============================================================
🔄 Round 516 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 516 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0046
   Val:   Loss=0.0738, RMSE=0.2717, R²=-0.0116
============================================================


📊 Round 516 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2617, R²: -0.0105

📊 Round 516 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2617, R²: -0.0105

📊 Round 516 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2617, R²: -0.0105

📊 Round 516 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2617, R²: -0.0105

============================================================
🔄 Round 521 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 521 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0107
   Val:   Loss=0.0891, RMSE=0.2984, R²=0.0193
============================================================


📊 Round 521 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2617, R²: -0.0105

============================================================
🔄 Round 523 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 523 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0042
   Val:   Loss=0.0736, RMSE=0.2713, R²=-0.0494
============================================================


📊 Round 523 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2616, R²: -0.0105

📊 Round 523 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2616, R²: -0.0105

📊 Round 523 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2616, R²: -0.0105

============================================================
🔄 Round 530 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 530 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2864, R²=-0.0031
   Val:   Loss=0.0801, RMSE=0.2831, R²=-0.0065
============================================================


📊 Round 530 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2616, R²: -0.0105

============================================================
🔄 Round 533 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 533 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0048
   Val:   Loss=0.0723, RMSE=0.2689, R²=-0.0346
============================================================


📊 Round 533 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2616, R²: -0.0105

============================================================
🔄 Round 534 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 534 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0003
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0173
============================================================


📊 Round 534 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2616, R²: -0.0105

============================================================
🔄 Round 536 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 536 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0010
   Val:   Loss=0.0818, RMSE=0.2861, R²=-0.0158
============================================================


📊 Round 536 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2616, R²: -0.0105

============================================================
🔄 Round 541 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 541 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0028
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0735
============================================================


📊 Round 541 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2616, R²: -0.0105

📊 Round 541 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2616, R²: -0.0105

============================================================
🔄 Round 546 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 546 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0017
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0263
============================================================


============================================================
🔄 Round 547 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 547 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0041
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0391
============================================================


📊 Round 547 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2616, R²: -0.0105

============================================================
🔄 Round 548 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 548 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0062
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0067
============================================================


📊 Round 548 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2616, R²: -0.0105

📊 Round 548 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2616, R²: -0.0105

📊 Round 548 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2616, R²: -0.0105

============================================================
🔄 Round 555 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 555 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0106
   Val:   Loss=0.0843, RMSE=0.2904, R²=0.0209
============================================================


============================================================
🔄 Round 556 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 556 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0019
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0121
============================================================


📊 Round 556 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2616, R²: -0.0105

============================================================
🔄 Round 557 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 557 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0087
   Val:   Loss=0.0852, RMSE=0.2919, R²=0.0026
============================================================


📊 Round 557 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2616, R²: -0.0105

============================================================
🔄 Round 558 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 558 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0075
   Val:   Loss=0.0777, RMSE=0.2787, R²=0.0105
============================================================


📊 Round 558 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2616, R²: -0.0105

📊 Round 558 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2616, R²: -0.0105

============================================================
🔄 Round 560 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 560 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0013
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0139
============================================================


============================================================
🔄 Round 561 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 561 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=0.0018
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0323
============================================================


📊 Round 561 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2616, R²: -0.0105

📊 Round 561 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2616, R²: -0.0105

============================================================
🔄 Round 567 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 567 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0022
   Val:   Loss=0.0735, RMSE=0.2710, R²=-0.0106
============================================================


📊 Round 567 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2616, R²: -0.0105

============================================================
🔄 Round 570 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 570 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=-0.0001
   Val:   Loss=0.0825, RMSE=0.2873, R²=-0.0411
============================================================


📊 Round 570 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2616, R²: -0.0105

============================================================
🔄 Round 571 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 571 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0015
   Val:   Loss=0.0813, RMSE=0.2852, R²=-0.0265
============================================================


============================================================
🔄 Round 572 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 572 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0054
   Val:   Loss=0.0740, RMSE=0.2720, R²=0.0039
============================================================


📊 Round 572 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2616, R²: -0.0105

============================================================
🔄 Round 573 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 573 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0027
   Val:   Loss=0.0791, RMSE=0.2812, R²=-0.0072
============================================================


📊 Round 573 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2616, R²: -0.0105

📊 Round 573 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2616, R²: -0.0105

❌ Client client_5 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8688 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8688 {grpc_status:14, grpc_message:"Socket closed"}"
>
