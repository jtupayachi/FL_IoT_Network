[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 737e7e9d-48b5-43af-9c69-787a890e0b3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e5584eb-2ba4-4f48-a163-65f79adcfc9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d850dee-aaba-406d-a249-27e3535e643c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb5e327f-67ee-4215-834d-1d0e64de84bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 761d4adb-94a6-48d2-8282-368125cf687b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b0fc42f-7a02-449a-a749-29e80e37cae6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 600a6055-1713-4912-b634-8909d02be0ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c421de0d-1bdf-4513-be27-f6bd544d592b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5ec28fa-dc30-4c6d-9774-cd2e80308c61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1d60dd8-c306-496c-a0d0-a8405a5fcb80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62fd3fe8-71ec-44f2-9549-b3edb4bf2b42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94bdfe44-4251-4568-8db3-cb917200240a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88c5e5e8-62da-40ba-b0f8-e6791ff7cef5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17f8903a-2c2f-46d5-a9a5-1dbce2ba8723
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a79cfdb2-e077-416a-bc27-f1843d54f0ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e97e3e28-605d-40c1-a339-557422c223d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88d5c844-cae7-4ce3-aa12-b958591c573e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 594f33a1-d1e7-4290-959a-1a01dd15cbb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f4dc820-c535-45d3-9b58-48898b3c2809
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9852fcc-378d-4520-93b9-32d7e915dc77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d76f28b3-d96e-4b69-aafc-4299a32cf820
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1fad47f4-5fab-4ca5-9b90-d60a972aa5cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message faf37777-0074-45bd-b137-d085b749e7ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31b89469-b079-46fb-b7bd-9ec940de1941
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 967f6dc1-7399-4af4-800a-e5e59d4d52be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8f97593-354c-410d-a2b7-ace9f06fc2b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d24d1581-5268-4bbe-985c-e911b980a305
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d00a23f4-ceac-4140-b9bf-6ca78ff532f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7f2f22b-fdc0-4ae9-b2fd-8bd9bcf36c1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51e7c2d8-f2e3-44ca-af13-cafe10e78985
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6149afca-a065-44ea-a9d7-ccb8997d36f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f388df1-3beb-407a-a683-23db418bebdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3d3fe2d-a161-48be-8a93-71669a559165
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd730313-03c5-4d14-a684-4f13cf378ee8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc7f8978-feee-46a2-b63b-ae6875772439
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28d85585-3b85-4909-b9cc-d895b2b2c454
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb76e3d3-e80f-4e0d-b2ad-f26e312ba9c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8c465e9-07fc-42df-b69f-55e7616ba138
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d55c6e90-837a-413d-a6b3-a1ca78544536
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 874a6916-1f18-4b3a-8d0f-6eaa2701742f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e32916c-c790-4b41-be8c-f9b4e0787b32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d9a90be-bf7a-49ca-9cb6-2265e18a2520
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6977618c-9a32-45f1-b84d-ec8c799d6c0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dfe953dd-240d-4edc-a5f3-b95e8ab314a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4c74a38-8089-4123-a683-358214cc6b3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4e9f1ff-338f-47e5-be49-09b4f20eed18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 978d95f2-1e82-4b6f-be93-034769c271f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9516d384-18a2-4fa3-8e0c-c2827e20f84a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ffc7cd02-b82a-4926-a59a-86f28fb436cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20e76119-dcb3-4574-ab9e-21a939676fb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6727d7b-a940-4839-a32a-400ea2d2e207
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e237164a-04b0-44c3-8d4d-9be4ab9a02c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ea1b5ba-5c61-46be-a997-c4a59a8672e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f61f1b47-2a83-4690-88f5-d3989625ed0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7742331-e054-46a7-a83a-4670636a5e49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86a5eaca-f09d-4bf5-a0a9-edb48119f4b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2189d161-6861-40a8-bcde-820235ae0315
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3dcfb60e-3960-43c6-8486-263ba196d358
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1e453c1-7ce6-4597-8d6b-78899e6a2c6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43e00d06-d41e-4a14-933d-05f25c7d19ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8edc1918-85e7-417f-ab64-9f5def848e36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad873ab8-21bb-4819-b392-16918aa2922c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7078fada-4145-4174-b5e1-fcf3c0ab30b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b04a9a84-2280-4ce9-95f9-a926c4a92845
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 456d5fd1-abac-4f32-9dc2-809e243c3582
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a87eace-2510-4604-82cd-b8082d816dca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7a1eb2b-b89c-4529-993a-26dd454a18a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51312fca-d3e8-4e3f-a139-b93204cfa6ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ebb7f15d-2435-46c3-88b3-518b71979287
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 581c46d4-7adb-4c5a-9d81-6f905ecb67cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a88fe114-b2bb-4673-af59-e3ff6b09f2e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6429210-5e5e-48e5-bcfc-31bc6ea94d56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e4c9c25-8486-4d7c-b3a2-efaec69699a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9146a13-a568-4e5b-a3e3-b7366424921d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5854d959-bb8b-4a43-8b0e-999053594531
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea40be70-5d27-419a-8a00-561b31b1d559
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5390603f-02e6-427c-8b65-13be67dbbbd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 422e54db-8e4f-4dcd-b46c-48096ee218a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3bf59047-5eab-4b4f-812c-037317471e2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4a8a0d0-f45b-4572-b522-6d259adf533a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 004daa8d-e51a-4f83-af69-c551333cf946
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6862b0eb-02fa-4e18-8ff1-65dec6e05b86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb22444e-6371-499c-b19f-1bef31285b84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0beed2e-579e-4dd8-822e-872fec7ff664
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e348f999-2bb3-4a14-8425-13ec5b972fbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35f2d54a-0ee6-4299-82b5-30fa8d6ae101
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9cbcec2-920d-4d93-b6e5-59708081b0ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message abfd47ef-9f78-4e44-99a3-cbeefb86c6f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ad65eb2-80a5-492b-9b1c-16859c79f2d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4dd904e2-9143-4999-8b72-edad71f282ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0fbd51cf-2a89-434d-bbea-c78faf44609e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54e568fa-d729-4d52-bc57-2a76d61ddaed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ddd482a-b4cf-4416-a644-6be638f0a39a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 275b340f-a79c-44a0-aa36-a06f3cf97f55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 681fb1e8-3d8b-4c2f-a7cd-337765c34ff3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message debec1fe-6375-416e-9f65-7974dcf66779
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b745d0fd-21bb-4c48-9645-f77edda7e3da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f67dcc49-5ebe-48da-a938-e9f6ec9b9f72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f863c7cc-d5ba-48aa-ac01-b1e66d411ca6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 642d847b-8f55-4cee-a4ce-cb6b3dc03aa4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a99773c6-5ac2-40b8-ab14-a6660fa4d24e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4183e6de-e8f0-4853-98c0-f36b7b64a158
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f5e2cad-5aa2-4f4f-8402-53d8819f26a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23bc4848-c1cb-4701-97ef-24ed994b1593
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be8fd71c-5159-4ebb-ba0e-1f79d3745de0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e908fd0f-5bbb-4b1b-9949-4362721c5eef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a59ea235-7b38-443f-a152-d13a01abe8b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e77bcfc-5d7e-4b74-bb95-bab1d2c386b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0743361c-e7fc-46ef-869a-2c3975374091
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63f4ec86-43f9-4fc1-9892-f97df16089a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7440e0df-4df3-450a-a10f-9fe4b33dd02b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba42fc42-321e-4e89-a066-c778fe7ff9af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6786cddb-15cc-4561-9462-faccc2802910
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 181fc89c-2fa5-41ae-b6a6-d99c1394a3c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3693bab-7ee2-4ba0-8b15-77c053e87e61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1214b0f6-a918-453c-9078-b59f94305873
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab533a03-5d6f-4828-a66f-d848c0145b0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1e9dc03-0b0e-4f24-b62c-8600e642ef28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ed9ae5f-b0a7-4906-af24-edc13c928db9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c20ba797-e954-49a3-a798-2216323a9b5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d78b83c-fdaf-4b45-8662-54368e82eadc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0dd42609-bf8a-496d-b91a-128b4757b0eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd5d06fd-2c13-4672-8544-84bd92c155de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8e882d1-14f0-4072-8bb4-64640a644723
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43d5b63a-acaa-4cd9-a81c-94b5e9f93165
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7040dd6-259e-4686-9025-c528ea70886a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1fb9d0b-cfb3-4880-acd5-819a794ff395
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 588f14bc-09bb-4b3f-826d-f293a920c78c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7074722d-52f4-4114-be95-fac8791bf8c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76fe6a8f-1c1c-4444-a788-310227e51017
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4556188f-36d9-40f8-9c52-db3ffd4d8ab2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b7bbe83-d889-4c9e-a361-2c3b6851b3b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d52d4072-689f-494e-8397-7ab430ff47d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49dd3a35-21de-446d-841b-42994b2b99ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 381d6515-3892-47d2-8dd1-2de2d144421d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 193f9202-8217-4656-bac6-0753c17f028a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c4a2714-a7f9-4aef-9cfc-331f55842b25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 159dd809-2fd9-4f29-bfa0-67b078c4d952
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7cbe39a-f1ab-49c2-b3d5-5474a03c94ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5924a804-db52-437c-a2b4-7751a8ce339e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0f567c0-58f8-41c1-8c0c-33bf5986b7b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa522616-dd2a-4d5f-b251-cb6e40b8b8f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c55b567f-36b7-4f49-b4d9-94990dc39b8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9361e66d-1ef5-4ab4-afc7-db01cfee7000
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 040032a1-95fb-4593-97f7-5928c8174eb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 754e57bc-b93a-4ee0-8295-546659768fe7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa61a5e4-8d22-47b6-b41f-672271e7d33d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5d3ebe0-c6c4-4df4-9a9a-b8019eade96b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d23fb12-021f-47b5-9e2c-7da4ddea49f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2cc6382a-6eb0-424d-98fe-9c2e51563b90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bcab1077-df99-4785-ab17-2065bb231204
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c23342b2-ac79-4904-bb6b-29b90c7a54ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0391e2a-06e0-4948-b98b-a41ffcbeca52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a828925-af37-425e-b060-fabc8d8a2e0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5355c16-a868-4dd3-8ee5-376f3fa4ac85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 998e2659-d8e5-4816-b2d7-67bae6e86fd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a514a724-cd81-41e3-93aa-feeb2b3d497d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f8bd7d1-6436-497b-ad76-dc98f0a59707
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a5524ec-21e9-4274-92ae-6739ab42ea40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71d274be-ad6c-45a5-907d-df65f86cffbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c1235d3-ee0d-4d3f-99fd-403f02da4674
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48ff25ed-1b63-4e87-987c-71e107c81879
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1bc9298-7328-42ee-aba8-1fdc991e8976
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c0306ff-c8fe-4302-b63f-db0a83cd8b82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4716fee9-9c27-4ee8-9a40-3c8402fcc14c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8dcfd9f7-e79f-4631-97ae-85db7cb5e9ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43ebe73e-f94e-4ddc-a037-b97bd504cae4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e10d526-9390-4ebd-8bb8-67c0f2dffea8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31e6f6ea-601f-4875-a89b-e5a2bad7742b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4dda1a5d-edf6-4c4e-a325-c0682ba31766
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0d0e247-04dc-4404-8bb4-dad43992958c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52ccc7ff-9383-47f7-bd33-9b3b05e08981
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0883dbb1-1b50-4052-8b7e-530d2832ec4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55315e67-ddfe-4980-bb65-dd5feb295887
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25dbf862-7acf-487c-8638-6b0d8e48bb51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7005588-9a95-4670-a266-db2f1fe1d195
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fad02b5b-8f68-4cb6-9c6b-c58d23ad28a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51606e4b-f520-486a-b1c2-192f0e3d1577
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 419c5222-38e9-4b44-a2ec-67f86bcb3231
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f00f266-477d-4c87-809f-fdd174446ec9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cdae2fb1-ae25-446e-b3fa-b427620db1a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5784d3d3-6091-4cd4-918a-5e5293f79ce1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6927e986-4f99-44a7-98fd-f795af573e72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73cb9942-c229-4cee-9863-0368f5a2169e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db8f51cc-249b-4676-957a-881b8a131339
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb7610e9-6996-4f2a-b630-7d382670f2e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10a8d039-9317-4b6c-b38d-c6c0e9fbf692
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 401bf916-99d8-426c-b6d8-aadc0926ac12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb19fdd2-bf83-45b1-8f21-b81d2dda0053
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d444a2d6-c9eb-48e9-8466-bd3e470c7ea3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0b6ac8a-cf18-4295-a2d8-85b3f38e99b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ebcad24-17b2-4c5d-9144-558eb5dce9ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8de283a3-292c-48dd-8c6c-f376fcbbbe34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19cae915-88e8-4e2f-9b6f-0ea8fd5498ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35159004-18dd-44b2-9671-d1814e9c5b30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cca95865-6913-493f-8b55-80638e0b5cb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71a04189-6315-4d55-bdee-230268774731
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb751b14-ea56-40ab-8e9f-48929cc06932
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66af1e1b-fe07-47b9-a6ec-6dc3cd99f814
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9dbe7133-63fc-4e79-8db5-48dac6d17d84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a7d8fbd-b76f-490b-b790-eca693271b91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4218dc3f-008b-46c2-938f-413778809c41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c093f82-c1f8-4b17-ad80-016bb07c8eff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c80ba18c-29ad-435e-9361-f02ea60cfa1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02d259e7-92cb-4ab7-a735-57d8433c72cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 397f71e1-d550-43d4-bde3-d126cb21b9ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 976339d5-b71c-453b-b333-047a832c7e06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4951fbf2-143d-435a-ac5b-0c4db75ef17e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd51137f-8d72-4a8c-ac37-41ece82c895c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b52fd410-fe38-4eb9-9814-5d306341ce1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b1183a2-934f-4114-ad67-b030c73f0a3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 187da7eb-33f5-4012-a3ec-c16eced1367d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77392a4b-69b1-4fbd-a910-1b7184a561a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4afaa0a-b9be-4045-98eb-12558b04f349
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0616dfea-4fbf-4912-b85b-c1e5a5d48d76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ae58a5b-5880-424d-91d7-90664f368ef9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2dda03e-651a-4542-8894-f3160f4d2feb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43930a1e-73f5-4d0f-ae7e-7e5dd7e86fbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 480fd420-dbf5-40cd-8966-cb06b5dd557b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d28b9c8e-8166-43d2-aaf6-911752324433
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ea8fce5-93b7-4384-8326-b2a99a8f605c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d585f299-3860-4059-bbd9-ee9ec83e8405
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a77bad0-1a9c-4421-8a6c-16df8db9e51c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 346d03b9-8dc3-41e5-95db-1f36b33015e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 973913e7-6709-4f64-a784-de2f4639cee6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b47ad6dc-3e71-450f-879e-111e5241a06c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c2d25ff-c27a-49a4-99fe-f1b4ef0ce06d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05f3931f-943e-40e9-b792-6275e6dbc84e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c33f2eba-cbfc-4430-b087-6b4884c7b57a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0a0ffaa-3058-41c6-9f5d-fcd7e87f4f31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2fb64f1-2f39-489c-bff0-af4a3a185d2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b38c4622-7b5c-44d0-b83e-9c584b9c2713
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8408241f-a6b4-437d-ad5c-4c6ad71007c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bbad2113-f58f-448d-8ac4-662209441b89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec262976-acc2-4b26-945d-e8ebea288837
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f6de400-b2d9-4628-b64e-81a62d66a4e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d21ea413-d34a-4578-a362-11de0bfbac44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df9966bf-6ce7-4d6a-8a8f-d5fb5a0966e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 891623a0-7d89-4247-8147-ee1f25081da1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02da9f34-f86b-48ad-8a8f-f6a25b4161be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6771f1cc-b027-4cbe-ac80-7b71e4ac8028
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9f02d1c-e1c1-4d41-abd6-535370ae19eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cfedc038-e6ff-4cf1-8113-cf70d4c7d8d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 951e2125-2780-42b9-9533-3061b1c9b79a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8adec718-6652-43c9-b343-62fce9441b5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4b7e226-0a48-4fff-a6dc-93b9e84f5946
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9242d20-6573-4e97-8d74-288839da69f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a5e567a-16c4-42b8-b4af-de04ea6fbd63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 406d37eb-9f47-43f9-bb81-b9ee5d037467
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ccc3407-65d4-4660-8f7c-d7d58d014af4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c223d02-39bc-4848-8754-859db39ff0e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 510b12ca-340e-4cd8-8e98-cf59adc407ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1cf7c06c-9544-4384-beea-410280e11018
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 224f5784-9180-4d9a-a0c7-6a4fd2fcdb9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5abdd709-f403-4aa5-80e8-0070bbb55483
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00e9c20b-5a58-4f83-a35b-cc58a3be8032
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17dddc7a-9642-458d-8456-b6442d8be40c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c633d02d-10d5-4078-8f6e-12c55f2c914c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b55ea999-6895-4122-8a29-bb43df23f7d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57d9897b-0ddd-412c-b42a-c35222116946
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a414924d-d130-451f-ac06-938beafb54f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 765270e1-bfbb-4a32-b036-80459747df73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0fca6dca-2be4-4ea7-9e7d-e5364239ccb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 574e07a0-5f0d-4635-b0de-f663ada6a684
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18eb6100-be27-4b1f-bb8c-58eca293d950
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53b1b982-79f5-4eba-9345-868263ff5dcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90cb6e1a-ee19-4377-a526-eebf4de9f712
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1df23494-f31e-4a37-b583-a39908d43cb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 175a7db0-a247-41cd-9d81-bffd5788fdd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d205bbc-f2ae-4b4e-8a69-209189225dd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message abe049d7-6e3f-4a91-9b1d-ccf269557bab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9c0e88f-fad2-4e4d-a635-7022d57baca6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7630a07b-d6fd-464c-93b0-cdfd858ee103
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 791fa8bb-3dd3-45a3-85a6-1bee195e756e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3dbeffc-faae-4f03-b338-2213e4e3034b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d0b7368-5696-432c-85fc-76bb4bec519b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f9f446b-ba67-4769-9ad5-34ec0988368e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8eea0658-bf42-4f0c-852d-ae43f9e13641
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 605df35b-9de6-4fa9-b519-1ff3d7ada4de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b9a55f6-7181-4d1d-afa2-83ede5d62ffb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d96ac3c1-8621-4ada-8a3e-8033df940940
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02902a7b-a940-4b49-9338-caad5cff3802
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56a61ee7-a089-4dfe-8c3f-86f521601f09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0e73adb-f483-4b87-b302-be4ea374a65b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3616bf94-cf8e-4070-9325-d2ee7c5d8e59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e4bf778-fdcc-44fa-83d9-831ea22d38f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f428f010-dd72-4b93-8c4c-6d3f74aff07f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99eaa850-752f-42a8-8ae6-6cf62ee808a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f8959d9-4d1d-4869-b124-526488060ceb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9499f312-8274-4187-9576-98af87a42450
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce32cd31-3e2e-4456-a6c6-15d458795f9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2816264b-aff0-474b-bd79-84e78547eae9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e0e4c95-696f-4e01-b3a9-98c2e3f04e3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message afc03d6e-d2dc-4207-b171-896e42a7f11b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 312b4e2b-6c0b-408a-9df9-2e4c5ca8cb3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b54b498-cc81-40e0-9fb1-6138b48f871b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 506ff72b-5ff2-441a-92d9-81a4a45ce9ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80c69be5-f1eb-48d4-96a3-94444ffcd453
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31e805ef-e423-48f6-a30f-0a5f769202ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71c649ca-738e-4df8-b08c-2d955b23bf80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78cea2c6-8874-4d2a-964e-124ede3e7d4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69c27091-9e9c-4bac-8ccd-136274e5a140
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 272c817c-345a-4f86-913e-42d4142a43fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f658c436-4b1d-4ef8-972a-4ded4f0d877d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message feeebdea-63b0-45fc-9256-94f36300a12b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f64710c3-2ced-4e7a-a616-145cb87dbbf1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f737ca18-6255-43dc-b0c3-aa8eafd26f81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e62f9366-1b76-41b4-8f30-413cc3a4d2ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07fc8ea8-1281-45c5-97e3-abe5c605a97a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3cedc4db-917a-41ef-8b6f-962b92471d41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3f28751-4d6d-4edb-bcbe-991b41775058
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ecac2e6-0ae3-43d9-8ea7-f55a434f648a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7eb21e20-428a-4bae-8df4-1aa796aeb78f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 321d352d-b594-4cb1-9d39-5f77d1d1c360
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 643580d8-583c-4303-a089-01007840cbdb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c627195a-fc35-4ca0-baac-fa7be0a46de4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63df0ef5-542e-4f76-99f2-cfaecc2e6c0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b3869af-a1f5-429b-8190-a92fdf32a012
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 540f51c1-adf9-4ae0-a4eb-a8be6516014c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f75209c-f43c-4517-a0c2-757319d0ac3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a18b0f0-533b-4080-8997-1f767fdcbf6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b24947b-1b4d-4f5f-ab64-dfead3b9fddd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d23094a-cf94-4350-8586-23bbc98d52e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ceec6c7-0960-4141-bf4f-92ae2440a355
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58c5ef0d-6e4e-45f9-8ae1-59e2c4fac0c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a322e2b2-f7f1-4216-8b94-9a21e798357c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8463a34-fe80-45bb-a998-cb27fd6a8109
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1e7be03-6a4d-4e2f-8d6d-5ad7649c9bdd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 884f9006-edca-4988-ad41-5df3cf258d97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 328ec603-51fc-4d0d-b981-adbd21b75268
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b6aab6a-a7f3-4eb8-a5ff-2add917e0c96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9152da6-34d4-4ab2-8c51-eec67459415d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70767747-8f57-42f1-ac16-d5bd10e56128
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 851387ff-53f8-4fc3-a764-1f9b0a764cae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72f6948e-21db-4a1a-8424-2309e205ffd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2051b3b6-4ea2-46bd-8990-731b42a2f2ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e927596-80a4-40a1-8799-565d77183946
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 471f19fa-5516-4962-990d-d410079dd730
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bbc136a6-05e7-4ebe-909c-a9ce781b828e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f22f9ee-c1cb-45c2-9ddd-8abe034ebbb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a1b95bf-8c27-41c4-be5f-a951834b119c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f76d36b0-25b1-4843-b2aa-78f7fca6f263
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f5a2990-8828-4d5c-b8a9-0e047215641c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37013b84-ea21-4bd0-a962-7ef6a61f61c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8c07893-72ba-4413-9cb9-a72b1cf5d04d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a615b57-a964-4014-a6bb-4ebf402321ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a89e7d7-703c-4a27-b9c2-294e5b5a4571
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e741f2b5-109f-496b-bfb7-d82727ff3f79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80090866-2c6a-423f-ba0b-54e1c8d80f1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0733087-512e-45aa-9c18-fbd6f1d76e3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac6ef685-0908-4a3c-a96c-2d87266b6000
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb8c2f06-9656-477d-a9dd-b7f48a6a3ce6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cbf0bbbd-9352-4c57-aa86-f2e6f88104ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b083b30b-427d-465c-963a-da1583102a94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4a2fe73-649f-4e45-a8d8-e0590d555e8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40e72725-c7d3-4ab4-a000-e68948785b4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9b12128-c983-46b4-bd56-914fd1982916
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40d88a9d-4101-4433-8fd5-2b2aa1da1b10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4de2be67-1cd2-439b-a4a9-efb2fa4156a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ad0e53c-eb1b-4ddd-8694-f4e79a3f95aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d42472d9-968d-4b31-b8e9-436d1d478b0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be47f9f6-32e0-4e25-a019-7c2ec47dd1fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff2101e6-0b60-4117-a5ab-1a646effece1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9118357c-90ab-4c7e-870d-1cd87efb17b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message daa52eef-33f0-4fd1-b6a2-b116be873970
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 481c6884-385b-466f-9bee-0e291c5e74bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22cb2502-e9b9-442a-ac32-f62c75077145
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf4f53e8-11ce-4bdb-8a88-38b0806e21eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90a280a5-5676-48a6-86d0-0baeeba46bfd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 104f9eb0-0176-41e9-b3bc-617e0309735d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e615d76-e6ff-4fe2-9f2e-cb43ba82af86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 821f442d-c752-4959-8d1d-a7448ec886f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79eb4ef9-bccc-4051-a160-9dd6c16da861
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cbfe345f-74a8-4098-922d-52edde4f33e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41153a3a-f6b8-4f18-b5a5-746b3c34e44e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3e5efec-58fb-4059-a6f4-57e8a53e63b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55752f78-73d5-413b-9871-dcf656ca9c94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8f15b78-f43d-497f-ba43-ad0526d7008e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 151c807d-f611-4d78-ad46-1ac290618238
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6854185-a563-4365-9739-9c73244bf607
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9718de60-a8df-4523-b720-ca9b175e541c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5371925-13a7-4c89-97ce-274789dc3cb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec1a1e3b-a549-4363-bf6d-7085738e871c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b809d1e9-3f87-4b62-9510-589a87ed1f43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e11d1a7a-57a5-49c1-9a4e-5962bd08a76d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02b8a5c0-f623-4e73-a626-d9341180d36e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3d81279-b97b-4b7a-b1dc-dc8d79c9f1da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55a4a2ed-d37c-4ead-a380-684a6b549dee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27bff8da-e084-4262-9dd4-9e42a0103e7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 452718a7-76c1-4c31-89fe-be76a3540d86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8870477-7181-4398-83c8-d8e581f0325a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2bdb73e7-36b5-46d5-9dcc-e73f65b5edcd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a02d8d97-e5a0-4f33-84a6-dfa207f603fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3786577-513c-4c52-afe7-9405bb4f07a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 256d7911-15a6-4d5a-98b4-97b8b54c23eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64718ef5-3efd-4f26-8990-56fb5b1241a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31ed248f-8e9b-41b6-8a82-924410f86279
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9fb7577-4fa1-4bb3-83a7-1f51616d22c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f1c4cb3-c7a3-4d57-aadc-1e4516f398b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e2d574f-4900-4458-a3af-e7e14bab8dc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13311770-2d79-45c2-badf-fab224e6066d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 673f0cab-cfce-4bac-82e0-e987d81cd01f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4792d38-288f-4403-a241-710643735bf6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc7dc6af-396e-4fea-bca6-4a19c675bf2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8416ade1-2416-42c4-b1fc-afa6384513c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e98f1cc-7c46-4819-aba9-92edc287a1c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85dc1f03-20d1-48d4-ae37-bd6737a4caf2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c14621bd-9476-490b-9be1-801a16afe2f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5cb222e-5d1a-4cdf-ab5a-d5ac932734c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8bb934a-4eeb-4dd2-bac1-9eae66c02b1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39d8eff4-9dd2-444c-ba68-ae1b67e49439
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message edab288b-119a-4948-8e6c-b18e9292e12c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77f94b8b-56f5-472d-adea-d0959634df88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7655e699-1b40-405e-b9c3-6b08d3275f55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a8b89bc-18c7-4d9c-a166-d049cc6c50a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db4ed63d-592a-4a96-a0b1-279d7c24a785
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 415532cd-020b-4986-81e8-59abf547de9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfa1cc77-bbc7-4da7-b2a1-77deb5392c5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3939db54-51c2-42f4-aff4-1a03395bcb30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ba06a73-016b-4584-9d3f-f072d3ae3c28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aead68ad-6aac-4a31-b604-1f0dc5a88e6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4809a4c7-eaca-4691-85e5-b1a47fefaab6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a832abb8-647d-4ea7-879d-da59aa9b20f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82b50907-1a6d-4d40-bf6e-514a246e5956
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8dfa3a04-85df-4e35-844e-e3873a662dc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b68c51c-41e8-4d88-92f1-450167a8a931
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a16b805-be78-4af6-89c3-026ae8937f72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8322464f-05be-4f24-b5e5-bbf00f0f2adf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38478e5d-361c-45cb-b500-bd1956886e2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66145c26-8932-4a99-ad3e-0135f3f7d8d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d550e34-91c6-4c29-a7be-e09d40973031
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 863566d1-c47d-4244-9942-e77370450950
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad6541b4-6fa9-42a2-a7b3-9507f03e4523
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49fdb32f-d08f-4db6-93d6-6564b99614df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b850947-4ee4-4965-a894-35acbad477d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c917a39-a6cb-4e69-9398-2e84efef5f3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d58d28e-a21c-46a0-b287-b567a2ecb7c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fed50844-dcc3-4f67-b185-0211684d000c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a4671a8-b724-454e-8062-0ba827203733
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e785149-43d6-4102-9c83-8e442756a6b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc3477ab-8560-4c3d-92b4-43e1ca4b98e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfac2231-8798-483c-9081-7a410dbe24e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 844135bf-23e2-4871-8086-15b57a0c4769
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4dffbc4-7260-4e12-a713-5534d0b2ec68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dbd97ef0-b988-4ebc-9ac8-940bc2e8ae58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd749f2b-ad27-411c-be8b-6a89ee2ed83d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8279ed6e-a989-44e5-ac7c-44d07e679929
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04dcefa3-7564-43f7-8dd1-2737d304e0d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a39f363a-5762-48cd-9419-8efb3be715a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b5ad5b3-905e-4fbc-9625-ea425d8a1d86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e383fc31-bb76-4e34-ad02-902491871bc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0a5c1d2-46c9-4568-8cc6-70c5c41c6981
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4d8b758-ac38-4345-9ef9-d26b8b003459
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3b36fd0-f4ba-4f9f-b46d-4973f83f858b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe076a3c-5cbb-4358-9f69-49bfb9dbdca2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23389dbd-863c-4495-805f-ef89ee35d4a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04d9694f-4c5b-4da1-9e4b-4b7c4aa4c4db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39c6c57b-ca55-4f91-b3b9-325db2251a8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f91dc65e-e561-43ec-8bd6-15ce4dc992bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6fa4cad-759a-47c2-848b-fc4381bfffc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3eaa7f3e-aee7-4d3c-9f51-9dc4a5f7165e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9eff0c19-0102-4322-af21-e22040a4adb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf1213a4-c63f-45d2-9b87-7317596a305d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64c5e264-ca40-429a-96ed-eee858cc71a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51b4e0e5-af8a-4c30-b247-8b073fa52e97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b54aa367-9842-42f5-8337-accefc782a56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3736627-2786-40a5-9a87-aae94b1e38ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb47f516-3061-4ff8-b892-55a69d2948ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce971fc2-682f-4e34-aa97-152903de3b66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ead63f8-fa16-4df0-b8f5-47f7ed5de1d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57f28d0f-4764-4988-a483-457f5d7d3a04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98029b86-0e3e-4628-9499-d6781b1fafd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 011c12b5-dd2b-4754-9953-3e3e4a9f97b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64e06b9d-f165-468a-8e54-f663cf288cd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message faad65e5-1a52-45c6-a4ff-c09de877ad39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ecbe610c-0307-4147-82f5-804803912efb
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8688 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_6
Server: localhost:8688
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_6
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_6/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_6/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_6/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_6/test_labels.txt

📊 Raw data loaded:
   Train: X=(4759, 24), y=(4759,)
   Test:  X=(1190, 24), y=(1190,)

⚠️  Limiting training data: 4759 → 800 samples
⚠️  Limiting test data: 1190 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_6 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.1052, RMSE: 0.3243, MAE: 0.2690, R²: -0.3416

============================================================
🔄 Round 6 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0811 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0817, val=0.0799 (↓), lr=0.001000
   ✓ Epoch   3/100: train=0.0808, val=0.0793 (↓), lr=0.001000
   • Epoch   4/100: train=0.0801, val=0.0794, patience=1/15, lr=0.001000
   • Epoch   5/100: train=0.0796, val=0.0792, patience=2/15, lr=0.001000
   • Epoch  11/100: train=0.0721, val=0.0809, patience=8/15, lr=0.001000
   📉 Epoch 12: LR reduced 0.001000 → 0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 6 Summary - Client client_6
   Epochs: 18/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0270
   Val:   Loss=0.0793, RMSE=0.2817, R²=-0.0051
============================================================


============================================================
🔄 Round 7 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0821 (↓), lr=0.000500
   • Epoch   2/100: train=0.0802, val=0.0829, patience=1/15, lr=0.000500
   • Epoch   3/100: train=0.0800, val=0.0826, patience=2/15, lr=0.000500
   • Epoch   4/100: train=0.0799, val=0.0826, patience=3/15, lr=0.000500
   • Epoch   5/100: train=0.0797, val=0.0825, patience=4/15, lr=0.000500
   📉 Epoch 6: LR reduced 0.000500 → 0.000250
   • Epoch  11/100: train=0.0788, val=0.0818, patience=10/15, lr=0.000250
   📉 Epoch 14: LR reduced 0.000250 → 0.000125
   • Epoch  21/100: train=0.0779, val=0.0811, patience=7/15, lr=0.000125
   📉 Epoch 22: LR reduced 0.000125 → 0.000063
   📉 Epoch 30: LR reduced 0.000063 → 0.000031
   • Epoch  31/100: train=0.0774, val=0.0808, patience=8/15, lr=0.000031
   📉 Epoch 38: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 7 Summary - Client client_6
   Epochs: 38/100 (early stopped)
   LR: 0.000500 → 0.000016 (5 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0441
   Val:   Loss=0.0810, RMSE=0.2847, R²=0.0170
============================================================


📊 Round 7 Test Metrics:
   Loss: 0.0783, RMSE: 0.2799, MAE: 0.2387, R²: 0.0010

📊 Round 7 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2412, R²: -0.0320

📊 Round 7 Test Metrics:
   Loss: 0.0763, RMSE: 0.2763, MAE: 0.2361, R²: 0.0264

============================================================
🔄 Round 10 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0735 (↓), lr=0.000016
   • Epoch   2/100: train=0.0814, val=0.0732, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0811, val=0.0730, patience=2/15, lr=0.000016
   ✓ Epoch   4/100: train=0.0809, val=0.0729 (↓), lr=0.000016
   • Epoch   5/100: train=0.0807, val=0.0728, patience=1/15, lr=0.000016
   • Epoch  11/100: train=0.0803, val=0.0726, patience=7/15, lr=0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 10 Summary - Client client_6
   Epochs: 19/100 (early stopped)
   LR: 0.000016 → 0.000016 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0310
   Val:   Loss=0.0729, RMSE=0.2700, R²=0.0190
============================================================


============================================================
🔄 Round 11 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0818 (↓), lr=0.000016
   • Epoch   2/100: train=0.0779, val=0.0818, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0779, val=0.0817, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0778, val=0.0817, patience=3/15, lr=0.000016
   📉 Epoch 5: LR reduced 0.000016 → 0.000008
   • Epoch   5/100: train=0.0778, val=0.0816, patience=4/15, lr=0.000008
   • Epoch  11/100: train=0.0777, val=0.0816, patience=10/15, lr=0.000008
   📉 Epoch 13: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 11 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=0.0371
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0212
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2381, R²: 0.0086

============================================================
🔄 Round 12 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0808 (↓), lr=0.000004
   • Epoch   2/100: train=0.0801, val=0.0807, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0799, val=0.0807, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0797, val=0.0807, patience=3/15, lr=0.000004
   📉 Epoch 5: LR reduced 0.000004 → 0.000002
   • Epoch   5/100: train=0.0795, val=0.0807, patience=4/15, lr=0.000002
   • Epoch  11/100: train=0.0790, val=0.0807, patience=10/15, lr=0.000002
   📉 Epoch 13: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 12 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0065
   Val:   Loss=0.0808, RMSE=0.2842, R²=0.0229
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.0745, RMSE: 0.2730, MAE: 0.2340, R²: 0.0494

📊 Round 12 Test Metrics:
   Loss: 0.0745, RMSE: 0.2730, MAE: 0.2338, R²: 0.0495

============================================================
🔄 Round 20 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 20 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0424
   Val:   Loss=0.0732, RMSE=0.2705, R²=0.0329
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0745, RMSE: 0.2730, MAE: 0.2338, R²: 0.0493

============================================================
🔄 Round 21 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 21 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2776, R²=0.0235
   Val:   Loss=0.0833, RMSE=0.2887, R²=0.0776
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0745, RMSE: 0.2730, MAE: 0.2337, R²: 0.0496

============================================================
🔄 Round 25 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 25 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=0.0392
   Val:   Loss=0.0772, RMSE=0.2779, R²=0.0374
============================================================


============================================================
🔄 Round 26 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 26 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0453
   Val:   Loss=0.0723, RMSE=0.2688, R²=-0.0017
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2337, R²: 0.0502

============================================================
🔄 Round 28 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0754, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0754, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0754, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0753, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 28 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0753, RMSE=0.2744, R²=0.0396
   Val:   Loss=0.0897, RMSE=0.2996, R²=0.0411
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2337, R²: 0.0503

📊 Round 28 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2337, R²: 0.0504

📊 Round 28 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2337, R²: 0.0506

============================================================
🔄 Round 32 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 32 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0496
   Val:   Loss=0.0774, RMSE=0.2782, R²=0.0144
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2337, R²: 0.0506

📊 Round 32 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2337, R²: 0.0507

============================================================
🔄 Round 39 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0747, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0747, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0747, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0747, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0747, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0746, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 39 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0747, RMSE=0.2733, R²=0.0513
   Val:   Loss=0.0914, RMSE=0.3024, R²=0.0158
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2337, R²: 0.0508

============================================================
🔄 Round 42 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 42 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2788, R²=0.0417
   Val:   Loss=0.0790, RMSE=0.2811, R²=0.0452
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2337, R²: 0.0507

============================================================
🔄 Round 43 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 43 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2765, R²=0.0380
   Val:   Loss=0.0842, RMSE=0.2901, R²=0.0617
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2338, R²: 0.0507

============================================================
🔄 Round 46 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 46 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0496
   Val:   Loss=0.0754, RMSE=0.2745, R²=0.0200
============================================================


============================================================
🔄 Round 48 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 48 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2766, R²=0.0503
   Val:   Loss=0.0839, RMSE=0.2897, R²=0.0209
============================================================


============================================================
🔄 Round 49 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 49 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0435
   Val:   Loss=0.0772, RMSE=0.2779, R²=0.0454
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2338, R²: 0.0505

📊 Round 49 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2338, R²: 0.0505

📊 Round 49 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2338, R²: 0.0505

============================================================
🔄 Round 56 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 56 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2806, R²=0.0365
   Val:   Loss=0.0748, RMSE=0.2734, R²=0.0675
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2338, R²: 0.0505

============================================================
🔄 Round 57 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 57 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2770, R²=0.0436
   Val:   Loss=0.0829, RMSE=0.2880, R²=0.0463
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2338, R²: 0.0505

============================================================
🔄 Round 59 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 59 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0554
   Val:   Loss=0.0734, RMSE=0.2709, R²=-0.0063
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2338, R²: 0.0504

============================================================
🔄 Round 63 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 63 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0413
   Val:   Loss=0.0771, RMSE=0.2776, R²=-0.0179
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2338, R²: 0.0503

============================================================
🔄 Round 64 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0673 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0673, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0673, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0673, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0673, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0673, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0673)

============================================================
📊 Round 64 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0391
   Val:   Loss=0.0673, RMSE=0.2594, R²=0.0678
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2338, R²: 0.0503

📊 Round 64 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2339, R²: 0.0503

============================================================
🔄 Round 66 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0655 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0655, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0655, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0655, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0655, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0655, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0655)

============================================================
📊 Round 66 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0400
   Val:   Loss=0.0655, RMSE=0.2559, R²=0.0666
============================================================


============================================================
🔄 Round 69 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0686 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0687, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0687, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0687, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0687, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0688, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0686)

============================================================
📊 Round 69 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0328
   Val:   Loss=0.0686, RMSE=0.2620, R²=0.0693
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2339, R²: 0.0502

📊 Round 69 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2339, R²: 0.0502

============================================================
🔄 Round 72 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 72 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0471
   Val:   Loss=0.0771, RMSE=0.2776, R²=0.0335
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2339, R²: 0.0501

============================================================
🔄 Round 74 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0694 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0694, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0694, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0694, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0694, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0694, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0694)

============================================================
📊 Round 74 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0434
   Val:   Loss=0.0694, RMSE=0.2634, R²=0.0478
============================================================


============================================================
🔄 Round 78 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 78 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0509
   Val:   Loss=0.0756, RMSE=0.2749, R²=0.0175
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2339, R²: 0.0502

============================================================
🔄 Round 80 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 80 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0438
   Val:   Loss=0.0780, RMSE=0.2793, R²=0.0461
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2339, R²: 0.0502

📊 Round 80 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2339, R²: 0.0502

📊 Round 80 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2339, R²: 0.0502

============================================================
🔄 Round 84 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 84 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2762, R²=0.0471
   Val:   Loss=0.0845, RMSE=0.2906, R²=0.0246
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2339, R²: 0.0502

============================================================
🔄 Round 88 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 88 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2772, R²=0.0511
   Val:   Loss=0.0822, RMSE=0.2867, R²=0.0172
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2338, R²: 0.0502

============================================================
🔄 Round 89 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0688 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0688, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0688, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0688, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0688, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0689, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0688)

============================================================
📊 Round 89 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0404
   Val:   Loss=0.0688, RMSE=0.2623, R²=0.0629
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2339, R²: 0.0502

============================================================
🔄 Round 91 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 91 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0464
   Val:   Loss=0.0776, RMSE=0.2786, R²=0.0387
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2339, R²: 0.0502

📊 Round 91 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2339, R²: 0.0501

============================================================
🔄 Round 93 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 93 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=0.0425
   Val:   Loss=0.0821, RMSE=0.2866, R²=0.0537
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2339, R²: 0.0500

============================================================
🔄 Round 97 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 97 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0505
   Val:   Loss=0.0752, RMSE=0.2742, R²=0.0169
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2339, R²: 0.0500

📊 Round 97 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2339, R²: 0.0500

============================================================
🔄 Round 100 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 100 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=0.0475
   Val:   Loss=0.0726, RMSE=0.2694, R²=0.0327
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2339, R²: 0.0500

============================================================
🔄 Round 102 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0694 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0694, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0694, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0694, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0694, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0694, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0694)

============================================================
📊 Round 102 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0417
   Val:   Loss=0.0694, RMSE=0.2635, R²=0.0580
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2339, R²: 0.0499

============================================================
🔄 Round 105 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 105 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0410
   Val:   Loss=0.0755, RMSE=0.2748, R²=0.0592
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2339, R²: 0.0499

============================================================
🔄 Round 106 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 106 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=0.0504
   Val:   Loss=0.0820, RMSE=0.2863, R²=0.0213
============================================================


============================================================
🔄 Round 107 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0660 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0660, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0660, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0660, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0660, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0660, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0660)

============================================================
📊 Round 107 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0497
   Val:   Loss=0.0660, RMSE=0.2570, R²=0.0209
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2339, R²: 0.0499

============================================================
🔄 Round 110 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 110 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=0.0461
   Val:   Loss=0.0810, RMSE=0.2845, R²=0.0351
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2339, R²: 0.0499

============================================================
🔄 Round 111 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 111 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0526
   Val:   Loss=0.0729, RMSE=0.2699, R²=0.0061
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2339, R²: 0.0499

============================================================
🔄 Round 113 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 113 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=0.0506
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0186
============================================================


============================================================
🔄 Round 114 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 114 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2766, R²=0.0410
   Val:   Loss=0.0835, RMSE=0.2890, R²=0.0418
============================================================


============================================================
🔄 Round 116 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 116 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2757, R²=0.0493
   Val:   Loss=0.0856, RMSE=0.2926, R²=0.0291
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2339, R²: 0.0499

============================================================
🔄 Round 125 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 125 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2753, R²=0.0492
   Val:   Loss=0.0864, RMSE=0.2939, R²=0.0106
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2339, R²: 0.0499

============================================================
🔄 Round 127 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 127 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0489
   Val:   Loss=0.0784, RMSE=0.2799, R²=0.0274
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2339, R²: 0.0499

============================================================
🔄 Round 129 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 129 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2764, R²=0.0460
   Val:   Loss=0.0840, RMSE=0.2898, R²=0.0371
============================================================


============================================================
🔄 Round 130 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 130 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2755, R²=0.0480
   Val:   Loss=0.0860, RMSE=0.2932, R²=0.0102
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2339, R²: 0.0500

📊 Round 130 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2339, R²: 0.0500

📊 Round 130 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2339, R²: 0.0500

📊 Round 130 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2339, R²: 0.0500

============================================================
🔄 Round 138 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 138 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0483
   Val:   Loss=0.0753, RMSE=0.2745, R²=0.0162
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2339, R²: 0.0500

============================================================
🔄 Round 141 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 141 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0453
   Val:   Loss=0.0728, RMSE=0.2698, R²=0.0444
============================================================


============================================================
🔄 Round 142 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 142 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=0.0403
   Val:   Loss=0.0820, RMSE=0.2863, R²=0.0587
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2339, R²: 0.0500

============================================================
🔄 Round 143 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0652 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0652, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0652, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0652, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0652, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0652, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0652)

============================================================
📊 Round 143 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0504
   Val:   Loss=0.0652, RMSE=0.2554, R²=0.0162
============================================================


============================================================
🔄 Round 144 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 144 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0507
   Val:   Loss=0.0798, RMSE=0.2825, R²=0.0130
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2339, R²: 0.0500

📊 Round 144 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2339, R²: 0.0500

============================================================
🔄 Round 147 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 147 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2772, R²=0.0384
   Val:   Loss=0.0821, RMSE=0.2866, R²=0.0693
============================================================


============================================================
🔄 Round 149 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 149 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0438
   Val:   Loss=0.0751, RMSE=0.2741, R²=0.0460
============================================================


============================================================
🔄 Round 150 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 150 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0481
   Val:   Loss=0.0738, RMSE=0.2717, R²=0.0301
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2338, R²: 0.0501

📊 Round 150 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2338, R²: 0.0502

📊 Round 150 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2338, R²: 0.0503

📊 Round 150 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2338, R²: 0.0503

📊 Round 150 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2338, R²: 0.0503

============================================================
🔄 Round 158 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 158 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0493
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0269
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2338, R²: 0.0503

============================================================
🔄 Round 159 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 159 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=0.0453
   Val:   Loss=0.0772, RMSE=0.2778, R²=0.0452
============================================================


============================================================
🔄 Round 161 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0711 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0711, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0711, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0711, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0711, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0711, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0711)

============================================================
📊 Round 161 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0431
   Val:   Loss=0.0711, RMSE=0.2667, R²=0.0553
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2338, R²: 0.0503

============================================================
🔄 Round 164 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 164 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0445
   Val:   Loss=0.0753, RMSE=0.2744, R²=0.0453
============================================================


============================================================
🔄 Round 165 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 165 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=0.0393
   Val:   Loss=0.0804, RMSE=0.2836, R²=0.0681
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2338, R²: 0.0503

============================================================
🔄 Round 168 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 168 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0489
   Val:   Loss=0.0785, RMSE=0.2803, R²=0.0058
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2338, R²: 0.0503

============================================================
🔄 Round 170 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 170 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0530
   Val:   Loss=0.0757, RMSE=0.2751, R²=0.0084
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2338, R²: 0.0503

============================================================
🔄 Round 171 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 171 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2765, R²=0.0451
   Val:   Loss=0.0836, RMSE=0.2892, R²=0.0450
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2338, R²: 0.0503

📊 Round 171 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2338, R²: 0.0503

============================================================
🔄 Round 173 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 173 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2765, R²=0.0342
   Val:   Loss=0.0835, RMSE=0.2889, R²=0.0785
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2338, R²: 0.0503

============================================================
🔄 Round 178 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 178 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2760, R²=0.0459
   Val:   Loss=0.0847, RMSE=0.2910, R²=0.0438
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2338, R²: 0.0503

============================================================
🔄 Round 179 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0651 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0651, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0651, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0651, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0651, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0651, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0651)

============================================================
📊 Round 179 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0398
   Val:   Loss=0.0651, RMSE=0.2551, R²=0.0676
============================================================


============================================================
🔄 Round 180 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0719 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0719, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0719, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0719)

============================================================
📊 Round 180 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0367
   Val:   Loss=0.0719, RMSE=0.2681, R²=0.0575
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0744, RMSE: 0.2729, MAE: 0.2338, R²: 0.0504

📊 Round 180 Test Metrics:
   Loss: 0.0744, RMSE: 0.2729, MAE: 0.2338, R²: 0.0504

============================================================
🔄 Round 184 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 184 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=0.0412
   Val:   Loss=0.0807, RMSE=0.2840, R²=0.0607
============================================================


============================================================
🔄 Round 186 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 186 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2765, R²=0.0449
   Val:   Loss=0.0834, RMSE=0.2888, R²=0.0469
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0744, RMSE: 0.2729, MAE: 0.2338, R²: 0.0504

📊 Round 186 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2338, R²: 0.0504

============================================================
🔄 Round 188 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 188 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0487
   Val:   Loss=0.0758, RMSE=0.2753, R²=0.0261
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2338, R²: 0.0504

📊 Round 188 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2338, R²: 0.0504

============================================================
🔄 Round 190 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 190 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0526
   Val:   Loss=0.0733, RMSE=0.2707, R²=0.0138
============================================================


📊 Round 190 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2338, R²: 0.0504

📊 Round 190 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2338, R²: 0.0504

📊 Round 190 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2338, R²: 0.0504

============================================================
🔄 Round 193 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 193 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2801, R²=0.0425
   Val:   Loss=0.0755, RMSE=0.2748, R²=0.0569
============================================================


📊 Round 193 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2338, R²: 0.0504

============================================================
🔄 Round 196 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 196 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2776, R²=0.0485
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0347
============================================================


📊 Round 196 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2338, R²: 0.0504

============================================================
🔄 Round 199 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 199 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0488
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0338
============================================================


============================================================
🔄 Round 201 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 201 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2755, R²=0.0499
   Val:   Loss=0.0857, RMSE=0.2928, R²=0.0304
============================================================


📊 Round 201 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2338, R²: 0.0505

============================================================
🔄 Round 203 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 203 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2759, R²=0.0480
   Val:   Loss=0.0848, RMSE=0.2912, R²=0.0373
============================================================


============================================================
🔄 Round 204 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 204 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=0.0389
   Val:   Loss=0.0770, RMSE=0.2775, R²=0.0702
============================================================


============================================================
🔄 Round 205 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 205 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2763, R²=0.0477
   Val:   Loss=0.0839, RMSE=0.2897, R²=0.0374
============================================================


📊 Round 205 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2338, R²: 0.0505

📊 Round 205 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2338, R²: 0.0505

📊 Round 205 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2338, R²: 0.0505

📊 Round 205 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2338, R²: 0.0506

============================================================
🔄 Round 210 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0707 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0707, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0707, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0707, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0707, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0707, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0707)

============================================================
📊 Round 210 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0425
   Val:   Loss=0.0707, RMSE=0.2659, R²=0.0513
============================================================


📊 Round 210 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2338, R²: 0.0506

============================================================
🔄 Round 211 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 211 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0553
   Val:   Loss=0.0788, RMSE=0.2807, R²=0.0069
============================================================


📊 Round 211 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2338, R²: 0.0507

============================================================
🔄 Round 213 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 213 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=0.0496
   Val:   Loss=0.0769, RMSE=0.2773, R²=0.0261
============================================================


📊 Round 213 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2337, R²: 0.0507

============================================================
🔄 Round 215 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 215 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=0.0501
   Val:   Loss=0.0768, RMSE=0.2772, R²=0.0289
============================================================


📊 Round 215 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2337, R²: 0.0507

============================================================
🔄 Round 217 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 217 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0469
   Val:   Loss=0.0765, RMSE=0.2766, R²=0.0421
============================================================


📊 Round 217 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2337, R²: 0.0508

============================================================
🔄 Round 220 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0680 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0680, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0680, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0680, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0680, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0680, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0680)

============================================================
📊 Round 220 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0457
   Val:   Loss=0.0680, RMSE=0.2607, R²=0.0455
============================================================


============================================================
🔄 Round 223 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 223 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0509
   Val:   Loss=0.0728, RMSE=0.2698, R²=0.0242
============================================================


============================================================
🔄 Round 224 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 224 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0555
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0016
============================================================


📊 Round 224 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2337, R²: 0.0508

============================================================
🔄 Round 225 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 225 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2790, R²=0.0509
   Val:   Loss=0.0779, RMSE=0.2791, R²=0.0138
============================================================


📊 Round 225 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2337, R²: 0.0508

📊 Round 225 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2337, R²: 0.0508

============================================================
🔄 Round 230 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 230 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0460
   Val:   Loss=0.0730, RMSE=0.2701, R²=0.0285
============================================================


📊 Round 230 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2337, R²: 0.0508

============================================================
🔄 Round 234 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 234 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=0.0411
   Val:   Loss=0.0737, RMSE=0.2714, R²=0.0664
============================================================


============================================================
🔄 Round 235 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 235 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0417
   Val:   Loss=0.0746, RMSE=0.2732, R²=0.0642
============================================================


📊 Round 235 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2337, R²: 0.0508

============================================================
🔄 Round 236 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0627 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0627, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0627, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0627, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0627, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0627, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0627)

============================================================
📊 Round 236 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0417
   Val:   Loss=0.0627, RMSE=0.2503, R²=0.0453
============================================================


📊 Round 236 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2337, R²: 0.0508

📊 Round 236 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2337, R²: 0.0508

============================================================
🔄 Round 239 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 239 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0445
   Val:   Loss=0.0781, RMSE=0.2794, R²=0.0525
============================================================


📊 Round 239 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2337, R²: 0.0508

============================================================
🔄 Round 243 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 243 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0431
   Val:   Loss=0.0779, RMSE=0.2792, R²=0.0578
============================================================


📊 Round 243 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2337, R²: 0.0508

============================================================
🔄 Round 244 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 244 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=0.0418
   Val:   Loss=0.0737, RMSE=0.2715, R²=0.0579
============================================================


============================================================
🔄 Round 245 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0690 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0690, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0690, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0690, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0690, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0691, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0690)

============================================================
📊 Round 245 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0416
   Val:   Loss=0.0690, RMSE=0.2628, R²=0.0603
============================================================


📊 Round 245 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2337, R²: 0.0508

📊 Round 245 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2337, R²: 0.0508

============================================================
🔄 Round 248 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 248 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2764, R²=0.0500
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0315
============================================================


📊 Round 248 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2337, R²: 0.0508

============================================================
🔄 Round 251 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0714 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0714, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0714, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0714, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0714, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0714, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0714)

============================================================
📊 Round 251 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0339
   Val:   Loss=0.0714, RMSE=0.2673, R²=0.0953
============================================================


📊 Round 251 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2337, R²: 0.0508

============================================================
🔄 Round 260 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 260 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0505
   Val:   Loss=0.0734, RMSE=0.2709, R²=0.0268
============================================================


📊 Round 260 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2337, R²: 0.0509

============================================================
🔄 Round 261 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 261 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2774, R²=0.0378
   Val:   Loss=0.0812, RMSE=0.2850, R²=0.0700
============================================================


============================================================
🔄 Round 265 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 265 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0415
   Val:   Loss=0.0790, RMSE=0.2811, R²=0.0617
============================================================


============================================================
🔄 Round 266 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 266 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2770, R²=0.0452
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0501
============================================================


📊 Round 266 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2337, R²: 0.0509

============================================================
🔄 Round 268 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0694 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0694, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0694, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0694, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0694, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0694, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0694)

============================================================
📊 Round 268 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0426
   Val:   Loss=0.0694, RMSE=0.2634, R²=0.0518
============================================================


📊 Round 268 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2337, R²: 0.0509

============================================================
🔄 Round 269 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 269 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0530
   Val:   Loss=0.0775, RMSE=0.2785, R²=0.0120
============================================================


📊 Round 269 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2337, R²: 0.0509

📊 Round 269 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2337, R²: 0.0509

📊 Round 269 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2337, R²: 0.0509

📊 Round 269 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2337, R²: 0.0509

📊 Round 269 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2337, R²: 0.0509

============================================================
🔄 Round 275 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 275 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2753, R²=0.0495
   Val:   Loss=0.0858, RMSE=0.2929, R²=0.0340
============================================================


============================================================
🔄 Round 277 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 277 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=0.0493
   Val:   Loss=0.0762, RMSE=0.2760, R²=0.0334
============================================================


📊 Round 277 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2337, R²: 0.0509

📊 Round 277 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2337, R²: 0.0509

============================================================
🔄 Round 281 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 281 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0493
   Val:   Loss=0.0754, RMSE=0.2745, R²=0.0247
============================================================


============================================================
🔄 Round 284 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0711 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0711, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0711, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0711, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0711, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0711, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0711)

============================================================
📊 Round 284 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0481
   Val:   Loss=0.0711, RMSE=0.2667, R²=0.0373
============================================================


📊 Round 284 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2337, R²: 0.0509

============================================================
🔄 Round 286 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 286 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2762, R²=0.0478
   Val:   Loss=0.0839, RMSE=0.2896, R²=0.0356
============================================================


📊 Round 286 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2337, R²: 0.0509

============================================================
🔄 Round 289 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 289 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0495
   Val:   Loss=0.0734, RMSE=0.2709, R²=0.0281
============================================================


📊 Round 289 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2337, R²: 0.0509

============================================================
🔄 Round 291 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 291 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0426
   Val:   Loss=0.0773, RMSE=0.2781, R²=0.0532
============================================================


============================================================
🔄 Round 293 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 293 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2788, R²=0.0427
   Val:   Loss=0.0780, RMSE=0.2792, R²=0.0566
============================================================


============================================================
🔄 Round 295 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0751, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0751, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0751, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0751, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0751, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0751, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 295 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0751, RMSE=0.2740, R²=0.0477
   Val:   Loss=0.0886, RMSE=0.2976, R²=0.0380
============================================================


📊 Round 295 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2337, R²: 0.0510

============================================================
🔄 Round 297 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 297 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0483
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0374
============================================================


============================================================
🔄 Round 299 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 299 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0456
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0437
============================================================


============================================================
🔄 Round 300 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 300 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2776, R²=0.0539
   Val:   Loss=0.0808, RMSE=0.2842, R²=0.0159
============================================================


============================================================
🔄 Round 301 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 301 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2774, R²=0.0464
   Val:   Loss=0.0812, RMSE=0.2849, R²=0.0463
============================================================


📊 Round 301 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2337, R²: 0.0511

============================================================
🔄 Round 302 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 302 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2764, R²=0.0475
   Val:   Loss=0.0835, RMSE=0.2889, R²=0.0422
============================================================


============================================================
🔄 Round 303 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 303 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0511
   Val:   Loss=0.0758, RMSE=0.2753, R²=0.0270
============================================================


============================================================
🔄 Round 306 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 306 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2790, R²=0.0560
   Val:   Loss=0.0776, RMSE=0.2786, R²=-0.0128
============================================================


📊 Round 306 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2337, R²: 0.0511

============================================================
🔄 Round 308 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 308 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2762, R²=0.0521
   Val:   Loss=0.0837, RMSE=0.2893, R²=0.0255
============================================================


============================================================
🔄 Round 309 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 309 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2770, R²=0.0466
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0418
============================================================


📊 Round 309 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2337, R²: 0.0512

📊 Round 309 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2337, R²: 0.0512

============================================================
🔄 Round 312 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 312 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2765, R²=0.0410
   Val:   Loss=0.0832, RMSE=0.2884, R²=0.0635
============================================================


============================================================
🔄 Round 314 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 314 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2774, R²=0.0431
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0507
============================================================


📊 Round 314 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2337, R²: 0.0512

============================================================
🔄 Round 317 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 317 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=0.0475
   Val:   Loss=0.0803, RMSE=0.2833, R²=0.0388
============================================================


============================================================
🔄 Round 319 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 319 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2785, R²=0.0496
   Val:   Loss=0.0786, RMSE=0.2803, R²=0.0344
============================================================


📊 Round 319 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2337, R²: 0.0513

============================================================
🔄 Round 320 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 320 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0432
   Val:   Loss=0.0752, RMSE=0.2742, R²=0.0588
============================================================


📊 Round 320 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2336, R²: 0.0513

============================================================
🔄 Round 324 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 324 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=0.0433
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0290
============================================================


📊 Round 324 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2336, R²: 0.0513

📊 Round 324 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2336, R²: 0.0513

============================================================
🔄 Round 328 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0719 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0719, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0719, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0719, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0719)

============================================================
📊 Round 328 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0365
   Val:   Loss=0.0719, RMSE=0.2681, R²=0.0849
============================================================


📊 Round 328 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2336, R²: 0.0514

============================================================
🔄 Round 331 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 331 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2775, R²=0.0403
   Val:   Loss=0.0808, RMSE=0.2842, R²=0.0575
============================================================


📊 Round 331 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2336, R²: 0.0514

============================================================
🔄 Round 332 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0652 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0652, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0652, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0652, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0652, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0652, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0652)

============================================================
📊 Round 332 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0440
   Val:   Loss=0.0652, RMSE=0.2554, R²=0.0568
============================================================


============================================================
🔄 Round 333 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 333 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2772, R²=0.0390
   Val:   Loss=0.0815, RMSE=0.2856, R²=0.0748
============================================================


============================================================
🔄 Round 334 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 334 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2783, R²=0.0396
   Val:   Loss=0.0791, RMSE=0.2812, R²=0.0587
============================================================


📊 Round 334 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2336, R²: 0.0514

============================================================
🔄 Round 337 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 337 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=0.0502
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0337
============================================================


📊 Round 337 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2336, R²: 0.0514

📊 Round 337 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2336, R²: 0.0514

============================================================
🔄 Round 340 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 340 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=0.0476
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0419
============================================================


📊 Round 340 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2336, R²: 0.0514

📊 Round 340 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2336, R²: 0.0513

============================================================
🔄 Round 344 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 344 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2801, R²=0.0430
   Val:   Loss=0.0751, RMSE=0.2740, R²=0.0548
============================================================


============================================================
🔄 Round 345 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 345 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0447
   Val:   Loss=0.0753, RMSE=0.2744, R²=0.0297
============================================================


📊 Round 345 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2336, R²: 0.0513

📊 Round 345 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2336, R²: 0.0513

📊 Round 345 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2336, R²: 0.0513

============================================================
🔄 Round 351 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 351 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=0.0486
   Val:   Loss=0.0755, RMSE=0.2748, R²=0.0389
============================================================


📊 Round 351 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2336, R²: 0.0513

============================================================
🔄 Round 352 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 352 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0401
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.0470
============================================================


📊 Round 352 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2336, R²: 0.0513

============================================================
🔄 Round 354 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 354 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0532
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0022
============================================================


📊 Round 354 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2336, R²: 0.0512

📊 Round 354 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2336, R²: 0.0512

============================================================
🔄 Round 360 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 360 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0459
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.0498
============================================================


📊 Round 360 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2336, R²: 0.0512

📊 Round 360 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2336, R²: 0.0512

============================================================
🔄 Round 363 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0754, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0754, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0754, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0753, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 363 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2749, R²=0.0438
   Val:   Loss=0.0865, RMSE=0.2941, R²=0.0501
============================================================


📊 Round 363 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2336, R²: 0.0512

📊 Round 363 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2336, R²: 0.0512

============================================================
🔄 Round 368 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 368 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2755, R²=0.0487
   Val:   Loss=0.0851, RMSE=0.2918, R²=0.0388
============================================================


📊 Round 368 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2336, R²: 0.0512

📊 Round 368 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2336, R²: 0.0513

📊 Round 368 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2336, R²: 0.0513

============================================================
🔄 Round 371 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 371 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0420
   Val:   Loss=0.0776, RMSE=0.2786, R²=0.0660
============================================================


============================================================
🔄 Round 372 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 372 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2783, R²=0.0418
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0659
============================================================


📊 Round 372 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2336, R²: 0.0514

📊 Round 372 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2336, R²: 0.0514

📊 Round 372 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2336, R²: 0.0514

📊 Round 372 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2336, R²: 0.0514

📊 Round 372 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2336, R²: 0.0513

============================================================
🔄 Round 380 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0702 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0702, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0702, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0702, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0702, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0702, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0702)

============================================================
📊 Round 380 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0427
   Val:   Loss=0.0702, RMSE=0.2649, R²=0.0567
============================================================


============================================================
🔄 Round 382 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 382 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0513
   Val:   Loss=0.0751, RMSE=0.2741, R²=0.0254
============================================================


📊 Round 382 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2336, R²: 0.0514

============================================================
🔄 Round 384 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 384 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2758, R²=0.0477
   Val:   Loss=0.0846, RMSE=0.2909, R²=0.0436
============================================================


============================================================
🔄 Round 386 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 386 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2759, R²=0.0511
   Val:   Loss=0.0843, RMSE=0.2904, R²=0.0258
============================================================


============================================================
🔄 Round 387 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 387 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=0.0494
   Val:   Loss=0.0798, RMSE=0.2825, R²=0.0053
============================================================


📊 Round 387 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2336, R²: 0.0514

============================================================
🔄 Round 388 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 388 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2775, R²=0.0419
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0650
============================================================


============================================================
🔄 Round 389 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0703 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0703, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0703, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0703, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0702, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0702, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0703)

============================================================
📊 Round 389 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0444
   Val:   Loss=0.0703, RMSE=0.2651, R²=0.0437
============================================================


📊 Round 389 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2336, R²: 0.0514

📊 Round 389 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2336, R²: 0.0515

📊 Round 389 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2336, R²: 0.0515

============================================================
🔄 Round 397 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0700 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0700, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0700, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0700, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0700, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0700, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0700)

============================================================
📊 Round 397 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0544
   Val:   Loss=0.0700, RMSE=0.2647, R²=0.0120
============================================================


📊 Round 397 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2336, R²: 0.0515

============================================================
🔄 Round 399 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 399 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=0.0484
   Val:   Loss=0.0753, RMSE=0.2745, R²=0.0398
============================================================


📊 Round 399 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2336, R²: 0.0514

============================================================
🔄 Round 400 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0705 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0705, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0705, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0705, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0705, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0705, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0705)

============================================================
📊 Round 400 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2820, R²=0.0435
   Val:   Loss=0.0705, RMSE=0.2656, R²=0.0611
============================================================


📊 Round 400 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2336, R²: 0.0515

============================================================
🔄 Round 404 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 404 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2785, R²=0.0518
   Val:   Loss=0.0785, RMSE=0.2801, R²=0.0232
============================================================


📊 Round 404 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2336, R²: 0.0515

============================================================
🔄 Round 406 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 406 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2799, R²=0.0402
   Val:   Loss=0.0753, RMSE=0.2744, R²=0.0717
============================================================


📊 Round 406 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2336, R²: 0.0515

============================================================
🔄 Round 407 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 407 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2776, R²=0.0484
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0413
============================================================


📊 Round 407 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2336, R²: 0.0516

============================================================
🔄 Round 408 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0717, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0717, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0717, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0717, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 408 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0548
   Val:   Loss=0.0717, RMSE=0.2678, R²=0.0055
============================================================


📊 Round 408 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2336, R²: 0.0516

📊 Round 408 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2336, R²: 0.0516

============================================================
🔄 Round 410 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 410 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0511
   Val:   Loss=0.0772, RMSE=0.2778, R²=0.0293
============================================================


============================================================
🔄 Round 412 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 412 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=0.0469
   Val:   Loss=0.0734, RMSE=0.2709, R²=0.0476
============================================================


📊 Round 412 Test Metrics:
   Loss: 0.0743, RMSE: 0.2727, MAE: 0.2336, R²: 0.0517

============================================================
🔄 Round 415 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0750, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0750, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0750, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0750, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0750, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0750, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 415 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0750, RMSE=0.2739, R²=0.0541
   Val:   Loss=0.0885, RMSE=0.2975, R²=0.0174
============================================================


============================================================
🔄 Round 416 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 416 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=0.0472
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.0412
============================================================


📊 Round 416 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2336, R²: 0.0518

============================================================
🔄 Round 419 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 419 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2764, R²=0.0523
   Val:   Loss=0.0831, RMSE=0.2883, R²=0.0277
============================================================


📊 Round 419 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2336, R²: 0.0518

============================================================
🔄 Round 421 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 421 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2775, R²=0.0473
   Val:   Loss=0.0807, RMSE=0.2840, R²=0.0435
============================================================


============================================================
🔄 Round 422 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 422 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2774, R²=0.0501
   Val:   Loss=0.0808, RMSE=0.2842, R²=0.0276
============================================================


📊 Round 422 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2336, R²: 0.0518

============================================================
🔄 Round 423 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 423 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0522
   Val:   Loss=0.0781, RMSE=0.2794, R²=0.0182
============================================================


📊 Round 423 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2336, R²: 0.0518

============================================================
🔄 Round 424 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 424 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2752, R²=0.0554
   Val:   Loss=0.0857, RMSE=0.2927, R²=0.0169
============================================================


============================================================
🔄 Round 425 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 425 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0502
   Val:   Loss=0.0766, RMSE=0.2768, R²=0.0185
============================================================


📊 Round 425 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2336, R²: 0.0518

============================================================
🔄 Round 426 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0755, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0755, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0755, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0755, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0755, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0755, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 426 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0754, RMSE=0.2745, R²=0.0461
   Val:   Loss=0.0872, RMSE=0.2953, R²=0.0436
============================================================


📊 Round 426 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2336, R²: 0.0518

📊 Round 426 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2336, R²: 0.0518

📊 Round 426 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2336, R²: 0.0518

📊 Round 426 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2336, R²: 0.0518

📊 Round 426 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2336, R²: 0.0518

============================================================
🔄 Round 433 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0751, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0751, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0751, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0751, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0751, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0751, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 433 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0752, RMSE=0.2742, R²=0.0465
   Val:   Loss=0.0879, RMSE=0.2964, R²=0.0441
============================================================


📊 Round 433 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2336, R²: 0.0519

============================================================
🔄 Round 434 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 434 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=0.0539
   Val:   Loss=0.0810, RMSE=0.2845, R²=0.0208
============================================================


📊 Round 434 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2336, R²: 0.0518

📊 Round 434 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2336, R²: 0.0518

============================================================
🔄 Round 437 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0710 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0710, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0710, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0710, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0710, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0710, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0710)

============================================================
📊 Round 437 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0434
   Val:   Loss=0.0710, RMSE=0.2664, R²=0.0630
============================================================


📊 Round 437 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2336, R²: 0.0519

📊 Round 437 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2336, R²: 0.0519

📊 Round 437 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2336, R²: 0.0519

============================================================
🔄 Round 441 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 441 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=0.0405
   Val:   Loss=0.0747, RMSE=0.2733, R²=0.0748
============================================================


============================================================
🔄 Round 444 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 444 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2785, R²=0.0396
   Val:   Loss=0.0783, RMSE=0.2798, R²=0.0705
============================================================


📊 Round 444 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2335, R²: 0.0519

============================================================
🔄 Round 446 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 446 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0546
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.0090
============================================================


============================================================
🔄 Round 447 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 447 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2770, R²=0.0368
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0837
============================================================


============================================================
🔄 Round 448 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 448 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2790, R²=0.0567
   Val:   Loss=0.0773, RMSE=0.2780, R²=-0.0122
============================================================


============================================================
🔄 Round 450 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 450 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2772, R²=0.0446
   Val:   Loss=0.0811, RMSE=0.2849, R²=0.0579
============================================================


============================================================
🔄 Round 451 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 451 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2764, R²=0.0513
   Val:   Loss=0.0829, RMSE=0.2880, R²=0.0278
============================================================


📊 Round 451 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2335, R²: 0.0521

📊 Round 451 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2335, R²: 0.0521

============================================================
🔄 Round 453 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 453 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2779, R²=0.0521
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0259
============================================================


📊 Round 453 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2335, R²: 0.0522

============================================================
🔄 Round 454 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 454 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2799, R²=0.0405
   Val:   Loss=0.0751, RMSE=0.2741, R²=0.0649
============================================================


============================================================
🔄 Round 455 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0676 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0676, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0676, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0676, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0676, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0676, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0676)

============================================================
📊 Round 455 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0494
   Val:   Loss=0.0676, RMSE=0.2601, R²=0.0294
============================================================


📊 Round 455 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2335, R²: 0.0522

============================================================
🔄 Round 456 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 456 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0448
   Val:   Loss=0.0758, RMSE=0.2753, R²=0.0571
============================================================


📊 Round 456 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2335, R²: 0.0522

📊 Round 456 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2335, R²: 0.0522

📊 Round 456 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2335, R²: 0.0522

📊 Round 456 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2335, R²: 0.0522

============================================================
🔄 Round 460 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 460 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2783, R²=0.0433
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0584
============================================================


📊 Round 460 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2335, R²: 0.0522

============================================================
🔄 Round 461 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 461 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2790, R²=0.0562
   Val:   Loss=0.0772, RMSE=0.2779, R²=0.0104
============================================================


📊 Round 461 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2335, R²: 0.0522

============================================================
🔄 Round 462 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0683 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0683, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0683, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0683, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0683, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0684, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0683)

============================================================
📊 Round 462 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0486
   Val:   Loss=0.0683, RMSE=0.2614, R²=0.0380
============================================================


📊 Round 462 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2335, R²: 0.0522

============================================================
🔄 Round 463 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 463 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2806, R²=0.0459
   Val:   Loss=0.0735, RMSE=0.2711, R²=0.0538
============================================================


============================================================
🔄 Round 465 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 465 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=0.0439
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0607
============================================================


============================================================
🔄 Round 467 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 467 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0431
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0630
============================================================


📊 Round 467 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2335, R²: 0.0522

📊 Round 467 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2335, R²: 0.0522

============================================================
🔄 Round 470 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 470 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=0.0505
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0357
============================================================


📊 Round 470 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2335, R²: 0.0522

📊 Round 470 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2335, R²: 0.0522

📊 Round 470 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2335, R²: 0.0522

============================================================
🔄 Round 473 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0706 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0706, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0706, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0706, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0706, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0706, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0706)

============================================================
📊 Round 473 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0470
   Val:   Loss=0.0706, RMSE=0.2656, R²=0.0470
============================================================


📊 Round 473 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2335, R²: 0.0522

============================================================
🔄 Round 475 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 475 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0438
   Val:   Loss=0.0765, RMSE=0.2766, R²=0.0609
============================================================


📊 Round 475 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2335, R²: 0.0522

============================================================
🔄 Round 477 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 477 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2764, R²=0.0534
   Val:   Loss=0.0829, RMSE=0.2880, R²=0.0255
============================================================


============================================================
🔄 Round 478 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 478 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0451
   Val:   Loss=0.0734, RMSE=0.2710, R²=0.0557
============================================================


📊 Round 478 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2335, R²: 0.0523

============================================================
🔄 Round 479 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 479 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0752, RMSE=0.2742, R²=0.0516
   Val:   Loss=0.0879, RMSE=0.2964, R²=0.0325
============================================================


📊 Round 479 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2335, R²: 0.0523

============================================================
🔄 Round 480 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 480 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2766, R²=0.0490
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0233
============================================================


============================================================
🔄 Round 481 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0725, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 481 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0415
   Val:   Loss=0.0725, RMSE=0.2693, R²=0.0669
============================================================


📊 Round 481 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2335, R²: 0.0523

============================================================
🔄 Round 482 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 482 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2794, R²=0.0440
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.0534
============================================================


📊 Round 482 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2335, R²: 0.0523

📊 Round 482 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2335, R²: 0.0523

📊 Round 482 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2335, R²: 0.0523

📊 Round 482 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2335, R²: 0.0523

============================================================
🔄 Round 490 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 490 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2766, R²=0.0528
   Val:   Loss=0.0824, RMSE=0.2870, R²=0.0272
============================================================


============================================================
🔄 Round 491 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0698 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0698, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0698, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0698, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0698, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0699, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0698)

============================================================
📊 Round 491 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0518
   Val:   Loss=0.0698, RMSE=0.2642, R²=-0.0048
============================================================


📊 Round 491 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2335, R²: 0.0523

============================================================
🔄 Round 495 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 495 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2772, R²=0.0442
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0598
============================================================


📊 Round 495 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2335, R²: 0.0523

📊 Round 495 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2335, R²: 0.0523

============================================================
🔄 Round 497 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0714 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0714, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0714, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0714, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0714, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0714, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0714)

============================================================
📊 Round 497 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0573
   Val:   Loss=0.0714, RMSE=0.2671, R²=0.0007
============================================================


============================================================
🔄 Round 498 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0698 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0698, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0698, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0698, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0698, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0698, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0698)

============================================================
📊 Round 498 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2822, R²=0.0484
   Val:   Loss=0.0698, RMSE=0.2642, R²=0.0444
============================================================


📊 Round 498 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2335, R²: 0.0523

============================================================
🔄 Round 501 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 501 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0525
   Val:   Loss=0.0752, RMSE=0.2743, R²=0.0249
============================================================


============================================================
🔄 Round 502 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 502 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2799, R²=0.0471
   Val:   Loss=0.0750, RMSE=0.2739, R²=0.0499
============================================================


📊 Round 502 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2335, R²: 0.0523

============================================================
🔄 Round 507 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0739, val=0.0931 (↓), lr=0.000001
   • Epoch   2/100: train=0.0739, val=0.0931, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0739, val=0.0931, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0739, val=0.0931, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0739, val=0.0931, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0738, val=0.0931, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0931)

============================================================
📊 Round 507 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0738, RMSE=0.2717, R²=0.0553
   Val:   Loss=0.0931, RMSE=0.3052, R²=0.0218
============================================================


============================================================
🔄 Round 508 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0713 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0713, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0713, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0713, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0713, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0713, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 508 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0466
   Val:   Loss=0.0713, RMSE=0.2671, R²=0.0512
============================================================


📊 Round 508 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2335, R²: 0.0523

📊 Round 508 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2335, R²: 0.0523

============================================================
🔄 Round 510 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 510 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2764, R²=0.0432
   Val:   Loss=0.0830, RMSE=0.2880, R²=0.0639
============================================================


============================================================
🔄 Round 511 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 511 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0448
   Val:   Loss=0.0792, RMSE=0.2815, R²=0.0573
============================================================


📊 Round 511 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2335, R²: 0.0524

============================================================
🔄 Round 518 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 518 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0404
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0716
============================================================


============================================================
🔄 Round 519 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 519 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2761, R²=0.0547
   Val:   Loss=0.0835, RMSE=0.2890, R²=0.0074
============================================================


📊 Round 519 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2335, R²: 0.0524

📊 Round 519 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2335, R²: 0.0524

============================================================
🔄 Round 524 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 524 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2758, R²=0.0533
   Val:   Loss=0.0842, RMSE=0.2902, R²=0.0067
============================================================


📊 Round 524 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2335, R²: 0.0524

============================================================
🔄 Round 526 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 526 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0370
   Val:   Loss=0.0745, RMSE=0.2729, R²=0.0869
============================================================


📊 Round 526 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2335, R²: 0.0523

============================================================
🔄 Round 529 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0755, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 529 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2752, R²=0.0484
   Val:   Loss=0.0855, RMSE=0.2924, R²=0.0441
============================================================


============================================================
🔄 Round 531 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 531 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2763, R²=0.0607
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0057
============================================================


📊 Round 531 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2335, R²: 0.0523

============================================================
🔄 Round 532 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 532 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0506
   Val:   Loss=0.0734, RMSE=0.2710, R²=0.0306
============================================================


============================================================
🔄 Round 533 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 533 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0364
   Val:   Loss=0.0724, RMSE=0.2690, R²=0.0910
============================================================


============================================================
🔄 Round 534 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 534 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2776, R²=0.0387
   Val:   Loss=0.0801, RMSE=0.2831, R²=0.0246
============================================================


📊 Round 534 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2335, R²: 0.0523

============================================================
🔄 Round 535 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 535 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2752, R²=0.0562
   Val:   Loss=0.0854, RMSE=0.2923, R²=0.0149
============================================================


============================================================
🔄 Round 536 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 536 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0378
   Val:   Loss=0.0812, RMSE=0.2850, R²=0.0817
============================================================


============================================================
🔄 Round 537 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 537 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0507
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0229
============================================================


📊 Round 537 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2335, R²: 0.0523

📊 Round 537 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2335, R²: 0.0523

============================================================
🔄 Round 541 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 541 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=0.0457
   Val:   Loss=0.0809, RMSE=0.2845, R²=0.0465
============================================================


📊 Round 541 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2335, R²: 0.0523

📊 Round 541 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2335, R²: 0.0523

============================================================
🔄 Round 547 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 547 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2769, R²=0.0378
   Val:   Loss=0.0819, RMSE=0.2861, R²=0.0760
============================================================


📊 Round 547 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2335, R²: 0.0522

============================================================
🔄 Round 550 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 550 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0430
   Val:   Loss=0.0720, RMSE=0.2684, R²=0.0682
============================================================


============================================================
🔄 Round 551 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 551 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0503
   Val:   Loss=0.0813, RMSE=0.2852, R²=-0.0017
============================================================


📊 Round 551 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2335, R²: 0.0522

📊 Round 551 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2335, R²: 0.0523

============================================================
🔄 Round 556 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 556 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2792, R²=0.0343
   Val:   Loss=0.0765, RMSE=0.2767, R²=0.0938
============================================================


============================================================
🔄 Round 557 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 557 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2767, R²=0.0562
   Val:   Loss=0.0821, RMSE=0.2866, R²=0.0146
============================================================


📊 Round 557 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2335, R²: 0.0523

============================================================
🔄 Round 560 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 560 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0474
   Val:   Loss=0.0735, RMSE=0.2711, R²=0.0494
============================================================


📊 Round 560 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2335, R²: 0.0524

============================================================
🔄 Round 563 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 563 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0532
   Val:   Loss=0.0735, RMSE=0.2711, R²=0.0205
============================================================


📊 Round 563 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2335, R²: 0.0524

📊 Round 563 Test Metrics:
   Loss: 0.0743, RMSE: 0.2725, MAE: 0.2335, R²: 0.0525

============================================================
🔄 Round 566 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0681 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0681, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0681, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0681, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0681, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0682, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0681)

============================================================
📊 Round 566 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0420
   Val:   Loss=0.0681, RMSE=0.2610, R²=0.0475
============================================================


📊 Round 566 Test Metrics:
   Loss: 0.0743, RMSE: 0.2725, MAE: 0.2335, R²: 0.0525

============================================================
🔄 Round 568 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0699 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0699, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0699, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0699, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0699, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0699, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0699)

============================================================
📊 Round 568 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0511
   Val:   Loss=0.0699, RMSE=0.2645, R²=0.0250
============================================================


📊 Round 568 Test Metrics:
   Loss: 0.0743, RMSE: 0.2725, MAE: 0.2335, R²: 0.0525

============================================================
🔄 Round 570 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0707 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0707, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0707, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0707, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0707, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0707, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0707)

============================================================
📊 Round 570 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0374
   Val:   Loss=0.0707, RMSE=0.2658, R²=0.0896
============================================================


============================================================
🔄 Round 571 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 571 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2766, R²=0.0569
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0026
============================================================


============================================================
🔄 Round 572 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 572 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0508
   Val:   Loss=0.0756, RMSE=0.2749, R²=0.0187
============================================================


📊 Round 572 Test Metrics:
   Loss: 0.0743, RMSE: 0.2725, MAE: 0.2335, R²: 0.0525

============================================================
🔄 Round 574 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0695 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0695, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0695, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0695, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0695, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0695, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0695)

============================================================
📊 Round 574 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0517
   Val:   Loss=0.0695, RMSE=0.2636, R²=0.0270
============================================================


❌ Client client_6 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8688 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8688 {grpc_status:14, grpc_message:"Socket closed"}"
>
