[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4fc2a2ea-5a28-42b6-bd0a-7581c505d211
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3443a7f-19f2-4b05-ad1f-03e3d0b481e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97781f6a-20c0-4bee-8434-b2e2ca043e04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb94e6d0-44ac-4233-aee9-6e37d4b86d0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 948552b3-bd42-4b7c-9ceb-c1f1e2b90ce2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0a2a86d-13d3-4ccf-bd18-84506cbb2943
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5106f1f6-9761-4c79-a26c-dc088b272c41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49963b36-3d8f-4293-b193-d97cb01d8a98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d4c7353-a65c-4a2e-a1f2-91311691e4e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89b7cea7-ea5a-4da7-bddc-c827bf1e8af5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29ce369b-6366-47be-8a48-bc9838816baa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 450620df-4e4b-4f98-9805-06bac5845932
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd3d4b7c-c5a9-45a8-8b76-14976182f4d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f8b86a3-b2e4-48e5-81e4-70350d5b993d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 215e5dac-1f4b-4f85-be4e-8d69da30cebb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c5fd246-5f29-432a-b2be-d4a2bad83acf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 668e99bb-7a6b-4ef7-8f37-34144f43e1e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bbcd5fb0-d286-46ec-b98b-d49fe76a6193
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9891fe5-b37f-4c11-b70d-0b75abec996f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a9779f9-a362-4783-98ab-d720c431b08a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17cd50c8-f7c3-46c0-a1b3-88372f1ec573
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0d3baf1-e003-4dab-a9f7-23aad8249b57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41037341-8dcd-43c3-965f-3f702cf513f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 105ba610-ff09-4403-b22b-47a6a8459133
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4b7af76-1122-426c-af9c-469d61c3d0f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3989790-5da4-4dbd-8a96-cc7b8fe63883
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 689f5c2e-6d0f-4927-a794-9e246a6bb9aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d3c166b-1046-4477-9d26-a4074e3337ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1320d57f-c84f-4e55-81cb-436173ead4eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3bc0cc3-bd4c-4cc2-9f8c-9a9fcf78a851
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0eea1348-3b52-4113-b3b8-1dee2911dcf6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 838d679f-030e-4e74-84be-6e364469842b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d2295fb-d821-43be-9d4a-d46483583404
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8bf803e7-ef29-4432-a094-d8cdb469cc4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f29b27b4-5372-4de1-a118-f1846955ef09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23205cfa-a169-4d65-98eb-ca137c2ff04e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 635533a8-df9e-49d1-bfdb-4d2b249cddb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d86f479c-0117-4dba-a661-0b2844a5faee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b04d645-250b-44ca-b165-d2a6758be0df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 129d588b-32bd-4dbd-a97e-f0b7c8c89716
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45f83de0-e81f-4bb9-a856-f5f6ed9cd053
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f60fc6d-45bc-4638-9687-48f474521b2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aec62fa7-a00d-41c6-9d18-965ca1ab9e9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f8bda8f-e73d-4fc1-9d04-fb01e9d50bcd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60f157b0-d60f-40dd-97a7-12b0a35ce605
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5f7aee5-aad4-4e79-b76f-8303b407bf54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8fbcb7ec-3c30-44fc-adbd-e22b96a29dd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d04fa9d4-762b-4e17-81c8-eada077f6bb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f593182-80ce-49c9-9adc-4e658bc98056
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6a30c6b-1359-4c88-a89a-8f8a47abcb57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f874e89-aaaa-4722-9891-423a173b2860
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4bd65037-327a-4db6-bf20-aa9a11cf3d92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0f15ba4-7159-4fab-a658-c184a6b14784
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d173730-9950-4628-8f14-f8f2cdaecc46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 558928bb-54f0-4a02-adc1-25dcd81a9c12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8d98bc8-c90d-4a6c-9f38-db06381e055e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c6738d3-bf8b-481c-9385-178a9fb1484a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03f9a5ed-2869-47aa-b64d-5b18d7672a28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0c7e327-c2c7-4f44-ab76-c86b27cdf84c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ebae3240-6e1e-46aa-8f3e-2713df404065
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0bf87f1-b4c7-49a3-ae4e-d01ad2cb01d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0aced38-ae34-4e57-962b-381d2ca2637c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b96af9d9-0963-4329-87b9-7dc71a674990
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 830b8b8c-54cb-4a86-9d96-57e87017ca6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d5168ab-9787-473a-91f2-42d13be8bbbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8229a1b-81ec-4a6a-b82d-cdf0bf00a3be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e36407c3-0136-4e45-b302-5786a73c050f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e927fc5-93ed-4d64-8f39-b5248829df7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8af706eb-ecad-4aac-bcf3-4aa7870c06ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1ee08be-159f-4085-b7c6-2a550f41bfef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 190bfdc3-7a1f-4ef1-a5e2-081f06849d87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77339d3e-6562-4d72-85fe-db2ff1d44ddf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3061dae7-7535-4fad-9085-09be6548d30c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6dfcf9a3-9559-42e1-9dba-22b118c0a6fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa752e77-3cdf-482c-86b3-86c838a71824
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11b8d19f-4ec6-4bb4-b216-daa2c5f4ac1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45f2a06a-40fc-4fd0-be45-b89c1215038b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53b329ae-3fe8-4a74-a4ed-b3acd8d8e6fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73c79338-8f56-4733-8776-eefdb8fc882f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc4b967f-7aab-45d7-96c1-5620c0f18431
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90cc18a6-d90b-4dc3-83b4-4fd4a78dd2a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6afdc730-92f8-461f-96a4-29ecd0a709f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d422bec3-1176-44f1-a946-801c167e6a5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c75f3d0-d251-4f0b-a60c-47b592d8569d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3f90d1a-a238-4d8c-b47c-74829f5d2831
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b988817-a0f5-4b48-b84d-d251e17c9429
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b912dfa-9ae3-4b45-b48e-ef46a9e43028
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 899d1fab-870e-4f79-899b-ddc121192f68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76bc7c32-248d-44d7-adab-4cc4609a7e14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92adb400-22ec-48a3-ba1d-47da6c6a3a09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7bd2cc4-70b4-41d5-a112-0cfdc9adac8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f03616e-881a-4dec-b6db-2cff8d8f5e31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2d1f4dd-e264-4416-a736-5f454869b856
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c7476cb-0f89-41c3-90b9-3d1bd70ee9f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea743519-c2ee-488f-ba5b-d133eb7c3c9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4608e5fb-5614-4844-a21c-fb738458d2cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 851ae7a7-ab6d-4a40-aa82-111b2c72e3a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 585d0fbc-a51d-4a45-ac1d-c5524a92b11e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b6a9a91-0417-4968-9d88-4fd813b52e7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d66e3cb-e0f3-43e5-bcfd-3aa31c8fd46a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ff64858-5299-4f5c-a9f4-252cc897ff65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43b4d5e1-613a-4b1d-a1c4-1baa55af2b5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0df61d69-5909-4cfd-81ab-25b0de7089c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6d3f425-e4b4-4496-9713-7408eeb210c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80d1e4a6-aa57-427a-9c8f-7bae4027df17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24229473-661d-4366-812f-e957fd4f99bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba1ba779-6f04-42da-9374-9055a5d608c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18a327dc-7525-4bb5-9f78-85f4611a6598
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c326cae-f1af-4292-8edd-af282a3bf0dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78ff1787-ded4-4ae4-a473-41af341473ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81c34e20-2ddc-47a1-8009-fe167ea1e179
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d8b1f88-8361-41a8-95b8-1559a4721291
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab975c31-dedf-46c5-a6e7-fa0e77afb6ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e1a04d3-ab61-4b24-92b9-c858c5a122b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1c29ab9-b6d6-4152-91ed-5a6ec351626f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18e1630e-19b5-4300-9802-efdce0f2f196
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ee9818d-2e54-438b-9f26-7fdb3302a98f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c2a7c28-5adf-4577-a14c-894105609c7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae22c4f3-dfae-4daa-9c84-e4ca002eb55f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a57a78b-fcbe-4568-981d-a2e2d51884ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f97ccba2-3e22-42fb-b3b5-69dfe507a91a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8439fdd-fcea-4457-b505-44e1a1f70d86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec8c057c-e114-4259-8a29-3088706fd35a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9123661e-e2c1-4ddd-9834-430d4f637d8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b12cadf1-f482-4dc1-9fc5-1d56fbada451
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c620d288-c750-45f3-b844-77c4d0480f46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2bc70e1-989b-46e3-af15-aa42f3c8249c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb95f7e2-6771-4df1-949a-889c29046e1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d358c6d-02f9-4506-85da-ed8a85c58ded
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2d8d3f2-16b3-40d5-a707-817aa1de1902
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e50e26bf-506f-46f7-a38b-7ba24913c538
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9cb01582-783c-4169-806e-62e21e45cf95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f39f346-529f-4eb8-9dd6-680a07e70888
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4d197d5-df7d-4212-abae-2ac235a432bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83cce9e8-9f97-4f5d-b0eb-404694f8c320
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e61cbc60-9593-405d-ab12-1d593a76c28c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cbb2ae3b-e6d2-498b-b1a5-e2f1a2aed664
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed629ca6-3fc3-4730-9306-7be5ac2b12ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 618a43a1-417b-4827-b9f4-62f3b20d93ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 000ec98d-b09d-4d3e-97ab-c86bb0e71530
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e456ae7e-8487-4ec6-8ca0-caab8f07c66f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 698053b3-4c9a-4159-9d05-0426b5d97a92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e19db8ed-a91d-49fa-a23e-b5657a1a4b31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 777bbb7b-fbe8-4d22-8495-9a298be98e8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6400d467-93ab-49af-9752-8ef0e32a5b2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29494f2d-5fbe-416f-887a-6b2c8244e801
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c4726d7-2fd1-4d2b-86d9-0b27bdf71c08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11a26f56-e6ae-4176-a98a-3f4284f9c924
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6bddf8ab-6cb9-480c-b9bb-2c79de39009c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae3f6242-a695-4853-85d3-766b12f02cd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ead9e73-1eb0-4e0d-8998-bdeafaa232f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 584eac7d-ed55-42ad-97b4-da804f5862f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message efe61de2-864f-4706-92ad-5252c46606ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ec804dc-9fa5-4e2f-ae50-cff78415d726
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab5f2c62-0cc3-493d-84d5-e8820b5a6b2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60881497-8876-4fbf-bdfb-a41877de8499
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ffb01342-aaed-4494-bb5b-ee9a957c67f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c2caee8-8cec-4721-81c9-8c740a02a752
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a135742-e329-4e08-bf36-b730ab46878c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 787e6ccc-fe60-4de3-83c6-aa18a28848f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message acbd5834-cdef-462b-a6fb-5c5097a6ccc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26f852c3-5166-4d90-a5e6-543a92c5e3b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c50272c-7f53-450d-b8d5-7b3b3905023d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b17e046-4d40-488c-92d6-dd0a48818111
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bfde429d-6f93-4bc3-aa82-c75cce6462d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd271a93-1412-4ffd-945d-e8225b393205
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b63b3eee-537d-4113-ad17-bf8b7c0ae8d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2e6478c-7859-4b40-ae2d-7c25263e44bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86985371-5d3f-4921-810a-5bb9a1f026b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b18905e6-d1dd-4474-8049-4011d09941a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19cb54bf-469d-4712-987b-021453a5f919
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 024c6a89-04c7-4b73-a6be-3c9a090d2eff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c878d7b0-9d48-4190-8574-8fd9a29dcbc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b711d3a-ac81-4bbe-8d09-c25ce605ca19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3deecc94-c825-4750-b460-6886bfd3cf0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 713c4a81-3809-40de-8645-ca61dcd96440
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a1f43ea-abe7-42e9-87e3-667989c3e6da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80118d45-36e7-4edc-a3cf-244132b2efd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35c899eb-9a20-420c-9eda-bd6e228d5d76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9111843-418c-4a10-928e-27ab6e2d23cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 804cba40-a4e5-4647-be14-c64640d53219
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d0c5339-f555-4db1-8706-8db855e3d094
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b430a792-dca3-4fd4-94ec-db74722a83ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5214538-bb6f-4b05-9665-736333cf8ba2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2538bf77-7b50-4813-b79d-19398aa40c13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be4d67d4-03b2-471a-ad78-bae8c2dd9385
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b0a8aa9-ad26-4005-8554-267d36879523
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 869101c0-d2e6-4d8f-9409-9068ed893c20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4bb13bd8-b717-4ffe-9272-bf9c84927c65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf8f6364-5cd5-4722-aa75-a4b972ca1ebd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa000183-fb03-40c3-8135-868b61b4d153
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc78f474-8901-4e97-804a-87b85fcd8650
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e1affa3-7cd3-476f-81a0-7588bf15cd17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05631c7d-e1dd-48b5-9a38-795fe4f9ce60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5508971-3cfa-4085-9168-b72e981fb156
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc584450-a534-4b8a-a28e-9814dbeb4a78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e6492ac-0fe6-4d17-9323-880533225b6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0846925b-09d2-443e-8842-bb3fa4cf13c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ca907a8-186d-41ee-8229-2918c2d19111
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9681b297-d1c8-422e-8b7b-1295b47ddb83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27a102ef-12f2-47b9-bb14-68cbf54ddad7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18e4e6d3-896c-4bf4-8c13-f2b8172e903a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec449bf2-e37f-437f-9410-c7caa96eff6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5aa07cd-e47f-44c2-a490-ef0daf13a55b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ff08089-1a16-449e-804a-2123c204687c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d80c0c08-574a-493f-8aa0-6fa7dbe572fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 148818fe-3c6d-4029-8c0c-b110ecb51f5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d029bd43-ef67-4014-bb97-897587d9a992
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00087180-e7f9-464a-8481-296b490f00fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a00a4923-bf1c-457f-b637-754a374e82b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 808fe009-7aa7-44e8-aeaa-9348c8a6a060
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 651dbdf2-2208-481f-ab28-d93d57f0acd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b59a848d-50d6-4726-86fc-8f1f1f664192
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c515411-d713-4322-be5f-f6fa2030c9f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ce8f6c3-6967-41eb-9f50-43ea29ea4594
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62eb760f-1f59-4c8d-8c21-a3ca4b36c032
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49eb08d0-750f-4770-b4b6-e7eb803a0d4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df30c3c8-de90-4b52-803e-b001f345eeb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 173a2a95-7254-4fc4-987f-c831984f078e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45cdcc88-320f-4e7f-b3b7-d87e9a45ce79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dfcb3c49-dae8-4a0e-bf6f-801af3b55cb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38e9ffb3-2fdf-4040-b912-56898ead7da5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 378d0d3f-aea0-46bb-a487-14b01d3e60e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfc5c3fe-f724-400d-8b7b-89127bd53c67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1de07f0-2228-4855-9308-d9144771217d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb6418e4-128b-4dc1-a1a6-00fcc88f1451
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3fa8cc6-7c84-4db9-8f2f-38c3bddab12a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f83e7ef6-12d8-484e-87cf-5525bdd40e19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26d7c97c-b9b3-46d5-bd9b-01e1a881a4b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66a4eab1-b325-4afc-918d-262edae80213
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3f6e53a-a979-4e4e-adcd-56a28aa02524
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5afd80b-453e-4962-906d-dc936ef029c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7709ffc7-a969-44e9-9da7-f8982d1f3097
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4098769-7559-46c9-9775-46a0846e3d8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6cb5ba7-9a4d-4426-b83a-989c2d653eb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 014d00ef-eea9-4ae8-bcc4-43ac1fbd0c69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1e0e0a6-38f6-48f2-8acd-42efcda7b44b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d19b36a-0492-4901-aace-95b70ee6ab82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c34e880-2eff-4b2f-b03b-d378bc4fa157
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9868f937-5b34-4c08-b4b7-6fbca420ac1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 527d70d4-bd0d-4a40-bd3f-014fd545c6ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03683871-d2dd-4680-95ba-a5359ce16210
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40826d85-aaab-4079-974f-93d5bcaa3abf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf7069e7-f6e7-4fea-866f-cd8928eb3538
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b65ad68-c5cb-4d1b-9f4d-8de7d22f8972
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 520bd4a8-aa11-41f1-9aa6-acf06e2cb836
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 549509ec-b025-472e-a125-3219a7999a23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 850b89ac-ec47-435d-9fee-edfc92a459a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4fe6a8b-895f-4529-add9-761385e7372c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c17380a-6f78-4a66-b4bb-f2484625cdeb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 981d2bfc-c481-4e89-baa7-38a4a2fe5709
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 437db961-ed2d-492a-ab6d-c8e2c0de1c73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f922cb1-3c99-4c9d-8807-29cd6c84472d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb99b53a-6bc3-403a-b548-b37d394459d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69f167bd-238e-47e0-86a0-19851d60c460
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5110aea0-15e0-4c1d-8780-68a56e3f10af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message adeaf803-23d8-49ec-af08-6aea8c9b337a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e476f9c-1121-4f7a-826f-b5209d25dab9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc01ea66-6b32-4e08-9efb-420f5c0bed8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0da961ca-6171-4a10-9171-f43fd88ebe38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fac3c78c-7132-415d-851a-e8f42c05c0eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e23b404b-b95e-44cb-8fc0-11b4a54e18da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7fda1310-b6a5-490b-9996-72822d9f4205
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57f9c892-d0bd-4545-8b6a-72c08da2f9e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4b6a377-53e5-4535-ac85-2206c89a5984
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f7756e9-8fe9-4a89-b4fc-b50dfef99edf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06c855b5-ef01-4c25-84af-6a60a0d4716b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b4644ef-6ffc-46dd-be5a-e579178d2b6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc02245c-1630-4469-b3f5-272ccfb37dcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56e5c399-7b42-460a-a1cb-be2269b96144
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41b4cd25-c126-4b6a-a254-11fad39aca19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0a09062-87af-4be0-96e5-9cb6fce9114b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eefc13e8-6085-4336-99a9-af653cf7d899
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95b74922-a22f-49f0-b728-10e8506a8571
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9569103e-96f3-4dbc-9304-89954b4b24e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca1d944d-29a4-465a-b733-0b74bea3c59f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e92c0f67-6ea2-437e-b241-46cd7dc5c2de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aaee4dde-1f74-47b7-9482-44e8bec89534
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e41f298-849d-4db8-a07e-3db870f63a34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c19cbed7-35ac-4f73-8c05-89ea2d945e75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e446ac74-57c2-424c-bdc5-2b9dfb863944
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a70ed0b-3d07-455f-bf68-a4ae3e6d2590
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac3f0e4d-716e-43f0-9c32-a00077925285
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a91490ff-3ac4-488f-8bb5-5e464210f15f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09a447c5-7513-40d4-9e71-f08ac3c6945d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af178901-4b76-4806-9afb-e9aca709e440
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 885f7f0a-e5fc-41f0-ae60-6fd10c8f6ad3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc0bf75f-43ed-4a42-8456-3dfc96be964f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70ed93f8-69f6-49f2-828c-fef0d99aa795
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 354163b0-bec7-490d-9068-18b2ccd85084
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d546545-35ba-44b7-9c63-5d59f5747b5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1863c6ff-ba0a-4417-a6e8-aec434fa6908
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4cda828c-6fe3-4bfc-96be-09f64467eba5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da026678-3650-41f3-9803-a6d5010c9837
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc089d41-2b7b-4955-a607-2960e78eb278
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8f12733-4c98-43c0-8f03-5d24b47f44c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a84fdbbf-dd94-46ec-9242-29cb37a7b397
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b7b6eb8-c6ab-4e12-909d-01e034400d6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00578bde-ad7b-43d0-b291-95a600d24b06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc13812c-bc04-46c5-8b66-a7a1829c81e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c063ffbd-8a92-43d1-9b48-a093b908db6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c162aeb-4b64-4c5d-b71c-ef2b5e2ca056
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1780eb25-12ff-45df-b25e-99f231d9941d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c303e387-943c-485f-9497-765aa8913be8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a801f701-fb7c-493e-8fde-715e41ebb11c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f85371c9-1fbe-476c-87bd-e45b3a1ff9df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0587cdc4-e65c-4184-a85b-12970dc0a699
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e76ce574-b38d-48c2-bcee-4aae61446a90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7761ffc-4c40-464a-a8ea-f3128a8c8237
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0cab32d1-acce-4fef-93ff-71828ea4a67e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 615955ea-7a10-48a2-a0f3-97ba8adf1039
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb97048c-0102-4722-9ff6-fe140c3f0524
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 634150b4-874e-464c-a943-0987923f46f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f64349b9-7e32-405b-8159-84088a1f9ca8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd51079c-30db-4c6f-a341-420a086f85da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90cd0958-2f16-46fe-be17-07c9cfbcb985
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 925a7da3-e18a-4b22-90b7-7632d62089a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33da4252-4cc6-4dd8-8281-5cda14543cd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4eac63d8-03ee-4242-b63d-e3dce2397002
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38749155-d2c0-4e05-84ca-0afe2f80dcb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b16da664-6694-42b4-8978-a78fbdbaa9ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac49d79b-3f36-486e-ab2c-8fbfad54db14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fedf014d-4b69-48de-9a44-2d8bc4791b6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd0fc0db-92e2-4a88-94b5-e98c6b3bf19b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ff0565b-3278-4efd-8751-4e2dd684d979
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b252774c-d6cf-4957-b1c1-d427b73f3927
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76645daa-c5b4-4f58-b24a-bb6e1925a8a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b32bc844-ccb7-42f1-bb31-9c39467cc00e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c06d332b-6212-4e1b-acf1-3567a595ef26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b611bfe3-5be3-4f2f-baf8-d5a6151190ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e0c7cc5-5cbc-43e9-a6e2-a8e8b820b473
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a1cac5f-2da5-44a8-9bac-bc08dc85e445
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef36b93f-7ab3-47dc-afe5-d7c33fc64756
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c42394db-684e-484a-8b54-cfedc349b8f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0dda9145-c50d-4af6-b496-e890e5abe6e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f8215ad-c946-4cc3-93fa-0c7bd2ebca41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d673b794-67f6-462b-88e6-7b98fc2f27e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cdb35c80-834e-4126-95bd-e855bcecb338
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 950dedbb-cc18-4076-afd9-51529142bbf1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23cb1307-099b-43d0-ac01-ae634313faf4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b0150f7-2f6d-48c5-a43d-5aeb39442881
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef157b9c-1fef-4656-b5b7-4cf993326b57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5efb0b12-fcbc-4d58-abd3-b07f7ccb248a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29b31977-5db1-4521-9871-45aedb081838
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d682da1a-281c-4acb-ac45-61fbc702eda7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 431a20f7-5b64-45b6-98c5-7c55c85089cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb431dcb-ee51-4da8-8fc3-24b5208cb964
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39ab76a0-5bce-42b8-bfad-949634540269
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7e07b5d-6d11-4854-8dd3-d996394d5930
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf3a5ed7-5af4-4494-8ab8-142c1ef3c8de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09389223-3617-4e78-86c4-c5f95a3ef51e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4282e24f-6414-4366-a3a7-515a20e67dd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69b0297b-ea9e-46f8-b1e3-59b4ef8eedda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39972d6c-484b-4db6-bf30-fda5979e2641
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce72ebed-ef54-4a02-9114-6ee383cda7da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c5b0219-23e0-44ac-a4c8-4d35f50e4ccf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d3fbb6c-01e9-490f-9ba0-a417e0bac3e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 505ef40d-db07-4a24-a462-7482d96dac98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a932f0cf-911a-4690-bcaa-00bac18132d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea3ffbe6-7590-4a2c-ab74-81154d96f973
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce6c5b16-495b-424f-8d8b-5d6300a47458
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e1e6615-28f8-49ad-abfb-2f71f27e224f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c80da7e2-d99d-47ad-ac93-526ce017f614
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74107ee7-b264-4b52-96a8-c0f707514cc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5557ebc2-a259-47e5-83e7-b6fd4ca5926a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87518f22-af77-4a3b-90a2-fc2097406164
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66172c35-a4f5-492e-91df-e1fb58b94a2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7bbe0682-e2a1-4ee6-b812-0f601de0a875
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64d752a8-36a2-437e-b90d-4cfa215c8eb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29186b82-0fb3-4c89-9408-330312268ef5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bef531c8-8da5-451d-8354-d38c22773760
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28518dc8-10a8-453f-8085-90a7cd99ad56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3c05748-02e8-4d73-bf48-2fac2c1f27e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1fc8307-4bb1-4d8f-b3bc-79990c5b32a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f48fecc-775e-46aa-afe6-56647d821456
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d36240d-967c-40cb-a49c-67d189e1d1d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9e8275a-8b8b-487f-a3bf-829485772d22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 637c354f-674b-4a95-bdb9-b40fc50ba0c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf51ee1e-f6a8-4d7e-8af8-b808c0715b3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c1502b3-22a7-41eb-89cb-a1d93a789277
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc48e7e3-168e-4f18-88aa-862e6b349902
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d936163-437c-420c-a94b-1090ead62e42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3df88f4a-22bb-4135-8b7d-a52234dbebc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41730964-fa06-4b6b-ba62-e045099adb63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6683b59b-045a-4ae1-8eab-4820a3a9f62e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1331bcf1-6139-4104-9dc6-0d3721705359
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 955a752a-5d58-49ba-852d-7831e7885905
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec9e7652-eb49-411a-b33e-652169bbe544
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9272d20b-7d23-4f0e-8850-60bf5a8cab86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 470492c3-5692-46fe-a845-ccda55e03c0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f17a357d-a99a-4d92-be82-0c3329427912
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8c0c1a6-86cb-4000-8ef0-b2512ade94b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7caf0f3c-bbbf-4ce1-8928-daa51d3a9380
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ecfd869-7de8-4d3c-926b-bc80ef19a60f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0795169f-4015-4dc8-8ff7-6394847f5a22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc999fd0-43a4-46d7-8f25-f51322ea3f1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40d150c5-c3b7-48c9-a887-7050a01b4d57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5cd4c6af-7416-4d30-b107-a734e304df20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a075959-a477-47ca-aa84-2fcd043da057
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 049ea6b9-a430-4da2-85b4-606fefbe3d09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05ae583a-0ee6-482b-9772-9bd76d1b325d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90638d5c-c835-4b66-b3c1-9475383f7c7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 518cc91c-5b3e-4863-877e-19edb8039793
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 451b2453-f8f4-4436-817e-0ae6c52e5aad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ea54ce1-79bb-430d-b806-f4b2d6ffe186
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8208d43-e5e3-4d98-a381-0808e7a1f4d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08a37594-cce4-4bfe-81c6-e623c37366e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92e7d0f6-4cf1-4db7-a016-1fc67b82c221
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92784b01-7f00-4b37-844d-df283342562a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c425763b-f186-4caa-b40b-640fdaaa585b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50661fc6-69d8-43e0-819f-34fe4eac686a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46b2ab7e-4204-4cd6-b66d-8d538aa92f14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7d14a15-db9c-4c9c-ab86-043ac3144739
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab9dd23b-24fb-46c0-bc61-82dbc9e59f44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16e4daa2-e79f-4313-8520-c14cad96be34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ddbb60fe-aaad-4561-9be3-32eb36ced818
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d02e518a-285e-483f-b7b2-a03f5abb3f77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 712c4404-290c-46f6-9315-fc6d85bdcd20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 788b20ba-a498-4d20-8fa1-a0d5d7f0e237
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 098c5a34-9677-4a3c-aeaa-4898a6fb1c5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4752c79-19a1-408a-9536-2beac6779e80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e369943-fd93-4371-8fbb-ffb0cee50721
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 688611cf-874f-4cb9-b8c2-af0ddeec3374
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52683971-6dbd-4d00-b566-f3706ef7f9dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f31c13e-935c-41ea-826c-0fc8265ca65d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7cd0e70f-aad4-4979-9c91-32aa12160efe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b9c5960-946c-4ac8-9f92-6c20c4bd8949
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad7f0c2f-f528-499e-803d-3b45e5652e92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9060bb8c-f5f4-493e-918a-7d1c6a584237
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 875df04f-81e9-447c-b751-c55dfefbf29c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74dfc5e0-e44e-4dc9-8e53-009de4382b27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77761680-235f-4cd6-af61-1b068461fbb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f236a23c-72ca-48f8-a286-1eb0db886e15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0dc245a1-b10d-41ed-975d-3fc6f4fffcd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d53b9d6-daed-44db-ac76-41ec5eee81fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4105c767-29bd-47f8-8010-586715b31dd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a445126-9917-40d7-b782-52743e3fb433
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee76fc7c-193c-4a6a-9ea3-8e1a02b8156f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6aad9f3-bce9-4107-8ad2-373f363ce199
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5c31c00-02e7-4131-bce4-30f52deab901
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d89819f-853d-437d-a9bd-471ee188e268
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0fe93de0-f300-4eb0-83a7-9b8cbf55fc91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72a52451-d742-4d58-b0e7-44be7c524a6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b41d6123-0295-4993-b382-ff7ebd941e31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0489af78-4284-402a-86b8-943f714822f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e380d7d-ce82-478e-a789-324e4538cfd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49eeffe1-99d5-4d30-bcf5-c172541905b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d053b5d7-9173-4031-beeb-cf94df79ba6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0eaf975-caab-44cd-aafb-314bcdd722f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 937f0f35-4e72-48b5-b646-036bab2a947f
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8688 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_7
Server: localhost:8688
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_7
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_7/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_7/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_7/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_7/test_labels.txt

📊 Raw data loaded:
   Train: X=(6192, 24), y=(6192,)
   Test:  X=(1549, 24), y=(1549,)

⚠️  Limiting training data: 6192 → 800 samples
⚠️  Limiting test data: 1549 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_7 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.3620, RMSE: 0.6017, MAE: 0.5285, R²: -3.3994

============================================================
🔄 Round 4 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0862 (↓), lr=0.001000
   • Epoch   2/100: train=0.0794, val=0.0867, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0790, val=0.0875, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0785, val=0.0872, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0783, val=0.0871, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0763, val=0.0867, patience=10/15, lr=0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 4 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0112
   Val:   Loss=0.0862, RMSE=0.2935, R²=-0.0120
============================================================


📊 Round 4 Test Metrics:
   Loss: 0.1012, RMSE: 0.3182, MAE: 0.2686, R²: -0.2305

============================================================
🔄 Round 5 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0822 (↓), lr=0.000500
   ✓ Epoch   2/100: train=0.0809, val=0.0788 (↓), lr=0.000500
   • Epoch   3/100: train=0.0807, val=0.0794, patience=1/15, lr=0.000500
   • Epoch   4/100: train=0.0802, val=0.0791, patience=2/15, lr=0.000500
   • Epoch   5/100: train=0.0801, val=0.0793, patience=3/15, lr=0.000500
   📉 Epoch 8: LR reduced 0.000500 → 0.000250
   • Epoch  11/100: train=0.0786, val=0.0796, patience=9/15, lr=0.000250
   📉 Epoch 16: LR reduced 0.000250 → 0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 5 Summary - Client client_7
   Epochs: 17/100 (early stopped)
   LR: 0.000500 → 0.000125 (2 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0102
   Val:   Loss=0.0788, RMSE=0.2808, R²=0.0078
============================================================


📊 Round 5 Test Metrics:
   Loss: 0.0843, RMSE: 0.2904, MAE: 0.2503, R²: -0.0250

============================================================
🔄 Round 8 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0814 (↓), lr=0.000125
   • Epoch   2/100: train=0.0784, val=0.0825, patience=1/15, lr=0.000125
   • Epoch   3/100: train=0.0781, val=0.0826, patience=2/15, lr=0.000125
   • Epoch   4/100: train=0.0779, val=0.0825, patience=3/15, lr=0.000125
   • Epoch   5/100: train=0.0778, val=0.0824, patience=4/15, lr=0.000125
   📉 Epoch 7: LR reduced 0.000125 → 0.000063
   • Epoch  11/100: train=0.0772, val=0.0824, patience=10/15, lr=0.000063
   📉 Epoch 15: LR reduced 0.000063 → 0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 8 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000125 → 0.000031 (2 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0220
   Val:   Loss=0.0814, RMSE=0.2852, R²=0.0036
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2438, R²: 0.0220

============================================================
🔄 Round 12 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0849 (↓), lr=0.000031
   • Epoch   2/100: train=0.0760, val=0.0851, patience=1/15, lr=0.000031
   • Epoch   3/100: train=0.0755, val=0.0853, patience=2/15, lr=0.000031
   • Epoch   4/100: train=0.0753, val=0.0854, patience=3/15, lr=0.000031
   • Epoch   5/100: train=0.0751, val=0.0855, patience=4/15, lr=0.000031
   📉 Epoch 7: LR reduced 0.000031 → 0.000016
   • Epoch  11/100: train=0.0747, val=0.0857, patience=10/15, lr=0.000016
   📉 Epoch 15: LR reduced 0.000016 → 0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 12 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000031 → 0.000008 (2 reductions)
   Train: Loss=0.0760, RMSE=0.2757, R²=0.0377
   Val:   Loss=0.0849, RMSE=0.2914, R²=0.0471
============================================================


============================================================
🔄 Round 14 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0784 (↓), lr=0.000008
   • Epoch   2/100: train=0.0781, val=0.0783, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0779, val=0.0781, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0777, val=0.0780, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0776, val=0.0779, patience=4/15, lr=0.000008
   • Epoch  11/100: train=0.0770, val=0.0776, patience=5/15, lr=0.000008
   • Epoch  21/100: train=0.0766, val=0.0775, patience=15/15, lr=0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 14 Summary - Client client_7
   Epochs: 21/100 (early stopped)
   LR: 0.000008 → 0.000008 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0452
   Val:   Loss=0.0779, RMSE=0.2791, R²=0.0511
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.0793, RMSE: 0.2817, MAE: 0.2425, R²: 0.0357

============================================================
🔄 Round 16 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0804 (↓), lr=0.000008
   • Epoch   2/100: train=0.0764, val=0.0804, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0764, val=0.0804, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0763, val=0.0804, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0763, val=0.0804, patience=4/15, lr=0.000008
   📉 Epoch 6: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0762, val=0.0804, patience=10/15, lr=0.000004
   📉 Epoch 14: LR reduced 0.000004 → 0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 16 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0761, RMSE=0.2759, R²=0.0523
   Val:   Loss=0.0804, RMSE=0.2835, R²=0.0432
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.0783, RMSE: 0.2799, MAE: 0.2408, R²: 0.0480

============================================================
🔄 Round 17 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0702 (↓), lr=0.000002
   • Epoch   2/100: train=0.0786, val=0.0702, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0786, val=0.0701, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0786, val=0.0701, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0786, val=0.0701, patience=4/15, lr=0.000002
   • Epoch  11/100: train=0.0785, val=0.0701, patience=10/15, lr=0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0702)

============================================================
📊 Round 17 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000002 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0468
   Val:   Loss=0.0702, RMSE=0.2649, R²=0.0660
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2405, R²: 0.0487

============================================================
🔄 Round 19 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0820 (↓), lr=0.000002
   • Epoch   2/100: train=0.0760, val=0.0819, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0759, val=0.0819, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0759, val=0.0819, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0759, val=0.0819, patience=4/15, lr=0.000002
   📉 Epoch 6: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0758, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 19 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0762, RMSE=0.2761, R²=0.0471
   Val:   Loss=0.0820, RMSE=0.2863, R²=0.0446
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2405, R²: 0.0485

============================================================
🔄 Round 20 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0699 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0699, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0699, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0699, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0699, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0698, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0699)

============================================================
📊 Round 20 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=0.0360
   Val:   Loss=0.0699, RMSE=0.2644, R²=0.0865
============================================================


============================================================
🔄 Round 22 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 22 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0327
   Val:   Loss=0.0739, RMSE=0.2719, R²=0.0711
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2404, R²: 0.0487

============================================================
🔄 Round 25 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 25 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=0.0513
   Val:   Loss=0.0783, RMSE=0.2799, R²=0.0224
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2404, R²: 0.0491

============================================================
🔄 Round 26 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0754, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0754, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0754, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0753, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 26 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0754, RMSE=0.2745, R²=0.0458
   Val:   Loss=0.0855, RMSE=0.2923, R²=0.0498
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2404, R²: 0.0493

📊 Round 26 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2404, R²: 0.0495

============================================================
🔄 Round 29 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0750, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0750, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0750, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0750, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0750, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0749, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 29 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0752, RMSE=0.2742, R²=0.0515
   Val:   Loss=0.0858, RMSE=0.2928, R²=0.0054
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2404, R²: 0.0496

============================================================
🔄 Round 32 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 32 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2776, R²=0.0490
   Val:   Loss=0.0777, RMSE=0.2788, R²=0.0495
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2404, R²: 0.0498

============================================================
🔄 Round 34 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 34 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2776, R²=0.0557
   Val:   Loss=0.0774, RMSE=0.2782, R²=0.0232
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2405, R²: 0.0498

============================================================
🔄 Round 38 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 38 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2767, R²=0.0597
   Val:   Loss=0.0790, RMSE=0.2810, R²=0.0135
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2405, R²: 0.0498

============================================================
🔄 Round 39 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0722 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 39 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=0.0346
   Val:   Loss=0.0722, RMSE=0.2688, R²=0.1079
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2405, R²: 0.0498

============================================================
🔄 Round 41 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 41 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2775, R²=0.0443
   Val:   Loss=0.0770, RMSE=0.2775, R²=0.0777
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2405, R²: 0.0498

============================================================
🔄 Round 42 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 42 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2761, R²=0.0551
   Val:   Loss=0.0800, RMSE=0.2829, R²=0.0235
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2405, R²: 0.0498

📊 Round 42 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2405, R²: 0.0498

============================================================
🔄 Round 44 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 44 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0562
   Val:   Loss=0.0739, RMSE=0.2719, R²=0.0308
============================================================


============================================================
🔄 Round 45 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0751, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0751, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0751, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0750, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0750, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0750, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 45 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0750, RMSE=0.2739, R²=0.0548
   Val:   Loss=0.0846, RMSE=0.2909, R²=0.0381
============================================================


============================================================
🔄 Round 48 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 48 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=0.0562
   Val:   Loss=0.0758, RMSE=0.2753, R²=0.0355
============================================================


============================================================
🔄 Round 49 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0713 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0713, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0713, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0713, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0713, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0713, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 49 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0590
   Val:   Loss=0.0713, RMSE=0.2671, R²=0.0195
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2406, R²: 0.0497

============================================================
🔄 Round 50 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 50 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=0.0494
   Val:   Loss=0.0778, RMSE=0.2789, R²=0.0598
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2406, R²: 0.0496

📊 Round 50 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2406, R²: 0.0496

============================================================
🔄 Round 54 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 54 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2764, R²=0.0603
   Val:   Loss=0.0789, RMSE=0.2808, R²=0.0199
============================================================


============================================================
🔄 Round 56 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 56 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0527
   Val:   Loss=0.0771, RMSE=0.2777, R²=0.0509
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2406, R²: 0.0495

============================================================
🔄 Round 58 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 58 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2750, R²=0.0664
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0032
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2406, R²: 0.0494

📊 Round 58 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2406, R²: 0.0494

============================================================
🔄 Round 63 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 63 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=0.0555
   Val:   Loss=0.0773, RMSE=0.2781, R²=0.0451
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2406, R²: 0.0493

============================================================
🔄 Round 64 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0755, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0755, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0755, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0754, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0754, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 64 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0755, RMSE=0.2748, R²=0.0565
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0425
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2406, R²: 0.0493

📊 Round 64 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2407, R²: 0.0491

============================================================
🔄 Round 71 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 71 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2755, R²=0.0508
   Val:   Loss=0.0803, RMSE=0.2835, R²=0.0629
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2407, R²: 0.0491

📊 Round 71 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2407, R²: 0.0491

============================================================
🔄 Round 75 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 75 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2762, R²=0.0614
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0240
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2407, R²: 0.0491

============================================================
🔄 Round 76 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 76 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2754, R²=0.0602
   Val:   Loss=0.0806, RMSE=0.2839, R²=0.0231
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2407, R²: 0.0491

============================================================
🔄 Round 79 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0671 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0670, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0670, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0670, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0670, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0670, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0671)

============================================================
📊 Round 79 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0532
   Val:   Loss=0.0671, RMSE=0.2589, R²=0.0562
============================================================


============================================================
🔄 Round 81 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0745, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0745, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0745, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0744, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0744, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0744, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 81 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0744, RMSE=0.2728, R²=0.0582
   Val:   Loss=0.0862, RMSE=0.2937, R²=0.0264
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2407, R²: 0.0490

============================================================
🔄 Round 88 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 88 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=0.0443
   Val:   Loss=0.0749, RMSE=0.2737, R²=0.0943
============================================================


============================================================
🔄 Round 90 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 90 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0553
   Val:   Loss=0.0730, RMSE=0.2701, R²=0.0433
============================================================


============================================================
🔄 Round 91 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 91 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2757, R²=0.0522
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0589
============================================================


============================================================
🔄 Round 93 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0707 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0707, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0707, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0707, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0707, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0707, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0707)

============================================================
📊 Round 93 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=0.0488
   Val:   Loss=0.0707, RMSE=0.2659, R²=0.0792
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0783, RMSE: 0.2797, MAE: 0.2407, R²: 0.0489

📊 Round 93 Test Metrics:
   Loss: 0.0783, RMSE: 0.2797, MAE: 0.2407, R²: 0.0489

📊 Round 93 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2407, R²: 0.0489

📊 Round 93 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2407, R²: 0.0488

============================================================
🔄 Round 98 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 98 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2772, R²=0.0613
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.0171
============================================================


============================================================
🔄 Round 99 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0754, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0754, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0754, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 99 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2750, R²=0.0468
   Val:   Loss=0.0809, RMSE=0.2845, R²=0.0830
============================================================


============================================================
🔄 Round 101 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 101 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2756, R²=0.0598
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0342
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2407, R²: 0.0488

============================================================
🔄 Round 102 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 102 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2766, R²=0.0573
   Val:   Loss=0.0774, RMSE=0.2783, R²=0.0449
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2407, R²: 0.0488

============================================================
🔄 Round 103 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0674 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0674, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0674, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0674, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0674, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0674, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0674)

============================================================
📊 Round 103 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0589
   Val:   Loss=0.0674, RMSE=0.2597, R²=0.0334
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2407, R²: 0.0487

============================================================
🔄 Round 105 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 105 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=0.0374
   Val:   Loss=0.0746, RMSE=0.2731, R²=0.1001
============================================================


============================================================
🔄 Round 108 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0718, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0719, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 108 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0501
   Val:   Loss=0.0718, RMSE=0.2680, R²=0.0565
============================================================


============================================================
🔄 Round 109 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 109 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2764, R²=0.0569
   Val:   Loss=0.0779, RMSE=0.2791, R²=0.0453
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2407, R²: 0.0487

📊 Round 109 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2407, R²: 0.0487

============================================================
🔄 Round 114 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0576 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0576, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0576, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0576, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0576, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0576, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0576)

============================================================
📊 Round 114 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0414
   Val:   Loss=0.0576, RMSE=0.2399, R²=0.1224
============================================================


============================================================
🔄 Round 115 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 115 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2781, R²=0.0520
   Val:   Loss=0.0741, RMSE=0.2721, R²=0.0666
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2407, R²: 0.0487

============================================================
🔄 Round 120 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 120 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2760, R²=0.0515
   Val:   Loss=0.0786, RMSE=0.2803, R²=0.0493
============================================================


============================================================
🔄 Round 124 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 124 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2759, R²=0.0564
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0474
============================================================


============================================================
🔄 Round 126 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0751, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0750, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0750, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0750, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0750, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0750, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 126 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0750, RMSE=0.2738, R²=0.0591
   Val:   Loss=0.0835, RMSE=0.2889, R²=0.0404
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2407, R²: 0.0487

📊 Round 126 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2407, R²: 0.0487

📊 Round 126 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2407, R²: 0.0487

📊 Round 126 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2407, R²: 0.0487

============================================================
🔄 Round 130 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0748, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0748, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0748, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0748, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0748, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0748, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 130 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0750, RMSE=0.2738, R²=0.0592
   Val:   Loss=0.0834, RMSE=0.2887, R²=0.0411
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2407, R²: 0.0487

📊 Round 130 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2407, R²: 0.0487

============================================================
🔄 Round 135 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 135 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2783, R²=0.0547
   Val:   Loss=0.0735, RMSE=0.2712, R²=0.0591
============================================================


============================================================
🔄 Round 138 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 138 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0551
   Val:   Loss=0.0741, RMSE=0.2721, R²=0.0543
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2407, R²: 0.0487

📊 Round 138 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2407, R²: 0.0487

============================================================
🔄 Round 142 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 142 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=0.0575
   Val:   Loss=0.0744, RMSE=0.2727, R²=0.0221
============================================================


============================================================
🔄 Round 143 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 143 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=0.0531
   Val:   Loss=0.0744, RMSE=0.2727, R²=0.0638
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2407, R²: 0.0487

============================================================
🔄 Round 145 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0747, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0747, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0747, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0747, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0747, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0747, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 145 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0749, RMSE=0.2737, R²=0.0571
   Val:   Loss=0.0834, RMSE=0.2889, R²=0.0396
============================================================


============================================================
🔄 Round 146 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 146 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0537
   Val:   Loss=0.0748, RMSE=0.2735, R²=0.0568
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2407, R²: 0.0487

📊 Round 146 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2407, R²: 0.0487

📊 Round 146 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2407, R²: 0.0487

============================================================
🔄 Round 149 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 149 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0691
   Val:   Loss=0.0746, RMSE=0.2731, R²=-0.0094
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2407, R²: 0.0488

============================================================
🔄 Round 151 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 151 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2753, R²=0.0620
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0314
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0783, RMSE: 0.2797, MAE: 0.2407, R²: 0.0489

📊 Round 151 Test Metrics:
   Loss: 0.0783, RMSE: 0.2797, MAE: 0.2407, R²: 0.0489

============================================================
🔄 Round 162 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 162 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2765, R²=0.0607
   Val:   Loss=0.0772, RMSE=0.2778, R²=0.0345
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0783, RMSE: 0.2797, MAE: 0.2407, R²: 0.0489

============================================================
🔄 Round 163 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0682 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0682, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0682, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0682, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0682, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0682, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0682)

============================================================
📊 Round 163 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0604
   Val:   Loss=0.0682, RMSE=0.2611, R²=0.0331
============================================================


============================================================
🔄 Round 168 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0754, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0754, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0754, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 168 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2749, R²=0.0507
   Val:   Loss=0.0808, RMSE=0.2842, R²=0.0707
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0783, RMSE: 0.2797, MAE: 0.2406, R²: 0.0489

============================================================
🔄 Round 170 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0715 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0715, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0715, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0715, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0715, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0715, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0715)

============================================================
📊 Round 170 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2790, R²=0.0572
   Val:   Loss=0.0715, RMSE=0.2675, R²=0.0444
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0783, RMSE: 0.2797, MAE: 0.2406, R²: 0.0489

📊 Round 170 Test Metrics:
   Loss: 0.0783, RMSE: 0.2797, MAE: 0.2406, R²: 0.0489

📊 Round 170 Test Metrics:
   Loss: 0.0783, RMSE: 0.2797, MAE: 0.2406, R²: 0.0489

📊 Round 170 Test Metrics:
   Loss: 0.0783, RMSE: 0.2797, MAE: 0.2407, R²: 0.0489

============================================================
🔄 Round 174 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 174 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=0.0588
   Val:   Loss=0.0763, RMSE=0.2763, R²=0.0427
============================================================


============================================================
🔄 Round 176 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0752, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0752, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0752, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0752, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0752, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0751, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 176 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0752, RMSE=0.2743, R²=0.0411
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.1081
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0783, RMSE: 0.2797, MAE: 0.2406, R²: 0.0489

============================================================
🔄 Round 178 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0697 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0697, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0697, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0697, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0697, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0697, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0697)

============================================================
📊 Round 178 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0558
   Val:   Loss=0.0697, RMSE=0.2641, R²=0.0568
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0783, RMSE: 0.2797, MAE: 0.2406, R²: 0.0489

📊 Round 178 Test Metrics:
   Loss: 0.0783, RMSE: 0.2797, MAE: 0.2406, R²: 0.0489

============================================================
🔄 Round 180 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0678 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0678, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0678, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0678, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0678, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0677, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0678)

============================================================
📊 Round 180 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0520
   Val:   Loss=0.0678, RMSE=0.2603, R²=0.0757
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0783, RMSE: 0.2797, MAE: 0.2406, R²: 0.0489

📊 Round 180 Test Metrics:
   Loss: 0.0783, RMSE: 0.2797, MAE: 0.2406, R²: 0.0489

============================================================
🔄 Round 186 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 186 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2764, R²=0.0612
   Val:   Loss=0.0773, RMSE=0.2780, R²=0.0204
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0783, RMSE: 0.2797, MAE: 0.2406, R²: 0.0489

📊 Round 186 Test Metrics:
   Loss: 0.0783, RMSE: 0.2797, MAE: 0.2406, R²: 0.0489

📊 Round 186 Test Metrics:
   Loss: 0.0783, RMSE: 0.2797, MAE: 0.2406, R²: 0.0489

============================================================
🔄 Round 189 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0712 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0712, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0712, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0712, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0712, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0712, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0712)

============================================================
📊 Round 189 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0550
   Val:   Loss=0.0712, RMSE=0.2669, R²=0.0621
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0783, RMSE: 0.2797, MAE: 0.2406, R²: 0.0489

📊 Round 189 Test Metrics:
   Loss: 0.0783, RMSE: 0.2797, MAE: 0.2406, R²: 0.0489

============================================================
🔄 Round 191 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0680 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0680, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0680, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0680, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0680, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0680, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0680)

============================================================
📊 Round 191 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0550
   Val:   Loss=0.0680, RMSE=0.2608, R²=0.0604
============================================================


============================================================
🔄 Round 192 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 192 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2783, R²=0.0521
   Val:   Loss=0.0730, RMSE=0.2702, R²=0.0670
============================================================


============================================================
🔄 Round 194 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 194 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2756, R²=0.0551
   Val:   Loss=0.0791, RMSE=0.2813, R²=0.0616
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0783, RMSE: 0.2797, MAE: 0.2406, R²: 0.0489

📊 Round 194 Test Metrics:
   Loss: 0.0783, RMSE: 0.2797, MAE: 0.2406, R²: 0.0489

📊 Round 194 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2406, R²: 0.0489

📊 Round 194 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2406, R²: 0.0489

============================================================
🔄 Round 202 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0745, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0745, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0745, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0745, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0745, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0745, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 202 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0746, RMSE=0.2731, R²=0.0520
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0711
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2406, R²: 0.0489

📊 Round 202 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2406, R²: 0.0489

📊 Round 202 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2406, R²: 0.0489

============================================================
🔄 Round 209 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 209 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2765, R²=0.0599
   Val:   Loss=0.0769, RMSE=0.2774, R²=0.0313
============================================================


============================================================
🔄 Round 210 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0696 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0696, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0696, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0696, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0696, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0696, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0696)

============================================================
📊 Round 210 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0611
   Val:   Loss=0.0696, RMSE=0.2639, R²=0.0345
============================================================


📊 Round 210 Test Metrics:
   Loss: 0.0783, RMSE: 0.2797, MAE: 0.2406, R²: 0.0490

📊 Round 210 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2406, R²: 0.0490

📊 Round 210 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2406, R²: 0.0491

============================================================
🔄 Round 214 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 214 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2772, R²=0.0513
   Val:   Loss=0.0755, RMSE=0.2748, R²=0.0763
============================================================


📊 Round 214 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2406, R²: 0.0491

📊 Round 214 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2406, R²: 0.0491

📊 Round 214 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2406, R²: 0.0491

📊 Round 214 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2406, R²: 0.0491

📊 Round 214 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2406, R²: 0.0491

📊 Round 214 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2406, R²: 0.0491

============================================================
🔄 Round 223 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0755, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 223 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2754, R²=0.0554
   Val:   Loss=0.0794, RMSE=0.2818, R²=0.0562
============================================================


📊 Round 223 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2406, R²: 0.0491

============================================================
🔄 Round 225 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 225 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2761, R²=0.0526
   Val:   Loss=0.0778, RMSE=0.2790, R²=0.0727
============================================================


============================================================
🔄 Round 227 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 227 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2769, R²=0.0604
   Val:   Loss=0.0761, RMSE=0.2759, R²=0.0364
============================================================


📊 Round 227 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2406, R²: 0.0491

============================================================
🔄 Round 228 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0755, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0755, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0755, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0755, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0755, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0755, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 228 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0754, RMSE=0.2747, R²=0.0536
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0657
============================================================


============================================================
🔄 Round 230 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 230 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0576
   Val:   Loss=0.0732, RMSE=0.2706, R²=0.0491
============================================================


============================================================
🔄 Round 232 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0747, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0747, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0747, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0747, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0746, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0746, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 232 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0745, RMSE=0.2729, R²=0.0660
   Val:   Loss=0.0848, RMSE=0.2911, R²=0.0231
============================================================


============================================================
🔄 Round 234 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 234 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=0.0358
   Val:   Loss=0.0738, RMSE=0.2716, R²=0.1291
============================================================


============================================================
🔄 Round 236 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0692 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0691, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0691, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0691, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0691, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0691, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0692)

============================================================
📊 Round 236 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0614
   Val:   Loss=0.0692, RMSE=0.2630, R²=0.0357
============================================================


============================================================
🔄 Round 237 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0755, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 237 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0752, RMSE=0.2743, R²=0.0506
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0799
============================================================


📊 Round 237 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2406, R²: 0.0491

============================================================
🔄 Round 238 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 238 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=0.0547
   Val:   Loss=0.0762, RMSE=0.2760, R²=0.0402
============================================================


📊 Round 238 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2406, R²: 0.0490

============================================================
🔄 Round 245 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 245 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2765, R²=0.0536
   Val:   Loss=0.0768, RMSE=0.2771, R²=0.0705
============================================================


📊 Round 245 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2406, R²: 0.0490

============================================================
🔄 Round 247 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0752, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0752, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0752, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0752, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0752, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0752, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 247 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0751, RMSE=0.2741, R²=0.0560
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0373
============================================================


📊 Round 247 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2406, R²: 0.0490

📊 Round 247 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2406, R²: 0.0490

============================================================
🔄 Round 254 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0704 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0704, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0704, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0704, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0704, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0704, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0704)

============================================================
📊 Round 254 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2794, R²=0.0400
   Val:   Loss=0.0704, RMSE=0.2653, R²=0.1260
============================================================


============================================================
🔄 Round 255 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0694 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0694, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0694, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0694, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0694, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0694, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0694)

============================================================
📊 Round 255 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0482
   Val:   Loss=0.0694, RMSE=0.2634, R²=0.0915
============================================================


============================================================
🔄 Round 258 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 258 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2754, R²=0.0628
   Val:   Loss=0.0791, RMSE=0.2812, R²=0.0298
============================================================


📊 Round 258 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2406, R²: 0.0491

📊 Round 258 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2406, R²: 0.0491

============================================================
🔄 Round 264 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 264 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2750, R²=0.0598
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0449
============================================================


============================================================
🔄 Round 265 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 265 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2785, R²=0.0535
   Val:   Loss=0.0723, RMSE=0.2689, R²=0.0593
============================================================


📊 Round 265 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2406, R²: 0.0491

📊 Round 265 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2406, R²: 0.0491

📊 Round 265 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2406, R²: 0.0491

============================================================
🔄 Round 271 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 271 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2757, R²=0.0541
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0228
============================================================


============================================================
🔄 Round 272 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 272 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0522
   Val:   Loss=0.0733, RMSE=0.2707, R²=0.0771
============================================================


📊 Round 272 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2406, R²: 0.0491

📊 Round 272 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2406, R²: 0.0491

============================================================
🔄 Round 278 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0751, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0751, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0751, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0750, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0750, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0750, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 278 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0752, RMSE=0.2742, R²=0.0485
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0894
============================================================


📊 Round 278 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2406, R²: 0.0492

📊 Round 278 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2406, R²: 0.0491

📊 Round 278 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2406, R²: 0.0491

============================================================
🔄 Round 285 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 285 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2762, R²=0.0567
   Val:   Loss=0.0773, RMSE=0.2781, R²=0.0605
============================================================


============================================================
🔄 Round 286 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0745, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0745, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0745, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0745, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0745, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0745, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 286 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0747, RMSE=0.2734, R²=0.0537
   Val:   Loss=0.0835, RMSE=0.2889, R²=0.0718
============================================================


============================================================
🔄 Round 288 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 288 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0475
   Val:   Loss=0.0727, RMSE=0.2697, R²=0.0893
============================================================


============================================================
🔄 Round 290 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 290 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2785, R²=0.0552
   Val:   Loss=0.0720, RMSE=0.2684, R²=0.0357
============================================================


📊 Round 290 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2406, R²: 0.0491

📊 Round 290 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2406, R²: 0.0492

============================================================
🔄 Round 293 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0664 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0664, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0664, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0664, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0664, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0664, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0664)

============================================================
📊 Round 293 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0615
   Val:   Loss=0.0664, RMSE=0.2576, R²=0.0263
============================================================


📊 Round 293 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2406, R²: 0.0492

📊 Round 293 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2405, R²: 0.0493

📊 Round 293 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2405, R²: 0.0493

============================================================
🔄 Round 304 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0755, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0755, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0755, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0755, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0755, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0755, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 304 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0754, RMSE=0.2746, R²=0.0497
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0862
============================================================


============================================================
🔄 Round 305 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0752, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0752, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0752, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0752, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0752, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0752, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 305 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0753, RMSE=0.2743, R²=0.0639
   Val:   Loss=0.0813, RMSE=0.2852, R²=0.0182
============================================================


============================================================
🔄 Round 306 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0748, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0748, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0748, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0748, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0748, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0748, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 306 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0748, RMSE=0.2735, R²=0.0588
   Val:   Loss=0.0831, RMSE=0.2883, R²=0.0484
============================================================


📊 Round 306 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2405, R²: 0.0493

📊 Round 306 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2405, R²: 0.0494

📊 Round 306 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2405, R²: 0.0494

============================================================
🔄 Round 310 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0749, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0749, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0749, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0749, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0749, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0748, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 310 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0748, RMSE=0.2736, R²=0.0505
   Val:   Loss=0.0830, RMSE=0.2881, R²=0.0659
============================================================


📊 Round 310 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2405, R²: 0.0494

============================================================
🔄 Round 311 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 311 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2750, R²=0.0586
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0451
============================================================


📊 Round 311 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2405, R²: 0.0494

============================================================
🔄 Round 313 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 313 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2758, R²=0.0527
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0773
============================================================


📊 Round 313 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2405, R²: 0.0494

📊 Round 313 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2405, R²: 0.0494

📊 Round 313 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2405, R²: 0.0494

============================================================
🔄 Round 316 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0752, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0752, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0752, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0752, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0752, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0752, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 316 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0751, RMSE=0.2741, R²=0.0626
   Val:   Loss=0.0818, RMSE=0.2859, R²=0.0399
============================================================


📊 Round 316 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2405, R²: 0.0494

============================================================
🔄 Round 318 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0704 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0704, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0704, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0703, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0703, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0703, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0704)

============================================================
📊 Round 318 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0521
   Val:   Loss=0.0704, RMSE=0.2653, R²=0.0832
============================================================


============================================================
🔄 Round 319 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0739, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0739, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0739, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0739, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0739, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0739, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 319 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0741, RMSE=0.2723, R²=0.0648
   Val:   Loss=0.0858, RMSE=0.2929, R²=0.0271
============================================================


📊 Round 319 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2405, R²: 0.0495

============================================================
🔄 Round 322 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0751, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0751, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0751, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0750, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0750, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0750, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 322 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0751, RMSE=0.2741, R²=0.0582
   Val:   Loss=0.0817, RMSE=0.2859, R²=0.0497
============================================================


📊 Round 322 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2405, R²: 0.0495

📊 Round 322 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2405, R²: 0.0495

============================================================
🔄 Round 327 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0738, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0738, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0738, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0738, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0738, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0738, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 327 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0739, RMSE=0.2719, R²=0.0547
   Val:   Loss=0.0866, RMSE=0.2943, R²=0.0609
============================================================


📊 Round 327 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2405, R²: 0.0495

📊 Round 327 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2405, R²: 0.0495

============================================================
🔄 Round 329 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 329 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2750, R²=0.0541
   Val:   Loss=0.0797, RMSE=0.2824, R²=0.0726
============================================================


============================================================
🔄 Round 330 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0749, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0749, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0749, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0749, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0749, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0748, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 330 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0749, RMSE=0.2738, R²=0.0516
   Val:   Loss=0.0824, RMSE=0.2871, R²=0.0593
============================================================


============================================================
🔄 Round 331 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 331 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2751, R²=0.0687
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0068
============================================================


📊 Round 331 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2405, R²: 0.0496

============================================================
🔄 Round 332 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 332 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2754, R²=0.0600
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0507
============================================================


📊 Round 332 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2405, R²: 0.0496

============================================================
🔄 Round 333 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 333 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2783, R²=0.0603
   Val:   Loss=0.0723, RMSE=0.2689, R²=0.0485
============================================================


📊 Round 333 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2405, R²: 0.0496

============================================================
🔄 Round 335 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 335 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=0.0534
   Val:   Loss=0.0755, RMSE=0.2747, R²=0.0708
============================================================


📊 Round 335 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2405, R²: 0.0495

📊 Round 335 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2405, R²: 0.0495

📊 Round 335 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2405, R²: 0.0495

📊 Round 335 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2405, R²: 0.0495

============================================================
🔄 Round 341 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 341 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2758, R²=0.0670
   Val:   Loss=0.0779, RMSE=0.2792, R²=0.0134
============================================================


📊 Round 341 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2405, R²: 0.0495

============================================================
🔄 Round 342 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 342 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2767, R²=0.0532
   Val:   Loss=0.0759, RMSE=0.2755, R²=0.0769
============================================================


============================================================
🔄 Round 343 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0744, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0744, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0744, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0744, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0744, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0743, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 343 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0745, RMSE=0.2730, R²=0.0612
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0304
============================================================


============================================================
🔄 Round 345 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0703 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0703, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0703, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0703, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0703, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0702, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0703)

============================================================
📊 Round 345 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2792, R²=0.0555
   Val:   Loss=0.0703, RMSE=0.2651, R²=0.0705
============================================================


📊 Round 345 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2405, R²: 0.0494

📊 Round 345 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2405, R²: 0.0494

============================================================
🔄 Round 348 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0717, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 348 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0558
   Val:   Loss=0.0717, RMSE=0.2678, R²=0.0472
============================================================


📊 Round 348 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2405, R²: 0.0494

📊 Round 348 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2405, R²: 0.0494

📊 Round 348 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2405, R²: 0.0494

============================================================
🔄 Round 352 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 352 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2757, R²=0.0653
   Val:   Loss=0.0782, RMSE=0.2796, R²=0.0302
============================================================


📊 Round 352 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2405, R²: 0.0494

📊 Round 352 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2405, R²: 0.0493

============================================================
🔄 Round 357 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0698 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0698, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0698, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0698, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0698, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0698, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0698)

============================================================
📊 Round 357 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=0.0520
   Val:   Loss=0.0698, RMSE=0.2641, R²=0.0828
============================================================


📊 Round 357 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2405, R²: 0.0493

============================================================
🔄 Round 358 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0740, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0740, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0740, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0740, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0740, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0739, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 358 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0740, RMSE=0.2720, R²=0.0647
   Val:   Loss=0.0860, RMSE=0.2933, R²=0.0357
============================================================


============================================================
🔄 Round 359 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 359 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2755, R²=0.0591
   Val:   Loss=0.0784, RMSE=0.2801, R²=0.0321
============================================================


📊 Round 359 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2405, R²: 0.0493

============================================================
🔄 Round 361 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 361 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2757, R²=0.0563
   Val:   Loss=0.0779, RMSE=0.2791, R²=0.0607
============================================================


📊 Round 361 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2405, R²: 0.0493

📊 Round 361 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2405, R²: 0.0493

============================================================
🔄 Round 363 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 363 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=0.0485
   Val:   Loss=0.0754, RMSE=0.2745, R²=0.0913
============================================================


📊 Round 363 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2405, R²: 0.0493

============================================================
🔄 Round 364 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 364 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=0.0568
   Val:   Loss=0.0745, RMSE=0.2729, R²=0.0627
============================================================


📊 Round 364 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2405, R²: 0.0493

============================================================
🔄 Round 365 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0747, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0747, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0747, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0747, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0747, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0747, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 365 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0744, RMSE=0.2728, R²=0.0603
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0233
============================================================


📊 Round 365 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2405, R²: 0.0493

============================================================
🔄 Round 367 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0649 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0649, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0649, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0649, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0649, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0649, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0649)

============================================================
📊 Round 367 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0547
   Val:   Loss=0.0649, RMSE=0.2548, R²=0.0766
============================================================


============================================================
🔄 Round 368 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 368 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0599
   Val:   Loss=0.0749, RMSE=0.2736, R²=0.0492
============================================================


📊 Round 368 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2405, R²: 0.0493

📊 Round 368 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2405, R²: 0.0494

============================================================
🔄 Round 372 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0742, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0742, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0742, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0742, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0742, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0742, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 372 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0742, RMSE=0.2724, R²=0.0642
   Val:   Loss=0.0851, RMSE=0.2918, R²=0.0309
============================================================


============================================================
🔄 Round 375 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 375 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2758, R²=0.0553
   Val:   Loss=0.0778, RMSE=0.2789, R²=0.0714
============================================================


📊 Round 375 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2405, R²: 0.0494

📊 Round 375 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2405, R²: 0.0494

📊 Round 375 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2405, R²: 0.0494

============================================================
🔄 Round 382 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 382 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=0.0652
   Val:   Loss=0.0755, RMSE=0.2747, R²=0.0317
============================================================


📊 Round 382 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2405, R²: 0.0494

============================================================
🔄 Round 384 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 384 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2775, R²=0.0573
   Val:   Loss=0.0739, RMSE=0.2718, R²=0.0650
============================================================


📊 Round 384 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2405, R²: 0.0494

📊 Round 384 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2405, R²: 0.0495

============================================================
🔄 Round 389 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0663 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0663, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0663, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0663, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0663, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0663, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0663)

============================================================
📊 Round 389 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0491
   Val:   Loss=0.0663, RMSE=0.2575, R²=0.1017
============================================================


📊 Round 389 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2405, R²: 0.0495

📊 Round 389 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2405, R²: 0.0495

============================================================
🔄 Round 391 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0703 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0703, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0703, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0703, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0703, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0703, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0703)

============================================================
📊 Round 391 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0628
   Val:   Loss=0.0703, RMSE=0.2651, R²=0.0409
============================================================


============================================================
🔄 Round 393 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0748, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0747, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0747, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0747, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0747, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0747, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 393 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0748, RMSE=0.2735, R²=0.0650
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0359
============================================================


============================================================
🔄 Round 395 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0747, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0747, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0747, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0747, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0747, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0747, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 395 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0745, RMSE=0.2730, R²=0.0692
   Val:   Loss=0.0838, RMSE=0.2895, R²=0.0120
============================================================


📊 Round 395 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2405, R²: 0.0495

============================================================
🔄 Round 396 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0750, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0750, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0750, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0750, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0750, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0750, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 396 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0753, RMSE=0.2744, R²=0.0649
   Val:   Loss=0.0806, RMSE=0.2839, R²=0.0336
============================================================


============================================================
🔄 Round 397 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0685 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0685, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0685, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0685, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0685, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0685, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0685)

============================================================
📊 Round 397 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=0.0595
   Val:   Loss=0.0685, RMSE=0.2618, R²=0.0557
============================================================


============================================================
🔄 Round 400 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 400 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2754, R²=0.0617
   Val:   Loss=0.0785, RMSE=0.2801, R²=0.0377
============================================================


============================================================
🔄 Round 401 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 401 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2772, R²=0.0628
   Val:   Loss=0.0745, RMSE=0.2729, R²=0.0424
============================================================


📊 Round 401 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2405, R²: 0.0495

📊 Round 401 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2405, R²: 0.0495

============================================================
🔄 Round 403 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0743, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0743, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0743, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0743, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0743, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0743, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 403 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0743, RMSE=0.2725, R²=0.0627
   Val:   Loss=0.0848, RMSE=0.2912, R²=0.0397
============================================================


📊 Round 403 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2405, R²: 0.0496

============================================================
🔄 Round 404 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 404 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2775, R²=0.0544
   Val:   Loss=0.0738, RMSE=0.2717, R²=0.0629
============================================================


============================================================
🔄 Round 405 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 405 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2760, R²=0.0676
   Val:   Loss=0.0772, RMSE=0.2778, R²=0.0231
============================================================


📊 Round 405 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2405, R²: 0.0496

============================================================
🔄 Round 408 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 408 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=0.0574
   Val:   Loss=0.0752, RMSE=0.2742, R²=0.0595
============================================================


📊 Round 408 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2405, R²: 0.0496

📊 Round 408 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2405, R²: 0.0496

📊 Round 408 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2405, R²: 0.0497

============================================================
🔄 Round 412 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0753, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0753, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0753, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0753, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0753, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0753, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 412 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0754, RMSE=0.2746, R²=0.0615
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0453
============================================================


============================================================
🔄 Round 413 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 413 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=0.0594
   Val:   Loss=0.0729, RMSE=0.2699, R²=0.0569
============================================================


📊 Round 413 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2404, R²: 0.0497

📊 Round 413 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2404, R²: 0.0497

============================================================
🔄 Round 416 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 416 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0589
   Val:   Loss=0.0747, RMSE=0.2733, R²=0.0577
============================================================


============================================================
🔄 Round 417 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 417 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2753, R²=0.0466
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.0990
============================================================


📊 Round 417 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2404, R²: 0.0498

📊 Round 417 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2404, R²: 0.0498

📊 Round 417 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2404, R²: 0.0499

📊 Round 417 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2404, R²: 0.0499

============================================================
🔄 Round 425 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0754, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0753, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0753, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0753, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 425 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0755, RMSE=0.2748, R²=0.0525
   Val:   Loss=0.0798, RMSE=0.2825, R²=0.0783
============================================================


📊 Round 425 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2404, R²: 0.0499

📊 Round 425 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2404, R²: 0.0499

📊 Round 425 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2404, R²: 0.0499

📊 Round 425 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2404, R²: 0.0499

============================================================
🔄 Round 432 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 432 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2766, R²=0.0677
   Val:   Loss=0.0758, RMSE=0.2753, R²=0.0098
============================================================


============================================================
🔄 Round 434 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 434 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2772, R²=0.0630
   Val:   Loss=0.0743, RMSE=0.2726, R²=0.0426
============================================================


📊 Round 434 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2404, R²: 0.0498

============================================================
🔄 Round 437 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 437 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2751, R²=0.0642
   Val:   Loss=0.0791, RMSE=0.2813, R²=0.0305
============================================================


📊 Round 437 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2404, R²: 0.0499

📊 Round 437 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2404, R²: 0.0499

============================================================
🔄 Round 441 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 441 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2758, R²=0.0647
   Val:   Loss=0.0775, RMSE=0.2784, R²=0.0368
============================================================


📊 Round 441 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2404, R²: 0.0499

============================================================
🔄 Round 442 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 442 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2774, R²=0.0659
   Val:   Loss=0.0739, RMSE=0.2718, R²=0.0281
============================================================


📊 Round 442 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2404, R²: 0.0499

============================================================
🔄 Round 445 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 445 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2762, R²=0.0621
   Val:   Loss=0.0765, RMSE=0.2766, R²=0.0401
============================================================


📊 Round 445 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2404, R²: 0.0500

============================================================
🔄 Round 447 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 447 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2760, R²=0.0525
   Val:   Loss=0.0769, RMSE=0.2773, R²=0.0851
============================================================


============================================================
🔄 Round 448 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0658 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0658, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0658, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0658, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0658, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0658, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0658)

============================================================
📊 Round 448 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0473
   Val:   Loss=0.0658, RMSE=0.2565, R²=0.1001
============================================================


============================================================
🔄 Round 449 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 449 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2766, R²=0.0637
   Val:   Loss=0.0757, RMSE=0.2752, R²=0.0341
============================================================


📊 Round 449 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2404, R²: 0.0500

============================================================
🔄 Round 452 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 452 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2758, R²=0.0655
   Val:   Loss=0.0774, RMSE=0.2782, R²=0.0342
============================================================


📊 Round 452 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2404, R²: 0.0501

============================================================
🔄 Round 454 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 454 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2754, R²=0.0529
   Val:   Loss=0.0783, RMSE=0.2798, R²=0.0804
============================================================


📊 Round 454 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2404, R²: 0.0501

============================================================
🔄 Round 455 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 455 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2765, R²=0.0648
   Val:   Loss=0.0760, RMSE=0.2756, R²=0.0340
============================================================


📊 Round 455 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2404, R²: 0.0501

📊 Round 455 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2404, R²: 0.0502

============================================================
🔄 Round 459 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0680 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0680, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0680, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0680, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0680, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0680, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0680)

============================================================
📊 Round 459 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2801, R²=0.0501
   Val:   Loss=0.0680, RMSE=0.2607, R²=0.0827
============================================================


📊 Round 459 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2404, R²: 0.0501

============================================================
🔄 Round 462 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0752, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0752, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0751, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0751, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0751, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0751, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 462 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0752, RMSE=0.2742, R²=0.0637
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0416
============================================================


📊 Round 462 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2404, R²: 0.0501

============================================================
🔄 Round 463 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0755, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0755, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0755, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0755, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0755, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0755, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 463 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2749, R²=0.0591
   Val:   Loss=0.0795, RMSE=0.2819, R²=0.0606
============================================================


📊 Round 463 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2404, R²: 0.0501

============================================================
🔄 Round 464 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 464 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2774, R²=0.0576
   Val:   Loss=0.0738, RMSE=0.2717, R²=0.0662
============================================================


📊 Round 464 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2404, R²: 0.0501

============================================================
🔄 Round 467 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0747, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0747, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0747, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0747, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0747, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0746, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 467 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0749, RMSE=0.2737, R²=0.0661
   Val:   Loss=0.0820, RMSE=0.2863, R²=0.0296
============================================================


============================================================
🔄 Round 469 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 469 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2764, R²=0.0589
   Val:   Loss=0.0761, RMSE=0.2758, R²=0.0577
============================================================


============================================================
🔄 Round 471 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0672 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0672, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0672, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0672, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0672, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0671, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0672)

============================================================
📊 Round 471 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0508
   Val:   Loss=0.0672, RMSE=0.2592, R²=0.0968
============================================================


📊 Round 471 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2404, R²: 0.0501

📊 Round 471 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2404, R²: 0.0501

============================================================
🔄 Round 473 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0755, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0755, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0755, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0755, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0755, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0755, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 473 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0754, RMSE=0.2746, R²=0.0664
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0080
============================================================


============================================================
🔄 Round 478 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0689 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0689, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0689, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0689, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0689, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0689, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0689)

============================================================
📊 Round 478 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0628
   Val:   Loss=0.0689, RMSE=0.2625, R²=0.0420
============================================================


📊 Round 478 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2404, R²: 0.0501

============================================================
🔄 Round 479 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 479 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2770, R²=0.0658
   Val:   Loss=0.0748, RMSE=0.2734, R²=0.0322
============================================================


============================================================
🔄 Round 480 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 480 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2758, R²=0.0546
   Val:   Loss=0.0773, RMSE=0.2780, R²=0.0774
============================================================


📊 Round 480 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2404, R²: 0.0502

============================================================
🔄 Round 483 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0665 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0665, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0665, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0665, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0665, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0665, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0665)

============================================================
📊 Round 483 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0519
   Val:   Loss=0.0665, RMSE=0.2578, R²=0.0747
============================================================


📊 Round 483 Test Metrics:
   Loss: 0.0781, RMSE: 0.2796, MAE: 0.2404, R²: 0.0502

============================================================
🔄 Round 487 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 487 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2775, R²=0.0541
   Val:   Loss=0.0735, RMSE=0.2711, R²=0.0788
============================================================


📊 Round 487 Test Metrics:
   Loss: 0.0781, RMSE: 0.2796, MAE: 0.2404, R²: 0.0502

============================================================
🔄 Round 488 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 488 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0658
   Val:   Loss=0.0730, RMSE=0.2702, R²=0.0327
============================================================


📊 Round 488 Test Metrics:
   Loss: 0.0781, RMSE: 0.2796, MAE: 0.2404, R²: 0.0502

📊 Round 488 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2404, R²: 0.0502

📊 Round 488 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2404, R²: 0.0502

📊 Round 488 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2404, R²: 0.0502

📊 Round 488 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2404, R²: 0.0502

============================================================
🔄 Round 494 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0750, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0750, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0750, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0750, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0749, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0749, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 494 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0751, RMSE=0.2740, R²=0.0554
   Val:   Loss=0.0811, RMSE=0.2849, R²=0.0755
============================================================


📊 Round 494 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2404, R²: 0.0502

📊 Round 494 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2404, R²: 0.0502

============================================================
🔄 Round 497 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0705 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0705, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0705, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0705, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0705, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0705, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0705)

============================================================
📊 Round 497 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0578
   Val:   Loss=0.0705, RMSE=0.2655, R²=0.0667
============================================================


📊 Round 497 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2404, R²: 0.0502

============================================================
🔄 Round 499 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0733, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0733, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0733, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0733, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0733, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0733, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 499 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0733, RMSE=0.2708, R²=0.0653
   Val:   Loss=0.0882, RMSE=0.2970, R²=0.0353
============================================================


📊 Round 499 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2404, R²: 0.0502

📊 Round 499 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2404, R²: 0.0502

📊 Round 499 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2404, R²: 0.0502

📊 Round 499 Test Metrics:
   Loss: 0.0781, RMSE: 0.2796, MAE: 0.2404, R²: 0.0502

============================================================
🔄 Round 504 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 504 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0691
   Val:   Loss=0.0725, RMSE=0.2692, R²=0.0153
============================================================


📊 Round 504 Test Metrics:
   Loss: 0.0781, RMSE: 0.2796, MAE: 0.2404, R²: 0.0502

============================================================
🔄 Round 511 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 511 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0643
   Val:   Loss=0.0744, RMSE=0.2727, R²=0.0367
============================================================


📊 Round 511 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2404, R²: 0.0502

============================================================
🔄 Round 512 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0715 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0715, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0715, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0715, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0715, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0715, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0715)

============================================================
📊 Round 512 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0476
   Val:   Loss=0.0715, RMSE=0.2673, R²=0.1027
============================================================


============================================================
🔄 Round 516 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 516 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2775, R²=0.0519
   Val:   Loss=0.0735, RMSE=0.2712, R²=0.0893
============================================================


📊 Round 516 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2404, R²: 0.0503

============================================================
🔄 Round 517 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 517 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2764, R²=0.0573
   Val:   Loss=0.0758, RMSE=0.2753, R²=0.0684
============================================================


📊 Round 517 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2404, R²: 0.0503

📊 Round 517 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2404, R²: 0.0503

============================================================
🔄 Round 519 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 519 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2765, R²=0.0556
   Val:   Loss=0.0757, RMSE=0.2751, R²=0.0765
============================================================


📊 Round 519 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2404, R²: 0.0503

============================================================
🔄 Round 520 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 520 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2756, R²=0.0714
   Val:   Loss=0.0777, RMSE=0.2787, R²=0.0114
============================================================


📊 Round 520 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2404, R²: 0.0503

============================================================
🔄 Round 524 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 524 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2762, R²=0.0458
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.1106
============================================================


============================================================
🔄 Round 525 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0693 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0693, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0693, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0693, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0693, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0692, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0693)

============================================================
📊 Round 525 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2794, R²=0.0568
   Val:   Loss=0.0693, RMSE=0.2632, R²=0.0738
============================================================


📊 Round 525 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2404, R²: 0.0502

============================================================
🔄 Round 530 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 530 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2760, R²=0.0616
   Val:   Loss=0.0767, RMSE=0.2770, R²=0.0520
============================================================


============================================================
🔄 Round 532 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 532 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2778, R²=0.0574
   Val:   Loss=0.0728, RMSE=0.2699, R²=0.0711
============================================================


📊 Round 532 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2404, R²: 0.0502

📊 Round 532 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2404, R²: 0.0502

============================================================
🔄 Round 535 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 535 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=0.0664
   Val:   Loss=0.0748, RMSE=0.2736, R²=0.0330
============================================================


📊 Round 535 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2404, R²: 0.0502

============================================================
🔄 Round 539 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0754, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0754, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0754, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 539 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0755, RMSE=0.2748, R²=0.0627
   Val:   Loss=0.0794, RMSE=0.2818, R²=0.0369
============================================================


📊 Round 539 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2404, R²: 0.0502

📊 Round 539 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2404, R²: 0.0502

============================================================
🔄 Round 541 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0704 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0704, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0704, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0704, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0704, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0704, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0704)

============================================================
📊 Round 541 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0524
   Val:   Loss=0.0704, RMSE=0.2653, R²=0.0802
============================================================


📊 Round 541 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2404, R²: 0.0502

============================================================
🔄 Round 544 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 544 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2757, R²=0.0527
   Val:   Loss=0.0773, RMSE=0.2780, R²=0.0885
============================================================


📊 Round 544 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2404, R²: 0.0501

============================================================
🔄 Round 545 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 545 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2761, R²=0.0500
   Val:   Loss=0.0765, RMSE=0.2765, R²=0.0610
============================================================


📊 Round 545 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2404, R²: 0.0501

============================================================
🔄 Round 548 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0741, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0741, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0741, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0741, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0741, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0740, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 548 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0738, RMSE=0.2717, R²=0.0579
   Val:   Loss=0.0861, RMSE=0.2933, R²=0.0674
============================================================


📊 Round 548 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2404, R²: 0.0501

============================================================
🔄 Round 549 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 549 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2765, R²=0.0649
   Val:   Loss=0.0755, RMSE=0.2748, R²=0.0389
============================================================


📊 Round 549 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2404, R²: 0.0501

============================================================
🔄 Round 550 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0749, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0749, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0749, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0749, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0749, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0749, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 550 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0752, RMSE=0.2742, R²=0.0620
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0384
============================================================


📊 Round 550 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2404, R²: 0.0501

📊 Round 550 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2404, R²: 0.0501

============================================================
🔄 Round 553 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 553 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2757, R²=0.0505
   Val:   Loss=0.0773, RMSE=0.2780, R²=0.0882
============================================================


📊 Round 553 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2404, R²: 0.0501

📊 Round 553 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2404, R²: 0.0502

============================================================
🔄 Round 556 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0755, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0755, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0755, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0755, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0755, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 556 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0751, RMSE=0.2740, R²=0.0596
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0411
============================================================


============================================================
🔄 Round 557 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0709 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0709, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0709, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0709, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0709, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0709, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0709)

============================================================
📊 Round 557 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0576
   Val:   Loss=0.0709, RMSE=0.2662, R²=0.0720
============================================================


📊 Round 557 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2404, R²: 0.0502

============================================================
🔄 Round 561 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0745, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0745, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0745, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0745, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0745, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0745, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 561 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0747, RMSE=0.2732, R²=0.0665
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0264
============================================================


📊 Round 561 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2404, R²: 0.0503

============================================================
🔄 Round 564 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0746, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0746, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0746, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0746, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0746, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0746, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 564 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0745, RMSE=0.2730, R²=0.0578
   Val:   Loss=0.0831, RMSE=0.2883, R²=0.0558
============================================================


📊 Round 564 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2403, R²: 0.0503

📊 Round 564 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2403, R²: 0.0504

============================================================
🔄 Round 569 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0697 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0697, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0697, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0697, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0697, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0697, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0697)

============================================================
📊 Round 569 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0617
   Val:   Loss=0.0697, RMSE=0.2640, R²=0.0542
============================================================


📊 Round 569 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2403, R²: 0.0504

============================================================
🔄 Round 571 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 571 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2760, R²=0.0662
   Val:   Loss=0.0765, RMSE=0.2766, R²=0.0355
============================================================


📊 Round 571 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2403, R²: 0.0504

============================================================
🔄 Round 572 - Client client_7
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 572 Summary - Client client_7
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2767, R²=0.0584
   Val:   Loss=0.0751, RMSE=0.2741, R²=0.0649
============================================================


📊 Round 572 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2403, R²: 0.0504

❌ Client client_7 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8688 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8688 {grpc_status:14, grpc_message:"Socket closed"}"
>
