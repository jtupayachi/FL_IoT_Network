[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3c0d190-36e0-4538-b9c3-04a5b9ca3b5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 834e0130-401c-43d2-a1bd-848402aef289
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a577824a-aff8-46bd-bd5b-2ae20df83116
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7bd72811-474c-4cbc-891c-b17170a3a389
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ddd97010-3ca1-4a82-86d6-6fb37402a32c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55f8a18e-9e88-4ef4-bacb-2e5b93224f4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 030c3927-b2e5-49d8-b331-16bcdd1b0b7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 089f7f34-b7d2-4830-afa2-bc219f6018a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 225f541f-f301-4557-94ba-d41b70f7d08f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8bcbc553-c254-42b1-abc0-069550c05cb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3189e668-55c5-45da-bcd2-ecd66c9917a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eec657b7-b39c-44a3-aa52-9c6eb2f2a871
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35f4299d-9962-4b49-aa43-38b1fd44ba74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe040248-22cb-482b-95ae-700d9c218f49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f653525-a5b0-4d64-9bc6-15c8387f1659
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 281965f9-5cfb-44e6-8f84-280256b165b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b65404b-8db7-430e-a081-c9b230eb59fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61b807c8-921d-496f-b49c-d12e34574956
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b950a80e-7b58-46ed-92e2-304e716fa7f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41ed899a-d396-4cf2-8760-bab869ffe2b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46d1e618-02c8-4597-a950-402e6eda7a74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7b7d0da-256d-4e32-a292-b65ddb088dbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e121da01-2111-4622-a660-3b77606360b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7211a33-e8d0-4409-9f5b-5f3e03d0f6b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9794811-0c03-459f-aa5b-024f589b3956
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a21766e-e8d6-425a-b5b6-3b4a08e654eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f96b443-8601-48af-98b9-443bea9248b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b14ad4bb-02c7-401a-9828-e8597ea96bdd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6adc8360-3095-402d-84a4-cf0191298c5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96ccfe22-25c4-43a3-b758-ecd1d78b1d33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ee8097b-c78e-4a2a-b1ae-3032110c27e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 768f6cd1-5775-4cd2-b955-f5eea9956404
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 309fa902-4e79-4420-afab-0ac96ced6f5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d81c714c-3c36-47b4-bf2e-b9c2952193dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95e9e539-12c8-484c-a637-17402b76d959
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82b0bb02-c1a6-4521-b25e-1f2454a69c14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4d149da-e2b6-417c-8144-89a1b5aa8a1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48966c4e-b2fd-44b2-8a00-0eba7e621a86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 538e9b1a-c087-4d0f-a8f0-7d0bdb3e7026
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d375eda-346f-402b-89af-410350e7fd1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d8ff3d1-ecb1-4275-a533-2debf09b2b0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 952e164b-ecb6-413e-b97f-31ed385bd252
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76071686-bacf-4974-b69d-b8ff6257f8f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3ba6358-1e05-4a3b-9ad3-9416606cbee5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f80bc2f-5d04-4495-9970-4f2a2da30ecb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1ca0def-48aa-4d01-a0b7-3207ed60ba43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d519c45-27c2-454f-a98d-f8eec85f8675
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36f3d44c-1156-4b36-a20e-3ac007db24d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f57db2e2-4f67-4091-8472-7e01371e62d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10567ed4-3169-4471-a81d-66a6dc748f29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 358c7d3b-57d3-419d-9a63-89a91893e575
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d112c2c-bb4f-4fbb-b04b-316a6a5ffa95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98b74170-2ad7-462b-8ccc-e0dab67bc98f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9498ab83-d6d8-4aba-809b-c623aebf059d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 940e5969-ecdb-4269-85be-f5b54525a93e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e60c9e2-f686-4ca5-8296-c11d7f7233c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cdce5031-cdd6-4f87-8bca-25e411accf28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c65de58-ae9a-4857-a2ba-fdb229d5985c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04e5a7e9-f50b-4b23-832e-6243c45cba02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5659ec2-b031-4bec-9fda-0d4c6c826d2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 382c37c8-c526-4902-b6c0-9346bd8bb5fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cebd3f83-7670-41f6-ba1f-18df1661986c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd4d7145-3136-43ac-b330-d299fa6eefc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d47c7822-46d7-4f48-8cc8-eb717e18630b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d8f2947-bf05-4293-81a4-72772858dd9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39e375be-db4c-442b-b8e3-6c8fc3e39853
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d640e680-0688-4edb-b9a6-e28bca2c043a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ae85035-090c-458c-918c-9742e53fd768
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22b8c3e2-662f-4cc6-b631-b6c2332952f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 353d18f6-3fc6-4f61-aeb7-1aabe872cc96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d9f13c9-53f2-40ab-911d-bed07565ad16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8c4d3cb-b5cd-4ae7-b7e6-8b8e4b51eff5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f05784c6-e13d-4076-9add-11a0e87160a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1a605d6-a871-43e8-8a91-76094ec37792
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84e88687-d6ed-4562-afbb-148a88a07ce9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 167ef100-b8d2-4705-b54e-5debe076724c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70e5c6ed-663b-40c7-973c-7a82a534bce6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 398d3b56-69b2-4b50-aaf9-f522d12d8cb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c38caa7-42d9-48b6-a73f-b757b00fadb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 546b6c02-fbe1-4eef-aeaf-de82a811116c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f628d39-9084-4b01-aeaa-11f8c052dcf5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0218012e-728c-47ab-a038-b9b7b93d1257
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00f68ab6-b826-4512-9995-fbf4095e7260
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d42e004-05e2-4743-bc86-a3e3fe95daf6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f51ee8a0-c36a-4c77-8e79-2e2e9c0eefca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c4d53a1-5f0d-452f-b275-2f6fab053f33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f78e94cf-aa38-4282-9ab7-c20351d1c0fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e5488c4-ec14-4993-adc5-3ef7defcdabe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e427141-724e-4e69-8154-aefdd4f38cdb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message afac83bf-fb87-4ad9-b5ec-0f19390b67b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bbeb9b81-c373-445e-9a9e-6bf5bfe204ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75e1f385-28ad-49bb-8a96-75ae6e8ce166
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c87bddb-8413-4d37-af52-4d46846a59c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9918f72a-02fd-4f9e-8848-451ff6c7e907
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ef9e33f-4f52-4105-8f7e-21d876863f37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95d34873-58ee-4dfb-af81-ac74b33e9905
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f0ed84c-0424-4ef2-93ca-6a9de983a91c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3a12cb2-013f-49af-8ff3-ba8e4d7961ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41e5c237-da4e-40fa-8525-4bd3ce7373f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 697c99b5-fcd9-4ea9-86d4-69f2d8080b31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 869712d9-e48f-4292-be9a-8242c2029624
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0508280-3592-4870-bbc8-aa107b4b8ef5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5432f98d-70c3-44fa-8bd2-21fe85b64f52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74c0f726-2311-4582-a644-ea0a18306d42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc5e95b6-b080-4bb0-8542-5b5fb8b49f97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d50fcf7-d5f2-420a-a755-8523e4fb4a29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46b55f39-c9e2-46dc-93b4-7382166ec0a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c16dff3-9693-4f25-b7ca-f5f10f4de32f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 070acce2-0cab-4b87-bc0b-c63c23d51df9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed206f77-a92d-4e64-96e3-4a05e2a9ea24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b011436c-536d-44b8-a82c-8bc186ce0eb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 826c28ed-4647-4cc4-ade9-90c4dac31462
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 869a229e-d7aa-407f-b679-2a4d45f1df45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3412c1bd-ad05-42f0-8eb9-114ecfa9e164
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ebd1cee3-03ca-462b-bc87-cc54440d0917
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42861a6b-efc7-4fba-991f-ac4b73783a54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a74ef6e0-e5a7-4372-ba8d-ad5917f4257c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 916bb6f0-b20d-438a-a7f3-1f7a10c499b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message abaaf3a9-a885-45fd-b5b4-eb8375c0c93e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a626edff-4016-4c58-8cb7-37b08cf79648
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message edc47b55-ace4-4f6c-8c65-49de30624142
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 489296a5-22a0-4df7-b61b-ff7217fe81b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b43896d6-b23b-4ace-bb60-0cc2f7cdbb29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f3fa975-5db7-4960-a7cc-f9a2edfab405
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dddd1aad-4df0-4598-9b86-fea1d3c17410
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4666ecb0-e08d-454a-bcfd-70f7a03e26af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 282db85e-0c0e-4beb-bb59-e860a319d290
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b5f278b-a3f6-4e1f-96d8-8d158c977d6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb36cd1d-42dc-4536-b368-ed1e78cc21cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe11f6f3-3ee3-4f85-9ff2-f4db6b8d167b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb147ebf-736a-41c8-8924-d327d5085c35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a81ce4f-9c7b-4b24-9457-303f64d3f67b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 744b4bfd-f2d5-4a1c-8164-5db96d61a592
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a75bdc4-43de-44a6-adf0-f2deafb15b44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aca33b68-7302-42d4-9ac9-31dfdab08656
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dbf1afb7-3ee9-43c8-baf4-42086ae56ca2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60e9a5f7-0f9d-4562-9bb1-887a963d126e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a284144f-631c-4544-809c-f43bcc232ae6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1e176aa-0f0a-4c30-8cd2-e2136f9ddf47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3dfadf0f-a703-4093-941d-784aef09bb78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa63e771-e36e-431e-9339-a22a2cbf2c24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b332c40-da84-49a2-84cd-9d860307aa96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b461b2db-f745-48c5-87dd-2bede82ad556
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4031f003-ba4c-4b2f-97b7-6c2adef31f3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4061d8c-4b68-4363-93ff-c1cb413d7827
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5d9ba3a-9869-4581-9dc7-840d90653433
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3af148f-b4d1-438e-b3f3-d9c4fe73f47d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 786c8397-9842-4876-95d2-73425b0a62ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79dca3d1-4110-495c-b709-a40dce9467cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af101db8-0dc1-455f-81b3-07822804f34e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c34cb15-4294-492d-b642-e83c5ba1a04b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f68fc53d-04ac-4d52-a641-06e91094236d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e05a5e0-a1ed-4ee7-a9f5-e8a5f5771724
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 816b6991-f75a-447a-b3c7-6651256433d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40ba0b85-cdea-4e72-b7d8-64e8665c17b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e17bc219-deac-4bf8-a18f-7a3fe68f3c5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c13b1476-3803-4b64-a884-eb1c8d8b94f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b837c2e7-ce8c-401e-8dcc-20a0e0ecad28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c9f81dd-b6fc-4c11-9f7d-32156a280ce3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77964326-f236-4070-992d-79446c9cf336
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c5677b4-862b-4652-9edf-55531d3c5c89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4cd11175-74ed-4a25-9de6-27d33d7126ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7772234c-13ac-4b05-b133-e5a2287e8fe0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9dbb98fd-4902-47b0-a39e-4b7efaf40d6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68f8230a-09a9-4748-8c3d-5f567b510000
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62691db4-6e6f-4d24-8f7a-5b239536e390
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba08d44c-87a7-447f-9d75-d827a502b50b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52db2334-438d-4a90-b629-188bbb9242f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b632ebb0-ddd8-44b3-9f7f-1c5c25755896
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message baa3898f-6e37-4569-b279-cf7e66c6c346
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bcb13322-5b0a-4d89-9e17-4d1d56b20016
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de4bb518-91dd-4b11-9b05-8f460f5d4eef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d2dcf57-f761-4a0d-bbf0-bb75b1984fbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ef12e5b-15e7-4b06-878d-360fcabc318f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30f8b9c9-f982-4845-847d-03dac0229782
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 768275a0-46be-4874-96e7-9bf18f9629be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07b55e83-4546-4722-b110-0c39ac6775db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8146d91-0fcb-4d18-bd97-8de751f3c608
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 347db363-e360-44dd-9b8c-62b086895fb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73f7079b-1f97-415d-a892-7038fdc1be5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bfb4aa0e-b5c7-418b-8195-f1596c470996
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 775058aa-751a-4045-9ddc-4a443313ff45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61046a3c-9b64-47fd-9d28-535ef997d508
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6fe3d06c-96b8-4872-b059-2bc6fc7cb2d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df8b6a30-234c-4d64-9391-e8e0c844eec7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 538137b2-db9f-40f6-a4dd-87c0e7bc79f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47950e6c-625f-424c-8b1e-36a910ebc23c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2783c72a-e834-456e-9d4a-30137bf04301
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ee8ecae-32bc-404f-b532-56482d62535e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4946ca49-4d20-41f0-aacc-2383a73c8b95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81acc299-896a-4101-9cb7-f10053483ae3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f94799e1-1f73-439e-8dbe-f8219b91c648
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 476c9b45-7215-4c69-842b-03d99cb5a9be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52907136-7a1d-4fe9-9d6c-b40c302a1e44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21d39637-ba3e-4b68-be1d-655209c0ba22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9195827e-9331-4d41-bd69-21b51e3cb19c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 030e6fae-fcf2-46f1-8dae-be2462cfae5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 455530fb-22e4-4a8a-9bbe-8e96c7f0f7f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ca61dc9-eac3-4d74-9536-9458d8afa9f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f674aded-d6b2-4e73-a083-bffdd3980779
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e7cfa15-5439-469f-b657-9a8b8465551c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a04f5a6-50c6-4219-b061-a33fceecee7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc4484db-b8a4-47e9-a757-0c06f6681dcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49034612-6a50-4f96-9113-548763b9159b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5655fd76-1919-45fe-905a-f09bc22f4be6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74d2685d-397d-4cae-9826-a966f2407e6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b3a1212-b31c-4eb7-9d8e-a8a8f7f3a178
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7844262-8edb-488f-964e-b9be8449626e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13fe5c90-591e-43b2-afd3-6ef4ea89617e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a737d13-407a-458f-aa88-f6bf33f72687
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 503f48af-1a60-488a-8577-7d25a5c06b52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34a70549-f71f-41b6-9323-3e50d3ed7b89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b793568-d64d-40c5-8e75-3d04674ada26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04a71333-d15e-4dea-9e58-262aa0844e28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 532fe706-530b-43f3-8ad9-65b6c14de18d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c526d65a-903d-413f-80c2-5cfb59ebd3ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3a54c9d-9f22-4ccb-9e18-f81dff3dba07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27c412a2-ca66-4310-9269-2f9fe0872f6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 811b21c6-331d-4176-beec-573bf0e13a88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d89a41e9-f8e1-4bce-b246-94adfe725c9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0bf8db72-51d4-4863-beb2-1c5b1436ede8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message afb049ee-344f-4697-a6ab-21ac0f44d5e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5de9351-bfb7-48cc-9ce5-9d7fb235fe21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f0df77e-a1e8-4b06-8d9e-a0ef685f3c0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 164e5976-f739-4f95-b16e-6379241b2e75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 510ea8ae-d238-4026-8adc-9786541fd6ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3360bdf9-2e4b-433e-9c3e-41a5fb0781fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ca9cc14-81a3-45c0-84ca-b125a9467be6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab46bfa3-8178-41f7-a7fa-f623dee5f460
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3247202d-af19-4f8f-b62e-ab813df6e4c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d93d82f-8cc4-41e9-816f-9412ef3bd5db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de4afb86-037a-46f8-92a2-39b42e7c91d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3fff5be6-fff9-4d09-8f8e-530c24e67351
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e91acad-79d7-4c67-a617-f72dcff71b91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73c45a3f-d45d-4f05-b46a-e2fd5ad3bbe5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61588e63-9f1d-4f36-aa01-fcf1febf89cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9910d1d3-c67a-4004-94f6-777ae2963a1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71aab938-dbc0-4a48-82b9-e8abb5836f66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 435aa0f6-9b08-4b6a-8463-409b7b7502a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5d9c117-27f1-4212-b20d-e1ea7aebfa9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e651d599-bc5c-413d-9b62-992e31f6b45e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e0d9ea3-4206-493a-a0ee-4f9fc8a6ffd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86d399cc-9ade-4b35-8724-a33f648e7a48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66788230-b9b2-476d-9f5e-acfe0aa9faf8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 523af84f-06c7-4058-9617-bb1cecfe0d88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eae8cea6-3bf1-4ef0-b334-14ea6addd019
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3478e99-4632-4a0c-8422-ae9e38a9554f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1aaf681d-f851-4aad-b61f-1346bc663c4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5cd4ee35-18e1-428b-830a-f83eba483bcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3bf129fd-8c0c-45c6-b516-ace6fd7b2048
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82548bf5-d8a3-414c-af98-e02c18194256
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08039b85-aab2-4cdb-a85b-a9f9e7187c9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d32176a1-ce8b-4f6e-bd31-2dccd55607af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message daa9986f-89e9-4b02-b713-9db37059045a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message efe1cf71-6db8-4b3c-9d3c-800cb18d1061
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f0f3aba-0cae-4018-8316-bd666ec59bc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44410687-dde8-4c1d-9273-b8a01c0b108c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 374eec09-5916-422a-aada-4367d7b7ebbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a922f5eb-4bf7-4e67-9df8-4d3e73d708c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c53387a1-0f11-4020-8c50-85f3bbd43801
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2973528e-5b8e-4730-99a8-d131184cdd82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9640f079-d186-41c6-b82c-426d7d8a095d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8960e0ad-b9bc-4f3a-b6c9-8de2e0cdf2e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d1e6793-1b96-430d-8091-96b7b657e46f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ceea8265-3644-4f79-9046-3f172b73ae01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f58965e2-700d-46b7-b058-0d17249eef33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9be0d2c-002e-454a-9835-8cca6f560839
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8704d4e1-c409-442f-9239-e2b2fb69c1c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c39d9d4d-cdb5-486d-97ea-6744472f08c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ffd21ef-0b55-43df-acac-cf75a0315f93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4b46bde-1d4e-405e-a2c9-4498c21690a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00edb3b3-da91-4a0a-ad80-6d2fa27a79b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c48381f5-5a4f-46fe-8e87-069736f2a275
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae1eb673-75e4-4223-8314-efee01f6dff4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66281377-5f65-40e6-8ce5-26b6750dce7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a68a71ae-7901-48b0-a617-42f44ae4a140
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d2c61f3-f758-4cbd-9af8-b843f5df0629
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 244e7163-225d-481b-938d-445d0729e857
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bcb175f7-6b9a-4a72-b812-4edf8b3972b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 466e80c3-4d2f-4dad-b67e-bd3b25dd925d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4607083c-bf3e-4b68-9635-03a71ffc05ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6843d064-fc22-49cd-8403-8ec1039d2c0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 502e5718-af59-47b7-8fe3-b70056ef2bff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 540bfcaf-5726-4d75-b13e-ce097541becc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10af662d-5f7b-477a-a930-62958e2bce31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9b5232e-e66c-4559-9828-cee841c56048
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d9f6b71-bbc4-4a91-9804-280ef4b4f1bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8d592b8-b90b-44fb-aabe-c9b4ced386da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2ee14e7-3517-48a3-9aa3-3bad06c2c1bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58727122-b50e-4efa-9508-1ff3614d53a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86160c34-cd91-487d-b652-2d9a6dac19b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f08ed48d-7dbc-4b9a-80c2-4f31464c89d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37053413-6da8-442e-9099-5411c5fd1e3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9fb092ae-a939-4b4b-a18f-2ac7ac3cd738
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8542929d-bbb4-4847-8835-e22278b4dec8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48290256-6476-49e0-873e-41b40a3cd235
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4c6dfca-aced-4421-addb-0284ad977cee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c4ff4e5-9a31-4a91-a8b0-035d247817ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 310b7635-3068-4581-80a6-75ce63d1103d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33fe1364-4791-4da1-aba3-0ba464733d6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9cbfd93d-48fd-4685-a8d1-86c47b518424
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2418fed9-edeb-4ac1-8fd9-c917e5583c51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c58c9ef-9939-4a08-8f57-f313f5e2bc3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7aad4d4-19f9-45af-a250-1504a0533314
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f317f66f-486d-41b1-b2c4-194f584b5764
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5750db88-3ea6-400f-964a-c2ab2da96d36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9017638-79a6-46cc-83db-c6682a8e3f30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aaf558c0-abbd-49a9-a3e0-a8b9fee29cb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a286538-b0df-41b3-a792-9a2f354424e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b81fef93-89de-41af-8f7e-388e4bcc4d6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40b6ff75-6c70-4519-9ba1-c692605b0253
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac667277-4f8a-4f26-a217-783ad434f3f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1c374a2-32f4-4e64-806a-55e0a4528a81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6947687-8993-4728-b9da-38553d2e53b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c586d209-2cb5-4111-a05f-4ab836370a13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a21a8cb-c025-40f1-9c77-fca0abb5f6cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 311192a8-9df9-48b3-8171-4ca876871408
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 555ddd48-7554-4a48-9ff6-4d285c831e73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e754c65e-f9eb-4b1d-b407-a4cf7abe6572
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a029eaec-8a6f-42ad-a1c5-8578aebedd9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2ae6b97-f3ac-42fe-95c1-a2679f90c910
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f3e60fd-e5bb-4f97-a1fe-39efc5707742
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52c9cd24-9fe5-41d7-a33e-287bd2ee9161
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef228cc2-c3c3-485e-941b-0e5a85f2d6ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4230b71c-689f-4437-9c18-930e70d293fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db38c343-352e-444e-8546-8f3167b8e482
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 210b19eb-ef02-46a0-9c52-3543d3a5b209
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7527c0b5-13f8-4bf2-b54b-98f5bd45ea6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 592940b4-3842-45c2-81e3-7a8e0200983a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e27d02c-eb3d-4f0f-9a33-a3b4ec611add
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07791ec0-e569-4c90-8d4d-ae5f4c18417c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f017406-241a-4b33-b0a6-d9feae12ce8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d16d5a4b-1144-4e35-b76c-2a4648cb2fe1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4da8e7ef-38f8-42ab-ac27-d91f565833fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7005a744-7eab-44b6-9a5e-83018fabc8d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0e35a63-00bb-4d35-8f14-8f9d5ae9de5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a71f157d-7332-4e1e-91d6-fec75d77cfd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 865d2146-b2e7-4724-b78d-95acdd215335
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 508761f6-0341-4550-a062-f9e1f7596409
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2b5e8d5-dbea-4c59-b694-e11db3744c7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aea94b12-fe58-489e-9ba3-99334ec9b2b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fbf49f22-69eb-4f1c-b5c0-22b5e4819e9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d037b76-f8c0-4ae9-b87d-85131a95327d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b188640f-eb98-4e1e-aa6e-74f07665a8c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 084d4598-e9d9-44f9-ae70-bede52ed4a24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 087e7eb2-38c0-4fd3-bd57-8677d512c066
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69c3a9cb-d6bf-49b7-8558-1e412a7e03b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56d6d13c-bcad-4622-a681-2830f9f5b494
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04ff5dc8-8bf5-4c5f-85a9-7563143bf0a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43515ba2-a30d-4052-98ee-8e5d458ddead
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a92d53e7-7a9c-4bdb-9306-4620e881919e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34578f5b-e5ef-400f-be74-8481e570a4e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa3c47cd-6029-4abc-bea2-e0f5bac9bfb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a19e030-ef3a-427a-8c87-89949e888b0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b23881e-ce85-4b16-927e-fe5377c89a1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e86f0100-68d9-47bb-85c9-4fe8d27a26d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 313debe0-304a-47b9-9058-6c0356d5da0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 824fb16e-0f53-4eba-abc3-6a40516837dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9bf5b7b-4f71-4056-a08f-dfe34172b9fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25631d1c-4536-4815-8350-376b080cee93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47dc9d37-5529-442f-9bb9-951532fd896b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39cd1f8d-914b-40c2-bbf6-abdf4de72752
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f7a579b-1de5-4dec-95be-73f674c4e239
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e1ecc0d-5b5c-46ae-a90e-4afdb568cd5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 488aa87f-678f-4f7a-86b4-8a2c12c2fbac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8fdd323-4286-4397-8c8a-1baa4428611f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ab724e7-011c-42f3-86aa-111ee9943f30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c0593f7-08a7-477a-ae3c-a49abdfb52b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08c2e5f8-99db-4955-8c71-ca8176f6f46b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc0c2e0d-e6ef-4399-a0db-f561bc1fd122
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9239b4c1-4f4c-4da9-97d0-faea05482aaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed11652b-8db1-4493-8633-ca3b5b8ca4ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a41681e2-7ea7-4ade-8dbe-9adfa08923b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58689d23-c34f-494b-9e0e-bc3d0791c608
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a6e6799-cf49-4e4b-8940-a93272a268f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4417ea3-f4c9-4455-8759-ba2f78f83616
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0decc8a6-668d-4a33-b354-2a66859dce86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d3a88a3-6a00-44c5-99ba-b2dfbbe39fc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 932089e0-b263-4ad2-aba6-d69152d6112c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34aa129e-e2e1-45a0-9f51-5853cffb1325
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63eb02f6-52f1-4a8d-bf62-726390a81f51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc30bf0f-c8ea-4ef1-979b-d027bb74b908
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58f6f132-4d2b-4647-b6f5-1dd4ff4d535c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7864ce4-e00e-4b58-96f0-021e01af844c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a21ca364-3797-4d5d-8e0d-8ad3abd29684
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7562ca8-f138-41b2-8f31-3c9cc9c1b8bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d10cc135-ccdd-4f2f-ab8d-fbeccece697b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0fb1f59-4a3e-45b7-ab3c-e4049c567705
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04309b6b-05f1-4da6-8960-2e952bb33927
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89004d2b-859b-4b7c-95e7-04d3000f715a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 713f0083-2774-47f5-b0c6-b3d0890285c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 161a5d7c-4f06-49ad-afdd-90bbe6cfda1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8347bec-aab8-4b9e-9d5d-d26ff23bf41d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea2406e2-9123-468f-ab94-241fc7d51fcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7a5387d-8a4e-49cb-b986-59a25393752c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eed171b5-bdf1-4615-9a62-5070fc986401
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a040c74-601d-4830-b4bc-e3a82709b1aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f78e862-3114-4bae-855c-2b3fcdc1697a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f0eac8e-83fa-4ac0-a376-a4738b73fe22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01359eee-618f-44c7-add7-341d8305218c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5505162c-9e4f-47f6-9c42-570b30ade96d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd61a1e2-78ba-4d3f-b0ec-57aa7bb04d2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28fc017a-ac32-45de-9b48-4e46e21f4806
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a24a18a0-2de9-4fb5-85b4-ed6db6ac20c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83c87542-39ef-4515-8355-f2d8a7c7835d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 368d06cf-6225-41c2-9c08-88ee5a648ea9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b9b9fc5-002c-4afe-bab2-2a87609295af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8fd83bcc-85c2-481b-b823-80367f7e8cc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d20dc7d-1b21-4ab5-ac44-ff4c72870a6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c02f001-6fb6-458a-ae7e-8f803cdbc790
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3342c465-c8bc-4825-8d9c-18b184485f96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04283c28-a16b-4c71-be72-b8b573ef895d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47fe217e-53dc-4c89-9adc-444fb3f9897c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56eb1636-0d8b-4927-8e28-1254a22f6635
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b93f535-5f91-47f5-a967-a57a0efdbd19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5497fd34-cfa5-4552-92ce-8db43f1b75df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6dba8d4a-238c-4d9e-b37b-c0d44527ed2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4bc0dcba-117d-4202-90cb-4c08e29fc602
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f061ee6a-e2fa-4dd9-9594-d0c9557d786a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a038db5-ec70-40b2-ac58-1727d9c342be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c15c98fe-57f0-4f07-9f99-286803361ee1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b1d1c9d-83ad-49c4-87dd-2b8e96f99f4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2cbaedd4-f222-48ca-b404-5a6ffe3163d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae02465f-4e8b-43f3-99e9-6812dd744964
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2efbee2-8185-47f4-8fab-053b9021f66e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 423f8d03-145d-4a0d-91ef-bf8519c168b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8149657e-7fce-4638-b739-272e2563f9ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6de4841-2492-4b27-9b95-1b64502b4872
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f3a4152-a5f0-4154-a9a0-b6a506484d65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28a4f796-88f9-403a-a7a1-37164a4c33bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 594cb40a-c421-4383-ba1e-c27de7da9600
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb5aaa30-d40f-41ff-a1b0-920b58568792
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00565e70-65fa-4e21-b916-9d51d9bcd9d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff6b169d-34d2-478d-9be7-0886ee0d04ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76a24edc-28cd-41bd-bf8b-b0b08703631b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 476ce223-d6a0-49ea-95a7-773062b67740
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0985dc42-d291-4cdc-a9cc-405cb8f95128
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc58e35d-fed3-4db1-8884-b883c40dcac7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89b43eaa-a4f1-4f7d-af0e-3afacbb0ced3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3665eac-44d4-4e42-868f-b5323d9c0b0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 226b6335-8e45-4328-8bec-451c7f810f51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5158cdc0-43b8-45f1-996c-1229dee3ec18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52216b02-c8a3-49dc-a048-9f9a9ac16a5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9cfc383-3e0c-4018-932e-9eb03e6796ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f6bca5f-9080-4f2d-b91d-244b71748259
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c77051c-f18f-4779-9e7b-22cd2943c4aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e49c14f-c81c-41e6-97d6-3e046c71c5a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4928f90e-b8af-41d2-88e5-b6e2513a0a98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94c86bb1-47a0-4bbe-96a4-63d000983cce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ad189f0-da8f-4266-9f33-5266430bc5d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9bcf23e-d1bf-4380-a951-f34c15da8459
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab9d0850-cc8f-42f2-9370-05dc994242d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c86e6fc-44d0-4025-998c-2aa9b2c28c30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc2641f9-1dca-458d-87ef-568fb06f6912
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5a9a095-e2c5-4b0e-87cb-c83d7e1252cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 923b6dab-4826-4db2-a51e-020dbd3e0e14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f6114ad-5e5e-4664-8519-2e0ca1fe1348
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dacbc1a2-e79f-4c4b-b546-e6c6135a5597
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76de58f6-190d-42d9-9b3e-46e8ab68641e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28db957c-f1ea-42b5-b80b-d34e71cd941d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a428233-aa92-4b49-9911-62e58927fec8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c68224c2-3079-4da9-b010-6e43fb5d2d07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9accb26c-b8e2-4abe-804d-8a2495ce6fce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb6edc7c-b6b8-4973-bfcf-92a716be9766
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82f6ef72-2cb3-4c27-9dd3-b96ddcbd284c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 377c1baa-cddf-47f1-83aa-6eb7714bfafe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 440b0cd8-0c68-4dac-9620-7461c1f0492a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5d6a519-d725-4f48-97f0-ce24de2d65ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f19e2a4-1ddf-45e2-8f22-7850e56640fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f67197fe-b10f-420a-8deb-24a2cdc992c8
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8688 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_8
Server: localhost:8688
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_8
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_8/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_8/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_8/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_8/test_labels.txt

📊 Raw data loaded:
   Train: X=(5265, 24), y=(5265,)
   Test:  X=(1317, 24), y=(1317,)

⚠️  Limiting training data: 5265 → 800 samples
⚠️  Limiting test data: 1317 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_8 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 2 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0889 (↓), lr=0.001000
   • Epoch   2/100: train=0.0824, val=0.0890, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0823, val=0.0893, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0822, val=0.0896, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0821, val=0.0897, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0813, val=0.0896, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 2 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0034
   Val:   Loss=0.0889, RMSE=0.2982, R²=-0.0185
============================================================


============================================================
🔄 Round 3 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1882, val=0.0842 (↓), lr=0.000250
   • Epoch   2/100: train=0.0869, val=0.0845, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0839, val=0.0849, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0830, val=0.0845, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0829, val=0.0842, patience=4/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0828, val=0.0842, patience=10/15, lr=0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 3 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000125 (1 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0047
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0016
============================================================


📊 Round 3 Test Metrics:
   Loss: 0.1566, RMSE: 0.3957, MAE: 0.3240, R²: -0.8775

============================================================
🔄 Round 4 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1219, val=0.0876 (↓), lr=0.000125
   • Epoch   2/100: train=0.0838, val=0.0871, patience=1/15, lr=0.000125
   ✓ Epoch   3/100: train=0.0825, val=0.0857 (↓), lr=0.000125
   • Epoch   4/100: train=0.0820, val=0.0855, patience=1/15, lr=0.000125
   • Epoch   5/100: train=0.0821, val=0.0856, patience=2/15, lr=0.000125
   📉 Epoch 6: LR reduced 0.000125 → 0.000063
   • Epoch  11/100: train=0.0818, val=0.0857, patience=8/15, lr=0.000063
   📉 Epoch 14: LR reduced 0.000063 → 0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 4 Summary - Client client_8
   Epochs: 18/100 (early stopped)
   LR: 0.000125 → 0.000031 (2 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0032
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0191
============================================================


============================================================
🔄 Round 5 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0958, val=0.0914 (↓), lr=0.000031
   ✓ Epoch   2/100: train=0.0903, val=0.0873 (↓), lr=0.000031
   ✓ Epoch   3/100: train=0.0868, val=0.0851 (↓), lr=0.000031
   ✓ Epoch   4/100: train=0.0849, val=0.0840 (↓), lr=0.000031
   ✓ Epoch   5/100: train=0.0839, val=0.0834 (↓), lr=0.000031
   • Epoch  11/100: train=0.0827, val=0.0829, patience=1/15, lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016
   • Epoch  21/100: train=0.0827, val=0.0830, patience=11/15, lr=0.000016
   📉 Epoch 23: LR reduced 0.000016 → 0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 5 Summary - Client client_8
   Epochs: 25/100 (early stopped)
   LR: 0.000031 → 0.000008 (2 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0028
   Val:   Loss=0.0829, RMSE=0.2880, R²=-0.0065
============================================================


📊 Round 5 Test Metrics:
   Loss: 0.0855, RMSE: 0.2924, MAE: 0.2523, R²: -0.0250

📊 Round 5 Test Metrics:
   Loss: 0.0868, RMSE: 0.2946, MAE: 0.2560, R²: -0.0405

============================================================
🔄 Round 8 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.1002 (↓), lr=0.000008
   • Epoch   2/100: train=0.0826, val=0.0999, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0823, val=0.0997, patience=2/15, lr=0.000008
   ✓ Epoch   4/100: train=0.0819, val=0.0995 (↓), lr=0.000008
   • Epoch   5/100: train=0.0817, val=0.0994, patience=1/15, lr=0.000008
   📉 Epoch 6: LR reduced 0.000008 → 0.000004
   ✓ Epoch  11/100: train=0.0809, val=0.0990 (↓), lr=0.000004
   📉 Epoch 14: LR reduced 0.000004 → 0.000002
   • Epoch  21/100: train=0.0804, val=0.0988, patience=10/15, lr=0.000002
   📉 Epoch 22: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0990)

============================================================
📊 Round 8 Summary - Client client_8
   Epochs: 26/100 (early stopped)
   LR: 0.000008 → 0.000001 (3 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0226
   Val:   Loss=0.0990, RMSE=0.3147, R²=-0.0070
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.0913, RMSE: 0.3022, MAE: 0.2609, R²: -0.0947

============================================================
🔄 Round 9 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0921, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0920, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0919, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0918, val=0.0880, patience=3/15, lr=0.000001
   ✓ Epoch   5/100: train=0.0917, val=0.0879 (↓), lr=0.000001
   • Epoch  11/100: train=0.0911, val=0.0872, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.0902, val=0.0863, patience=5/15, lr=0.000001
   • Epoch  31/100: train=0.0895, val=0.0855, patience=2/15, lr=0.000001
   • Epoch  41/100: train=0.0889, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  51/100: train=0.0884, val=0.0843, patience=5/15, lr=0.000001
   • Epoch  61/100: train=0.0880, val=0.0838, patience=5/15, lr=0.000001
   • Epoch  71/100: train=0.0875, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  81/100: train=0.0872, val=0.0829, patience=2/15, lr=0.000001
   • Epoch  91/100: train=0.0868, val=0.0825, patience=12/15, lr=0.000001

============================================================
📊 Round 9 Summary - Client client_8
   Epochs: 100/100
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0330
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0351
============================================================


📊 Round 9 Test Metrics:
   Loss: 0.0865, RMSE: 0.2940, MAE: 0.2555, R²: -0.0367

============================================================
🔄 Round 12 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0957 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0957, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0957, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0956, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0956, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0955, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0957)

============================================================
📊 Round 12 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0286
   Val:   Loss=0.0957, RMSE=0.3094, R²=-0.0244
============================================================


============================================================
🔄 Round 13 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0852, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0860, val=0.0849, patience=5/15, lr=0.000001
   • Epoch  31/100: train=0.0858, val=0.0847, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 13 Summary - Client client_8
   Epochs: 31/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0330
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0415
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.0862, RMSE: 0.2937, MAE: 0.2534, R²: -0.0340

============================================================
🔄 Round 15 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 15 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2916, R²=-0.0158
   Val:   Loss=0.0818, RMSE=0.2861, R²=-0.0340
============================================================


============================================================
🔄 Round 16 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 16 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0263
   Val:   Loss=0.0880, RMSE=0.2967, R²=0.0053
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.0850, RMSE: 0.2916, MAE: 0.2533, R²: -0.0193

============================================================
🔄 Round 19 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 19 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0187
   Val:   Loss=0.0859, RMSE=0.2930, R²=-0.0508
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0852, RMSE: 0.2918, MAE: 0.2535, R²: -0.0212

============================================================
🔄 Round 22 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 22 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0361
   Val:   Loss=0.0852, RMSE=0.2918, R²=-0.0018
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0851, RMSE: 0.2918, MAE: 0.2535, R²: -0.0206

============================================================
🔄 Round 23 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 23 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0295
   Val:   Loss=0.0881, RMSE=0.2969, R²=-0.0252
============================================================


============================================================
🔄 Round 28 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0934 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0934, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0934, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0934, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0933, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0933, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0934)

============================================================
📊 Round 28 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2878, R²=-0.0191
   Val:   Loss=0.0934, RMSE=0.3056, R²=-0.0480
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0850, RMSE: 0.2915, MAE: 0.2532, R²: -0.0189

============================================================
🔄 Round 29 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 29 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0348
   Val:   Loss=0.0857, RMSE=0.2927, R²=0.0112
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0849, RMSE: 0.2914, MAE: 0.2532, R²: -0.0184

============================================================
🔄 Round 30 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 30 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0231
   Val:   Loss=0.0790, RMSE=0.2812, R²=-0.0305
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0849, RMSE: 0.2914, MAE: 0.2531, R²: -0.0181

============================================================
🔄 Round 31 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 31 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0237
   Val:   Loss=0.0926, RMSE=0.3043, R²=-0.0223
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0849, RMSE: 0.2913, MAE: 0.2530, R²: -0.0175

============================================================
🔄 Round 34 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 34 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0313
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0161
============================================================


============================================================
🔄 Round 36 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0975 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0975, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0975, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0975, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0975, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0975, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0975)

============================================================
📊 Round 36 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0194
   Val:   Loss=0.0975, RMSE=0.3123, R²=-0.0266
============================================================


============================================================
🔄 Round 37 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 37 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0187
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0340
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2529, R²: -0.0165

============================================================
🔄 Round 40 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 40 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0204
   Val:   Loss=0.0917, RMSE=0.3028, R²=-0.0193
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2528, R²: -0.0162

============================================================
🔄 Round 41 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 41 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0232
   Val:   Loss=0.0831, RMSE=0.2882, R²=-0.0077
============================================================


============================================================
🔄 Round 42 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 42 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0242
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0018
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2527, R²: -0.0157

📊 Round 42 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2527, R²: -0.0156

📊 Round 42 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2527, R²: -0.0156

📊 Round 42 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2527, R²: -0.0155

============================================================
🔄 Round 51 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 51 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0185
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0191
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2527, R²: -0.0153

📊 Round 51 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2527, R²: -0.0152

============================================================
🔄 Round 54 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 54 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0172
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0257
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2526, R²: -0.0152

📊 Round 54 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2526, R²: -0.0152

📊 Round 54 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2526, R²: -0.0151

============================================================
🔄 Round 60 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 60 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0187
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0156
============================================================


============================================================
🔄 Round 61 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 61 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0230
   Val:   Loss=0.0902, RMSE=0.3003, R²=0.0006
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2526, R²: -0.0150

============================================================
🔄 Round 63 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0996 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0996, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0995, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0995, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0995, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0995, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0996)

============================================================
📊 Round 63 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0125
   Val:   Loss=0.0996, RMSE=0.3155, R²=-0.0361
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2526, R²: -0.0149

📊 Round 63 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2526, R²: -0.0149

============================================================
🔄 Round 67 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 67 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0220
   Val:   Loss=0.0748, RMSE=0.2736, R²=-0.0088
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2526, R²: -0.0148

============================================================
🔄 Round 69 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 69 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0146
   Val:   Loss=0.0793, RMSE=0.2815, R²=-0.0311
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2526, R²: -0.0148

============================================================
🔄 Round 71 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 71 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2935, R²=-0.0210
   Val:   Loss=0.0773, RMSE=0.2780, R²=-0.0046
============================================================


============================================================
🔄 Round 75 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 75 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2904, R²=-0.0172
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0219
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2525, R²: -0.0147

============================================================
🔄 Round 77 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 77 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0245
   Val:   Loss=0.0735, RMSE=0.2711, R²=0.0167
============================================================


============================================================
🔄 Round 78 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 78 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0230
   Val:   Loss=0.0871, RMSE=0.2951, R²=0.0050
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2525, R²: -0.0148

📊 Round 78 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2525, R²: -0.0148

📊 Round 78 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2525, R²: -0.0148

📊 Round 78 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2525, R²: -0.0148

============================================================
🔄 Round 88 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 88 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0181
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0167
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2525, R²: -0.0148

============================================================
🔄 Round 89 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 89 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0184
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0129
============================================================


============================================================
🔄 Round 91 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 91 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=-0.0172
   Val:   Loss=0.0724, RMSE=0.2691, R²=-0.0193
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2525, R²: -0.0148

============================================================
🔄 Round 92 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 92 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0184
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0124
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2525, R²: -0.0147

📊 Round 92 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2525, R²: -0.0147

============================================================
🔄 Round 94 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 94 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0112
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0442
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2525, R²: -0.0147

📊 Round 94 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2525, R²: -0.0147

============================================================
🔄 Round 97 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 97 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=-0.0222
   Val:   Loss=0.0782, RMSE=0.2797, R²=-0.0165
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2525, R²: -0.0147

============================================================
🔄 Round 99 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 99 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0187
   Val:   Loss=0.0859, RMSE=0.2930, R²=-0.0098
============================================================


============================================================
🔄 Round 103 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 103 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0242
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0124
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2525, R²: -0.0147

📊 Round 103 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2525, R²: -0.0147

============================================================
🔄 Round 110 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 110 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0163
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0508
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2525, R²: -0.0147

============================================================
🔄 Round 115 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 115 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0193
   Val:   Loss=0.0914, RMSE=0.3024, R²=-0.0114
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2525, R²: -0.0147

============================================================
🔄 Round 116 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 116 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0175
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0146
============================================================


============================================================
🔄 Round 119 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 119 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0129
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0320
============================================================


============================================================
🔄 Round 122 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 122 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=-0.0186
   Val:   Loss=0.0734, RMSE=0.2709, R²=-0.0066
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2525, R²: -0.0147

📊 Round 122 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2525, R²: -0.0147

============================================================
🔄 Round 124 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 124 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0189
   Val:   Loss=0.0852, RMSE=0.2918, R²=-0.0180
============================================================


============================================================
🔄 Round 125 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 125 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0176
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0115
============================================================


============================================================
🔄 Round 127 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 127 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2896, R²=-0.0207
   Val:   Loss=0.0861, RMSE=0.2935, R²=-0.0066
============================================================


============================================================
🔄 Round 128 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 128 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0166
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0143
============================================================


============================================================
🔄 Round 129 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 129 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0130
   Val:   Loss=0.0908, RMSE=0.3014, R²=-0.0282
============================================================


============================================================
🔄 Round 132 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 132 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=-0.0179
   Val:   Loss=0.0913, RMSE=0.3022, R²=-0.0138
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2525, R²: -0.0148

📊 Round 132 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2525, R²: -0.0148

============================================================
🔄 Round 140 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0962 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0962, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0962, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0963, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0963, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0963, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0962)

============================================================
📊 Round 140 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0166
   Val:   Loss=0.0962, RMSE=0.3102, R²=-0.0180
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2525, R²: -0.0148

📊 Round 140 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2525, R²: -0.0148

============================================================
🔄 Round 143 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 143 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0196
   Val:   Loss=0.0838, RMSE=0.2896, R²=-0.0023
============================================================


============================================================
🔄 Round 144 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 144 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0135
   Val:   Loss=0.0809, RMSE=0.2845, R²=-0.0274
============================================================


============================================================
🔄 Round 147 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 147 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0155
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0188
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2525, R²: -0.0148

============================================================
🔄 Round 148 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 148 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0177
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0101
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2525, R²: -0.0148

============================================================
🔄 Round 150 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 150 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2932, R²=-0.0133
   Val:   Loss=0.0777, RMSE=0.2788, R²=-0.0284
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2525, R²: -0.0149

============================================================
🔄 Round 155 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 155 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0207
   Val:   Loss=0.0827, RMSE=0.2877, R²=0.0018
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2526, R²: -0.0149

============================================================
🔄 Round 158 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 158 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0118
   Val:   Loss=0.0858, RMSE=0.2930, R²=-0.0339
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2526, R²: -0.0149

============================================================
🔄 Round 160 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 160 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0229
   Val:   Loss=0.0864, RMSE=0.2940, R²=-0.0090
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2526, R²: -0.0149

============================================================
🔄 Round 161 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 161 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0107
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0475
============================================================


============================================================
🔄 Round 167 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 167 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0213
   Val:   Loss=0.0864, RMSE=0.2940, R²=0.0027
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0847, RMSE: 0.2909, MAE: 0.2526, R²: -0.0150

📊 Round 167 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2526, R²: -0.0150

📊 Round 167 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2526, R²: -0.0150

============================================================
🔄 Round 172 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 172 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0153
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0201
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2526, R²: -0.0150

============================================================
🔄 Round 173 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 173 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0185
   Val:   Loss=0.0834, RMSE=0.2889, R²=-0.0320
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2526, R²: -0.0150

📊 Round 173 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2526, R²: -0.0150

============================================================
🔄 Round 177 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 177 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0123
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0315
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2526, R²: -0.0150

📊 Round 177 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2526, R²: -0.0150

============================================================
🔄 Round 183 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 183 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=-0.0170
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0311
============================================================


============================================================
🔄 Round 184 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 184 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=-0.0155
   Val:   Loss=0.0848, RMSE=0.2913, R²=-0.0331
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2526, R²: -0.0150

============================================================
🔄 Round 185 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 185 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0181
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0081
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2526, R²: -0.0150

📊 Round 185 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2526, R²: -0.0150

============================================================
🔄 Round 187 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 187 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0176
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0086
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2526, R²: -0.0150

============================================================
🔄 Round 189 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 189 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0135
   Val:   Loss=0.0866, RMSE=0.2942, R²=-0.0287
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2526, R²: -0.0150

============================================================
🔄 Round 192 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 192 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0156
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0183
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2526, R²: -0.0150

============================================================
🔄 Round 193 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 193 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0179
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0443
============================================================


============================================================
🔄 Round 194 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 194 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0179
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0345
============================================================


============================================================
🔄 Round 195 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0935 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0935, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0935, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0935, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0935, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0935, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0935)

============================================================
📊 Round 195 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0226
   Val:   Loss=0.0935, RMSE=0.3057, R²=0.0071
============================================================


============================================================
🔄 Round 197 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 197 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0220
   Val:   Loss=0.0826, RMSE=0.2874, R²=0.0021
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2526, R²: -0.0150

📊 Round 197 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2526, R²: -0.0150

📊 Round 197 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2526, R²: -0.0150

============================================================
🔄 Round 204 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 204 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0189
   Val:   Loss=0.0742, RMSE=0.2723, R²=-0.0129
============================================================


📊 Round 204 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2526, R²: -0.0151

============================================================
🔄 Round 205 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 205 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0162
   Val:   Loss=0.0879, RMSE=0.2965, R²=-0.0139
============================================================


============================================================
🔄 Round 206 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 206 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=-0.0150
   Val:   Loss=0.0732, RMSE=0.2705, R²=-0.0222
============================================================


📊 Round 206 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2526, R²: -0.0151

📊 Round 206 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2526, R²: -0.0151

============================================================
🔄 Round 209 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 209 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0192
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0270
============================================================


============================================================
🔄 Round 214 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 214 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0157
   Val:   Loss=0.0787, RMSE=0.2806, R²=-0.0204
============================================================


============================================================
🔄 Round 215 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 215 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0112
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0341
============================================================


📊 Round 215 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2526, R²: -0.0151

📊 Round 215 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2526, R²: -0.0151

============================================================
🔄 Round 219 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 219 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=-0.0169
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0131
============================================================


📊 Round 219 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2526, R²: -0.0152

============================================================
🔄 Round 221 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 221 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0169
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0189
============================================================


📊 Round 221 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2526, R²: -0.0152

============================================================
🔄 Round 222 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 222 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2885, R²=-0.0143
   Val:   Loss=0.0884, RMSE=0.2973, R²=-0.0312
============================================================


📊 Round 222 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2526, R²: -0.0152

============================================================
🔄 Round 223 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0924 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 223 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=-0.0175
   Val:   Loss=0.0924, RMSE=0.3039, R²=-0.0120
============================================================


📊 Round 223 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2526, R²: -0.0152

📊 Round 223 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2526, R²: -0.0152

📊 Round 223 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2526, R²: -0.0152

============================================================
🔄 Round 226 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 226 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0168
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0155
============================================================


============================================================
🔄 Round 229 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 229 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0129
   Val:   Loss=0.0914, RMSE=0.3024, R²=-0.0276
============================================================


📊 Round 229 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2526, R²: -0.0152

============================================================
🔄 Round 230 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 230 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0182
   Val:   Loss=0.0890, RMSE=0.2983, R²=-0.0086
============================================================


============================================================
🔄 Round 232 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 232 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0186
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0098
============================================================


📊 Round 232 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2526, R²: -0.0152

============================================================
🔄 Round 235 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 235 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0101
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0571
============================================================


📊 Round 235 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2526, R²: -0.0152

📊 Round 235 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2526, R²: -0.0152

📊 Round 235 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2526, R²: -0.0152

📊 Round 235 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2526, R²: -0.0152

============================================================
🔄 Round 241 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 241 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0177
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0204
============================================================


📊 Round 241 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2526, R²: -0.0152

📊 Round 241 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2526, R²: -0.0153

============================================================
🔄 Round 246 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 246 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0105
   Val:   Loss=0.0900, RMSE=0.3000, R²=-0.0486
============================================================


📊 Round 246 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2526, R²: -0.0153

📊 Round 246 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2526, R²: -0.0153

============================================================
🔄 Round 249 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 249 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0077
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0557
============================================================


📊 Round 249 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2526, R²: -0.0153

============================================================
🔄 Round 250 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 250 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0119
   Val:   Loss=0.0871, RMSE=0.2952, R²=-0.0378
============================================================


📊 Round 250 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2526, R²: -0.0153

============================================================
🔄 Round 255 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 255 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0194
   Val:   Loss=0.0893, RMSE=0.2989, R²=-0.0019
============================================================


📊 Round 255 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2526, R²: -0.0153

============================================================
🔄 Round 256 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 256 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0163
   Val:   Loss=0.0887, RMSE=0.2979, R²=-0.0189
============================================================


============================================================
🔄 Round 260 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0958 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0958, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0958, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0958, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0958, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0957, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0958)

============================================================
📊 Round 260 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0097
   Val:   Loss=0.0958, RMSE=0.3095, R²=-0.0358
============================================================


📊 Round 260 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2526, R²: -0.0154

============================================================
🔄 Round 263 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 263 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0152
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0173
============================================================


📊 Round 263 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2526, R²: -0.0154

============================================================
🔄 Round 266 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 266 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0149
   Val:   Loss=0.0901, RMSE=0.3002, R²=-0.0222
============================================================


📊 Round 266 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2526, R²: -0.0154

============================================================
🔄 Round 267 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0922 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0922, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0922, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0922)

============================================================
📊 Round 267 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0113
   Val:   Loss=0.0922, RMSE=0.3036, R²=-0.0318
============================================================


📊 Round 267 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2526, R²: -0.0154

📊 Round 267 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2526, R²: -0.0154

📊 Round 267 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2526, R²: -0.0154

============================================================
🔄 Round 272 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 272 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0175
   Val:   Loss=0.0817, RMSE=0.2857, R²=-0.0251
============================================================


============================================================
🔄 Round 273 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 273 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0124
   Val:   Loss=0.0896, RMSE=0.2993, R²=-0.0386
============================================================


📊 Round 273 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2526, R²: -0.0154

============================================================
🔄 Round 275 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 275 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2937, R²=-0.0255
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.0269
============================================================


📊 Round 275 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2526, R²: -0.0154

📊 Round 275 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2526, R²: -0.0155

============================================================
🔄 Round 279 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 279 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0098
   Val:   Loss=0.0865, RMSE=0.2942, R²=-0.0386
============================================================


📊 Round 279 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2526, R²: -0.0155

📊 Round 279 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2526, R²: -0.0155

============================================================
🔄 Round 282 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 282 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0168
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0146
============================================================


📊 Round 282 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2526, R²: -0.0155

============================================================
🔄 Round 283 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 283 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=-0.0144
   Val:   Loss=0.0791, RMSE=0.2813, R²=-0.0233
============================================================


============================================================
🔄 Round 286 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 286 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=-0.0147
   Val:   Loss=0.0774, RMSE=0.2782, R²=-0.0193
============================================================


============================================================
🔄 Round 287 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 287 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0118
   Val:   Loss=0.0854, RMSE=0.2923, R²=-0.0311
============================================================


============================================================
🔄 Round 289 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 289 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0164
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0179
============================================================


============================================================
🔄 Round 290 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 290 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0246
   Val:   Loss=0.0824, RMSE=0.2871, R²=0.0018
============================================================


📊 Round 290 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2526, R²: -0.0155

📊 Round 290 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2526, R²: -0.0155

============================================================
🔄 Round 292 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 292 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=-0.0100
   Val:   Loss=0.0774, RMSE=0.2783, R²=-0.0414
============================================================


📊 Round 292 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2526, R²: -0.0155

============================================================
🔄 Round 293 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 293 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0096
   Val:   Loss=0.0860, RMSE=0.2932, R²=-0.0393
============================================================


📊 Round 293 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2526, R²: -0.0155

============================================================
🔄 Round 297 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 297 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0155
   Val:   Loss=0.0907, RMSE=0.3011, R²=-0.0351
============================================================


📊 Round 297 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2527, R²: -0.0155

============================================================
🔄 Round 298 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 298 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0128
   Val:   Loss=0.0805, RMSE=0.2838, R²=-0.0321
============================================================


📊 Round 298 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2527, R²: -0.0155

============================================================
🔄 Round 299 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 299 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=-0.0165
   Val:   Loss=0.0790, RMSE=0.2810, R²=-0.0114
============================================================


📊 Round 299 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2527, R²: -0.0155

============================================================
🔄 Round 301 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 301 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0142
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0423
============================================================


📊 Round 301 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2527, R²: -0.0155

📊 Round 301 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2527, R²: -0.0155

============================================================
🔄 Round 303 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 303 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0182
   Val:   Loss=0.0756, RMSE=0.2750, R²=-0.0129
============================================================


============================================================
🔄 Round 304 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 304 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=-0.0121
   Val:   Loss=0.0819, RMSE=0.2861, R²=-0.0336
============================================================


============================================================
🔄 Round 305 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 305 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0189
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0095
============================================================


📊 Round 305 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2527, R²: -0.0155

============================================================
🔄 Round 306 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 306 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0053
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0725
============================================================


📊 Round 306 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2527, R²: -0.0155

============================================================
🔄 Round 310 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 310 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0227
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0049
============================================================


============================================================
🔄 Round 311 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 311 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0161
   Val:   Loss=0.0757, RMSE=0.2751, R²=-0.0370
============================================================


============================================================
🔄 Round 312 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 312 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=-0.0133
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0251
============================================================


📊 Round 312 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2527, R²: -0.0156

📊 Round 312 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2527, R²: -0.0156

============================================================
🔄 Round 315 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 315 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0184
   Val:   Loss=0.0869, RMSE=0.2948, R²=-0.0046
============================================================


📊 Round 315 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2527, R²: -0.0156

📊 Round 315 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2527, R²: -0.0156

============================================================
🔄 Round 319 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 319 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0165
   Val:   Loss=0.0786, RMSE=0.2803, R²=-0.0202
============================================================


📊 Round 319 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2527, R²: -0.0156

📊 Round 319 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2527, R²: -0.0156

============================================================
🔄 Round 324 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 324 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0072
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0491
============================================================


📊 Round 324 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2527, R²: -0.0157

============================================================
🔄 Round 327 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0991 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0991, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0991, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0991, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0991, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0991, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0991)

============================================================
📊 Round 327 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=-0.0097
   Val:   Loss=0.0991, RMSE=0.3148, R²=-0.0596
============================================================


============================================================
🔄 Round 328 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 328 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0100
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0547
============================================================


📊 Round 328 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2527, R²: -0.0157

============================================================
🔄 Round 329 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 329 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2903, R²=-0.0154
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0163
============================================================


📊 Round 329 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2527, R²: -0.0157

============================================================
🔄 Round 332 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 332 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0162
   Val:   Loss=0.0829, RMSE=0.2880, R²=-0.0312
============================================================


📊 Round 332 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2527, R²: -0.0157

============================================================
🔄 Round 333 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 333 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0217
   Val:   Loss=0.0904, RMSE=0.3006, R²=0.0054
============================================================


============================================================
🔄 Round 334 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 334 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0148
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0293
============================================================


📊 Round 334 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2527, R²: -0.0157

============================================================
🔄 Round 336 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 336 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2920, R²=-0.0166
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0359
============================================================


============================================================
🔄 Round 338 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 338 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=-0.0211
   Val:   Loss=0.0779, RMSE=0.2791, R²=-0.0139
============================================================


📊 Round 338 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2527, R²: -0.0157

============================================================
🔄 Round 340 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 340 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0210
   Val:   Loss=0.0757, RMSE=0.2752, R²=0.0070
============================================================


📊 Round 340 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2527, R²: -0.0157

============================================================
🔄 Round 343 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 343 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0144
   Val:   Loss=0.0880, RMSE=0.2967, R²=-0.0192
============================================================


📊 Round 343 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2527, R²: -0.0157

============================================================
🔄 Round 346 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 346 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0195
   Val:   Loss=0.0868, RMSE=0.2945, R²=0.0004
============================================================


============================================================
🔄 Round 347 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 347 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0134
   Val:   Loss=0.0786, RMSE=0.2803, R²=-0.0273
============================================================


📊 Round 347 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2527, R²: -0.0157

============================================================
🔄 Round 350 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 350 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0180
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0055
============================================================


============================================================
🔄 Round 351 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 351 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0248
   Val:   Loss=0.0847, RMSE=0.2910, R²=0.0191
============================================================


============================================================
🔄 Round 352 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 352 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0081
   Val:   Loss=0.0782, RMSE=0.2796, R²=-0.0673
============================================================


📊 Round 352 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2527, R²: -0.0157

============================================================
🔄 Round 357 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 357 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0143
   Val:   Loss=0.0779, RMSE=0.2792, R²=-0.0229
============================================================


📊 Round 357 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2527, R²: -0.0157

============================================================
🔄 Round 360 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 360 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0138
   Val:   Loss=0.0884, RMSE=0.2973, R²=-0.0216
============================================================


📊 Round 360 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2527, R²: -0.0157

============================================================
🔄 Round 364 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 364 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0142
   Val:   Loss=0.0871, RMSE=0.2952, R²=-0.0213
============================================================


📊 Round 364 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2527, R²: -0.0157

============================================================
🔄 Round 366 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 366 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=-0.0148
   Val:   Loss=0.0805, RMSE=0.2838, R²=-0.0238
============================================================


============================================================
🔄 Round 367 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 367 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0151
   Val:   Loss=0.0787, RMSE=0.2806, R²=-0.0159
============================================================


📊 Round 367 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2527, R²: -0.0158

📊 Round 367 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2527, R²: -0.0158

📊 Round 367 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2527, R²: -0.0158

📊 Round 367 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2527, R²: -0.0158

============================================================
🔄 Round 376 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0952 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0952, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0952, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0952, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0952, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0952, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0952)

============================================================
📊 Round 376 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0146
   Val:   Loss=0.0952, RMSE=0.3085, R²=-0.0285
============================================================


📊 Round 376 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2527, R²: -0.0158

📊 Round 376 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2527, R²: -0.0158

============================================================
🔄 Round 378 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 378 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0188
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0020
============================================================


📊 Round 378 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2527, R²: -0.0158

📊 Round 378 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2527, R²: -0.0158

============================================================
🔄 Round 381 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 381 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0178
   Val:   Loss=0.0767, RMSE=0.2770, R²=-0.0107
============================================================


============================================================
🔄 Round 382 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 382 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=-0.0204
   Val:   Loss=0.0863, RMSE=0.2937, R²=0.0007
============================================================


📊 Round 382 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2527, R²: -0.0158

============================================================
🔄 Round 383 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 383 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0132
   Val:   Loss=0.0894, RMSE=0.2989, R²=-0.0261
============================================================


============================================================
🔄 Round 384 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 384 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0119
   Val:   Loss=0.0830, RMSE=0.2880, R²=-0.0300
============================================================


📊 Round 384 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2527, R²: -0.0158

============================================================
🔄 Round 387 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 387 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0085
   Val:   Loss=0.0883, RMSE=0.2972, R²=-0.0579
============================================================


============================================================
🔄 Round 389 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 389 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0100
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0411
============================================================


📊 Round 389 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2527, R²: -0.0159

📊 Round 389 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2527, R²: -0.0159

📊 Round 389 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2527, R²: -0.0159

============================================================
🔄 Round 395 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 395 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0168
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0091
============================================================


============================================================
🔄 Round 397 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 397 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0190
   Val:   Loss=0.0814, RMSE=0.2852, R²=-0.0011
============================================================


============================================================
🔄 Round 398 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0959 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0959, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0959, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0959, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0959, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0959, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0959)

============================================================
📊 Round 398 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0114
   Val:   Loss=0.0959, RMSE=0.3097, R²=-0.0351
============================================================


📊 Round 398 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2527, R²: -0.0159

============================================================
🔄 Round 400 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 400 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0120
   Val:   Loss=0.0752, RMSE=0.2743, R²=-0.0374
============================================================


📊 Round 400 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2527, R²: -0.0159

============================================================
🔄 Round 401 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 401 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=-0.0129
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0264
============================================================


============================================================
🔄 Round 402 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 402 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0125
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0266
============================================================


📊 Round 402 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2527, R²: -0.0159

============================================================
🔄 Round 403 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 403 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0124
   Val:   Loss=0.0892, RMSE=0.2987, R²=-0.0305
============================================================


📊 Round 403 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2527, R²: -0.0159

📊 Round 403 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2527, R²: -0.0159

============================================================
🔄 Round 405 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 405 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0142
   Val:   Loss=0.0796, RMSE=0.2822, R²=-0.0329
============================================================


📊 Round 405 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2527, R²: -0.0160

📊 Round 405 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2527, R²: -0.0160

============================================================
🔄 Round 409 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 409 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0194
   Val:   Loss=0.0833, RMSE=0.2887, R²=0.0012
============================================================


📊 Round 409 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2527, R²: -0.0160

============================================================
🔄 Round 412 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0988 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0988, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0988, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0987, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0987, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0987, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0988)

============================================================
📊 Round 412 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0170
   Val:   Loss=0.0988, RMSE=0.3143, R²=-0.0109
============================================================


============================================================
🔄 Round 413 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 413 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0072
   Val:   Loss=0.0901, RMSE=0.3002, R²=-0.0511
============================================================


📊 Round 413 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2527, R²: -0.0160

📊 Round 413 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2527, R²: -0.0160

============================================================
🔄 Round 415 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 415 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0124
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0282
============================================================


============================================================
🔄 Round 417 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0937 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0937, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0937, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0937, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0937, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0937, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0937)

============================================================
📊 Round 417 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0093
   Val:   Loss=0.0937, RMSE=0.3061, R²=-0.0392
============================================================


📊 Round 417 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2528, R²: -0.0160

============================================================
🔄 Round 421 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 421 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0154
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0575
============================================================


📊 Round 421 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2528, R²: -0.0160

📊 Round 421 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2528, R²: -0.0160

📊 Round 421 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2528, R²: -0.0160

📊 Round 421 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2528, R²: -0.0160

📊 Round 421 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2528, R²: -0.0160

============================================================
🔄 Round 428 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 428 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=-0.0153
   Val:   Loss=0.0743, RMSE=0.2725, R²=-0.0218
============================================================


📊 Round 428 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2528, R²: -0.0160

============================================================
🔄 Round 429 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 429 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0175
   Val:   Loss=0.0900, RMSE=0.3000, R²=-0.0079
============================================================


📊 Round 429 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2528, R²: -0.0160

📊 Round 429 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2528, R²: -0.0160

============================================================
🔄 Round 433 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0945 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0945, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0945, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0945, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0945, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0945, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0945)

============================================================
📊 Round 433 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0135
   Val:   Loss=0.0945, RMSE=0.3073, R²=-0.0271
============================================================


============================================================
🔄 Round 434 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 434 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0176
   Val:   Loss=0.0807, RMSE=0.2840, R²=-0.0071
============================================================


============================================================
🔄 Round 439 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 439 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0207
   Val:   Loss=0.0845, RMSE=0.2906, R²=0.0005
============================================================


============================================================
🔄 Round 440 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 440 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0189
   Val:   Loss=0.0776, RMSE=0.2786, R²=-0.0013
============================================================


============================================================
🔄 Round 441 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 441 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0147
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0179
============================================================


============================================================
🔄 Round 443 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 443 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0130
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0404
============================================================


📊 Round 443 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2528, R²: -0.0161

============================================================
🔄 Round 444 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 444 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0173
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0127
============================================================


📊 Round 444 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2528, R²: -0.0161

📊 Round 444 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2528, R²: -0.0161

📊 Round 444 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2528, R²: -0.0161

📊 Round 444 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2528, R²: -0.0161

📊 Round 444 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2528, R²: -0.0161

============================================================
🔄 Round 451 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 451 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2937, R²=-0.0146
   Val:   Loss=0.0762, RMSE=0.2761, R²=-0.0193
============================================================


============================================================
🔄 Round 452 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 452 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0238
   Val:   Loss=0.0826, RMSE=0.2874, R²=0.0168
============================================================


============================================================
🔄 Round 453 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 453 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0126
   Val:   Loss=0.0877, RMSE=0.2962, R²=-0.0459
============================================================


📊 Round 453 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2528, R²: -0.0161

============================================================
🔄 Round 455 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 455 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0169
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0110
============================================================


📊 Round 455 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2528, R²: -0.0161

============================================================
🔄 Round 456 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 456 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=-0.0145
   Val:   Loss=0.0774, RMSE=0.2782, R²=-0.0541
============================================================


============================================================
🔄 Round 458 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0946 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0946, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0946, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0946, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0946, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0946, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0946)

============================================================
📊 Round 458 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0187
   Val:   Loss=0.0946, RMSE=0.3076, R²=-0.0057
============================================================


📊 Round 458 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2528, R²: -0.0161

============================================================
🔄 Round 459 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 459 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=-0.0209
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0077
============================================================


📊 Round 459 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2528, R²: -0.0161

============================================================
🔄 Round 460 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 460 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0183
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0048
============================================================


============================================================
🔄 Round 461 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 461 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0184
   Val:   Loss=0.0862, RMSE=0.2935, R²=-0.0048
============================================================


📊 Round 461 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2528, R²: -0.0161

============================================================
🔄 Round 464 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0978 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0978, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0978, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0978, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0978, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0977, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0978)

============================================================
📊 Round 464 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0134
   Val:   Loss=0.0978, RMSE=0.3127, R²=-0.0222
============================================================


============================================================
🔄 Round 466 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 466 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0185
   Val:   Loss=0.0776, RMSE=0.2786, R²=-0.0054
============================================================


============================================================
🔄 Round 467 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 467 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0250
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0094
============================================================


📊 Round 467 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2528, R²: -0.0162

📊 Round 467 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2528, R²: -0.0162

============================================================
🔄 Round 470 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 470 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0089
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0417
============================================================


============================================================
🔄 Round 474 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 474 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0096
   Val:   Loss=0.0756, RMSE=0.2750, R²=-0.0473
============================================================


📊 Round 474 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2528, R²: -0.0162

============================================================
🔄 Round 475 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 475 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0181
   Val:   Loss=0.0752, RMSE=0.2741, R²=-0.0056
============================================================


📊 Round 475 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2528, R²: -0.0162

📊 Round 475 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2528, R²: -0.0162

============================================================
🔄 Round 478 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 478 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0198
   Val:   Loss=0.0810, RMSE=0.2845, R²=0.0029
============================================================


📊 Round 478 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2528, R²: -0.0162

📊 Round 478 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2528, R²: -0.0162

============================================================
🔄 Round 483 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 483 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0147
   Val:   Loss=0.0918, RMSE=0.3030, R²=-0.0197
============================================================


============================================================
🔄 Round 485 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 485 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0217
   Val:   Loss=0.0841, RMSE=0.2901, R²=0.0066
============================================================


============================================================
🔄 Round 486 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 486 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0262
   Val:   Loss=0.0909, RMSE=0.3015, R²=0.0070
============================================================


📊 Round 486 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2528, R²: -0.0163

============================================================
🔄 Round 488 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 488 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0186
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0159
============================================================


============================================================
🔄 Round 489 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 489 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0149
   Val:   Loss=0.0728, RMSE=0.2697, R²=-0.0196
============================================================


============================================================
🔄 Round 490 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 490 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0125
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0361
============================================================


============================================================
🔄 Round 491 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 491 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0190
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0210
============================================================


📊 Round 491 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2528, R²: -0.0162

📊 Round 491 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2528, R²: -0.0162

============================================================
🔄 Round 496 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 496 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0181
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0078
============================================================


📊 Round 496 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2528, R²: -0.0162

============================================================
🔄 Round 497 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 497 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=-0.0190
   Val:   Loss=0.0748, RMSE=0.2736, R²=0.0000
============================================================


📊 Round 497 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2528, R²: -0.0162

📊 Round 497 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2528, R²: -0.0162

📊 Round 497 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2528, R²: -0.0162

📊 Round 497 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2528, R²: -0.0163

============================================================
🔄 Round 503 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 503 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=-0.0174
   Val:   Loss=0.0761, RMSE=0.2759, R²=-0.0098
============================================================


📊 Round 503 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2528, R²: -0.0163

📊 Round 503 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2528, R²: -0.0163

============================================================
🔄 Round 505 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 505 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0182
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0078
============================================================


📊 Round 505 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2528, R²: -0.0163

============================================================
🔄 Round 506 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 506 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0137
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0222
============================================================


============================================================
🔄 Round 507 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 507 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0135
   Val:   Loss=0.0823, RMSE=0.2868, R²=-0.0235
============================================================


============================================================
🔄 Round 509 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 509 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0155
   Val:   Loss=0.0920, RMSE=0.3033, R²=-0.0253
============================================================


📊 Round 509 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2528, R²: -0.0163

============================================================
🔄 Round 510 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 510 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0163
   Val:   Loss=0.0912, RMSE=0.3019, R²=-0.0390
============================================================


📊 Round 510 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2528, R²: -0.0163

============================================================
🔄 Round 511 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0952 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0952, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0952, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0952, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0952, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0952, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0952)

============================================================
📊 Round 511 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0153
   Val:   Loss=0.0952, RMSE=0.3086, R²=-0.0197
============================================================


📊 Round 511 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2528, R²: -0.0163

📊 Round 511 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2528, R²: -0.0163

============================================================
🔄 Round 515 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 515 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0197
   Val:   Loss=0.0913, RMSE=0.3021, R²=-0.0112
============================================================


📊 Round 515 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2528, R²: -0.0163

📊 Round 515 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2528, R²: -0.0163

============================================================
🔄 Round 517 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0979 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0979, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0979, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0979, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0979, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0979, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0979)

============================================================
📊 Round 517 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0215
   Val:   Loss=0.0979, RMSE=0.3129, R²=0.0003
============================================================


============================================================
🔄 Round 518 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 518 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0185
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0034
============================================================


📊 Round 518 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2528, R²: -0.0163

============================================================
🔄 Round 520 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 520 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0211
   Val:   Loss=0.0829, RMSE=0.2880, R²=0.0078
============================================================


📊 Round 520 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2528, R²: -0.0163

============================================================
🔄 Round 521 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 521 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0156
   Val:   Loss=0.0864, RMSE=0.2940, R²=-0.0244
============================================================


📊 Round 521 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2528, R²: -0.0163

============================================================
🔄 Round 524 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 524 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0136
   Val:   Loss=0.0740, RMSE=0.2720, R²=-0.0233
============================================================


📊 Round 524 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2528, R²: -0.0163

============================================================
🔄 Round 526 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 526 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0143
   Val:   Loss=0.0893, RMSE=0.2989, R²=-0.0269
============================================================


📊 Round 526 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2528, R²: -0.0163

============================================================
🔄 Round 529 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 529 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0172
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0074
============================================================


📊 Round 529 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2528, R²: -0.0163

============================================================
🔄 Round 531 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 531 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0143
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0201
============================================================


============================================================
🔄 Round 533 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 533 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=-0.0194
   Val:   Loss=0.0830, RMSE=0.2880, R²=-0.0220
============================================================


📊 Round 533 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2528, R²: -0.0163

============================================================
🔄 Round 534 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 534 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2877, R²=-0.0160
   Val:   Loss=0.0902, RMSE=0.3003, R²=-0.0290
============================================================


============================================================
🔄 Round 535 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 535 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0088
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0569
============================================================


📊 Round 535 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2528, R²: -0.0163

📊 Round 535 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2528, R²: -0.0163

============================================================
🔄 Round 538 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 538 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0126
   Val:   Loss=0.0908, RMSE=0.3013, R²=-0.0280
============================================================


📊 Round 538 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2528, R²: -0.0163

============================================================
🔄 Round 540 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 540 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0130
   Val:   Loss=0.0896, RMSE=0.2994, R²=-0.0249
============================================================


📊 Round 540 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2528, R²: -0.0163

📊 Round 540 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2528, R²: -0.0163

============================================================
🔄 Round 549 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.1028 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.1028, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.1028, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.1028, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.1028, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.1028, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1028)

============================================================
📊 Round 549 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=-0.0203
   Val:   Loss=0.1028, RMSE=0.3206, R²=-0.0024
============================================================


============================================================
🔄 Round 551 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 551 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0213
   Val:   Loss=0.0791, RMSE=0.2812, R²=0.0091
============================================================


============================================================
🔄 Round 552 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 552 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0107
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0376
============================================================


📊 Round 552 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2528, R²: -0.0164

============================================================
🔄 Round 553 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 553 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0085
   Val:   Loss=0.0811, RMSE=0.2849, R²=-0.0485
============================================================


============================================================
🔄 Round 555 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 555 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0148
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0303
============================================================


============================================================
🔄 Round 556 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 556 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0206
   Val:   Loss=0.0905, RMSE=0.3008, R²=-0.0185
============================================================


============================================================
🔄 Round 557 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 557 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0062
   Val:   Loss=0.0740, RMSE=0.2721, R²=-0.0598
============================================================


============================================================
🔄 Round 558 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0974 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0975, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0975, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0975, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0975, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0976, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0974)

============================================================
📊 Round 558 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0169
   Val:   Loss=0.0974, RMSE=0.3122, R²=-0.0376
============================================================


📊 Round 558 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2528, R²: -0.0164

============================================================
🔄 Round 560 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 560 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0124
   Val:   Loss=0.0891, RMSE=0.2985, R²=-0.0279
============================================================


📊 Round 560 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2528, R²: -0.0164

============================================================
🔄 Round 562 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 562 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0200
   Val:   Loss=0.0824, RMSE=0.2870, R²=0.0030
============================================================


📊 Round 562 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2528, R²: -0.0164

============================================================
🔄 Round 564 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 564 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0162
   Val:   Loss=0.0787, RMSE=0.2806, R²=-0.0203
============================================================


============================================================
🔄 Round 565 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 565 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=-0.0080
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0473
============================================================


============================================================
🔄 Round 566 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 566 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0152
   Val:   Loss=0.0774, RMSE=0.2782, R²=-0.0305
============================================================


============================================================
🔄 Round 568 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 568 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2897, R²=-0.0207
   Val:   Loss=0.0853, RMSE=0.2921, R²=0.0028
============================================================


📊 Round 568 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2528, R²: -0.0164

============================================================
🔄 Round 569 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 569 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0236
   Val:   Loss=0.0864, RMSE=0.2940, R²=0.0085
============================================================


📊 Round 569 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2528, R²: -0.0165

============================================================
🔄 Round 571 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 571 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=-0.0106
   Val:   Loss=0.0861, RMSE=0.2935, R²=-0.0332
============================================================


📊 Round 571 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2528, R²: -0.0165

============================================================
🔄 Round 573 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 573 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0208
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0110
============================================================


📊 Round 573 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2528, R²: -0.0165

============================================================
🔄 Round 574 - Client client_8
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 574 Summary - Client client_8
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=-0.0164
   Val:   Loss=0.0738, RMSE=0.2717, R²=-0.0091
============================================================


❌ Client client_8 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8688 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8688 {grpc_status:14, grpc_message:"Socket closed"}"
>
