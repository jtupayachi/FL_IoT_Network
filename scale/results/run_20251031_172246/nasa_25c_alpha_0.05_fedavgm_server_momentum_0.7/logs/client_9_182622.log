[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9aa6f81b-a086-459b-92a3-4bf947ee66fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64eb76ea-d6df-4573-a404-9e142f7e3e8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b6628da-dc9f-43c6-be9c-b7997cd2adca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7aa3e75f-2935-411e-ba00-c3928a47255f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01599a0f-30d8-489e-8f76-f1e702504b97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3993ff98-2acb-4e25-ac25-d3071b9f0da4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9819b35-f0d6-4d1f-866c-1861d53fb70e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 629d42c4-622b-4a57-b749-f55d44feb058
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bead9da0-b6fa-4b6c-81f2-c93804eda1a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa667eab-0232-4eba-8f50-07165f2992c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14a27429-b22a-4bca-9f13-410bc5e46a18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44f652a2-5d75-4955-b2db-19818b6e1ddd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1aa32974-1cec-4582-80c2-963e3f695652
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93c3e838-f089-4fe2-bb63-123258bf96ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6a8ccd4-882f-46dc-aaf0-7444a2aca39d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 919b25ec-784b-4ff2-a180-9995f48053f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a071c44-3e10-4536-90d0-a4fc961b670b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 154cb152-452a-4c19-999b-6dff204381e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19cfb38a-d19c-43ea-b8d4-9dc0bd5f5b2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e83eb42e-1284-4b04-b835-80ec1a8b7345
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5370406d-88ec-44df-95bd-cdbe5d6db5b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message acb4b101-ec0d-4431-aa94-72feab5b529d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66390e15-67c0-41c9-a92b-808c88b590b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4de58560-587f-49ed-8c7a-70bc687f1c5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96113baa-dc57-4c13-9bcc-21d44af47742
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7cfd2915-1840-4fbf-bd8a-0da528d41ec4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac99b9cf-e1e3-45e5-9908-21209f34368b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b955d1e-be81-462f-9f39-cabc22c10838
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4734584b-24f7-4c45-ad32-2f38c8eeb58e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95fab0b8-3826-4187-9500-f5db08cb64df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2260d9d8-4f0f-45b1-a35e-ba8642f332fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24f6b6a9-16cf-4e35-b3ee-5a0dfcc9b31b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7a51f55-76bc-4463-a578-6c4773f09a78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c9dc2dd-5f0e-475a-b3bb-0c72cfb53fc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8db25ff-acb4-4398-898b-ab022986eeda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b59b45a8-b690-4ff5-888a-b9b5d7272247
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72df41e0-5926-47a5-b74c-b1af3b7ae4d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6727bce-b64f-4a2e-b799-4927e084f2d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d1f8178-6a7e-4714-b6d6-8e15861a88de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2cad0ce-6ec6-4321-92e7-8152fee3c016
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ddbc2117-fe27-4e37-a5d1-ee77a66481fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb017034-16b5-4544-8f9a-7a3f4e1d4e59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b3bc842-65f7-49c9-8038-3ed5aab8090b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 686eb450-1b0b-41d8-9614-009801d73da6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98bd29cd-185c-45a6-8661-0dcb914b475b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c776645c-de76-440a-8015-8d1008e9ea56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1dd7495a-6594-4664-8abd-525377dfa4f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0533de1-3186-489b-b0c8-556be8fc8b20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 396cab5c-c462-4517-b25b-28c039f55238
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d133f9e-c54b-4443-b5a8-9ecfff3b5ece
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0957aed2-0140-43b9-84f9-6d07cdad3ef2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e58b0264-6e38-4ac6-9b9a-22ca81469507
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9446984-918b-4e2a-8ee2-1818641e375b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f4ce367-8860-4cfc-937c-9f4da51e7697
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ba857a2-4cab-443e-b602-1262ea25c48d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45ce17d3-bf92-442f-8b3a-4f15b14aad24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a88aaf9-9af5-406f-a885-2533fe6be666
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1db2ca97-278e-499e-a0f1-c5efbaf02b4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92d4aa74-1f7a-41ab-8156-97ba0312c04e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2317fafe-66fa-43c3-8eb1-cf7a8e9c91d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b92f8550-2a08-4725-96b3-c3c58772d866
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af60063b-d7c6-413d-a347-f985f9428d40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a54030b-2375-42dc-91f7-b9daf2f32ca8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 537709fd-3ad8-4598-9e3b-9fe3ba3dbe88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24ae74da-260e-4c15-bb10-a73b5e5f52bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08faa890-dc36-470b-bc9a-cf60181b6e83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07f5faaf-2472-4f81-9617-502f46fb52e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message abdc815c-1d9a-4756-8fa2-c2b4f56f81c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f15d981-58ff-4037-94b8-ba834293d840
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c79030b1-a520-433c-be21-daf54c48fa41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 029acce1-5e12-41b4-b4cd-465e7f653fc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed810c54-7470-4788-b972-954967bd3daa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d3ad83d-1e5e-4bd1-87ee-6fe95c279735
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13c393b9-88d4-466c-aa76-8b52a2724024
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2ec778d-5bde-40c2-8381-205ec18c046a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e80fac7d-b152-4a3d-8cc0-937467b46052
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22af7c3c-76ef-4d61-a2d6-c8f96d07b93f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7174240-4a4b-4c01-b314-ddf98e0c7da8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10f48709-e90e-4b38-93f7-b8b9cb55880a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 786083af-5756-4c16-989e-5055d3dc9e50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99db6e18-41e6-4862-9c65-eea9e1ca746c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4306717-d71e-4818-9636-979f8390e0e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4a9ba04-7635-45fb-9e3d-70d55dceb766
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53cdeb58-72fd-4aa4-9c09-e39996c467d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8127512a-5858-4e54-9534-8ee51fc338e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ade3a9d-2819-4fb1-b7b0-e9b882daecff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33ef03e2-7d64-4202-a061-a002f427c964
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8dbc3fc5-fe98-4079-8b70-a19cc52b14e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1798c17f-592b-48cd-89ca-1194e241682f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20475bd8-3822-41ed-84f6-628f5f27e50c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e14abe5-8500-46b0-9273-34f36244a9bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bcc430cb-53fd-412c-91b5-a2d74261f7ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e331ad9-f080-4f48-bac3-272e5df03824
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77a61cf2-b9cf-4570-9754-51faa45344f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f384401-f2a5-4399-be5d-f36dda9250ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ceeb8fd-3d2c-41c3-a976-a45f6966f064
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c07b6d98-354c-4038-aa55-3bc042ec6e56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4736a39-1bf6-4c47-814b-72d419dea72b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1f016b3-3708-491b-9a19-b6936dee9f66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b41c7bbd-2947-4698-9f6a-6ac8dd3b708c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b688155-96de-4565-b2b2-f929c87eb33b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2cc06eaf-d915-4636-bb15-5a1112c34ec0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ceb0e4bf-8dc8-42c6-be79-ec0587e46861
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f467d60f-2cff-4e98-aad8-645c2e2e1e8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79814798-ed1e-4b15-aad0-4cc410224996
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2c7ece9-c5ae-4765-bb89-38785e7bb737
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe029951-366c-4b0b-8dc7-f319ed23acf2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8992ea9f-5823-40c2-9106-4dc5c8216f2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b780481-3b43-4229-b008-19b32f8a1520
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b44e3b69-e26a-4aea-ada5-3b5f8ab7edd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e3e63d9-0e2f-4541-8cd6-19d4f7c71b73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b2904ca-7d41-44ed-877a-6489ef0ae26f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b496e532-e4fa-4bf8-904e-75f19b70d436
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb7894ec-4496-4de4-982b-7c7d396dfbb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58df8ba1-bf2e-4692-bf07-2a4f93254d5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46432586-fe51-4864-9789-b66f16396f30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d68a431-53bb-4320-a480-c92a95bcab1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90f0999f-2b23-4fbe-ab0e-da08ee439569
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2dbfbdf0-4099-4662-9c86-f37d11fbb7f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36d87cfb-3657-410a-bee0-436af1cbf2f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07a385e1-b7af-4298-a7bd-0acfeab676ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 433b6b79-8a4d-4a2a-8beb-ff661ccb8139
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef04c33b-c153-4176-ad4e-43e9e7542a80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c693fc1b-8eb7-432d-bc56-bf82aad4eb2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72dfe817-1afc-4121-9afb-3b01542b1c35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1116381-03c4-4683-92c5-68521f93a469
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1abfc7ed-fc26-4329-87b4-979cf785a8b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 735847d2-d1e4-4025-85d8-7bc1b923d835
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e7cf1a3-b8a3-4aba-ae23-667da2bdeac2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6aeadc5f-0491-4b2e-b602-343861c07708
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 682e0940-252a-47b4-a9aa-b62c03e6043e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73589e00-e573-4be2-8406-55dfffcdfb96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3d3e112-9355-4ecd-9766-84265fcc0698
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5bb21d5-75ee-483b-95e5-9cd7dc2428f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message befcc8ff-4cc3-47d3-83f8-f58accd3903d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f033bc25-dec0-4605-b15c-990e7def320d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a98af9d-3a6f-4fc0-978e-a0066564df05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40d7f6d7-cf7f-416d-b33c-a767d4a39050
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1539160a-bd35-4d1f-a300-89b9b36a74f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d158b871-243b-4bb7-a49b-29b194ce8efe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eda4b853-85f8-4e79-9a0c-663b742a0b46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6abb5ce6-b769-400e-bb1e-496585f9e028
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a70eeaff-55d0-4163-8c08-65932b0a27b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a440bbdb-0fb7-4d70-9d6f-c012ba5cf34f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 669745b8-23c8-4d97-aa0a-2f456b708341
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db0caa7e-2606-42cc-9c8b-0ac7602109fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 656ce8b0-1f14-4b4a-911d-9b5bca51c3bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07efef97-91be-4cc5-b394-dfc8bd27362e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3236f5af-ac78-4659-aa62-53a042521a59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c9f46b8-fa7c-461f-9386-4bb7d14f3513
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8117a1f-a11f-4ae9-a4b9-faae9b12501e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 532f18e2-abf0-40dd-904e-5a534b9da67d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e60e8426-3128-4e3b-9364-9e6fb56611a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f0a64ef-7f57-40d1-9558-ff630b796e99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9a8cfb2-0b59-4dfa-ad7e-ab64614f034c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7ce326b-7cce-4137-a45d-c8adcdfbbf3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ad53b1d-00d6-4945-9d4c-2492994f450a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d90192f9-abac-4937-98eb-8480799b4b4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69a44c8d-dcf2-4bc3-8322-c49873ebd399
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d64e096-8815-4d51-8612-77813cfaf0a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d99dabd-cc51-4642-a2ee-5a133be96ce7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f8221ee-8af3-48b6-a6de-0c1842c25840
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b52ac16-afee-4c5f-bbd9-e1899f06da9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41f3506f-d66a-4e83-8a12-1d40229216f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c120451-95d8-4f08-abea-87186791d833
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d640a763-6c84-4fd7-bbc0-d40515545f99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6560093-3939-4acf-abec-858a145bb1ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b81a4de-2bcf-41cd-a5d4-cfbe82727fdb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c709cb22-ad14-438a-adb9-1e879b7efad4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29677059-5c66-420d-adf1-79c68198d702
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ec1f893-ed33-43e6-a2e7-30da7df62823
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02bf65fd-4eed-4cc0-ad97-2de1f686e5a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4cd474d-3527-49bf-b691-12e27a88d742
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b96928c4-7510-4feb-aa20-1e6cc50f3c01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0311cbe6-348a-4e21-adf2-bcf7cbcaf7ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b0cca6d-257a-48b5-9e04-1c56963a1b42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec370f40-dc55-4533-99dc-6cb45e5cccf8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09c9dbf3-c3e6-4030-9400-c31744995254
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7419487e-4cd3-43e3-a6af-c42b5ba71855
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9a2a1b0-f0df-4c77-ab79-91a402800b25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80a10d0a-746c-4c3e-bf92-b247bf34ccdb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00c67350-b640-446b-a5ac-6f72fb7d555b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5ce0813-c865-44af-a77e-a611634eff59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36db26d6-4863-4eb2-8eb6-4ccd983430cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfa2bca9-0774-4b90-9bb2-d950b2b74b56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89602cf7-5866-43d0-90e7-ee9c64d03d51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f61651b-653a-4616-ba7f-e676a8b48cf0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b08cd732-cf34-4379-87d1-10d0e726b122
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba0eabb0-7376-4260-9c63-5966b3e83329
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37d157d1-424f-41ba-93d2-dd8bd2e47d6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68c8d184-6154-4174-9064-8ed2ac1112e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b31e6795-62d7-4cfe-abe9-56cfcdab41b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b455c02-d3b9-42b7-acba-7c524218e02c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d861cab4-f556-459f-87b7-e4b99a99050d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93cce4d4-9e71-4eb9-bc15-0bde14050c34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec1adf5f-e32f-4b7c-89ba-13347e7b6679
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3cf687b-abd4-4505-a769-0b0c66c3a9a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 204c2452-63e9-4827-8544-88a77df5a85f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae808a7a-e0d5-43ee-a17b-cffac43589b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a16c9fa7-9f5f-4a0b-86c8-8b3a7738eb6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0dcae990-1617-4129-981a-b6868d10a56a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 868201df-fd98-459d-858c-83bb59d001cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15ab6f92-93ae-48b9-9021-0caf6b96954e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19ac67cc-3d4b-4467-890c-a7eb9f7ee9ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ce2e9da-e4ea-441a-b960-6eb3d53eb884
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af60b9ce-beea-4265-a1aa-203c47859ce5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a20d68a-dbfc-4404-b333-27df69c02ebc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2cebc93-3698-46ae-8800-30080ac12ec0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3076787f-2d1b-44b2-b118-d28bdf3dbc8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5878837-d177-4522-9c8d-b70400f67029
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a13b972-967e-436a-91ea-1525fe7f69f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36177eb2-ef69-4d96-8d77-fc67ffc46ca5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c649a5f8-6a2e-4ff1-aa96-711d244116ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5029c0f-ee9e-4b39-b397-75ade6d6b221
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99e4ca2a-04a8-492d-9ba3-4cb6e4a104fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5017da3b-1b15-400a-aefc-dd3851eaf6df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c748698d-2a27-4d82-b09b-a57db14cc2d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 142da6ac-e094-4db4-adaf-30ff3455b9db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7275c49a-3696-4eaa-b748-4db038bb4e52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e198bfbf-ab6d-41e3-8c46-aee8de6bb257
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2f08143-e1e8-49cf-a590-c9ff2150723a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20ae94b6-9f97-4c6b-9c4d-ff8b67a57558
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d732e24-371a-448b-aab8-706412099801
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70940dec-b7c8-4aa1-885c-347b622242f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3665854-87b6-4918-87b0-45cfc30496f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90ca3a93-4c72-419f-a079-8abf658ab57e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e009949a-6df8-4052-b145-1d88e90e711b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c7b7ee3-7e59-4b3a-927c-e513ce354407
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f150fe8-2590-47b9-9db9-a13651361716
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61eb9751-2d92-483a-83d3-b9a438b1a06f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee1e2b3a-0357-4790-8fb8-cf54d6b6d8b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0a05b1d-171f-4d29-8f18-d00c50bef01e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7f37590-e3b8-44c7-a399-7ef497eca79f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec8d46ba-9346-46be-85e4-e806a2071a9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 822d7acd-1558-4cf4-b9b9-84da895921ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 651fe926-6ef8-4d7f-aa66-b9883f94c4ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 276f845c-429d-4952-84b7-caa94047600f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7fd65343-671f-49e6-ac39-3b5b9409381d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e75158da-75fe-4e99-a4aa-51023694ede2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a2792bb-8c45-4442-baa5-34795edcf0aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97569f76-6b82-4a4e-9dda-1b690b9bdd90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8de6b3c4-31ae-4d34-8b09-8ce961ab46c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d3dceef-de26-415d-883c-2233eff0f59d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d32be327-cc06-4568-bf93-ad9f729747d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e548a32-a104-437d-9914-4969d9dce321
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 356ce95f-e014-49d7-a007-54afa59476b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48279dab-b48b-4538-bedf-647aa5710027
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b70b6331-386b-4ec0-8117-fe9f0b53c0c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36b43cda-87ee-402f-b967-726f0600b791
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 883b5b30-6b01-44d4-9ad1-4eabf47f789e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20e07fe2-16bd-4e0e-909a-63ae5ea76754
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e265daf7-140b-4489-b810-632b22ce09b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39443bb9-444a-43a6-8f37-e35ada1ea9f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfefefb8-559b-4347-87cf-f005878761de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 829182e0-b537-4ff0-a87a-d89c7018fc69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d1b66c0-659c-4e15-bf0a-052d93b750eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b963895-20b8-4ae8-a12b-038899714135
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f101290-86ac-4f0f-8421-2ac06edd1955
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3543c28f-b3c3-4241-b618-caf20d17667f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a481f74b-eb13-4b39-ba78-918ee997d4e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4937d16f-0966-4d06-ac25-885544ee6eb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2fc75b7-93cc-493b-859e-f459b331f88a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0e51a11-0620-43bd-9ff8-a6a9bb4d438b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6fbc6a1-9eae-431a-8967-c940d0d89ae5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 117f3af3-57ff-4181-a136-3e13d3aaf707
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f279a271-2fab-4b22-a57b-fc3a82a7d845
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce4fe865-e706-4f39-84c0-07f5f15915bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48a9a243-140d-4d80-8a85-276c29bfb5ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e43211b-e1c2-4eae-8e52-c2cd9cae2fac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce671f1e-722f-4571-834c-fd68bade74e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1b7b369-5a5f-4b13-8340-155a1c5cecc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20b3961b-dfa7-4db3-aa27-595925e24d29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 926590c5-f93d-4c6c-9e8b-ab65a6ece95d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4fe97b2-9858-4000-a389-c5d347afcf62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7228dbec-fdda-4bd0-85db-1cb252b2a2b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 261797da-89ed-4bf3-9a2f-9df88c968f15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9153f686-a064-4ca7-bfdb-fddea51e62ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1235e7fc-f279-4bd7-8b85-46b8c2b45903
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30a66ad1-46b0-4236-ac18-1eb26ead1e39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb539547-64f3-46e1-b055-485b69b3971f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 949e745a-ad1b-4ad0-82d0-65b49ff2b7ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 321d65e6-23b5-460a-af2a-13e7b3aa0fd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2183846-41d6-4940-8f3e-231f06394ea3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d9ab648-a046-400a-b5e4-b8d561e224a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7633fa5a-60cd-4364-81cf-b3270a63af7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11f80cbb-5e6f-4270-ab29-8484d95226e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0af9539-fdff-4b5b-b431-95bd5a09eef0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0868334c-56c1-49ca-a350-340921c91485
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1437bc80-5711-4f14-9273-e42fd26e7fcd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96aa681f-8a62-462c-a511-620cae05b3ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16b79485-8ce7-4f09-8e12-56391021b23a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c5f3245-d9b8-4cdb-8380-e86f0c96cef0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f37af7c5-53be-42d5-bbf2-25de2d6d531f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d981cb97-2057-42ed-92b9-179f92ff1475
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd61193e-cf37-4583-b7e7-18c777d90010
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43636857-c282-4b15-8344-7cbe42dad97a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eabe4dd2-2f5a-4913-9ad3-839ce18ce93f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message baad273a-db62-4f68-a55c-628e5f56b145
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea88e5d3-555f-474f-9b86-5ff741256bdb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d77fd81-20fa-47c9-a7af-50535e316cff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fcb32397-e401-44ce-8b19-a852f56e8de1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message faa5856b-c68c-4767-a1a3-37ee9ce6d9c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af94986f-07f0-4418-8b7a-1fe1b3ea24d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91c61a01-6a61-46a2-a04d-cef298a61016
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f80de82b-05f2-4c87-b50c-96e9b58158ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38ddc3e4-a330-4ee7-a477-bf994f423ea5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53b83750-546e-46f7-8915-1b3ded189291
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b0de126-d10b-4dbe-9c5e-9b57a7321ec6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03ba4d15-44f3-48be-8638-78d7bdf90aa6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b18a4b70-540f-4911-bd0a-bb9a4a530196
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9d4e303-c111-42cc-8f70-f05b1b9edd13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01bc45bf-305e-4e6e-93e9-9320c979fc1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d15c396-32d6-4c4f-ba9c-3025348bb17d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 074dd8b6-246b-4eb1-8010-c2c49ba2c779
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a5cebb6-df39-4bc9-af12-dedc3b5a7576
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e05a583-37dd-4301-be82-243e13d1da4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f3e0507-a6f3-4a3a-b6d9-cb39f183f639
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b6738a7-0fcc-4263-85f8-7bb7393d3cee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ac4fddc-91b4-43af-be45-a75068c9d471
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ebaa27a-65c7-49ad-9716-7c3b3f5ff01f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97dd863a-0dab-43f0-b59f-07e44c6f6047
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77b4c86a-c2ff-42fd-8c5e-53a81d70979b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c958a4b-b380-4b89-8cc5-f1b3450fba69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4adc0dd2-accd-4130-8e05-d8027e79acfc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1d17266-0a71-42a6-9abe-32b83f0936c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92365ca1-bb26-4168-ad2e-142a33e93fdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 145c8f4a-de7f-42d2-8b64-a1add7ece2d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ac5bea0-7bd2-4f95-af2e-ec7f866da881
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f529236-0b64-49fb-b761-104676cd99f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8362fbae-17d3-49b6-a476-4d2ebcc46fe0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ab0fad2-bf53-47bf-ba76-c2e8a353be1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7c32081-d972-4e04-aa5f-f04472bbec97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77f04b3b-b10f-432c-aaac-33453df83fc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 397b8c41-c772-4977-8738-eeadd08eac5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4be7adeb-3658-4495-ac1f-a6666e8f3ee6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27eb688a-9570-4d2c-8a68-49988010e425
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7436ec3-61db-43da-92da-c0989b43084a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a31dbc05-e5f7-45ca-b607-3499518c1c40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78818720-0d8a-434a-9c11-fd408225a83d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd93ad96-6c16-4b94-a12b-bf67150061a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa0dd702-1ec2-45d0-99fa-f03188b57631
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5139c58-ed43-4069-9a34-8b88e185f998
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b042c0f7-fc4c-4c88-80cf-420d2fcb279a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67ec74f5-a54f-4679-923d-359a3f996a1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb61ab60-da98-45a0-a67b-c2326f388129
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09d09c84-a057-406c-afe0-3e955078dc52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5134bde-4769-4d50-ba4f-5606a86ce1e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2c9cd03-b282-471d-bc24-e086cd08480d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84274b27-b423-4039-9db8-feb892841ac8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 502e432c-d58e-4b40-b74c-6c7a4e6967f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4319f70a-2193-4067-9a7f-f2eca892c19f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95a433a1-3eea-4151-a1b4-e876bbe7cd5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17e00110-d946-4535-bd9d-acdce53e1a30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8768574a-ef81-43da-ae0e-d8fea49b2aca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 020ca968-4826-4da3-b1ce-edbdaa6b39de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9fe73874-0ea2-49fb-bc52-2cddc759c8bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6a0f9a7-6aed-466e-bb31-571b63fbf19f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc5c9fb5-97a8-48bb-b528-23cb2c46843f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8d71ef1-7670-4402-bb2e-4bb4f646baee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec9b3f92-b949-46bb-8327-7d74ea2ca42a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 505f93eb-548d-4aec-bcd0-ae3ec446984c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12c5d2e4-7c75-4643-baa2-d6bcf8375567
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04c340d6-2121-4ffe-beea-54551bf32df1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5d332b0-0c4b-4867-9d85-561e2267a215
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd71e36a-d54f-45da-be7f-853f5409f6e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6bd537a-9327-4352-841c-aab00fbe8b66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 373fd163-1390-493d-9723-739ccf36af57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 893e6aea-42d9-41f4-8a05-03e7eb055b8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a1e95de-e3e1-4385-b0fe-aedfc594d45f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0dec5228-9f63-4c95-9e18-c4e3629721f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 512eb657-5b16-4ca3-8e19-d3a4fc8c9101
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2605c42f-949c-48b4-8d13-0e1c098b4ec2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79211bff-fadf-43cd-a80f-9916f3157d03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9cebf271-b973-4840-ac18-d73c7a56e75f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69f98eae-8799-4fcb-8118-b558db1fe42a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48ded86a-5818-4729-b2e9-1eb376f8bbf7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc83079e-6403-4ded-8290-180be434b41f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8145bfec-8ece-4e48-87fa-e1f6e6756653
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44c96c60-be48-48df-a848-e1357ce5a2db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2be40222-e41d-4f4c-9162-67ee640d92fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfe5143b-9883-4457-8237-a47eff64f120
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 641853b3-c1d1-4abe-a032-85bfd0adf4e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18e0ba85-c701-45a1-9dd5-efc76e5da9ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7cd061e-9dd5-4f3a-9465-83e8f216b2a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8869134f-1858-4a44-8a37-6fa9a9a3dd9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 148c4000-2cf1-4cfa-a97c-718e8a38a276
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d5c77f5-013b-4aba-9328-09d49eef21ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ee1b07e-c0aa-4db2-afcd-dc495b81ee79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4082391-0f3a-4ac7-9c9c-dde3fd40afde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5035d3ea-9551-4f39-a989-4a6103d01f59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 450c5171-4979-4286-b47d-6013de7a269f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e94ce7d-9640-4eeb-a271-280e64916620
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 367cbc6a-8e8c-4223-bc9e-c0cc11065514
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message faafced4-d12f-4125-93ce-c0d134a4960c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07e24f0f-7e78-4ab3-8d6c-6be9d05267a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d638e8fc-e8af-4928-b311-013c468726c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ce75661-9a73-4122-9cc8-70e8ab2f1149
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 938c142e-987d-4d27-bf6b-f4a4af1f3641
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b289973c-c013-494e-80e7-3113bcd937a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4c6449c-db7b-4b7f-a3af-a0b2d1fe9faf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8144617f-c13d-45e1-a9ee-efdf7ff6f048
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2d33a20-c4bc-41a1-be8f-89e50f3d8262
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ac7c20c-3c1e-40d5-9947-85546c6e24d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b262d15-0764-46ad-948f-422898abfa2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f949c4f1-5bbc-4ad6-ae90-936b13ed812e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32be1a29-4c94-453f-9870-a9ad52e82bf0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e045e22-593e-419f-a284-ed5e04621106
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f598b15-a0ea-402a-9cb2-49660e3f5309
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 025b7318-c67e-4c77-9a41-cc51e15b5339
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62c80cfd-f66d-464d-8153-5755756dd15b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7795fb07-f311-4c1e-b6ed-e0e5bbc11ca4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c51b70d-e6ca-424b-8494-dd5e68a1d781
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48346c27-fd83-4bed-ba35-ad0a8377ccb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d55125ff-4089-4b9f-8233-d3db5e07f974
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 578c8ef3-c942-4650-aa27-2b61579c3c10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0243ca31-a724-49a9-85e4-f4c19b6974ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1cc16709-b1be-4936-8845-8cbe294a1e89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f1f75b4-3864-4e2e-a5d3-46743e736b99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d39757e-6061-4716-b022-efaaf5d06bd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c127ff2-f743-4282-8504-dc50ceb7b3f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2460c65a-5b34-4a04-bd13-d11e82f1d2cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73886b8e-233b-4669-9d72-ea89b452695a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c0ba313-1330-4841-9724-a59a02ab07e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 691dcddb-0fe6-4319-900c-25402e9b9d3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c05af24-a926-4458-ab65-6d4a4f417862
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee82fd1b-aaa7-4d06-93a9-1f0da99f0cfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 222b1188-30ba-45a6-b49a-32becfbd5f28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0dea2deb-2044-473f-8115-c3a1d16e1aac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7609ae4-1fca-41e6-9b47-73f3f8e4d45e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c1ab7e6-b2b0-4849-8910-403a48612066
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0204dfbe-bf4d-4eeb-bfd7-b3db91e7b419
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d97c1645-af50-4994-bc0b-71e33e476fe3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47b6ed87-473e-408e-b10a-087f594b0b73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 291bf707-cdae-4769-9aee-e95ee91caef2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2cacd91-ed2f-4215-9e76-8f9c65d9d933
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 962b30a3-39ac-4cbd-9a24-a72eaf76770f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e662987a-2389-430b-bdea-cdc7ff40f5f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message feb22eb0-ec45-48cf-9b02-5dda0cd0b3cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9f0d58b-221d-4784-930c-0080c49e814a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb3a3ae0-7ac2-4e4c-a77e-17b03b880637
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac78c902-462f-4ee2-9d23-c627a862b609
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b5f6d37-f7e8-42fc-98a1-13dae32bc4f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 000e0e2c-b1fe-4d6b-8ce7-b966a6b3d669
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d853ea2-8c5b-43a3-b554-1c5f95b2abd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c978bd87-c3ae-455c-bdda-71474373af5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5bd255bc-8aff-4349-b806-f48510e5a2f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1eba91b6-02a6-49a6-a946-3de2c64edeb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 570d7c8d-d754-4e06-8d50-0224be8c51d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f90166ee-beff-445d-a3f3-4941b1daadc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05055437-0e49-461b-8185-5174cd02411e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59334553-0571-4203-867a-6a113259edbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c141a064-6c57-40b5-becb-b07687c43582
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e98f4e0f-6fc2-4547-a3d4-2662e5d54955
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 236c6c58-1a91-4fa7-b73d-89100aa067b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f561ef5-13b2-4e9b-b619-330cad4433e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51ed93e3-7fb8-4cde-ad8c-eb3e8c509082
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8688 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_9
Server: localhost:8688
Algorithm: FEDAVGM
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_9
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_9/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_9/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_9/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_9/test_labels.txt

📊 Raw data loaded:
   Train: X=(5643, 24), y=(5643,)
   Test:  X=(1411, 24), y=(1411,)

⚠️  Limiting training data: 5643 → 800 samples
⚠️  Limiting test data: 1411 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_9 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 2 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0795 (↓), lr=0.001000
   • Epoch   2/100: train=0.0814, val=0.0797, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0820, val=0.0810, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0818, val=0.0825, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0812, val=0.0829, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0791, val=0.0826, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 2 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0196
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0029
============================================================


📊 Round 2 Test Metrics:
   Loss: 0.1503, RMSE: 0.3877, MAE: 0.3195, R²: -0.8471

============================================================
🔄 Round 5 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0835 (↓), lr=0.000250
   • Epoch   2/100: train=0.0800, val=0.0854, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0797, val=0.0845, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0795, val=0.0845, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0794, val=0.0846, patience=4/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0789, val=0.0847, patience=10/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 5 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0154
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0018
============================================================


============================================================
🔄 Round 6 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0986, val=0.0782 (↓), lr=0.000063
   ✓ Epoch   2/100: train=0.0886, val=0.0733 (↓), lr=0.000063
   ✓ Epoch   3/100: train=0.0840, val=0.0722 (↓), lr=0.000063
   • Epoch   4/100: train=0.0824, val=0.0722, patience=1/15, lr=0.000063
   • Epoch   5/100: train=0.0820, val=0.0725, patience=2/15, lr=0.000063
   📉 Epoch 9: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0816, val=0.0728, patience=8/15, lr=0.000031
   📉 Epoch 17: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 6 Summary - Client client_9
   Epochs: 18/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0053
   Val:   Loss=0.0722, RMSE=0.2687, R²=0.0162
============================================================


📊 Round 6 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2495, R²: -0.0170

============================================================
🔄 Round 8 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0808 (↓), lr=0.000016
   ✓ Epoch   2/100: train=0.0840, val=0.0801 (↓), lr=0.000016
   ✓ Epoch   3/100: train=0.0832, val=0.0796 (↓), lr=0.000016
   • Epoch   4/100: train=0.0826, val=0.0792, patience=1/15, lr=0.000016
   ✓ Epoch   5/100: train=0.0822, val=0.0789 (↓), lr=0.000016
   📉 Epoch 7: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0810, val=0.0783, patience=2/15, lr=0.000008
   📉 Epoch 15: LR reduced 0.000008 → 0.000004
   • Epoch  21/100: train=0.0806, val=0.0781, patience=12/15, lr=0.000004
   📉 Epoch 23: LR reduced 0.000004 → 0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 8 Summary - Client client_9
   Epochs: 24/100 (early stopped)
   LR: 0.000016 → 0.000002 (3 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0021
   Val:   Loss=0.0784, RMSE=0.2799, R²=0.0069
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2487, R²: -0.0126

============================================================
🔄 Round 10 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0761 (↓), lr=0.000002
   • Epoch   2/100: train=0.0847, val=0.0760, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0846, val=0.0759, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0845, val=0.0757, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0844, val=0.0756, patience=4/15, lr=0.000002
   📉 Epoch 7: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0840, val=0.0753, patience=5/15, lr=0.000001
   • Epoch  21/100: train=0.0836, val=0.0749, patience=3/15, lr=0.000001
   • Epoch  31/100: train=0.0833, val=0.0746, patience=13/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 10 Summary - Client client_9
   Epochs: 33/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0146
   Val:   Loss=0.0750, RMSE=0.2739, R²=-0.0058
============================================================


📊 Round 10 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2463, R²: 0.0029

📊 Round 10 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2477, R²: -0.0202

📊 Round 10 Test Metrics:
   Loss: 0.0845, RMSE: 0.2906, MAE: 0.2488, R²: -0.0380

📊 Round 10 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2463, R²: 0.0056

📊 Round 10 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2468, R²: 0.0038

📊 Round 10 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2470, R²: 0.0024

📊 Round 10 Test Metrics:
   Loss: 0.0811, RMSE: 0.2849, MAE: 0.2470, R²: 0.0027

============================================================
🔄 Round 23 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 23 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0035
   Val:   Loss=0.0843, RMSE=0.2904, R²=0.0021
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2469, R²: 0.0032

============================================================
🔄 Round 25 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 25 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=-0.0102
   Val:   Loss=0.0782, RMSE=0.2797, R²=0.0382
============================================================


============================================================
🔄 Round 26 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 26 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0010
   Val:   Loss=0.0756, RMSE=0.2750, R²=-0.0106
============================================================


============================================================
🔄 Round 28 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 28 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=-0.0080
   Val:   Loss=0.0851, RMSE=0.2916, R²=0.0363
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2467, R²: 0.0044

📊 Round 28 Test Metrics:
   Loss: 0.0810, RMSE: 0.2845, MAE: 0.2466, R²: 0.0050

============================================================
🔄 Round 31 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 31 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=-0.0056
   Val:   Loss=0.0890, RMSE=0.2983, R²=0.0332
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2465, R²: 0.0054

============================================================
🔄 Round 33 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 33 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0122
   Val:   Loss=0.0778, RMSE=0.2788, R²=-0.0303
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2465, R²: 0.0056

📊 Round 33 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2465, R²: 0.0057

============================================================
🔄 Round 35 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 35 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=-0.0005
   Val:   Loss=0.0868, RMSE=0.2946, R²=0.0136
============================================================


============================================================
🔄 Round 36 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 36 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0118
   Val:   Loss=0.0873, RMSE=0.2954, R²=-0.0173
============================================================


============================================================
🔄 Round 37 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 37 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0177
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0899
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2464, R²: 0.0061

============================================================
🔄 Round 38 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 38 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2792, R²=0.0067
   Val:   Loss=0.0899, RMSE=0.2998, R²=-0.0026
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2464, R²: 0.0062

============================================================
🔄 Round 39 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 39 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0003
   Val:   Loss=0.0782, RMSE=0.2796, R²=0.0220
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2464, R²: 0.0063

============================================================
🔄 Round 41 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 41 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0137
   Val:   Loss=0.0888, RMSE=0.2979, R²=-0.0274
============================================================


============================================================
🔄 Round 42 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 42 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0002
   Val:   Loss=0.0795, RMSE=0.2819, R²=0.0133
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2463, R²: 0.0066

📊 Round 42 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2463, R²: 0.0067

============================================================
🔄 Round 46 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 46 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0066
   Val:   Loss=0.0810, RMSE=0.2845, R²=0.0146
============================================================


============================================================
🔄 Round 50 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 50 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0062
   Val:   Loss=0.0734, RMSE=0.2709, R²=0.0076
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2462, R²: 0.0070

============================================================
🔄 Round 51 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 51 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0031
   Val:   Loss=0.0733, RMSE=0.2707, R²=0.0457
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2462, R²: 0.0071

============================================================
🔄 Round 52 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 52 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0065
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0148
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2462, R²: 0.0071

============================================================
🔄 Round 55 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 55 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0080
   Val:   Loss=0.0840, RMSE=0.2897, R²=0.0164
============================================================


============================================================
🔄 Round 56 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 56 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0135
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0104
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2461, R²: 0.0072

📊 Round 56 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2461, R²: 0.0072

============================================================
🔄 Round 58 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 58 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0142
   Val:   Loss=0.0806, RMSE=0.2838, R²=-0.0060
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2461, R²: 0.0073

📊 Round 58 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2461, R²: 0.0073

📊 Round 58 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2461, R²: 0.0073

============================================================
🔄 Round 61 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 61 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0075
   Val:   Loss=0.0832, RMSE=0.2885, R²=0.0178
============================================================


============================================================
🔄 Round 62 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 62 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0195
   Val:   Loss=0.0743, RMSE=0.2725, R²=-0.0534
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2461, R²: 0.0074

============================================================
🔄 Round 63 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 63 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0080
   Val:   Loss=0.0723, RMSE=0.2689, R²=0.0158
============================================================


============================================================
🔄 Round 65 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 65 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0079
   Val:   Loss=0.0782, RMSE=0.2797, R²=0.0219
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2461, R²: 0.0074

============================================================
🔄 Round 67 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 67 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2813, R²=0.0088
   Val:   Loss=0.0831, RMSE=0.2883, R²=0.0195
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2460, R²: 0.0074

============================================================
🔄 Round 68 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 68 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=0.0021
   Val:   Loss=0.0910, RMSE=0.3016, R²=0.0404
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0808, RMSE: 0.2842, MAE: 0.2460, R²: 0.0075

📊 Round 68 Test Metrics:
   Loss: 0.0807, RMSE: 0.2842, MAE: 0.2460, R²: 0.0075

============================================================
🔄 Round 71 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 71 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0206
   Val:   Loss=0.0873, RMSE=0.2954, R²=-0.0332
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0807, RMSE: 0.2842, MAE: 0.2460, R²: 0.0075

📊 Round 71 Test Metrics:
   Loss: 0.0807, RMSE: 0.2842, MAE: 0.2460, R²: 0.0075

📊 Round 71 Test Metrics:
   Loss: 0.0807, RMSE: 0.2842, MAE: 0.2460, R²: 0.0076

============================================================
🔄 Round 75 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0701 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0701, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0701, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0701, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0701, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0700, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0701)

============================================================
📊 Round 75 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0108
   Val:   Loss=0.0701, RMSE=0.2647, R²=0.0140
============================================================


============================================================
🔄 Round 76 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 76 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0182
   Val:   Loss=0.0750, RMSE=0.2739, R²=-0.0276
============================================================


============================================================
🔄 Round 77 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 77 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0099
   Val:   Loss=0.0774, RMSE=0.2781, R²=0.0181
============================================================


============================================================
🔄 Round 81 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 81 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=0.0147
   Val:   Loss=0.0866, RMSE=0.2943, R²=-0.0078
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2460, R²: 0.0077

============================================================
🔄 Round 84 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 84 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0124
   Val:   Loss=0.0764, RMSE=0.2764, R²=0.0066
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2460, R²: 0.0077

============================================================
🔄 Round 88 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 88 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0126
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0035
============================================================


============================================================
🔄 Round 89 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 89 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0130
   Val:   Loss=0.0797, RMSE=0.2822, R²=-0.0024
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2460, R²: 0.0077

============================================================
🔄 Round 93 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 93 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2810, R²=0.0079
   Val:   Loss=0.0836, RMSE=0.2892, R²=0.0244
============================================================


============================================================
🔄 Round 95 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 95 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0047
   Val:   Loss=0.0740, RMSE=0.2720, R²=0.0437
============================================================


============================================================
🔄 Round 97 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 97 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0145
   Val:   Loss=0.0896, RMSE=0.2994, R²=0.0035
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2459, R²: 0.0078

============================================================
🔄 Round 100 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 100 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=0.0168
   Val:   Loss=0.0837, RMSE=0.2894, R²=-0.0124
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2459, R²: 0.0078

============================================================
🔄 Round 103 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 103 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0122
   Val:   Loss=0.0777, RMSE=0.2788, R²=0.0030
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2459, R²: 0.0078

📊 Round 103 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2459, R²: 0.0078

============================================================
🔄 Round 105 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 105 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0095
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0024
============================================================


============================================================
🔄 Round 106 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 106 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0044
   Val:   Loss=0.0733, RMSE=0.2707, R²=0.0470
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2459, R²: 0.0079

============================================================
🔄 Round 108 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 108 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0177
   Val:   Loss=0.0750, RMSE=0.2739, R²=-0.0155
============================================================


============================================================
🔄 Round 110 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 110 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0131
   Val:   Loss=0.0824, RMSE=0.2870, R²=0.0101
============================================================


============================================================
🔄 Round 112 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 112 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=0.0032
   Val:   Loss=0.0736, RMSE=0.2713, R²=0.0216
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2459, R²: 0.0079

============================================================
🔄 Round 113 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 113 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0123
   Val:   Loss=0.0830, RMSE=0.2881, R²=0.0129
============================================================


============================================================
🔄 Round 116 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 116 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=0.0034
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0421
============================================================


============================================================
🔄 Round 118 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 118 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0192
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0550
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2459, R²: 0.0080

============================================================
🔄 Round 119 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 119 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0099
   Val:   Loss=0.0784, RMSE=0.2801, R²=0.0243
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2459, R²: 0.0080

📊 Round 119 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2459, R²: 0.0080

============================================================
🔄 Round 123 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 123 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0208
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0360
============================================================


============================================================
🔄 Round 124 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 124 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0216
   Val:   Loss=0.0823, RMSE=0.2868, R²=-0.0285
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2459, R²: 0.0080

============================================================
🔄 Round 127 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 127 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0165
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0069
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2459, R²: 0.0081

📊 Round 127 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2459, R²: 0.0081

📊 Round 127 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2459, R²: 0.0081

============================================================
🔄 Round 133 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 133 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0093
   Val:   Loss=0.0810, RMSE=0.2845, R²=0.0266
============================================================


============================================================
🔄 Round 134 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 134 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=0.0056
   Val:   Loss=0.0780, RMSE=0.2794, R²=0.0376
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2459, R²: 0.0081

📊 Round 134 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2459, R²: 0.0081

============================================================
🔄 Round 136 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 136 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0143
   Val:   Loss=0.0775, RMSE=0.2783, R²=0.0028
============================================================


============================================================
🔄 Round 137 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 137 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0115
   Val:   Loss=0.0769, RMSE=0.2773, R²=0.0191
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2459, R²: 0.0081

📊 Round 137 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2459, R²: 0.0081

============================================================
🔄 Round 141 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0665 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0665, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0665, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0665, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0665, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0665, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0665)

============================================================
📊 Round 141 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0128
   Val:   Loss=0.0665, RMSE=0.2580, R²=0.0131
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2459, R²: 0.0082

📊 Round 141 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2459, R²: 0.0082

============================================================
🔄 Round 147 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 147 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2835, R²=0.0146
   Val:   Loss=0.0776, RMSE=0.2785, R²=0.0021
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2459, R²: 0.0083

📊 Round 147 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2459, R²: 0.0083

📊 Round 147 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2459, R²: 0.0083

============================================================
🔄 Round 159 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 159 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0110
   Val:   Loss=0.0737, RMSE=0.2714, R²=0.0209
============================================================


============================================================
🔄 Round 163 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 163 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0124
   Val:   Loss=0.0801, RMSE=0.2831, R²=0.0092
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2459, R²: 0.0084

============================================================
🔄 Round 166 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 166 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2772, R²=0.0166
   Val:   Loss=0.0915, RMSE=0.3025, R²=-0.0029
============================================================


============================================================
🔄 Round 169 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0707 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0707, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0707, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0706, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0706, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0706, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0707)

============================================================
📊 Round 169 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0191
   Val:   Loss=0.0707, RMSE=0.2658, R²=-0.0181
============================================================


============================================================
🔄 Round 170 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 170 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0092
   Val:   Loss=0.0765, RMSE=0.2766, R²=0.0191
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2458, R²: 0.0084

============================================================
🔄 Round 172 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 172 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0162
   Val:   Loss=0.0776, RMSE=0.2786, R²=-0.0108
============================================================


============================================================
🔄 Round 174 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 174 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2776, R²=0.0200
   Val:   Loss=0.0908, RMSE=0.3013, R²=-0.0112
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2458, R²: 0.0084

============================================================
🔄 Round 178 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 178 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0151
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0044
============================================================


============================================================
🔄 Round 179 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 179 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0093
   Val:   Loss=0.0886, RMSE=0.2976, R²=0.0198
============================================================


============================================================
🔄 Round 181 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 181 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0135
   Val:   Loss=0.0764, RMSE=0.2765, R²=0.0054
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2458, R²: 0.0085

============================================================
🔄 Round 182 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 182 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=0.0117
   Val:   Loss=0.0856, RMSE=0.2926, R²=0.0148
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2458, R²: 0.0085

============================================================
🔄 Round 184 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 184 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0064
   Val:   Loss=0.0885, RMSE=0.2974, R²=0.0176
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2458, R²: 0.0085

============================================================
🔄 Round 185 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 185 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2810, R²=0.0106
   Val:   Loss=0.0831, RMSE=0.2884, R²=0.0214
============================================================


============================================================
🔄 Round 186 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 186 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0172
   Val:   Loss=0.0885, RMSE=0.2975, R²=-0.0024
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2458, R²: 0.0086

============================================================
🔄 Round 189 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 189 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0168
   Val:   Loss=0.0898, RMSE=0.2996, R²=-0.0014
============================================================


============================================================
🔄 Round 190 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 190 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0085
   Val:   Loss=0.0755, RMSE=0.2748, R²=0.0177
============================================================


============================================================
🔄 Round 191 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 191 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0159
   Val:   Loss=0.0748, RMSE=0.2735, R²=0.0007
============================================================


============================================================
🔄 Round 194 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 194 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0111
   Val:   Loss=0.0740, RMSE=0.2721, R²=0.0198
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2458, R²: 0.0086

============================================================
🔄 Round 196 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 196 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=0.0237
   Val:   Loss=0.0866, RMSE=0.2942, R²=-0.0291
============================================================


📊 Round 196 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2458, R²: 0.0086

============================================================
🔄 Round 197 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 197 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0181
   Val:   Loss=0.0781, RMSE=0.2794, R²=-0.0165
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2458, R²: 0.0087

📊 Round 197 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2458, R²: 0.0087

📊 Round 197 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2458, R²: 0.0087

📊 Round 197 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2458, R²: 0.0087

============================================================
🔄 Round 202 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 202 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0180
   Val:   Loss=0.0740, RMSE=0.2721, R²=-0.0097
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2458, R²: 0.0087

📊 Round 202 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2458, R²: 0.0087

📊 Round 202 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2458, R²: 0.0087

============================================================
🔄 Round 212 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 212 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0085
   Val:   Loss=0.0842, RMSE=0.2902, R²=0.0297
============================================================


📊 Round 212 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2458, R²: 0.0088

============================================================
🔄 Round 214 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 214 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0126
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0064
============================================================


📊 Round 214 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2458, R²: 0.0088

📊 Round 214 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2458, R²: 0.0088

============================================================
🔄 Round 216 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 216 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0146
   Val:   Loss=0.0786, RMSE=0.2803, R²=-0.0076
============================================================


📊 Round 216 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2458, R²: 0.0089

📊 Round 216 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2458, R²: 0.0089

============================================================
🔄 Round 218 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 218 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=0.0126
   Val:   Loss=0.0861, RMSE=0.2934, R²=0.0148
============================================================


============================================================
🔄 Round 219 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 219 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0092
   Val:   Loss=0.0794, RMSE=0.2818, R²=0.0233
============================================================


📊 Round 219 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2458, R²: 0.0089

============================================================
🔄 Round 223 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 223 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0203
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0481
============================================================


📊 Round 223 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2458, R²: 0.0089

📊 Round 223 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2458, R²: 0.0089

============================================================
🔄 Round 227 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 227 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0156
   Val:   Loss=0.0787, RMSE=0.2806, R²=0.0018
============================================================


============================================================
🔄 Round 228 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 228 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0123
   Val:   Loss=0.0793, RMSE=0.2817, R²=-0.0026
============================================================


============================================================
🔄 Round 229 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 229 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=0.0115
   Val:   Loss=0.0816, RMSE=0.2856, R²=0.0074
============================================================


============================================================
🔄 Round 231 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 231 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=0.0161
   Val:   Loss=0.0750, RMSE=0.2739, R²=0.0005
============================================================


📊 Round 231 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2458, R²: 0.0090

============================================================
🔄 Round 232 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 232 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0165
   Val:   Loss=0.0783, RMSE=0.2799, R²=-0.0190
============================================================


📊 Round 232 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2458, R²: 0.0090

============================================================
🔄 Round 235 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 235 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0122
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0151
============================================================


📊 Round 235 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2458, R²: 0.0090

============================================================
🔄 Round 236 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 236 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0195
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0118
============================================================


📊 Round 236 Test Metrics:
   Loss: 0.0806, RMSE: 0.2840, MAE: 0.2458, R²: 0.0090

============================================================
🔄 Round 240 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 240 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0111
   Val:   Loss=0.0773, RMSE=0.2780, R²=0.0172
============================================================


📊 Round 240 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2458, R²: 0.0090

============================================================
🔄 Round 241 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 241 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0118
   Val:   Loss=0.0765, RMSE=0.2766, R²=0.0083
============================================================


📊 Round 241 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2458, R²: 0.0090

============================================================
🔄 Round 243 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 243 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0137
   Val:   Loss=0.0856, RMSE=0.2925, R²=-0.0054
============================================================


📊 Round 243 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2458, R²: 0.0090

============================================================
🔄 Round 248 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 248 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0103
   Val:   Loss=0.0753, RMSE=0.2744, R²=0.0264
============================================================


📊 Round 248 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2458, R²: 0.0091

============================================================
🔄 Round 251 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 251 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0115
   Val:   Loss=0.0725, RMSE=0.2692, R²=0.0217
============================================================


============================================================
🔄 Round 252 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 252 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0148
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0066
============================================================


============================================================
🔄 Round 253 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 253 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0113
   Val:   Loss=0.0812, RMSE=0.2849, R²=0.0205
============================================================


📊 Round 253 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2458, R²: 0.0091

============================================================
🔄 Round 255 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0689 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0689, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0689, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0689, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0689, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0689, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0689)

============================================================
📊 Round 255 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2871, R²=0.0202
   Val:   Loss=0.0689, RMSE=0.2626, R²=-0.0223
============================================================


📊 Round 255 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2458, R²: 0.0091

📊 Round 255 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2458, R²: 0.0091

📊 Round 255 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2458, R²: 0.0091

============================================================
🔄 Round 260 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 260 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0158
   Val:   Loss=0.0819, RMSE=0.2863, R²=0.0042
============================================================


============================================================
🔄 Round 261 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 261 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0090
   Val:   Loss=0.0744, RMSE=0.2727, R²=0.0087
============================================================


📊 Round 261 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2458, R²: 0.0092

============================================================
🔄 Round 264 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 264 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0056
   Val:   Loss=0.0806, RMSE=0.2839, R²=0.0310
============================================================


============================================================
🔄 Round 265 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 265 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0126
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0006
============================================================


============================================================
🔄 Round 266 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 266 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0162
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0018
============================================================


📊 Round 266 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2458, R²: 0.0091

============================================================
🔄 Round 267 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 267 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0129
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0149
============================================================


📊 Round 267 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2458, R²: 0.0092

📊 Round 267 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2458, R²: 0.0092

============================================================
🔄 Round 273 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 273 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=0.0145
   Val:   Loss=0.0848, RMSE=0.2913, R²=0.0097
============================================================


============================================================
🔄 Round 274 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 274 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0120
   Val:   Loss=0.0780, RMSE=0.2793, R²=0.0201
============================================================


============================================================
🔄 Round 275 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 275 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0123
   Val:   Loss=0.0756, RMSE=0.2749, R²=0.0180
============================================================


============================================================
🔄 Round 276 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 276 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0166
   Val:   Loss=0.0789, RMSE=0.2810, R²=-0.0050
============================================================


============================================================
🔄 Round 277 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 277 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0093
   Val:   Loss=0.0774, RMSE=0.2782, R²=0.0311
============================================================


📊 Round 277 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2458, R²: 0.0092

============================================================
🔄 Round 278 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 278 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0111
   Val:   Loss=0.0779, RMSE=0.2791, R²=0.0138
============================================================


📊 Round 278 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2458, R²: 0.0092

📊 Round 278 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2458, R²: 0.0092

📊 Round 278 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2458, R²: 0.0092

============================================================
🔄 Round 283 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 283 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0186
   Val:   Loss=0.0769, RMSE=0.2774, R²=-0.0081
============================================================


📊 Round 283 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2458, R²: 0.0092

============================================================
🔄 Round 286 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 286 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0114
   Val:   Loss=0.0795, RMSE=0.2819, R²=0.0189
============================================================


============================================================
🔄 Round 288 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0671 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0671, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0671, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0671, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0671, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0671, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0671)

============================================================
📊 Round 288 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0050
   Val:   Loss=0.0671, RMSE=0.2590, R²=0.0541
============================================================


📊 Round 288 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2457, R²: 0.0092

============================================================
🔄 Round 290 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 290 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0125
   Val:   Loss=0.0734, RMSE=0.2709, R²=0.0189
============================================================


📊 Round 290 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2457, R²: 0.0092

📊 Round 290 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2457, R²: 0.0092

📊 Round 290 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2457, R²: 0.0092

============================================================
🔄 Round 293 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 293 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0116
   Val:   Loss=0.0796, RMSE=0.2822, R²=0.0024
============================================================


📊 Round 293 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2458, R²: 0.0092

📊 Round 293 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2458, R²: 0.0093

============================================================
🔄 Round 296 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 296 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2783, R²=0.0145
   Val:   Loss=0.0889, RMSE=0.2982, R²=0.0104
============================================================


============================================================
🔄 Round 297 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 297 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0089
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0232
============================================================


============================================================
🔄 Round 299 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 299 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0223
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0402
============================================================


📊 Round 299 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2458, R²: 0.0093

============================================================
🔄 Round 303 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 303 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0123
   Val:   Loss=0.0764, RMSE=0.2763, R²=0.0162
============================================================


📊 Round 303 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2458, R²: 0.0094

============================================================
🔄 Round 307 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 307 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2835, R²=0.0119
   Val:   Loss=0.0774, RMSE=0.2782, R²=0.0041
============================================================


============================================================
🔄 Round 311 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 311 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0089
   Val:   Loss=0.0733, RMSE=0.2707, R²=0.0289
============================================================


📊 Round 311 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2457, R²: 0.0094

📊 Round 311 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2457, R²: 0.0094

📊 Round 311 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2457, R²: 0.0095

============================================================
🔄 Round 317 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 317 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0146
   Val:   Loss=0.0750, RMSE=0.2739, R²=0.0084
============================================================


📊 Round 317 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2457, R²: 0.0095

📊 Round 317 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2457, R²: 0.0095

📊 Round 317 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2457, R²: 0.0095

📊 Round 317 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2457, R²: 0.0095

============================================================
🔄 Round 322 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 322 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2799, R²=0.0109
   Val:   Loss=0.0853, RMSE=0.2921, R²=0.0213
============================================================


📊 Round 322 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2457, R²: 0.0095

📊 Round 322 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2457, R²: 0.0095

============================================================
🔄 Round 325 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 325 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2842, R²=0.0088
   Val:   Loss=0.0758, RMSE=0.2753, R²=0.0323
============================================================


📊 Round 325 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2457, R²: 0.0095

============================================================
🔄 Round 331 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0709 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0708, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0708, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0708, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0708, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0708, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0709)

============================================================
📊 Round 331 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0144
   Val:   Loss=0.0709, RMSE=0.2662, R²=-0.0087
============================================================


============================================================
🔄 Round 332 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 332 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0096
   Val:   Loss=0.0848, RMSE=0.2911, R²=0.0257
============================================================


============================================================
🔄 Round 333 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 333 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0134
   Val:   Loss=0.0759, RMSE=0.2754, R²=0.0132
============================================================


📊 Round 333 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2457, R²: 0.0096

============================================================
🔄 Round 334 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0664 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0664, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0664, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0663, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0663, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0663, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0664)

============================================================
📊 Round 334 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0097
   Val:   Loss=0.0664, RMSE=0.2576, R²=0.0243
============================================================


📊 Round 334 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2457, R²: 0.0096

============================================================
🔄 Round 336 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 336 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0082
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0323
============================================================


============================================================
🔄 Round 337 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 337 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=0.0144
   Val:   Loss=0.0778, RMSE=0.2789, R²=0.0000
============================================================


📊 Round 337 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2457, R²: 0.0096

============================================================
🔄 Round 341 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 341 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0160
   Val:   Loss=0.0778, RMSE=0.2789, R²=-0.0057
============================================================


📊 Round 341 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2457, R²: 0.0096

📊 Round 341 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2457, R²: 0.0096

📊 Round 341 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2457, R²: 0.0096

============================================================
🔄 Round 344 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 344 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0151
   Val:   Loss=0.0791, RMSE=0.2812, R²=-0.0129
============================================================


📊 Round 344 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2457, R²: 0.0096

============================================================
🔄 Round 346 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 346 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0116
   Val:   Loss=0.0843, RMSE=0.2903, R²=0.0060
============================================================


📊 Round 346 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2457, R²: 0.0096

============================================================
🔄 Round 347 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 347 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0173
   Val:   Loss=0.0797, RMSE=0.2824, R²=-0.0016
============================================================


📊 Round 347 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2457, R²: 0.0096

📊 Round 347 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2457, R²: 0.0097

📊 Round 347 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2457, R²: 0.0097

============================================================
🔄 Round 353 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 353 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0131
   Val:   Loss=0.0759, RMSE=0.2754, R²=0.0032
============================================================


============================================================
🔄 Round 354 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 354 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0070
   Val:   Loss=0.0738, RMSE=0.2716, R²=0.0426
============================================================


📊 Round 354 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2457, R²: 0.0097

============================================================
🔄 Round 355 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 355 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0081
   Val:   Loss=0.0801, RMSE=0.2831, R²=0.0337
============================================================


📊 Round 355 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2457, R²: 0.0097

============================================================
🔄 Round 357 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 357 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0124
   Val:   Loss=0.0895, RMSE=0.2992, R²=0.0180
============================================================


📊 Round 357 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2457, R²: 0.0097

============================================================
🔄 Round 359 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 359 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0136
   Val:   Loss=0.0763, RMSE=0.2761, R²=-0.0098
============================================================


📊 Round 359 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2457, R²: 0.0097

============================================================
🔄 Round 360 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 360 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0129
   Val:   Loss=0.0815, RMSE=0.2854, R²=0.0172
============================================================


📊 Round 360 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2457, R²: 0.0097

============================================================
🔄 Round 361 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 361 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0101
   Val:   Loss=0.0895, RMSE=0.2992, R²=0.0152
============================================================


📊 Round 361 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2457, R²: 0.0097

============================================================
🔄 Round 362 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 362 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0131
   Val:   Loss=0.0815, RMSE=0.2854, R²=0.0113
============================================================


============================================================
🔄 Round 367 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 367 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0139
   Val:   Loss=0.0783, RMSE=0.2798, R²=0.0140
============================================================


📊 Round 367 Test Metrics:
   Loss: 0.0806, RMSE: 0.2838, MAE: 0.2457, R²: 0.0097

============================================================
🔄 Round 373 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 373 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0199
   Val:   Loss=0.0865, RMSE=0.2942, R²=-0.0134
============================================================


📊 Round 373 Test Metrics:
   Loss: 0.0806, RMSE: 0.2838, MAE: 0.2457, R²: 0.0097

============================================================
🔄 Round 375 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 375 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0036
   Val:   Loss=0.0827, RMSE=0.2875, R²=0.0378
============================================================


============================================================
🔄 Round 376 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 376 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0187
   Val:   Loss=0.0786, RMSE=0.2803, R²=-0.0076
============================================================


📊 Round 376 Test Metrics:
   Loss: 0.0806, RMSE: 0.2838, MAE: 0.2457, R²: 0.0097

============================================================
🔄 Round 377 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 377 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2806, R²=0.0138
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0138
============================================================


============================================================
🔄 Round 378 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 378 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0124
   Val:   Loss=0.0871, RMSE=0.2951, R²=0.0176
============================================================


📊 Round 378 Test Metrics:
   Loss: 0.0806, RMSE: 0.2838, MAE: 0.2457, R²: 0.0097

============================================================
🔄 Round 379 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 379 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0161
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0036
============================================================


============================================================
🔄 Round 380 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 380 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0204
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0218
============================================================


📊 Round 380 Test Metrics:
   Loss: 0.0806, RMSE: 0.2838, MAE: 0.2457, R²: 0.0097

============================================================
🔄 Round 383 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 383 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0078
   Val:   Loss=0.0721, RMSE=0.2685, R²=0.0326
============================================================


📊 Round 383 Test Metrics:
   Loss: 0.0806, RMSE: 0.2838, MAE: 0.2457, R²: 0.0097

📊 Round 383 Test Metrics:
   Loss: 0.0806, RMSE: 0.2838, MAE: 0.2457, R²: 0.0098

============================================================
🔄 Round 390 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 390 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0128
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0175
============================================================


============================================================
🔄 Round 391 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 391 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0210
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0232
============================================================


============================================================
🔄 Round 393 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 393 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0159
   Val:   Loss=0.0743, RMSE=0.2726, R²=-0.0114
============================================================


📊 Round 393 Test Metrics:
   Loss: 0.0806, RMSE: 0.2838, MAE: 0.2457, R²: 0.0098

📊 Round 393 Test Metrics:
   Loss: 0.0806, RMSE: 0.2838, MAE: 0.2457, R²: 0.0098

📊 Round 393 Test Metrics:
   Loss: 0.0806, RMSE: 0.2838, MAE: 0.2457, R²: 0.0098

📊 Round 393 Test Metrics:
   Loss: 0.0806, RMSE: 0.2838, MAE: 0.2457, R²: 0.0098

============================================================
🔄 Round 403 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0709 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0709, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0709, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0709, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0709, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0709, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0709)

============================================================
📊 Round 403 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0128
   Val:   Loss=0.0709, RMSE=0.2662, R²=0.0060
============================================================


📊 Round 403 Test Metrics:
   Loss: 0.0806, RMSE: 0.2838, MAE: 0.2457, R²: 0.0098

📊 Round 403 Test Metrics:
   Loss: 0.0806, RMSE: 0.2838, MAE: 0.2457, R²: 0.0099

📊 Round 403 Test Metrics:
   Loss: 0.0806, RMSE: 0.2838, MAE: 0.2457, R²: 0.0099

============================================================
🔄 Round 406 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0675 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0674, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0674, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0674, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0674, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0674, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0675)

============================================================
📊 Round 406 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0136
   Val:   Loss=0.0675, RMSE=0.2597, R²=0.0153
============================================================


📊 Round 406 Test Metrics:
   Loss: 0.0806, RMSE: 0.2838, MAE: 0.2457, R²: 0.0099

============================================================
🔄 Round 409 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 409 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0157
   Val:   Loss=0.0840, RMSE=0.2897, R²=0.0058
============================================================


📊 Round 409 Test Metrics:
   Loss: 0.0806, RMSE: 0.2838, MAE: 0.2457, R²: 0.0099

📊 Round 409 Test Metrics:
   Loss: 0.0806, RMSE: 0.2838, MAE: 0.2457, R²: 0.0099

============================================================
🔄 Round 411 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 411 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0177
   Val:   Loss=0.0819, RMSE=0.2863, R²=-0.0041
============================================================


📊 Round 411 Test Metrics:
   Loss: 0.0806, RMSE: 0.2838, MAE: 0.2457, R²: 0.0099

============================================================
🔄 Round 412 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0722 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 412 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0103
   Val:   Loss=0.0722, RMSE=0.2686, R²=0.0295
============================================================


📊 Round 412 Test Metrics:
   Loss: 0.0806, RMSE: 0.2838, MAE: 0.2457, R²: 0.0099

============================================================
🔄 Round 414 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 414 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0215
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0141
============================================================


📊 Round 414 Test Metrics:
   Loss: 0.0806, RMSE: 0.2838, MAE: 0.2457, R²: 0.0099

============================================================
🔄 Round 416 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 416 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0086
   Val:   Loss=0.0812, RMSE=0.2850, R²=0.0303
============================================================


📊 Round 416 Test Metrics:
   Loss: 0.0806, RMSE: 0.2838, MAE: 0.2457, R²: 0.0099

============================================================
🔄 Round 418 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 418 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0142
   Val:   Loss=0.0801, RMSE=0.2831, R²=0.0071
============================================================


📊 Round 418 Test Metrics:
   Loss: 0.0806, RMSE: 0.2838, MAE: 0.2457, R²: 0.0100

============================================================
🔄 Round 424 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 424 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0143
   Val:   Loss=0.0745, RMSE=0.2729, R²=0.0095
============================================================


📊 Round 424 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2457, R²: 0.0100

============================================================
🔄 Round 426 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 426 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0056
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0256
============================================================


============================================================
🔄 Round 427 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 427 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0192
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0089
============================================================


📊 Round 427 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2457, R²: 0.0100

============================================================
🔄 Round 428 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 428 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=0.0086
   Val:   Loss=0.0780, RMSE=0.2792, R²=0.0344
============================================================


============================================================
🔄 Round 429 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 429 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0125
   Val:   Loss=0.0915, RMSE=0.3025, R²=0.0169
============================================================


============================================================
🔄 Round 430 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 430 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0162
   Val:   Loss=0.0773, RMSE=0.2779, R²=0.0036
============================================================


📊 Round 430 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2457, R²: 0.0100

📊 Round 430 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2457, R²: 0.0100

============================================================
🔄 Round 432 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 432 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0210
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0168
============================================================


============================================================
🔄 Round 433 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 433 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0158
   Val:   Loss=0.0786, RMSE=0.2803, R²=-0.0193
============================================================


📊 Round 433 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2457, R²: 0.0100

📊 Round 433 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2457, R²: 0.0100

📊 Round 433 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2457, R²: 0.0100

📊 Round 433 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2457, R²: 0.0100

============================================================
🔄 Round 440 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 440 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0176
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0055
============================================================


============================================================
🔄 Round 441 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 441 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0186
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0072
============================================================


📊 Round 441 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2457, R²: 0.0101

============================================================
🔄 Round 444 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 444 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0160
   Val:   Loss=0.0767, RMSE=0.2770, R²=0.0007
============================================================


============================================================
🔄 Round 445 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0692 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0692, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0692, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0692, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0692, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0692, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0692)

============================================================
📊 Round 445 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0135
   Val:   Loss=0.0692, RMSE=0.2631, R²=0.0152
============================================================


📊 Round 445 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2457, R²: 0.0101

============================================================
🔄 Round 446 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 446 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2785, R²=0.0122
   Val:   Loss=0.0885, RMSE=0.2975, R²=0.0190
============================================================


📊 Round 446 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2457, R²: 0.0101

📊 Round 446 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2457, R²: 0.0101

============================================================
🔄 Round 453 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 453 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0112
   Val:   Loss=0.0747, RMSE=0.2733, R²=0.0239
============================================================


📊 Round 453 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2457, R²: 0.0102

============================================================
🔄 Round 454 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 454 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0087
   Val:   Loss=0.0785, RMSE=0.2801, R²=0.0317
============================================================


============================================================
🔄 Round 457 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0702 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0702, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0701, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0701, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0701, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0701, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0702)

============================================================
📊 Round 457 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0199
   Val:   Loss=0.0702, RMSE=0.2649, R²=-0.0191
============================================================


============================================================
🔄 Round 459 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 459 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0102
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0063
============================================================


============================================================
🔄 Round 460 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 460 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0170
   Val:   Loss=0.0729, RMSE=0.2699, R²=-0.0165
============================================================


============================================================
🔄 Round 461 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 461 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2785, R²=0.0217
   Val:   Loss=0.0886, RMSE=0.2977, R²=-0.0272
============================================================


📊 Round 461 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2457, R²: 0.0102

============================================================
🔄 Round 464 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 464 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0175
   Val:   Loss=0.0840, RMSE=0.2899, R²=-0.0189
============================================================


📊 Round 464 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2457, R²: 0.0102

============================================================
🔄 Round 469 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 469 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0073
   Val:   Loss=0.0752, RMSE=0.2742, R²=0.0322
============================================================


📊 Round 469 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2457, R²: 0.0102

📊 Round 469 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2457, R²: 0.0102

============================================================
🔄 Round 472 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 472 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0132
   Val:   Loss=0.0757, RMSE=0.2752, R²=0.0103
============================================================


📊 Round 472 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2457, R²: 0.0102

============================================================
🔄 Round 473 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 473 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0185
   Val:   Loss=0.0851, RMSE=0.2918, R²=-0.0050
============================================================


📊 Round 473 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2457, R²: 0.0102

📊 Round 473 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2457, R²: 0.0102

============================================================
🔄 Round 477 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0683 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0683, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0683, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0682, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0682, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0682, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0683)

============================================================
📊 Round 477 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0105
   Val:   Loss=0.0683, RMSE=0.2613, R²=0.0269
============================================================


📊 Round 477 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2457, R²: 0.0103

📊 Round 477 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2457, R²: 0.0103

============================================================
🔄 Round 481 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 481 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0130
   Val:   Loss=0.0776, RMSE=0.2786, R²=-0.0222
============================================================


📊 Round 481 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2457, R²: 0.0103

============================================================
🔄 Round 482 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 482 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0139
   Val:   Loss=0.0810, RMSE=0.2845, R²=0.0126
============================================================


📊 Round 482 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2457, R²: 0.0103

📊 Round 482 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2457, R²: 0.0103

📊 Round 482 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2457, R²: 0.0103

============================================================
🔄 Round 486 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 486 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0094
   Val:   Loss=0.0771, RMSE=0.2778, R²=0.0284
============================================================


📊 Round 486 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2457, R²: 0.0103

📊 Round 486 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2457, R²: 0.0103

📊 Round 486 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2457, R²: 0.0103

📊 Round 486 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2457, R²: 0.0103

📊 Round 486 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2457, R²: 0.0103

============================================================
🔄 Round 494 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 494 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0120
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0162
============================================================


📊 Round 494 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2457, R²: 0.0103

📊 Round 494 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2457, R²: 0.0103

📊 Round 494 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2457, R²: 0.0103

============================================================
🔄 Round 504 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 504 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0105
   Val:   Loss=0.0775, RMSE=0.2784, R²=0.0215
============================================================


============================================================
🔄 Round 505 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 505 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0177
   Val:   Loss=0.0841, RMSE=0.2899, R²=-0.0020
============================================================


📊 Round 505 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2457, R²: 0.0103

============================================================
🔄 Round 506 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 506 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=0.0119
   Val:   Loss=0.0857, RMSE=0.2927, R²=0.0176
============================================================


📊 Round 506 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2457, R²: 0.0104

📊 Round 506 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2457, R²: 0.0104

============================================================
🔄 Round 511 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 511 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2822, R²=0.0168
   Val:   Loss=0.0800, RMSE=0.2829, R²=0.0004
============================================================


📊 Round 511 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2457, R²: 0.0104

📊 Round 511 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2457, R²: 0.0104

📊 Round 511 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2457, R²: 0.0104

============================================================
🔄 Round 519 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 519 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0197
   Val:   Loss=0.0840, RMSE=0.2899, R²=-0.0093
============================================================


📊 Round 519 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2457, R²: 0.0104

📊 Round 519 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2457, R²: 0.0104

============================================================
🔄 Round 523 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 523 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0185
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0045
============================================================


============================================================
🔄 Round 524 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 524 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0172
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0001
============================================================


============================================================
🔄 Round 525 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 525 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0169
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0014
============================================================


📊 Round 525 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2457, R²: 0.0104

============================================================
🔄 Round 528 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 528 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=0.0065
   Val:   Loss=0.0761, RMSE=0.2758, R²=0.0305
============================================================


📊 Round 528 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2457, R²: 0.0105

📊 Round 528 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2457, R²: 0.0105

============================================================
🔄 Round 531 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 531 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2801, R²=0.0094
   Val:   Loss=0.0848, RMSE=0.2912, R²=0.0299
============================================================


📊 Round 531 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2457, R²: 0.0105

============================================================
🔄 Round 532 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 532 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=0.0132
   Val:   Loss=0.0857, RMSE=0.2927, R²=0.0113
============================================================


============================================================
🔄 Round 533 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 533 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0160
   Val:   Loss=0.0750, RMSE=0.2739, R²=0.0007
============================================================


============================================================
🔄 Round 535 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 535 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0095
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0199
============================================================


============================================================
🔄 Round 537 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 537 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0123
   Val:   Loss=0.0765, RMSE=0.2766, R²=0.0187
============================================================


============================================================
🔄 Round 538 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 538 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0096
   Val:   Loss=0.0724, RMSE=0.2691, R²=0.0322
============================================================


📊 Round 538 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2457, R²: 0.0104

============================================================
🔄 Round 539 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 539 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0231
   Val:   Loss=0.0749, RMSE=0.2736, R²=-0.0331
============================================================


📊 Round 539 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2457, R²: 0.0104

📊 Round 539 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2457, R²: 0.0104

📊 Round 539 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2457, R²: 0.0104

============================================================
🔄 Round 542 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 542 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0028
   Val:   Loss=0.0854, RMSE=0.2922, R²=0.0458
============================================================


📊 Round 542 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2457, R²: 0.0104

============================================================
🔄 Round 543 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 543 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0188
   Val:   Loss=0.0756, RMSE=0.2750, R²=-0.0076
============================================================


📊 Round 543 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2457, R²: 0.0104

============================================================
🔄 Round 544 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 544 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0049
   Val:   Loss=0.0806, RMSE=0.2839, R²=0.0460
============================================================


============================================================
🔄 Round 545 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 545 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0135
   Val:   Loss=0.0765, RMSE=0.2766, R²=0.0160
============================================================


📊 Round 545 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2457, R²: 0.0104

📊 Round 545 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2457, R²: 0.0104

============================================================
🔄 Round 547 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 547 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2785, R²=0.0124
   Val:   Loss=0.0882, RMSE=0.2969, R²=0.0204
============================================================


📊 Round 547 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2457, R²: 0.0104

📊 Round 547 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2457, R²: 0.0104

============================================================
🔄 Round 550 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 550 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0165
   Val:   Loss=0.0849, RMSE=0.2914, R²=0.0059
============================================================


📊 Round 550 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2457, R²: 0.0104

============================================================
🔄 Round 555 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 555 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0189
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0045
============================================================


📊 Round 555 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2457, R²: 0.0104

📊 Round 555 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2457, R²: 0.0105

============================================================
🔄 Round 560 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 560 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0100
   Val:   Loss=0.0794, RMSE=0.2818, R²=0.0299
============================================================


📊 Round 560 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2457, R²: 0.0105

============================================================
🔄 Round 563 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 563 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=0.0200
   Val:   Loss=0.0811, RMSE=0.2849, R²=-0.0651
============================================================


============================================================
🔄 Round 565 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 565 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=0.0115
   Val:   Loss=0.0731, RMSE=0.2703, R²=0.0257
============================================================


📊 Round 565 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2457, R²: 0.0105

📊 Round 565 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2457, R²: 0.0105

============================================================
🔄 Round 570 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 570 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2812, R²=0.0107
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0263
============================================================


============================================================
🔄 Round 572 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 572 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0175
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0190
============================================================


📊 Round 572 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2457, R²: 0.0105

============================================================
🔄 Round 573 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 573 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0056
   Val:   Loss=0.0762, RMSE=0.2760, R²=0.0372
============================================================


📊 Round 573 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2457, R²: 0.0105

============================================================
🔄 Round 575 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 575 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0181
   Val:   Loss=0.0811, RMSE=0.2847, R²=-0.0071
============================================================


📊 Round 575 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2457, R²: 0.0106

============================================================
🔄 Round 576 - Client client_9
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 576 Summary - Client client_9
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2849, R²=0.0087
   Val:   Loss=0.0739, RMSE=0.2718, R²=0.0374
============================================================


❌ Client client_9 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8688 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8688 {grpc_message:"Socket closed", grpc_status:14}"
>
