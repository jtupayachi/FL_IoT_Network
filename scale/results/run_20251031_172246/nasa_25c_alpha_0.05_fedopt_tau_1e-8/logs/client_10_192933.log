[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff7472bb-8124-4924-a9e9-67f6835f77a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7fe636ca-2d3a-4d43-af07-24a8b1d905ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5b9f303-116d-49c7-9869-79117f1bc1b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9a29b95-5bbf-4bb4-ab8a-525ffe928b87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89f18303-fe3d-472e-a74a-6ae7de1795ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e8f0de5-6149-470e-8f3d-f15cefa44dd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96e64aeb-220b-454d-94e0-1712d723b183
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 833d3499-4baa-4745-ac81-cb7b5b7f2d5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 612b5f5b-98e4-4e6a-85a6-3e9212158a8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b5a7607-a114-4e19-83c6-e6d85e24a28c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1863d04-6e92-4646-b3b4-f4f13154babb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 079ef114-4c0d-42e5-9441-00fbaa2bd066
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a518e5fb-97e5-4e7f-a553-8127f639166b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44bb663b-fb27-4583-b445-58806c149c4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d05dfa5-ae76-475f-9882-b0d698d0d07a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9f58b4e-7c37-4094-8d7a-6eeff9136310
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13e0fb54-daa7-4611-971a-6386dc9addc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c833bb08-3375-4e6e-a3c4-0ee6f24095c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c750ebc-6dc4-49e2-9c30-077525183b98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35bcfc7d-2240-47e0-908f-1cf09e145972
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15e73ab1-00cc-4f3c-9881-8af5bf4a451a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e64ed441-e9fc-4f8d-8ba3-9dd7b5075619
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3919141c-d2b1-499f-a966-ef8db93136ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a54e409-7188-4b66-8e7d-49ee52be0286
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2348fc85-1a20-446a-97a6-29e0528c35a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5f529b7-cdbb-4fc9-a870-eb75783f8277
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ef011dd-aa67-47b0-83f8-01dcc2ada1cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0dc40e94-90e8-4c09-9970-66f10460997f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ebdf953-a411-4592-a4f5-96ffaaf0c834
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 319eb39f-832c-4eb2-89d6-e85aaf0ec0be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57d4d8d7-7aea-4432-9869-6e51afa15b56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d433620-c367-4ccd-a9af-d0da4d57b9ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20884f0b-03db-412e-96bb-43333705611c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2cd24d0d-1d15-4d16-b984-6f5748f1d4f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a62b272-c8d6-43a1-82a3-2ba35e878275
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00930363-3a9d-436f-9a18-1318e3ffef23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92f182d0-d5c0-4226-8bf8-c2a43ff262a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef601dcc-fbed-4c5e-9091-0ca2fa14887d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41049398-7b6c-4062-8ddf-0d66f19955ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d6a13b2-bc19-48d8-a483-5924c56dc989
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25df513a-5ceb-4d13-a66f-4d845d4b1414
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5003ade-b91d-4961-9a87-09e7e094360f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed9eced5-f7f3-4ea9-8189-1b1fa1f251c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64d3d331-fc9f-4ea0-aeee-7d4eb0c680e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f28cdde-d4cc-4cb1-9023-d0811fb67951
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 725185d9-c230-4f58-92f3-ccb4cf1845b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c98ab0f6-414b-4fad-b6c8-6c379b49a6c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0cc62b8-0ad9-48e3-8918-035255494831
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9b8b6e2-7935-4db1-8d42-c35bd18f9619
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7e47eaf-1b35-4daf-b41f-010ced11264b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aab6dced-077c-4e56-8c00-56cf4c82ef7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63955da8-acdd-48b8-8a87-75a1b26f4d7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5dab2794-9a25-4d4f-a447-d33c2f802eed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1dc04474-bab7-4b23-9567-f414d24aeef5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 225052e6-3f66-4685-bc47-1b2b6b7f5dd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c268083-ad01-4c47-9a58-3178311b2c7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18231c16-6d3c-4c55-8090-d09ca8667105
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b66d82da-d1c7-49f9-bc19-0b13843f741b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe4504c7-13a6-4b45-855d-d6eed9dfb5e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21c3525b-4226-4678-b850-1a2adf2cd76f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7b4ed7b-6c8a-4a4d-89f1-e6580e509cab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3f60967-4623-4864-9d6a-ec8318e31a9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 607e04a4-f2be-46ec-a5c7-91e33f3e93c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0a5f83a-26a7-460b-8505-2a9082957a20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61d046ff-dad6-4ecf-b6ac-fa5885b45c68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d889c148-0654-4bdb-b2a3-cb997f2c6c2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8373d6da-f788-4043-b3da-eb2cd2a3e9b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 920e51a3-5a6a-47b2-82bf-9f65878862a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51b0855d-3f88-4118-af94-ede8098bd00c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e433829-1a8b-499b-81e4-57f98df0050d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e2a146b-fd2d-47e8-9eb5-ef26f81a47bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76a20517-8138-489e-8064-e85e66563da2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab08a130-25a2-4104-b27a-ffcd44a1dd9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6e69514-58a4-4859-b4d7-ef23c7d1b2f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93f4ff01-749a-4fc7-9faa-476fa771ff97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 886dfa35-3660-4ba5-9c92-a927a4ad1a1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c8e88b9-8bb2-4191-a984-c83ae2aaf282
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60ebb041-0ab5-4e59-bb28-ae52aacc18a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97412916-4414-4386-ba6b-ff7447985d9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f6f10ae-84b8-4a3e-9ce2-e491af5e4504
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7042557-1b0b-4b86-b360-5080de867276
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e534d1ff-b5c7-4c5b-85ef-2406dc90fb4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f791f4ac-7fb0-4c65-8de2-2763ba1bcb46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46212110-d7d6-453f-8671-e41aa3398e95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a73251b-0b8c-46fd-8b3d-3f7d9215cee6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3295d18-7668-4d2b-8ebc-43f1296f1b0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e1018d1-5ff8-447e-b7f1-d15e9a4ddc57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7f961ad-1a7d-4f8a-b387-502d99ef9147
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d586e8b2-3ad3-4b91-bc72-7511e6dfd043
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3fe9b5d9-e97e-4374-b16b-19d68e6ba901
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message abc83ca1-f19c-43f0-b9cc-ca43b2d62300
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3712bf1f-be69-47da-a47b-d2624ce69b01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e845e359-4d2f-400c-8251-691b7a57c74c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 279655f0-c840-44c3-b3c0-d4a6634f70cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46ef7a58-76ea-4f9c-8834-3b2ffa3d5c55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25f4661e-5c14-4f3a-97e8-e428f5a55a1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1c7d184-c8b4-4639-bbe3-1a499aecb069
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4167370-9b27-462f-a6c9-6c8d27ac3fb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c3d2763-eaf6-4a73-a795-c941fbf3d791
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9aa1e76a-b00a-4ffe-b99e-9df163620f58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d48e114-e8b9-45cd-8141-ac212c028160
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3fbd47df-5466-4ccc-a6e4-6dfe6ef704d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c344783b-7724-4ab2-a06f-ab1da123872d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34e7b407-f8ce-4eca-834a-c82584166b4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8c0bb06-e5c1-47c6-87ba-580def85fc47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e4f78b0-9b4f-40a1-bb5c-e9dfb433b0f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d4a910a-cb8f-4302-8206-af1e99f7846e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f0f2d86-0b84-4ba0-b01b-293005430123
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3709d13-cef1-4cc1-9a59-0ae399d03f80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6aa78ad-f058-47a0-9a1b-1760c61126b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 014f64ee-1ee3-4940-bf54-50d9c0f8faaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7695249-2db0-4da6-8b86-1dc1bd08949c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7f6b443-5717-463c-b0c6-124d4e5f1022
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c51116f-bf92-4084-ac71-5038db2dd718
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b35b449a-5695-4430-a86a-448281f17293
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b10f9146-4b95-4517-9b5d-3f718fde74b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dea7ad05-7e54-4b42-b7f3-c3f85f777db7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1175ee4-c083-4a2c-ba87-85fee494e4da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8afdc32b-f7c6-4e14-9601-efe4d36a28e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dbb694b6-cd2a-4b9e-ab8f-d8a9f04a848e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3c122bc-3343-43c7-923c-778affd90bd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7994f012-fe4a-4e2f-b1cd-6c406f520f2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f091d5d-3ec6-4685-9332-2da99159aea3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9af16c7-be50-4376-bf98-52e64c32a891
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ffd1bc8-7467-476e-81e6-b3fe606060f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a65466c-404f-4bad-b331-dd9d224803bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5732210c-1347-4ff9-b4d2-c30c1cff3c95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b56115fd-58ca-4c10-b753-30c40d510fa5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8be6c2f-8864-4d96-956f-ef84c5b3a352
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e916b47a-4867-4976-9347-1e3bdb7cbdd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9815cd86-e5f1-41e8-b1f2-73f924b8ce94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7deab2a0-1a92-40d9-b4f6-9f608a74c187
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4ba8cf9-6c07-4bfe-ad12-acbf86c4a87f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af87bcdd-14ea-4330-b84c-7cfe5164603e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b7a1c4e-6beb-4904-80cb-847acb63fd05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f878cb8-99a2-4278-a809-c46586952c62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b9a7429-2cf7-487b-8592-db8a4efd78ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2020c7b8-d3b0-48d4-8671-64edb53cdaa7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68941f68-a815-4e84-a00e-00a86091cd62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b8717d1-3002-42e6-bf36-84efe3674b10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8672fd49-ad64-4a89-8d5b-513a82551d2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3caaca50-7042-4838-bf1a-0a4b2ba3ee3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65ed3da0-45dd-404e-87f1-ade0e9abc13f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f4bdbfa-5836-4f6a-882f-2538ede4d502
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f15d733-8b87-4e67-81bb-5408f6579d9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c24640f-6704-41b3-a8ee-259fc117ff4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20fc9327-41ec-4a14-95ac-64fcb3f9d72e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7efb4a0f-4481-4b95-bc5d-cc109a51ef99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70f8833f-f69c-41fc-aa1b-8fa25a12d08c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d12793d1-5e54-49e3-b78f-7614e6f5911d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22c444bb-ac7c-41da-b5f6-cfe3d3c60455
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c373c81e-f715-4557-b2d9-27479f389e2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8911a09f-45bd-4d5e-82d4-4b81f21bfde2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ebfe9dd0-160a-4626-9b5e-1acd8fb13099
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a82355e5-1787-4e0b-96f7-7a90af666a59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8c7a209-78fa-4666-ae85-0f73cf3db9a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 496d6b7a-7535-49b9-883e-0798e9243849
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5be21828-902d-48d5-975d-9f28cf336b77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46cc7a29-76d9-4b0d-9e61-61ce9d30d092
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d17305d-8666-41aa-8611-982f94cc4b2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ad0beb8-43e7-45a6-b79a-e7546ece415a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3228acee-2a68-4769-a662-3e3a549bcb1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe0b459c-7b1d-4faf-bc41-9b9897ad089e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4fa19d97-2bd0-4321-91f4-c20779658f92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57f3e9cd-bf2b-4b77-b4ef-58f7aeeb6beb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 162569d6-814c-4ee1-a8c6-a4f106492cba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fef17767-a514-4dd8-bdfe-24072468c94c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 523e4461-588a-47d7-8fa9-d1395c5544e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cea801b0-f121-4c7d-88ca-b2b78ebc6746
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message adcb3a8c-dda6-4d12-b6b4-c095d6769d3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46186aa0-8b79-4987-9e96-aa16e818cf6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81bbe104-9bd2-45c5-859c-0d276586c6d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e99f44b-53ea-4148-9bc9-018726af484b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a0a187d-34e0-424b-aeee-f00ccd016b54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 166382ed-bc9f-489e-b5e0-98c987efd115
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 215da578-e8b7-463e-a78e-d434739668ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee93807b-166a-42ce-a1cf-fe0d1120b14b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa5605e2-33c4-4916-b718-7ea58ade27fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a928e500-7026-45db-b5d2-f36f3b8ab969
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20bc9bea-31c2-42e3-bf6f-146999b10988
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c147d585-c7de-4818-8d8a-4d1bd72e4fe2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb4efa25-fd27-4dcc-840c-344d684afcee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 762bc138-fb0d-4c9b-ab2f-3279d09da7a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1bc6e1d-1c64-406d-9814-a64b3ddb5e67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6bbb88b4-59d2-4b15-b134-33197adf40dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ce9c722-f451-48a6-b506-abefd02b8c68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49d4b367-e738-4f60-91ef-07a2ff8d8744
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba10156b-cf6c-4164-bf38-b397ce7b86a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8eccd683-fd0b-4720-8349-d909284f533e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ffcd019-5f6f-4248-b5ae-51be49974997
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 700b3853-68ec-4a97-a98c-b90ba54e329e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ba6578a-15c2-4dc6-a00e-66fa29d7e675
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af81b7f8-93bc-46d1-9c5b-1afae0012b10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a47c294-d527-4511-bf61-7e3bc1637b3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f703f461-5f88-46c2-9aab-cde206a8492d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5649e060-3ce8-491a-81d6-77bfb85c730f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bfcc3914-94b5-4907-9037-bd2093ec2267
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 024b891e-72f1-4c13-98d4-2a7462e46873
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c21221bb-e5a1-4aa1-92fe-ed936bbc2f5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8a8f491-0d86-4cae-af4d-2c5706dd11cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c85e8fc7-f091-4fdc-a443-acb22d764a5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 876bddd8-c27e-4b01-9ead-965a1772dac5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac5b2531-cb2a-479b-a0f9-52c9fa0b437c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8611db4c-9a8e-41d3-92fd-9ab71d6315ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48d3acd3-3104-4fc3-8b33-af727571b2c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c23bae6e-885b-484f-b7da-ec834d61110b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61affc45-2247-4496-b945-2b0e23c706df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 227ef332-b5f3-481b-bd22-0f628d08f6e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e81d1ff-1d89-4d4a-9c0b-f76e539cc1da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ffd38df8-954d-488e-b8e0-d1a95cc64701
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33683f8b-f693-4320-a201-d600af32f63a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 961bdc04-5442-4e02-8d80-12b30f996e02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6ba609b-d4f0-47e2-aca8-7fd880d747bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb775f5d-47e7-4423-a806-fdc2179f856f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51b345fa-e496-43ce-8c89-f258f2b35767
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bedfc1dc-9e91-4ffe-8cae-417eb252a88b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4fb0ed4-b329-49d0-9ed2-8fe884b5b787
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f72ea58-2ad0-4ef6-902f-09cd06bb3988
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4de44de7-4d0e-4007-ac47-8a587e85f2ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1d671f3-087d-497f-aa66-40f86d7df0af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4cc2a38-4963-43c1-aeb7-c5a0db136683
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 185696a5-5bc5-4423-ae85-453660db1e23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c60806d-74d9-4627-bc70-6d61b8207016
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d15f39d-a21a-4eb0-b83f-0b1ce5e9ecf0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0445954-bdf0-4727-a417-8c5a8ec8bb95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 862eb6be-189c-4853-a3d4-9162b1d55e37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70670dc3-d1c8-4a1a-8ff3-299fe15f4f45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84139ec0-24fc-47fe-b69f-8d85ac896838
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 067bb0f9-8265-40b0-bc7d-cca19f4c7210
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38c068da-2ca6-4cfd-87b3-4754241efe15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 440adae0-9a73-4cd4-87af-3e56cc1bc0be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53eb4f03-1c3d-448b-b2f9-960a9f797b39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b63ce985-9453-4cd3-8a83-03e387a4ac9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 170bc66d-883e-4447-8a98-6dc1336fda7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fcb4495c-183f-43a1-a8ba-ba2c7807d905
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78e98c87-3df8-4975-b458-74d9bb3f1220
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5bd92e46-59a9-4329-a528-12dc195e16c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b51357e5-1566-47ef-9c6a-09ad41cfbc9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8ea4d02-c9c3-4140-a99c-8c75edf63164
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47b37be1-9c2f-465a-828a-c6edc1f49e44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9185210-d6b6-4a83-a22a-88fa35237c65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb9a0685-5c71-4639-bb1b-ffb243d1d08e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 496663fd-b461-414f-9e18-0edf99639a9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6757e90-1577-4af3-a220-80b44e173b0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46d5b8a4-a809-427a-b005-d1b552038998
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a3237b8-79fb-4343-b2b5-cb28e507d0d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22cc0c62-22db-43c7-8215-473cf4dda904
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd949342-58c0-4ef5-b96d-780055378f6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae7a365c-86e0-4a2f-8f4c-2c0597f50c4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 479f1aec-6f44-4833-9014-22e536d90ddc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e9c3675-781d-43b6-97a5-53132f416937
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c986a2d0-3b5b-4b4a-8850-1746088c8b53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75fd372c-ecd5-44dc-8189-a19270481b00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02818900-f2d3-4ef4-9305-49cda627f057
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e12f885-a77d-4d8f-b2e6-2378e1b74683
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4b5bc90-6e43-4bad-be17-841e1d153bac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd5f826a-f1c8-4163-a6de-500f8e4b612b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5015cd95-d0be-41cf-8c9d-7ef9df311460
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message faa64065-ee69-4cf3-a747-ae4c102804b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26d43eda-9d9a-444a-a9a8-8d63adc95fed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c74dc1d-520c-48a3-83f5-081bd0801b20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5f33248-c231-49cf-be8d-027b603261cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a96b07b2-99b9-4b8f-bd5b-ee20afb646bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ac1dd6d-b508-4bfd-abfb-0aad19693f22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5884a3ab-69fe-4991-8e4e-62f728d27060
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a77ab073-e93b-458a-abfc-a0e15ab505fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 319ac49a-2476-4b3b-8b19-41e39f754c90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26874964-271b-491b-bdfd-39880432f49b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de0ed079-7d54-47c3-b05d-0b070a3f3971
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac5f18ad-6a14-45e1-ab9b-e843a64111e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3c4e41a-4860-4b5f-bc2d-ecb3a57aab24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35c8ce89-cbaf-4fe1-9740-0a79a05201ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e328d905-5316-4860-be95-6893b03e38de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 423678c7-b248-4016-904e-1ea9525b96b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f39e3eb4-7b13-4a2d-a2d0-ca1c7b639f35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45f75c87-82be-49a3-b87a-d20476b6e2ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66b61340-d5fb-4863-a5c2-95ce436b2230
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e98dbd5e-87c0-46ac-87ce-4f8486615371
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e11dc5b6-c47b-445f-815f-89bbea7a6bec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f266979-5afa-46e1-937b-8da0d68a1f9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e463bba1-dbf9-436f-ae29-d5c8c6cbc9be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fcb4727d-210d-46ab-bb3c-fefa67c87a72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d0ef613-e5b9-4a1d-a358-769e0790e591
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a257aa1-46d3-4ba8-859e-44c99a4e3c33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ffee3818-886a-44b1-a762-2298139da98d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2511aa99-97df-4faf-92de-d9d9c7fbd399
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f490ab5-4495-495d-8b9a-d038f1833df0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00f36129-ce3f-43d0-8cbe-60aa9ac94e8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53a5dbe2-f53d-439e-b05f-86d81351207d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f431b4fb-235d-4ae1-98f1-d8b786508ea3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ecda6688-4fbf-4744-974a-7859cb1123c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c305af60-1ee1-40c5-a6f5-fada58714b69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b0f034a-d03f-43d5-aa97-133be8221549
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3006bdd5-d571-43bf-aa6f-b0e3a81ceb0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 097f43fe-52a6-49d0-a5b8-e64735c30f35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a89386d-6701-4c90-9711-9d323b78ffc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88c9a806-961f-45fa-9fcf-e4766260b883
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3462203-5201-4c10-b166-8fa92bdb89ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83004954-5b93-4e7d-9291-027696b7b03f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36467ac3-e6f0-424e-82a7-0c4d9e7eed71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a80bd33-6d10-4d31-a435-a31750f17d26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9883176-74e2-440b-b24a-9a1a9f7442d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 959d2b6e-36a2-4f2d-80d2-da4d3b93db2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50b66a72-1d59-4424-bb41-0792c05b948c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e267e42c-d255-4882-9238-4ebc846260d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6925b35c-be43-4c79-bb84-31626d1ae5f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9015480-53bd-4666-9384-af0c520fab33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5a39b9e-2ddc-4266-81ff-2eebe1cb01cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 749d2d37-5605-49e0-94da-4ae2ff2f06cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ddd9bbc0-f882-4c46-a27c-ff3ecd3961a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f2755ed-f6af-4ed6-88f2-fd6e0e2c5e6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 871e6977-3cc2-408c-8469-6e727cf31967
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45928565-d917-48b2-9877-affb575b7b51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3ecd593-b0c9-4002-93a7-50d86c150f8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08fa43eb-b072-4e9d-973c-678a35735667
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff86894b-3a74-443a-866d-994e9bb55531
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24bd0dd8-2db3-4b17-bc82-6202893e546a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a64912cf-3967-4560-b9be-ae62f1f76a08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2db928c-e559-4f8c-b49c-b4092e527c61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60b5d74b-8654-46a5-b280-64587966134e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b753112-a8c1-4704-9d0f-eaa371ef6fef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79c7cb7a-a316-440d-91c5-957329f397ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 040e1e00-62a2-458c-8cbc-356abf53b20e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1489e088-4c7a-4ed5-903f-3e1c5d6babb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec776300-2537-47f1-8792-75cc04e4550d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f08a540-790f-49b5-b2dd-70ac71dc6f4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5a5abcb-f817-4817-b4a6-7aa2eecaf1cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1997f49-e597-495c-a48c-20892d6d9f72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4ff15ef-0458-4a0f-a8d9-d78accc509dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93955e68-6426-4da8-9b84-98e1ebd28134
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 568c8f5a-3573-43f4-8168-9cda4e2797d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39910a19-a05f-4ffe-896a-79d399cf166f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 095f8db3-ba43-43e3-aa3f-6b222833e98c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2cb2299-297d-4ced-9c5f-bb62890d2312
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed589f36-55d9-4280-9cd2-0ab50d3c8a1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27511a05-3403-4d99-8708-15ef796249f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73b4da18-5ec6-4f3a-b76e-5c99abb1c42e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15d752f8-6c13-4b3e-9dc2-c5ceffd20ec3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c2a0431-aa6e-43c2-8138-fd1e8492ead9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba5e4db0-a6bc-4e43-9eb4-fa4a58148794
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db6eb014-f0c2-4295-aa2e-aa83575c8183
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b35ec46-459e-4fb2-b6b9-d965f1323970
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46703af3-6a9a-4cfc-84e1-0407e4242935
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91426b27-5456-4cc1-ae6f-7ac02990d3dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66fc7946-d1ab-41e5-821d-bdfb08134b13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f1727ee-21a6-4658-bd1e-22dd6202dfd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d97b697-73cb-4abf-9058-84b0a0e012b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc66d55b-97dc-4418-9fd3-2949f785a938
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 676cc8c7-7f71-4a37-bafe-9ddadaa3f31c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f94b284a-a878-4ef7-ac99-461e12cba938
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 180b367c-173b-4e41-954f-44872b136f78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8f7ffb1-40f9-4fc6-9b4b-5521ba48b866
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10cc5ab6-9ac6-4c15-9e69-fa248bcbaad8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c8b985a-4a62-4b52-81c4-4fc95adf4bb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e83e47b4-3048-49c0-9d5e-31dc99437f3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0f54941-a258-408e-b263-3c7341947654
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 192e50a9-5f7e-44d6-8d1b-7883447be221
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c03f1c69-9d37-4821-bd6f-d664d4f6ed34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75b23382-36d5-4a19-9c72-7d74be21b1c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 971d9955-7203-4826-9b7a-9738e0f8929c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cff7b16c-32ad-4adc-a543-103931f23275
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0df4253a-6094-49fe-a177-ff1a2959fea8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b917b5ec-d0c5-4fcd-82e0-91bec2e5f9af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c964fa27-35cc-4384-ab7d-38be5168438c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14586494-1e0d-49c9-b8cf-829cb0508bb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 806629f1-f3b7-419e-9c6b-4520049a0048
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61ac5f30-6c25-454f-86c0-9b478e9c1eca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ae04fda-c257-4d4a-bbee-cbb1b322af1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4896bff2-86d6-4f0e-b382-7a7339b5d999
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 964688a8-3c92-4d62-847b-616b4ab34592
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 175206c7-1dea-4e4d-a8a0-03a45be57821
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dcff9da4-c5de-408c-bd39-4db624d836d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4a5e4ee-1741-456b-b66a-7974e2735258
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d46303f2-95d3-46c6-8f90-b7a231c52918
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6331db41-5afc-451b-aec6-4659b0a1421a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65a5ef33-7072-4f63-9f9c-1b03241d9671
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15249561-d917-405b-8321-9fb49fae942e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89b7eda3-0803-414b-8a82-b1bb8f4117ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1bf8a2d4-eeb2-479e-a2d1-44371d884c63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e645ca68-f4f7-4385-92e4-eb960c721827
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5dd5d6b4-5a1b-4cb7-a646-4e35c159385e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb34e2fd-2b9e-46f2-a834-886dc39ce218
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6761bce7-7d06-4fa1-8557-a8f276eb7117
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9b5d6b0-af3d-4a02-b968-c8a3b9e47437
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f2dedbd-e9b7-4daf-8f29-3ad50b003666
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67ae7658-51f6-41ff-81ca-4bf5e491c282
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d65993f-ecc1-44fd-a993-eaa74b203ef0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b82bee88-99e4-4d5b-aa07-b45dbbd522ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59f6ad48-a283-42e9-bc9a-6192c1726395
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 732f4ff1-d045-4db5-9949-f613f8928df1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50a4a9a5-36c7-472c-90d9-ff8f7ea47f4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e25362b4-83fa-4756-b38c-a365e110adf6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59f2df0e-83ac-42a0-a7b3-1e4d3a6562ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4dc980b6-94d6-4c02-bccb-98cb36dcee04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ecc43ad-a123-499b-a07a-cdddb5e1f50b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dbef0a32-1220-4117-b2bd-3e97d3db3de5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 734075af-0e84-4c08-9be8-68d2a27fcc54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9d67ad2-e0ac-4f8c-9742-1c9f9d6a933e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2dee97ab-e504-4974-9f45-ce077db62a8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36649ab7-3d93-450e-876b-a6758e9fb008
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b676ba0-0f92-4d94-9bd4-ee9d5abff9b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d234d2f-f625-4fcc-8549-34353910c020
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 311e4ff4-6d56-4108-bff6-2b00a91d9ea4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2c914ea-8c23-4ba7-b46c-9c04fbd36657
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60c30d65-925b-4276-8b06-788cd7f6af51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ef702d2-1325-4da5-84fa-fb524fe5a764
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa37e9f9-5ea1-4846-a5ce-dc3f0f8a709a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c78f9f7e-de96-469b-91a1-8dedb876cfe1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 218cda70-eb37-4526-a4a7-607fc68ad50f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 308e8779-feaa-4cd6-bdc2-88bd148ddc46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6c9640e-631c-4ced-a250-3b5f5f351e09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 054866ab-7b18-44a6-b352-acf06847e199
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00b3b4c0-dc08-4d8c-8f35-bec0b1ce4499
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c472d90f-432c-48e5-91aa-215e915673b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message faa3b6c7-581a-4a56-9745-24dcc97c76fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97ee37e5-2595-437c-a286-55cfcc97ccfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49c53c9c-5ffe-4d14-9bb8-29b73c23c7fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88718666-fda2-41ca-8dde-4c96dd0800a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2013c8bb-495d-4a77-8b06-055c24dcb1d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c53d444-1699-41c9-8060-bbe7485840fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9db0608a-0188-49c2-aa4e-9ff6b86e2479
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e27282dd-0dc5-4fb5-832a-faa7539f4241
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ab4c1bb-4ada-4e70-8e6f-576ba8da5a43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d950542f-8468-4c95-aca5-45e9c51011d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 063256fe-ab19-44b4-a878-a9f3c00f5014
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2c54467-7176-4efd-9b7f-4b7e5e0239a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d75c05a-682f-4211-afb4-661d081d9c86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a7cfa7a-f207-4579-89c7-76d2b3db3e9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 179b14f0-010f-44bf-a54e-3b427130974c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3bfa0064-102e-493a-a63c-47389cf0b710
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 066b6962-681d-4ca3-bb54-b2d68cf5551b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02ac7f7d-ff24-4339-a69a-f1c1fd8d8ee1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64928be6-57c4-45e5-8f8c-3fc7cc2f1c8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ee26354-eb64-460e-8baa-f0a39ea0adf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 192fef4c-534f-4f5f-a9a6-02456a2c707f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e35f5be7-d2a7-4f30-aa7f-8f3a2ee1de9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf9c9c4b-486e-41cc-8ab8-abd35544623d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6375ee8e-cf9c-4b3f-a6ed-2975e958c19c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c212c84f-322d-4cac-9578-77d5bb71a244
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b67db0a-9113-4d49-bdff-b3f59c6dc604
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97ec0559-8f3a-406a-ba43-e3d39658910b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31b865ed-a198-4470-ad1a-53ff3845a699
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 839ee168-c01a-44d7-a01c-6d17161ea760
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f22a8bf3-309f-4967-ae93-42c7db8856b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 004ba454-eee1-41f8-afe1-cfde07a66c63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd4337d1-2f09-487c-89d8-fab8a7fab85a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1cd09315-592e-444e-881b-1bcd7202d1d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4184fee4-67b8-4fd6-9d63-40592347d872
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29a92419-b794-4300-905e-39d7e26bace1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 563c9a4b-aae8-471b-a62e-a8473a00911d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 657f1405-65b0-4dc8-bf21-f8a98c0cc244
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3bdcae26-3096-42f4-94f2-f5310f29df3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85e73bde-4df6-4db0-82b1-7f04f4469d81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1689603d-a378-4f49-a7c7-698da0831f3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3feed54-0ca4-48a4-b33c-892a6f97b507
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b00c42c-bd73-4365-96bb-f0816d1177fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cdc722f0-8968-450a-80b2-cd6b1402c6d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec7b34ae-6182-4c56-ad65-9229c40d8011
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5255cde3-5583-4dbb-8723-21e4c9670062
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 689ddcab-26be-4d99-b89e-fff7f0de3ff9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74a50e8a-fe01-40ed-8feb-473dc8b9768f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4417c76-dfbc-4b0b-8195-c8d69f5cf36d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9620fc2e-2508-41e7-a192-792134429ffe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 447705fa-42c1-4b5f-b4a3-3b104f2d737f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1b57b2d-6456-4feb-bb5f-53787cf821dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ebda03e-c1f8-437b-be23-0e600e331419
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8e789e9-d990-4783-b571-2ac93343e1bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfc9f979-188e-43dc-9723-be0d92821be7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b41d4882-489e-4257-b9ba-65ef4259c212
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8fc84da0-d2c4-4d62-b819-e1943a2c426b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd2bc52d-e0a7-49b4-9643-fc989e75467e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d10c3034-9f1a-4afe-9dcd-1d04ea1a00a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b8f9617-c4b9-4210-b174-71c466bbb20c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0ce05c6-afd2-4061-b014-b55d26c12efe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b99631a-d2be-439e-bea9-66c3f930f403
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bdcd5808-af05-434a-b83f-1320de3c448d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 248837f8-0a20-4e79-a846-58f9001c9830
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e83f205-bc0d-4379-b5ca-590ca19ec7d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 621b4704-64ee-4ad4-81bc-675e0c5d916e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73a55364-105e-4641-a95a-7aa3afdb2c8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4b63d52-06a3-4a1b-80ba-e16a25aeeae9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25763017-4c09-4a34-a497-8c1e7934c64a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08cdb7a8-05dc-412f-b496-bf29c234325f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a4848f5-4aaa-48f3-8241-5a8cc482921e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db3ec16a-0f4e-4b54-b05b-e72960b5c719
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ad3f93f-3dcb-4595-b0e9-248d12435f28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df781dd7-3e8a-4400-a632-02172fd655f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message adbf5706-bb43-4e6f-9715-b8af13b860e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f7e1b98-2ace-4979-9666-16545809b20f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c612bceb-e299-4895-b289-1914eeae2bd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1a8e6c1-0a0a-42cd-a325-ff4e44e77463
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2d9f780-6dc9-4c10-b286-48f6b37b1b1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bfb255f8-0908-48b0-aabd-d21c286b3f6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 063d0cc6-f3c7-42e8-893f-ad90c321bccd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b6d541e-aad3-4ded-97f7-0b32b418b85b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f32cf9ca-8e3f-4dd5-bc00-6e05592d3e12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce3e38db-2faa-4c75-8a6d-37ed0907d6ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b97139df-b3ba-41b9-aed2-223831ac5148
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9e8655b-a0e5-4f2a-8622-1eff811ddccc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1fa19ff1-a209-4564-80b9-bb6127759409
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1274ab9-76fa-4028-8a1a-66bc58b4cae2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5977a9d4-538a-4d52-9792-964cca84611b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f155edf3-3577-43c2-932d-11c5d68ddbaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 808a16c7-2431-4651-aa31-25c3b6db9c47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a927798-ff77-442a-83ac-e760b7a9892c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58b0073d-6af8-4b3f-8292-3206a2c86b53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8ff6b1b-896d-4ce0-aede-c8ed9583a687
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 967a51b3-4b20-4015-9596-fc0352077efd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 326030f7-8bbb-4182-96f0-be7ca65481e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2c1f67b-95fe-4c28-ae49-f5fa96a14e72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f2079c3-a6c7-4b9b-8dc7-e09054f0d083
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0e326a3-3516-406e-9844-c2a018e67d5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87195f69-d17f-4bbf-919e-35ffa32915d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62185a6a-99ae-431b-ae63-8749a51b9bb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc6cb6fc-f110-4049-a55c-95fc886d2338
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3ed8345-5060-45c7-9967-1598849b697e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08f02e28-b5fc-4bd2-8007-f368bc066f9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0fece0e1-51bd-4c9f-8149-851093dcf214
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c45a35db-476a-45df-bd2e-934b8f5642ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4779c6c-ba5a-4df3-ae70-549834b9dcee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a08005c7-e3e4-4425-9a60-4130510fec3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b483e46-8f79-4138-b0ed-c4d5cbb0c897
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28d98983-20ab-47f3-b3dd-4716834f5623
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9642840-94ad-47ff-b78a-5737f0ff79a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 690d05a2-a191-4f8b-a635-2f98844e67c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 006ba70c-f7ac-486b-ad2c-8e8992c6ca07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8afaa2c-801b-455d-a02b-172d887d3b16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a68d78c-1f3c-4e14-ae24-a8b9baec9daf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c4e16a0-d377-4eda-8b23-872a0f8c4b5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6989abc-c809-4b69-808e-43f547f766e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4014003b-bcec-4402-9109-911fb0613729
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aeaa8a15-08de-46ec-b8e3-08eaf55cb747
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 753c9bad-8c8e-41e4-8541-345a2de8b84a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53034611-0fcd-43e1-a6e7-7c1b3921530c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c9ff6ff-3fab-44a0-b295-c794f31981fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d5a68e3-5d8e-4d0e-8eb5-8e0fe1e3ca88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99c94648-5625-440d-8163-153be7dbfe7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c37f3c8-3545-49c3-a01f-29cf9f4ed7a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb578b61-1363-4dea-90e9-b27f2361e23a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f0473d1-35fe-448d-bca9-38ca9320fa94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 990cd1ae-ae93-4672-bd84-0651ee9835cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db2200c6-e5b5-41eb-b4eb-afb4197c3bdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5be52f23-5d07-40a8-b887-0006b9a01a32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4aa844ce-778f-41f2-9eeb-6265ec1d20d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8556eaf6-b4c7-43e6-ba8e-4067a34050da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46f86e93-c0e5-465d-ac4c-e015b55a4b26
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8690 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_10
Server: localhost:8690
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_10
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_10/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_10/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_10/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_10/test_labels.txt

📊 Raw data loaded:
   Train: X=(4872, 24), y=(4872,)
   Test:  X=(1218, 24), y=(1218,)

⚠️  Limiting training data: 4872 → 800 samples
⚠️  Limiting test data: 1218 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_10 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 1 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.3108, val=0.1121 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0946, val=0.0801 (↓), lr=0.001000
   ✓ Epoch   3/100: train=0.0830, val=0.0776 (↓), lr=0.001000
   • Epoch   4/100: train=0.0828, val=0.0772, patience=1/15, lr=0.001000
   ✓ Epoch   5/100: train=0.0826, val=0.0770 (↓), lr=0.001000
   📉 Epoch 11: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0822, val=0.0777, patience=6/15, lr=0.000500
   📉 Epoch 19: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 1 Summary - Client client_10
   Epochs: 20/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0015
   Val:   Loss=0.0770, RMSE=0.2775, R²=-0.0119
============================================================


📊 Round 1 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2510, R²: -0.0109

📊 Round 1 Test Metrics:
   Loss: 0.0844, RMSE: 0.2905, MAE: 0.2500, R²: -0.0067

============================================================
🔄 Round 4 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0813 (↓), lr=0.000250
   • Epoch   2/100: train=0.0811, val=0.0829, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0810, val=0.0821, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0808, val=0.0824, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0808, val=0.0826, patience=4/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0805, val=0.0828, patience=10/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 4 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=-0.0004
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0684
============================================================


📊 Round 4 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0019

============================================================
🔄 Round 7 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0849 (↓), lr=0.000063
   • Epoch   2/100: train=0.0798, val=0.0851, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0797, val=0.0853, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0797, val=0.0854, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0796, val=0.0855, patience=4/15, lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0795, val=0.0860, patience=10/15, lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 7 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0018
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0042
============================================================


============================================================
🔄 Round 8 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0683 (↓), lr=0.000016
   • Epoch   2/100: train=0.0842, val=0.0683, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0841, val=0.0684, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0841, val=0.0684, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0841, val=0.0685, patience=4/15, lr=0.000016
   📉 Epoch 7: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0840, val=0.0686, patience=10/15, lr=0.000008
   📉 Epoch 15: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0683)

============================================================
📊 Round 8 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0018
   Val:   Loss=0.0683, RMSE=0.2613, R²=0.0060
============================================================


============================================================
🔄 Round 9 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0912 (↓), lr=0.000004
   • Epoch   2/100: train=0.0783, val=0.0912, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0783, val=0.0912, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0783, val=0.0913, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0783, val=0.0913, patience=4/15, lr=0.000004
   📉 Epoch 7: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0783, val=0.0913, patience=10/15, lr=0.000002
   📉 Epoch 15: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 9 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0016
   Val:   Loss=0.0912, RMSE=0.3020, R²=-0.0063
============================================================


============================================================
🔄 Round 10 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 10 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0013
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0024
============================================================


📊 Round 10 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0019

📊 Round 10 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2494, R²: -0.0013

============================================================
🔄 Round 13 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 13 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0001
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0029
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.0841, RMSE: 0.2899, MAE: 0.2497, R²: -0.0029

============================================================
🔄 Round 14 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 14 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0005
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0085
============================================================


============================================================
🔄 Round 15 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 15 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0013
   Val:   Loss=0.0842, RMSE=0.2901, R²=-0.0083
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2496, R²: -0.0025

📊 Round 15 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0022

📊 Round 15 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0020

📊 Round 15 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0020

📊 Round 15 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0020

============================================================
🔄 Round 22 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 22 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=-0.0012
   Val:   Loss=0.0790, RMSE=0.2811, R²=0.0061
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0020

============================================================
🔄 Round 24 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 24 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0010
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0006
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0020

============================================================
🔄 Round 26 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 26 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0022
   Val:   Loss=0.0754, RMSE=0.2747, R²=0.0049
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0020

📊 Round 26 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0020

============================================================
🔄 Round 28 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 28 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0013
   Val:   Loss=0.0802, RMSE=0.2833, R²=-0.0095
============================================================


============================================================
🔄 Round 30 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 30 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0008
   Val:   Loss=0.0912, RMSE=0.3020, R²=-0.0050
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0019

============================================================
🔄 Round 32 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 32 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0013
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0018
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0019

============================================================
🔄 Round 33 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 33 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0004
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0054
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0019

============================================================
🔄 Round 34 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 34 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0008
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0032
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0019

============================================================
🔄 Round 35 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 35 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0008
   Val:   Loss=0.0780, RMSE=0.2792, R²=-0.0049
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0019

============================================================
🔄 Round 36 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0691 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0691, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0691, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0691, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0691, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0691, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0691)

============================================================
📊 Round 36 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0020
   Val:   Loss=0.0691, RMSE=0.2629, R²=-0.0091
============================================================


============================================================
🔄 Round 37 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 37 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0012
   Val:   Loss=0.0737, RMSE=0.2715, R²=-0.0040
============================================================


============================================================
🔄 Round 38 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0699 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0699, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0699, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0699, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0699, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0699, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0699)

============================================================
📊 Round 38 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=0.0019
   Val:   Loss=0.0699, RMSE=0.2644, R²=-0.0108
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0018

============================================================
🔄 Round 40 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 40 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0005
   Val:   Loss=0.0806, RMSE=0.2840, R²=-0.0056
============================================================


============================================================
🔄 Round 41 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 41 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0007
   Val:   Loss=0.0760, RMSE=0.2756, R²=-0.0041
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0019

📊 Round 41 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0018

📊 Round 41 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0019

============================================================
🔄 Round 45 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 45 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0011
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0009
============================================================


============================================================
🔄 Round 46 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 46 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0022
   Val:   Loss=0.0747, RMSE=0.2734, R²=-0.0410
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0019

📊 Round 46 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0019

============================================================
🔄 Round 50 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 50 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0010
   Val:   Loss=0.0800, RMSE=0.2829, R²=-0.0021
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0019

============================================================
🔄 Round 51 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 51 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0011
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0041
============================================================


============================================================
🔄 Round 52 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0725, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 52 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0005
   Val:   Loss=0.0725, RMSE=0.2692, R²=-0.0209
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0019

============================================================
🔄 Round 57 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 57 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0025
   Val:   Loss=0.0897, RMSE=0.2996, R²=-0.0085
============================================================


============================================================
🔄 Round 59 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 59 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0009
   Val:   Loss=0.0807, RMSE=0.2840, R²=-0.0053
============================================================


============================================================
🔄 Round 60 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 60 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2822, R²=0.0015
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0072
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0019

📊 Round 60 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0019

============================================================
🔄 Round 62 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 62 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=-0.0008
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0052
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0019

============================================================
🔄 Round 64 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 64 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0031
   Val:   Loss=0.0773, RMSE=0.2781, R²=-0.0362
============================================================


============================================================
🔄 Round 65 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 65 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0017
   Val:   Loss=0.0756, RMSE=0.2750, R²=-0.0064
============================================================


============================================================
🔄 Round 66 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 66 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0004
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0024
============================================================


============================================================
🔄 Round 68 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 68 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0024
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0056
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0018

============================================================
🔄 Round 69 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 69 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0023
   Val:   Loss=0.0761, RMSE=0.2758, R²=-0.0089
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0018

📊 Round 69 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0019

============================================================
🔄 Round 76 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 76 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0007
   Val:   Loss=0.0842, RMSE=0.2901, R²=0.0001
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0019

============================================================
🔄 Round 77 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 77 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0009
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0099
============================================================


============================================================
🔄 Round 78 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 78 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0002
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0013
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0018

📊 Round 78 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0019

📊 Round 78 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0019

============================================================
🔄 Round 84 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 84 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0026
   Val:   Loss=0.0801, RMSE=0.2831, R²=0.0023
============================================================


============================================================
🔄 Round 85 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 85 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0013
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0021
============================================================


============================================================
🔄 Round 88 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 88 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0020
   Val:   Loss=0.0750, RMSE=0.2738, R²=-0.0047
============================================================


============================================================
🔄 Round 91 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 91 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0005
   Val:   Loss=0.0888, RMSE=0.2979, R²=-0.0066
============================================================


============================================================
🔄 Round 93 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 93 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0002
   Val:   Loss=0.0860, RMSE=0.2933, R²=0.0035
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0019

📊 Round 93 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0019

============================================================
🔄 Round 97 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 97 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0023
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0294
============================================================


============================================================
🔄 Round 100 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 100 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0020
   Val:   Loss=0.0826, RMSE=0.2873, R²=-0.0241
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0018

============================================================
🔄 Round 103 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0937 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0937, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0937, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0937, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0937, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0937, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0937)

============================================================
📊 Round 103 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0029
   Val:   Loss=0.0937, RMSE=0.3060, R²=-0.0087
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0018

============================================================
🔄 Round 105 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 105 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0010
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0148
============================================================


============================================================
🔄 Round 106 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 106 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0005
   Val:   Loss=0.0873, RMSE=0.2954, R²=0.0005
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0019

============================================================
🔄 Round 108 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 108 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0002
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0009
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0018

📊 Round 108 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0018

📊 Round 108 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0018

============================================================
🔄 Round 112 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 112 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0019
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0036
============================================================


============================================================
🔄 Round 114 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0705 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0705, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0705, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0705, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0705, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0706, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0705)

============================================================
📊 Round 114 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0011
   Val:   Loss=0.0705, RMSE=0.2655, R²=-0.0263
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0017

📊 Round 114 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0017

============================================================
🔄 Round 118 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 118 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0004
   Val:   Loss=0.0764, RMSE=0.2764, R²=-0.0094
============================================================


============================================================
🔄 Round 119 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 119 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0004
   Val:   Loss=0.0756, RMSE=0.2749, R²=0.0020
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0017

============================================================
🔄 Round 121 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 121 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0028
   Val:   Loss=0.0780, RMSE=0.2792, R²=-0.0306
============================================================


============================================================
🔄 Round 122 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0708 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0708, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0708, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0708, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0708, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0708, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0708)

============================================================
📊 Round 122 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0008
   Val:   Loss=0.0708, RMSE=0.2660, R²=-0.0062
============================================================


============================================================
🔄 Round 126 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 126 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0006
   Val:   Loss=0.0790, RMSE=0.2810, R²=-0.0234
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0017

📊 Round 126 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0017

📊 Round 126 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0017

📊 Round 126 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0018

📊 Round 126 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0018

📊 Round 126 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0018

============================================================
🔄 Round 135 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 135 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2826, R²=0.0009
   Val:   Loss=0.0855, RMSE=0.2923, R²=-0.0037
============================================================


============================================================
🔄 Round 137 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 137 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0009
   Val:   Loss=0.0844, RMSE=0.2906, R²=0.0030
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0019

============================================================
🔄 Round 140 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 140 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0019
   Val:   Loss=0.0750, RMSE=0.2739, R²=-0.0034
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0019

📊 Round 140 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0019

============================================================
🔄 Round 142 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 142 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=0.0011
   Val:   Loss=0.0778, RMSE=0.2789, R²=-0.0020
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0019

📊 Round 142 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0019

📊 Round 142 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0018

============================================================
🔄 Round 145 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 145 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0002
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0011
============================================================


============================================================
🔄 Round 147 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 147 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0021
   Val:   Loss=0.0763, RMSE=0.2763, R²=-0.0055
============================================================


============================================================
🔄 Round 148 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 148 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=0.0003
   Val:   Loss=0.0746, RMSE=0.2732, R²=0.0023
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0018

============================================================
🔄 Round 149 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 149 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0004
   Val:   Loss=0.0867, RMSE=0.2945, R²=0.0017
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0018

============================================================
🔄 Round 151 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 151 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0012
   Val:   Loss=0.0810, RMSE=0.2845, R²=-0.0015
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0018

============================================================
🔄 Round 152 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 152 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0022
   Val:   Loss=0.0787, RMSE=0.2806, R²=0.0131
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0018

📊 Round 152 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0017

============================================================
🔄 Round 156 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 156 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=0.0014
   Val:   Loss=0.0895, RMSE=0.2992, R²=-0.0018
============================================================


============================================================
🔄 Round 159 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 159 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0011
   Val:   Loss=0.0837, RMSE=0.2894, R²=-0.0494
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0017

============================================================
🔄 Round 160 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 160 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0032
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0119
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0017

📊 Round 160 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0017

📊 Round 160 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0017

📊 Round 160 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0017

📊 Round 160 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0017

============================================================
🔄 Round 171 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 171 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0013
   Val:   Loss=0.0766, RMSE=0.2768, R²=-0.0021
============================================================


============================================================
🔄 Round 174 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 174 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0015
   Val:   Loss=0.0764, RMSE=0.2764, R²=-0.0029
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0016

============================================================
🔄 Round 177 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 177 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=-0.0003
   Val:   Loss=0.0858, RMSE=0.2929, R²=0.0037
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0016

============================================================
🔄 Round 181 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 181 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0009
   Val:   Loss=0.0825, RMSE=0.2871, R²=-0.0024
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0017

📊 Round 181 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0017

============================================================
🔄 Round 189 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 189 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0020
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0053
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0018

============================================================
🔄 Round 192 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 192 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0013
   Val:   Loss=0.0863, RMSE=0.2937, R²=-0.0013
============================================================


============================================================
🔄 Round 193 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 193 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0006
   Val:   Loss=0.0848, RMSE=0.2912, R²=0.0007
============================================================


============================================================
🔄 Round 194 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0710 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0710, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0710, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0710, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0710, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0711, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0710)

============================================================
📊 Round 194 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0018
   Val:   Loss=0.0710, RMSE=0.2665, R²=0.0040
============================================================


============================================================
🔄 Round 195 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 195 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0006
   Val:   Loss=0.0764, RMSE=0.2763, R²=0.0061
============================================================


📊 Round 195 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0018

📊 Round 195 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0018

============================================================
🔄 Round 198 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 198 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0007
   Val:   Loss=0.0799, RMSE=0.2826, R²=-0.0284
============================================================


============================================================
🔄 Round 199 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 199 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=-0.0001
   Val:   Loss=0.0805, RMSE=0.2838, R²=-0.0103
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0018

============================================================
🔄 Round 200 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 200 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0027
   Val:   Loss=0.0788, RMSE=0.2806, R²=-0.0092
============================================================


📊 Round 200 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0018

📊 Round 200 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0018

============================================================
🔄 Round 205 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 205 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0014
   Val:   Loss=0.0859, RMSE=0.2932, R²=-0.0016
============================================================


============================================================
🔄 Round 208 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0715 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0715, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0715, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0715, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0715, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0715, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0715)

============================================================
📊 Round 208 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0002
   Val:   Loss=0.0715, RMSE=0.2675, R²=0.0048
============================================================


📊 Round 208 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0018

📊 Round 208 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0018

📊 Round 208 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0018

============================================================
🔄 Round 212 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 212 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0027
   Val:   Loss=0.0770, RMSE=0.2775, R²=-0.0303
============================================================


📊 Round 212 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0018

============================================================
🔄 Round 216 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 216 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0009
   Val:   Loss=0.0776, RMSE=0.2786, R²=0.0065
============================================================


📊 Round 216 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0018

📊 Round 216 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0018

============================================================
🔄 Round 221 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 221 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=-0.0002
   Val:   Loss=0.0874, RMSE=0.2957, R²=0.0041
============================================================


============================================================
🔄 Round 224 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 224 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=-0.0007
   Val:   Loss=0.0853, RMSE=0.2921, R²=0.0037
============================================================


============================================================
🔄 Round 225 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 225 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2801, R²=0.0000
   Val:   Loss=0.0911, RMSE=0.3019, R²=0.0031
============================================================


📊 Round 225 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0018

============================================================
🔄 Round 226 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 226 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0003
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0047
============================================================


📊 Round 226 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0017

📊 Round 226 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0018

============================================================
🔄 Round 231 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 231 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0009
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0047
============================================================


============================================================
🔄 Round 233 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 233 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0003
   Val:   Loss=0.0818, RMSE=0.2861, R²=0.0025
============================================================


============================================================
🔄 Round 234 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 234 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0021
   Val:   Loss=0.0765, RMSE=0.2766, R²=-0.0105
============================================================


============================================================
🔄 Round 235 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 235 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0017
   Val:   Loss=0.0780, RMSE=0.2794, R²=-0.0231
============================================================


============================================================
🔄 Round 236 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 236 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0009
   Val:   Loss=0.0818, RMSE=0.2861, R²=-0.0031
============================================================


============================================================
🔄 Round 237 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 237 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0014
   Val:   Loss=0.0785, RMSE=0.2801, R²=0.0075
============================================================


============================================================
🔄 Round 238 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0708 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0708, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0708, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0708, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0708, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0708, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0708)

============================================================
📊 Round 238 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0008
   Val:   Loss=0.0708, RMSE=0.2661, R²=-0.0007
============================================================


📊 Round 238 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0018

============================================================
🔄 Round 240 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 240 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0004
   Val:   Loss=0.0732, RMSE=0.2705, R²=-0.0063
============================================================


📊 Round 240 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0018

============================================================
🔄 Round 241 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 241 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2836, R²=0.0008
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0099
============================================================


📊 Round 241 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0019

============================================================
🔄 Round 242 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 242 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0018
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0106
============================================================


📊 Round 242 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0018

📊 Round 242 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0019

📊 Round 242 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0019

============================================================
🔄 Round 246 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 246 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0027
   Val:   Loss=0.0801, RMSE=0.2831, R²=-0.0078
============================================================


📊 Round 246 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0018

📊 Round 246 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0018

============================================================
🔄 Round 248 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 248 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0004
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0009
============================================================


📊 Round 248 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0018

📊 Round 248 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0018

📊 Round 248 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0019

📊 Round 248 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0018

📊 Round 248 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0018

============================================================
🔄 Round 261 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 261 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0004
   Val:   Loss=0.0879, RMSE=0.2966, R²=0.0018
============================================================


============================================================
🔄 Round 262 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0703 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0703, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0703, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0703, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0703, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0703, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0703)

============================================================
📊 Round 262 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0000
   Val:   Loss=0.0703, RMSE=0.2651, R²=0.0043
============================================================


📊 Round 262 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0017

📊 Round 262 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0017

============================================================
🔄 Round 265 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 265 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=0.0022
   Val:   Loss=0.0762, RMSE=0.2761, R²=-0.0080
============================================================


📊 Round 265 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0018

============================================================
🔄 Round 266 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 266 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0006
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0073
============================================================


📊 Round 266 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0018

📊 Round 266 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0018

============================================================
🔄 Round 270 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 270 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0004
   Val:   Loss=0.0775, RMSE=0.2785, R²=0.0035
============================================================


============================================================
🔄 Round 271 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 271 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=-0.0014
   Val:   Loss=0.0806, RMSE=0.2840, R²=0.0075
============================================================


📊 Round 271 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0018

============================================================
🔄 Round 274 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 274 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0018
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0072
============================================================


============================================================
🔄 Round 275 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 275 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=-0.0022
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0322
============================================================


============================================================
🔄 Round 276 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 276 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0012
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0017
============================================================


📊 Round 276 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0018

============================================================
🔄 Round 277 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 277 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0021
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0045
============================================================


============================================================
🔄 Round 278 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 278 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0012
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0055
============================================================


📊 Round 278 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0018

============================================================
🔄 Round 282 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 282 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0009
   Val:   Loss=0.0825, RMSE=0.2871, R²=0.0003
============================================================


📊 Round 282 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0018

📊 Round 282 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0018

📊 Round 282 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0018

============================================================
🔄 Round 287 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 287 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0013
   Val:   Loss=0.0748, RMSE=0.2736, R²=-0.0020
============================================================


============================================================
🔄 Round 288 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 288 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0002
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0078
============================================================


📊 Round 288 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0018

📊 Round 288 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0018

============================================================
🔄 Round 293 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 293 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0004
   Val:   Loss=0.0834, RMSE=0.2889, R²=-0.0063
============================================================


📊 Round 293 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0018

============================================================
🔄 Round 299 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 299 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0003
   Val:   Loss=0.0836, RMSE=0.2892, R²=0.0027
============================================================


============================================================
🔄 Round 300 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 300 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0013
   Val:   Loss=0.0752, RMSE=0.2742, R²=0.0031
============================================================


📊 Round 300 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0018

============================================================
🔄 Round 306 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 306 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0008
   Val:   Loss=0.0741, RMSE=0.2722, R²=-0.0044
============================================================


📊 Round 306 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0018

============================================================
🔄 Round 309 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 309 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0008
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0048
============================================================


============================================================
🔄 Round 310 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 310 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0011
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0155
============================================================


📊 Round 310 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0018

📊 Round 310 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0018

============================================================
🔄 Round 313 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 313 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0014
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0113
============================================================


📊 Round 313 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0018

============================================================
🔄 Round 315 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 315 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0020
   Val:   Loss=0.0829, RMSE=0.2880, R²=-0.0087
============================================================


============================================================
🔄 Round 320 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 320 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0014
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0020
============================================================


============================================================
🔄 Round 322 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 322 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0004
   Val:   Loss=0.0767, RMSE=0.2769, R²=-0.0380
============================================================


📊 Round 322 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0018

============================================================
🔄 Round 324 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 324 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0013
   Val:   Loss=0.0917, RMSE=0.3028, R²=-0.0102
============================================================


📊 Round 324 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0018

============================================================
🔄 Round 328 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 328 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0003
   Val:   Loss=0.0833, RMSE=0.2887, R²=0.0016
============================================================


📊 Round 328 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0018

============================================================
🔄 Round 330 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 330 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0021
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0053
============================================================


============================================================
🔄 Round 333 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 333 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0003
   Val:   Loss=0.0857, RMSE=0.2927, R²=0.0023
============================================================


📊 Round 333 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0018

============================================================
🔄 Round 334 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 334 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0007
   Val:   Loss=0.0777, RMSE=0.2787, R²=0.0070
============================================================


📊 Round 334 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0018

============================================================
🔄 Round 337 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 337 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0009
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0003
============================================================


============================================================
🔄 Round 338 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 338 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0004
   Val:   Loss=0.0852, RMSE=0.2919, R²=0.0035
============================================================


📊 Round 338 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0018

============================================================
🔄 Round 341 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 341 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0003
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0204
============================================================


📊 Round 341 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0018

============================================================
🔄 Round 346 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 346 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0003
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0094
============================================================


============================================================
🔄 Round 347 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0718, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 347 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0028
   Val:   Loss=0.0718, RMSE=0.2680, R²=-0.0157
============================================================


📊 Round 347 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0017

============================================================
🔄 Round 348 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 348 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0003
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.0021
============================================================


============================================================
🔄 Round 349 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 349 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2857, R²=0.0013
   Val:   Loss=0.0782, RMSE=0.2796, R²=-0.0076
============================================================


============================================================
🔄 Round 350 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 350 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=-0.0015
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0171
============================================================


============================================================
🔄 Round 351 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 351 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0007
   Val:   Loss=0.0738, RMSE=0.2716, R²=0.0052
============================================================


============================================================
🔄 Round 352 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 352 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2836, R²=0.0010
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0004
============================================================


============================================================
🔄 Round 353 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 353 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0015
   Val:   Loss=0.0887, RMSE=0.2979, R²=-0.0023
============================================================


📊 Round 353 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0017

📊 Round 353 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0017

📊 Round 353 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0017

============================================================
🔄 Round 356 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 356 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0000
   Val:   Loss=0.0795, RMSE=0.2819, R²=-0.0022
============================================================


============================================================
🔄 Round 357 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 357 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0003
   Val:   Loss=0.0860, RMSE=0.2932, R²=-0.0019
============================================================


============================================================
🔄 Round 358 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 358 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=0.0016
   Val:   Loss=0.0895, RMSE=0.2991, R²=-0.0069
============================================================


📊 Round 358 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0017

============================================================
🔄 Round 359 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0714 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0714, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0714, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0714, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0714, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0714, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0714)

============================================================
📊 Round 359 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0021
   Val:   Loss=0.0714, RMSE=0.2671, R²=-0.0072
============================================================


📊 Round 359 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0017

📊 Round 359 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0017

============================================================
🔄 Round 361 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 361 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0000
   Val:   Loss=0.0754, RMSE=0.2746, R²=-0.0076
============================================================


📊 Round 361 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0016

============================================================
🔄 Round 363 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 363 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0016
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0029
============================================================


📊 Round 363 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0016

============================================================
🔄 Round 365 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 365 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0001
   Val:   Loss=0.0806, RMSE=0.2838, R²=-0.0189
============================================================


============================================================
🔄 Round 366 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 366 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0011
   Val:   Loss=0.0723, RMSE=0.2690, R²=-0.0035
============================================================


📊 Round 366 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0016

============================================================
🔄 Round 368 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 368 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0003
   Val:   Loss=0.0723, RMSE=0.2689, R²=-0.0119
============================================================


📊 Round 368 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0016

📊 Round 368 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0016

============================================================
🔄 Round 373 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 373 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0008
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0012
============================================================


📊 Round 373 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0016

============================================================
🔄 Round 374 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 374 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0002
   Val:   Loss=0.0744, RMSE=0.2728, R²=0.0028
============================================================


============================================================
🔄 Round 375 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 375 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0006
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0018
============================================================


📊 Round 375 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0016

============================================================
🔄 Round 376 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 376 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0022
   Val:   Loss=0.0827, RMSE=0.2875, R²=-0.0045
============================================================


📊 Round 376 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0016

============================================================
🔄 Round 377 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0929 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0929, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0929, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0929, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0929, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0929, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 377 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0010
   Val:   Loss=0.0929, RMSE=0.3047, R²=-0.0010
============================================================


📊 Round 377 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0017

📊 Round 377 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0017

📊 Round 377 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0017

============================================================
🔄 Round 384 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 384 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0013
   Val:   Loss=0.0777, RMSE=0.2787, R²=-0.0060
============================================================


📊 Round 384 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0016

============================================================
🔄 Round 386 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 386 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0002
   Val:   Loss=0.0773, RMSE=0.2781, R²=0.0023
============================================================


============================================================
🔄 Round 387 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 387 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0005
   Val:   Loss=0.0779, RMSE=0.2792, R²=0.0023
============================================================


📊 Round 387 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0016

============================================================
🔄 Round 389 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 389 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0014
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0012
============================================================


📊 Round 389 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0016

📊 Round 389 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0016

📊 Round 389 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0017

============================================================
🔄 Round 394 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 394 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0014
   Val:   Loss=0.0844, RMSE=0.2906, R²=-0.0017
============================================================


📊 Round 394 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0016

📊 Round 394 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0016

📊 Round 394 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0017

============================================================
🔄 Round 402 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 402 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0012
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0305
============================================================


============================================================
🔄 Round 403 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 403 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0002
   Val:   Loss=0.0882, RMSE=0.2969, R²=0.0019
============================================================


📊 Round 403 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0017

📊 Round 403 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0017

============================================================
🔄 Round 405 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 405 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0004
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0028
============================================================


📊 Round 405 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0017

============================================================
🔄 Round 407 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 407 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0002
   Val:   Loss=0.0828, RMSE=0.2878, R²=0.0047
============================================================


📊 Round 407 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0017

============================================================
🔄 Round 410 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0958 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0958, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0958, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0958, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0958, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0958, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0958)

============================================================
📊 Round 410 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0016
   Val:   Loss=0.0958, RMSE=0.3094, R²=-0.0051
============================================================


📊 Round 410 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0017

============================================================
🔄 Round 412 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 412 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0014
   Val:   Loss=0.0852, RMSE=0.2918, R²=-0.0104
============================================================


📊 Round 412 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0017

📊 Round 412 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0018

📊 Round 412 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0018

============================================================
🔄 Round 415 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 415 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0002
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0068
============================================================


============================================================
🔄 Round 416 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 416 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0003
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0101
============================================================


============================================================
🔄 Round 418 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 418 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0014
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0045
============================================================


📊 Round 418 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0018

============================================================
🔄 Round 419 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 419 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0012
   Val:   Loss=0.0859, RMSE=0.2930, R²=-0.0034
============================================================


============================================================
🔄 Round 420 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 420 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0010
   Val:   Loss=0.0861, RMSE=0.2935, R²=-0.0057
============================================================


============================================================
🔄 Round 421 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 421 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0011
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0000
============================================================


📊 Round 421 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0018

📊 Round 421 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0018

📊 Round 421 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0018

============================================================
🔄 Round 428 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 428 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0005
   Val:   Loss=0.0849, RMSE=0.2915, R²=-0.0030
============================================================


============================================================
🔄 Round 429 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 429 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0012
   Val:   Loss=0.0732, RMSE=0.2705, R²=-0.0068
============================================================


📊 Round 429 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0019

📊 Round 429 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0019

============================================================
🔄 Round 433 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 433 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=-0.0028
   Val:   Loss=0.0889, RMSE=0.2982, R²=-0.0171
============================================================


============================================================
🔄 Round 434 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 434 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0004
   Val:   Loss=0.0828, RMSE=0.2877, R²=0.0020
============================================================


📊 Round 434 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0019

============================================================
🔄 Round 436 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 436 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=0.0010
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0044
============================================================


📊 Round 436 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0018

📊 Round 436 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0018

============================================================
🔄 Round 438 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0725, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 438 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0015
   Val:   Loss=0.0725, RMSE=0.2692, R²=-0.0053
============================================================


📊 Round 438 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0018

============================================================
🔄 Round 439 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 439 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0019
   Val:   Loss=0.0757, RMSE=0.2751, R²=-0.0039
============================================================


📊 Round 439 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0018

📊 Round 439 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0018

============================================================
🔄 Round 441 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 441 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0007
   Val:   Loss=0.0764, RMSE=0.2765, R²=0.0072
============================================================


📊 Round 441 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0018

📊 Round 441 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0018

============================================================
🔄 Round 445 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 445 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0003
   Val:   Loss=0.0882, RMSE=0.2969, R²=0.0027
============================================================


📊 Round 445 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0018

📊 Round 445 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0018

============================================================
🔄 Round 447 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 447 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0024
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0078
============================================================


============================================================
🔄 Round 448 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 448 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0000
   Val:   Loss=0.0776, RMSE=0.2785, R²=-0.0128
============================================================


📊 Round 448 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0017

📊 Round 448 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0018

============================================================
🔄 Round 450 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 450 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0010
   Val:   Loss=0.0807, RMSE=0.2842, R²=0.0001
============================================================


📊 Round 450 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0018

============================================================
🔄 Round 451 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 451 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0027
   Val:   Loss=0.0774, RMSE=0.2782, R²=-0.0069
============================================================


============================================================
🔄 Round 452 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 452 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0000
   Val:   Loss=0.0790, RMSE=0.2811, R²=0.0035
============================================================


📊 Round 452 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0018

============================================================
🔄 Round 453 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 453 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=0.0014
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0065
============================================================


📊 Round 453 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0018

📊 Round 453 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0018

============================================================
🔄 Round 456 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 456 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0005
   Val:   Loss=0.0735, RMSE=0.2711, R²=-0.0030
============================================================


============================================================
🔄 Round 457 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 457 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0018
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0141
============================================================


============================================================
🔄 Round 458 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 458 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0011
   Val:   Loss=0.0834, RMSE=0.2887, R²=-0.0003
============================================================


📊 Round 458 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0018

📊 Round 458 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0018

============================================================
🔄 Round 461 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 461 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=-0.0024
   Val:   Loss=0.0905, RMSE=0.3008, R²=-0.0002
============================================================


============================================================
🔄 Round 462 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 462 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0008
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0017
============================================================


📊 Round 462 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0017

============================================================
🔄 Round 464 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0722 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 464 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0022
   Val:   Loss=0.0722, RMSE=0.2688, R²=-0.0141
============================================================


============================================================
🔄 Round 465 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 465 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0005
   Val:   Loss=0.0837, RMSE=0.2894, R²=0.0016
============================================================


============================================================
🔄 Round 466 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 466 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0008
   Val:   Loss=0.0769, RMSE=0.2773, R²=-0.0047
============================================================


📊 Round 466 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0017

============================================================
🔄 Round 468 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 468 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0010
   Val:   Loss=0.0815, RMSE=0.2856, R²=-0.0027
============================================================


📊 Round 468 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0017

============================================================
🔄 Round 469 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 469 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=-0.0013
   Val:   Loss=0.0805, RMSE=0.2838, R²=0.0007
============================================================


============================================================
🔄 Round 470 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 470 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0020
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0133
============================================================


📊 Round 470 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0017

============================================================
🔄 Round 475 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 475 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0007
   Val:   Loss=0.0757, RMSE=0.2751, R²=0.0063
============================================================


📊 Round 475 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0016

============================================================
🔄 Round 476 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 476 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=-0.0007
   Val:   Loss=0.0912, RMSE=0.3021, R²=0.0048
============================================================


📊 Round 476 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0016

📊 Round 476 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0016

============================================================
🔄 Round 483 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 483 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0013
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0012
============================================================


============================================================
🔄 Round 484 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 484 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0006
   Val:   Loss=0.0782, RMSE=0.2796, R²=-0.0033
============================================================


📊 Round 484 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0017

============================================================
🔄 Round 485 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 485 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0001
   Val:   Loss=0.0779, RMSE=0.2792, R²=0.0042
============================================================


📊 Round 485 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0016

============================================================
🔄 Round 487 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 487 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0013
   Val:   Loss=0.0740, RMSE=0.2721, R²=-0.0011
============================================================


============================================================
🔄 Round 490 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 490 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0015
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0100
============================================================


📊 Round 490 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0017

============================================================
🔄 Round 491 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 491 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0011
   Val:   Loss=0.0840, RMSE=0.2899, R²=-0.0049
============================================================


============================================================
🔄 Round 492 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 492 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0020
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0096
============================================================


📊 Round 492 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0016

📊 Round 492 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0016

============================================================
🔄 Round 495 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0710 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0710, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0710, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0710, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0710, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0710, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0710)

============================================================
📊 Round 495 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0007
   Val:   Loss=0.0710, RMSE=0.2664, R²=0.0016
============================================================


📊 Round 495 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0017

📊 Round 495 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0017

📊 Round 495 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0017

============================================================
🔄 Round 499 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 499 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0016
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0025
============================================================


📊 Round 499 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0017

📊 Round 499 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0016

============================================================
🔄 Round 502 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 502 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0004
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0025
============================================================


============================================================
🔄 Round 503 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 503 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0008
   Val:   Loss=0.0744, RMSE=0.2728, R²=0.0015
============================================================


============================================================
🔄 Round 504 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 504 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0022
   Val:   Loss=0.0727, RMSE=0.2696, R²=-0.0052
============================================================


📊 Round 504 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0017

============================================================
🔄 Round 508 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 508 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0020
   Val:   Loss=0.0859, RMSE=0.2930, R²=-0.0054
============================================================


📊 Round 508 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0017

📊 Round 508 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0018

============================================================
🔄 Round 513 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 513 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0024
   Val:   Loss=0.0876, RMSE=0.2959, R²=-0.0090
============================================================


============================================================
🔄 Round 514 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0942 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0942, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0942, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0942, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0942, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0942, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0942)

============================================================
📊 Round 514 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=-0.0005
   Val:   Loss=0.0942, RMSE=0.3069, R²=-0.0000
============================================================


📊 Round 514 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0018

============================================================
🔄 Round 515 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 515 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0004
   Val:   Loss=0.0733, RMSE=0.2708, R²=0.0027
============================================================


============================================================
🔄 Round 516 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 516 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0020
   Val:   Loss=0.0789, RMSE=0.2809, R²=-0.0058
============================================================


📊 Round 516 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0018

============================================================
🔄 Round 518 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 518 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0003
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0069
============================================================


📊 Round 518 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0017

📊 Round 518 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0017

📊 Round 518 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0017

📊 Round 518 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0017

📊 Round 518 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0017

============================================================
🔄 Round 533 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 533 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0001
   Val:   Loss=0.0738, RMSE=0.2717, R²=0.0032
============================================================


📊 Round 533 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0017

============================================================
🔄 Round 535 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 535 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=0.0014
   Val:   Loss=0.0762, RMSE=0.2760, R²=-0.0014
============================================================


📊 Round 535 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0017

📊 Round 535 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0017

============================================================
🔄 Round 540 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 540 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0019
   Val:   Loss=0.0831, RMSE=0.2884, R²=-0.0119
============================================================


📊 Round 540 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0017

============================================================
🔄 Round 542 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 542 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0009
   Val:   Loss=0.0729, RMSE=0.2699, R²=-0.0016
============================================================


📊 Round 542 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0016

============================================================
🔄 Round 544 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 544 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=0.0011
   Val:   Loss=0.0729, RMSE=0.2701, R²=-0.0060
============================================================


📊 Round 544 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0016

📊 Round 544 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0016

📊 Round 544 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0017

============================================================
🔄 Round 554 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 554 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=-0.0021
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0108
============================================================


📊 Round 554 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0017

============================================================
🔄 Round 555 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 555 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0002
   Val:   Loss=0.0769, RMSE=0.2773, R²=0.0053
============================================================


📊 Round 555 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0017

📊 Round 555 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0017

============================================================
🔄 Round 558 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 558 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0014
   Val:   Loss=0.0789, RMSE=0.2808, R²=-0.0043
============================================================


============================================================
🔄 Round 559 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 559 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0012
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0060
============================================================


📊 Round 559 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0017

📊 Round 559 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0016

📊 Round 559 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0017

📊 Round 559 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0017

============================================================
🔄 Round 565 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 565 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0001
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0016
============================================================


📊 Round 565 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0016

============================================================
🔄 Round 566 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 566 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0006
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.0034
============================================================


📊 Round 566 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0017

============================================================
🔄 Round 567 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 567 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0017
   Val:   Loss=0.0724, RMSE=0.2691, R²=-0.0062
============================================================


📊 Round 567 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0017

📊 Round 567 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0017

============================================================
🔄 Round 569 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 569 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0003
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0016
============================================================


============================================================
🔄 Round 570 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0722 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 570 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2884, R²=0.0016
   Val:   Loss=0.0722, RMSE=0.2686, R²=-0.0021
============================================================


📊 Round 570 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0016

============================================================
🔄 Round 573 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 573 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0011
   Val:   Loss=0.0740, RMSE=0.2720, R²=-0.0119
============================================================


📊 Round 573 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0016

📊 Round 573 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0016

📊 Round 573 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0017

============================================================
🔄 Round 577 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 577 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2820, R²=-0.0002
   Val:   Loss=0.0866, RMSE=0.2943, R²=0.0039
============================================================


============================================================
🔄 Round 579 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 579 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=-0.0013
   Val:   Loss=0.0883, RMSE=0.2972, R²=-0.0050
============================================================


============================================================
🔄 Round 580 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 580 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0020
   Val:   Loss=0.0776, RMSE=0.2786, R²=-0.0062
============================================================


📊 Round 580 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0017

============================================================
🔄 Round 581 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0933 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0933, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0933, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0933, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0933, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0934, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0933)

============================================================
📊 Round 581 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0007
   Val:   Loss=0.0933, RMSE=0.3055, R²=-0.0154
============================================================


============================================================
🔄 Round 582 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 582 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0003
   Val:   Loss=0.0845, RMSE=0.2906, R²=0.0029
============================================================


📊 Round 582 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0017

📊 Round 582 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2496, R²: -0.0017

============================================================
🔄 Round 585 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 585 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0003
   Val:   Loss=0.0846, RMSE=0.2909, R²=0.0027
============================================================


============================================================
🔄 Round 586 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 586 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0013
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0116
============================================================


============================================================
🔄 Round 587 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 587 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0024
   Val:   Loss=0.0769, RMSE=0.2773, R²=-0.0056
============================================================


============================================================
🔄 Round 588 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 588 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0019
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0034
============================================================


📊 Round 588 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0016

============================================================
🔄 Round 590 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 590 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0004
   Val:   Loss=0.0833, RMSE=0.2887, R²=-0.0004
============================================================


📊 Round 590 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0016

============================================================
🔄 Round 592 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 592 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2826, R²=-0.0006
   Val:   Loss=0.0854, RMSE=0.2923, R²=0.0053
============================================================


============================================================
🔄 Round 593 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 593 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0003
   Val:   Loss=0.0774, RMSE=0.2781, R²=0.0001
============================================================


📊 Round 593 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0017

============================================================
🔄 Round 597 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 597 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0031
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0162
============================================================


📊 Round 597 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0016

📊 Round 597 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0016

📊 Round 597 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2495, R²: -0.0016

📊 Round 597 Test Metrics:
   Loss: 0.0840, RMSE: 0.2897, MAE: 0.2495, R²: -0.0016

============================================================
🔄 Round 602 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 602 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0001
   Val:   Loss=0.0800, RMSE=0.2829, R²=0.0042
============================================================


============================================================
🔄 Round 603 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 603 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0006
   Val:   Loss=0.0853, RMSE=0.2921, R²=0.0023
============================================================


📊 Round 603 Test Metrics:
   Loss: 0.0840, RMSE: 0.2897, MAE: 0.2495, R²: -0.0016

============================================================
🔄 Round 604 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 604 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0001
   Val:   Loss=0.0843, RMSE=0.2904, R²=0.0007
============================================================


============================================================
🔄 Round 606 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 606 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0017
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0029
============================================================


============================================================
🔄 Round 607 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 607 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0004
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0009
============================================================


📊 Round 607 Test Metrics:
   Loss: 0.0840, RMSE: 0.2897, MAE: 0.2495, R²: -0.0015

============================================================
🔄 Round 608 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 608 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0020
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0027
============================================================


📊 Round 608 Test Metrics:
   Loss: 0.0840, RMSE: 0.2897, MAE: 0.2495, R²: -0.0015

============================================================
🔄 Round 611 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 611 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0016
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0031
============================================================


============================================================
🔄 Round 612 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 612 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0021
   Val:   Loss=0.0863, RMSE=0.2937, R²=-0.0078
============================================================


📊 Round 612 Test Metrics:
   Loss: 0.0840, RMSE: 0.2897, MAE: 0.2495, R²: -0.0015

📊 Round 612 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2495, R²: -0.0015

📊 Round 612 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2495, R²: -0.0015

📊 Round 612 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2495, R²: -0.0014

============================================================
🔄 Round 619 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 619 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=0.0017
   Val:   Loss=0.0909, RMSE=0.3015, R²=-0.0033
============================================================


============================================================
🔄 Round 620 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 620 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=0.0021
   Val:   Loss=0.0758, RMSE=0.2754, R²=-0.0190
============================================================


📊 Round 620 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2495, R²: -0.0014

📊 Round 620 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2495, R²: -0.0014

============================================================
🔄 Round 623 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 623 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0006
   Val:   Loss=0.0728, RMSE=0.2699, R²=0.0064
============================================================


📊 Round 623 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2495, R²: -0.0013

============================================================
🔄 Round 626 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 626 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0017
   Val:   Loss=0.0768, RMSE=0.2771, R²=-0.0019
============================================================


============================================================
🔄 Round 627 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 627 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0005
   Val:   Loss=0.0891, RMSE=0.2985, R²=-0.0059
============================================================


📊 Round 627 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2495, R²: -0.0014

============================================================
🔄 Round 630 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 630 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2857, R²=0.0003
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0040
============================================================


📊 Round 630 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2495, R²: -0.0013

📊 Round 630 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2495, R²: -0.0013

📊 Round 630 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2495, R²: -0.0014

============================================================
🔄 Round 633 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 633 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0013
   Val:   Loss=0.0850, RMSE=0.2916, R²=0.0091
============================================================


📊 Round 633 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2495, R²: -0.0014

============================================================
🔄 Round 635 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 635 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0015
   Val:   Loss=0.0773, RMSE=0.2781, R²=-0.0020
============================================================


============================================================
🔄 Round 637 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 637 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0020
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0035
============================================================


📊 Round 637 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2495, R²: -0.0014

📊 Round 637 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2495, R²: -0.0014

============================================================
🔄 Round 642 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 642 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0010
   Val:   Loss=0.0791, RMSE=0.2813, R²=-0.0004
============================================================


============================================================
🔄 Round 643 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0709 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0709, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0709, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0709, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0709, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0710, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0709)

============================================================
📊 Round 643 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0009
   Val:   Loss=0.0709, RMSE=0.2663, R²=-0.0109
============================================================


📊 Round 643 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2495, R²: -0.0014

============================================================
🔄 Round 647 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 647 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0000
   Val:   Loss=0.0749, RMSE=0.2736, R²=0.0046
============================================================


📊 Round 647 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2495, R²: -0.0014

============================================================
🔄 Round 650 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 650 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0020
   Val:   Loss=0.0753, RMSE=0.2743, R²=-0.0165
============================================================


============================================================
🔄 Round 651 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 651 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0016
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0106
============================================================


============================================================
🔄 Round 652 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 652 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0002
   Val:   Loss=0.0821, RMSE=0.2866, R²=0.0042
============================================================


📊 Round 652 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2495, R²: -0.0014

============================================================
🔄 Round 656 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 656 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=-0.0014
   Val:   Loss=0.0865, RMSE=0.2940, R²=0.0037
============================================================


============================================================
🔄 Round 658 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 658 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0014
   Val:   Loss=0.0759, RMSE=0.2756, R²=-0.0172
============================================================


============================================================
🔄 Round 659 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 659 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0026
   Val:   Loss=0.0775, RMSE=0.2784, R²=-0.0075
============================================================


============================================================
🔄 Round 660 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 660 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0002
   Val:   Loss=0.0857, RMSE=0.2927, R²=0.0025
============================================================


📊 Round 660 Test Metrics:
   Loss: 0.0840, RMSE: 0.2897, MAE: 0.2495, R²: -0.0015

============================================================
🔄 Round 662 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 662 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0001
   Val:   Loss=0.0888, RMSE=0.2981, R²=0.0034
============================================================


📊 Round 662 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2495, R²: -0.0015

❌ Client client_10 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8690 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8690 {grpc_status:14, grpc_message:"Socket closed"}"
>
