[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14e56fbb-bdb9-40c2-bd42-02a043fcd3e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3c9d602-a5a5-44fe-b3b8-efd3816e5dec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28db23d3-a919-4563-9eef-7a3aaa5b3f8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a017d24-daa3-4b0b-bd34-c94756837210
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d0f7e18-929d-4986-9493-baef4e6526fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6c3fc41-4509-4ea2-addb-ca09a4b43faf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1fd32f3-8fda-484b-ab4a-393dedce675f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4441ab9b-541f-4c5f-9070-5b66b444da00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d61fb070-99ef-4b17-9723-4c90b589962a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac51fa9f-f413-48d7-aa67-b1109d02b479
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a4d099e-0020-475e-9aff-baec3a87aeac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8df5631b-0ef7-4169-b51b-2cec0c38252f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9be179c-ebf2-474a-aea6-789d8e42cf9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ffbcb319-0fbe-4dd6-a29b-c768ef1035eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6fb5c918-2f84-4b91-ba7a-062a1bc0c0ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ebd76af1-1b2b-4d6a-a713-6fffe1b9aef9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d7e4e00-ca44-4255-a7cc-a65b83ddbb6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48a7af0a-cf74-4109-a294-47f836437b70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d0c6661-81a4-4fb9-a603-4221c3b6f9f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bbf4eec2-6033-4d4c-97dd-32d090dc040a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 237bd255-0824-41d9-a942-b4847744e553
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d5fb842-cb6f-4934-ae51-093fc0a2788b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8c295fa-b594-4d04-b626-e69d3d1fea5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 092abbf2-acaa-42d8-8e64-5d44c9aa7224
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e59e43b9-7048-485e-832c-bd1c8cb383e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14985fc8-6bbe-462c-8a50-bfccc7121d24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 165ab9c1-174e-473d-9648-168dc42e386f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cdd97f6e-a3c1-4926-b58e-35432df741fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d31a7c89-8d5e-43ce-af92-6242a6c0a2d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55e00728-54b7-4ec0-9200-cc1521ca72c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b96af123-0536-437b-8a40-cb806ac58f6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 170e8bde-f172-4f07-b6bf-8d048a5cb20f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89a480ab-b86d-444d-9c4c-67be71c571b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25fb064a-4e19-43bd-8f05-1d2a3d7289fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8fe0270d-0c70-4d77-b67b-3da12cfb95e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 520aa0a4-9e21-4d2e-ba8f-87450dcfcf05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c89ba38f-741b-460c-9eaf-50ebc2231416
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74c85134-f4c6-4402-9428-4feed508e294
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3185e3f-3c49-4c4a-98fb-496da94e8bb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ea8e891-1f92-4c59-b390-84a7a95d5ead
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6689876-acdc-4829-8126-81bf19c0f323
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa2d0d79-642d-4303-b606-373f467b27a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4c98a0e-2d3f-412b-9350-4b47e722a63b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dbad982f-d58e-4ddc-8e32-2262abfd8773
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7f1a1a0-f826-4d31-9f8b-b6e3f1946993
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6b32ab2-4d8a-4092-9d2d-1eca19b99340
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42c4fb78-3e6d-4f8e-802b-6427845e7831
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe43522e-caba-48d9-821c-db3c0f811bca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb241156-e580-47d5-8036-89892d525fd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06930d9d-5572-4b60-8bd9-754a1903c09c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe91388f-f574-4207-b146-b2cfe369c74c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f32b652b-be36-4791-b68f-3f47a8fdb470
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1d41751-ec0f-45ca-bd3a-69b1b65f5a06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b481d3b-ba80-493c-8a56-32e22ff23399
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 656568b3-ff74-4fe0-9cf5-96ed997a9acf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d5507a0-82dd-4bd6-b9b0-29869c21abd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d16db0f-df86-40a7-9517-995c1dada694
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a67e0ae8-2a26-4525-b3f3-7481ad1155c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7af06dd4-cae9-43b9-ac6c-179b9eec58a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3e8bc73-1b0d-41cb-88e3-f5743a0f6e8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed78b86c-f91f-4f4b-bd32-dffc2d94502f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af1944d5-82a5-4c35-a7b7-20b888579ebe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c5f3eef-6fc6-40e6-bfbd-e0789e0c8e92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8fdede1c-28c0-495e-8eb1-6d426ecfd1e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3957e6c-11a1-405d-b7d6-0d35029dc652
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 197e6ac8-ddb0-4763-91e4-d9970aaedec6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02afdd76-afd7-4320-b6e1-183e9bfac412
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message faea19b5-301b-4a5a-b0d8-55d893e9b3a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ffa89cb-8646-4f45-aad6-dd3afd395052
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 469dd823-292c-4292-bd54-b1f10a2cae7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33d513fa-2928-4c64-bec7-684dfc90d096
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22d35d29-2d18-4962-9daf-9e6881b51dc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7446af87-6139-46f4-b02b-b344306dcb0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f503ed21-df26-48df-b651-d07b0d975b38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a65c7762-b84c-4fb6-9594-9408d595c21d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c2b3c42-95b9-47b1-8403-527dad29a725
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2dec7f25-14ee-4fe2-bd43-8b156c995d08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3724844-f5d4-40f6-8be8-74131cff0528
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ee46145-5d68-44fa-ae18-ebcf4c114228
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a216f8ab-1569-4138-8099-ec8d12ace03d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6307697-d44a-443c-b4df-f881e5badd2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c4d839d-2aa7-4f20-b985-d6414cf6e6d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b09816a-0353-442c-a416-bed3b2ea8d75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf08667d-18d3-46d0-a4f0-80d73be96644
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message acaf2ca4-65d0-4d96-926f-313fb99f791f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0738f5c-a9da-4cf3-a3a0-bff9c42a14d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5b9f27a-4e49-43ca-b37b-68cdeceea170
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2fbbad27-fd34-4e6f-96c5-85cb17b8e4eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9405f46d-8651-47e0-ad4f-bb80135214ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c19234d-31b8-42d1-bee2-8d10ab5fe2b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f53366f8-ddd5-4a43-98f3-bc7890272986
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03e27c80-5fe7-4976-addf-c0840fd4ad73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31925700-95ea-46fd-9e3b-7451b8bf7a6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e92d02a-f468-4da1-a204-8d235de65cb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e88bd0d-f8a7-418f-aaf7-d7eb18c024a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca48f790-9c21-4015-bfce-8ff1e015c673
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 425d7b87-f358-4964-b0c5-eccee890518e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5100a1ad-5cbb-4d74-a951-3771039c6c13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81f06286-0396-428c-bbd2-548ba94cb57c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40fe4ccd-04ef-4dfc-8622-935970af6375
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dfda3c93-e12f-4678-a084-4b0258488c1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9372fe29-f28f-44c3-97c0-852d7a521b3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25a8c958-af39-429e-8beb-ae55f5a1afc1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 845632ec-4d02-41a9-a682-a373c69ca5ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b76c5225-b478-41f7-8a39-f26b5e6a0fac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aea22e71-0792-4b3e-9432-2c2e19ead0a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dbd05e30-37e8-4734-b05b-23760335150f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f91a86a6-528d-4c95-a4ef-aab7192fbacf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d5f054a-8d7f-4483-82be-0ca95a3036f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f77dc050-1f6e-4ce4-8922-082ffd458990
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6f0cf4f-4c38-4dfd-960a-2f3181239f65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 611ea9a1-b78c-4377-9cfa-dc7e3e110a1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21dbd47d-eacb-4da4-b4c2-9403aa04b9b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb230127-b9b4-4876-b91a-21292901513f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31c84fea-0b00-46a7-9c8d-71c6321840a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc709aa0-e5a5-43de-945f-6360618501b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9bbc476e-3858-4660-895a-0419bc90fbb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83e1b6a4-1053-4748-ac49-92e3666bff1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3e08e6b-b85d-4364-9ea7-96328909f287
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6d92a76-6ec5-4a76-8a97-52002587ef64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92960bea-a5a5-4f15-a8f4-6ecfd8950f6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d555afde-c4f7-4a72-8105-147402721033
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8916cb87-3805-472f-b2ca-dd722ace2b0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf0e72bb-e310-41d3-835b-f033f10747a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39ae44dd-8c90-413c-b7cd-e6ae1ce36904
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31d8b1e7-733b-44d0-b00f-5c2e91ab60d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bff0d791-a77b-4116-b6a8-1e25006362ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3adcd625-2ed1-4008-9c3e-3c99c5432415
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b172e1e-4ce5-4645-895f-d797eaaa6d53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a82fb3e1-892e-4565-8775-b4c5e6e7845c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70b22732-7739-47bb-81d5-1e85f9bf6f2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a5adb80-8a65-4271-8014-05613ded04b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94819915-ca3b-4545-b29a-ce7882b858af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4adb51c6-a6cb-41e1-a289-413e221ed5fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 641865ed-efd4-4fc8-bcb5-fa23c8d9769c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83254d56-e971-4536-b851-baf83802dee0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a8615e2-e260-446b-bfd3-78ebff78f720
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3fc7970c-66c6-43cb-9cd1-d27051cc2f67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0feabcde-519c-4ead-9ee9-8e471bdd6d7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c7d0946-e4bd-48ab-b4f9-fade6171b400
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b890745-d1fd-45dd-9d42-1d8e6c4d2a20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1bcc28f4-2012-4061-8e7c-2fd4e7cde662
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab2338a8-6a65-43f9-a0cc-6b9efc13ee8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 249d58c5-b49c-4d63-8757-253f3fd6fa3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9596553-a292-4253-a116-a2206580884c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32f14d19-1701-47d5-aea2-3d1686916cc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd5d2101-4afa-4a4e-866e-e78fcc5563b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81eaca99-719e-41a0-8fd7-2c3b20a12590
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97aea281-ed8d-4433-ba70-81b8fc0eafd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e55d1ef-1421-4dd1-b418-63d97753ee5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e8745f9-ddfd-4398-be30-748da6af83f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df75d762-114a-4a8a-8735-39b9408ffee4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24723678-9882-489c-bd72-69052eb91b70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53390595-de6b-479a-a37c-795c1ef6d6c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2425908-fd84-494d-8c06-65a45df3317d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0071cbaf-af19-4fb1-9014-96d121cae1c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc7a2e8c-350c-4768-926a-0b7348397c90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 688a30ad-98ec-4852-afe9-3d5adc1d39a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28410d63-e68e-4db4-8569-582142238cfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5780759-d5e5-41b2-b429-a462a04347c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8640563-8433-42b0-b009-06eebb6eb434
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 464106c2-68d4-43fc-9ca1-6e41c07598ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3960941d-90c0-48ac-9246-fbd8795bbd51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02cdf276-7dbf-406c-a545-d82df0ed141a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 339242d1-5d4a-4a1a-ac03-98c8bdcbcc8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0759a5a-b883-4e2d-bddd-5aa140cf0f01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77516c40-9740-41e2-b9f6-182bd540e142
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68c1b733-9a82-4258-a8b0-56b996602302
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9dfc421-13fc-4731-8cd6-95dc9e642e2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20247374-324e-480d-92a9-8afda82f1df9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2764ce8b-7cfa-4ae8-ae5b-348b91ed0b39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc8b2198-794e-4876-a937-5b715340ffd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40081d26-1477-4ff5-83af-27da5cd460b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message acb72ea1-0297-46dc-9274-8c589964ec8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 346fd8f7-534f-44d5-b868-7afcb56950fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0278140f-d449-4362-9b06-01db7ad7624a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3f2c2e1-147a-4eec-a2d2-123ae03ff1bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1b9cd56-9027-4dca-af23-7a6986d46eeb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b7de8ab-af7b-4bce-86ca-c26717571bfc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e69f31a4-a04a-448f-99e3-f8db40afb18d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9340b72-357a-49a0-83c9-9b4d9962bdb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12d6f246-d911-4189-8db5-4b8587b2a1b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aee765ce-d0a3-4ebe-9031-1a6dfe025e7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6df2ffbf-cee8-4d16-89cc-5cd1494a07f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ecd330e1-22c1-4103-a233-d1916c11f6b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b3ae488-5a1d-4507-a587-496da659cfb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d65c5a98-91a7-4ea3-aa5d-15304c00a5b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 303c2e2a-e3a0-4c31-bc44-91a7bb8e72a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45f68dae-a225-43ed-9c30-bb078d0becde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5f2104f-3b23-48ff-bde6-355b730264cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee070365-158e-4e13-b3d4-5a3507947931
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message adc86ea2-2249-4a97-accb-89f999635085
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b029784-e3e4-47c6-a350-02a61b608397
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bac90cf1-533e-42ca-9595-0411c3599c22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44d31f4a-0e30-43ca-a616-6b57bafaf6bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb301736-c340-4356-b6b5-da1abbe34388
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f8bf504-7064-49fe-a94b-33c00599d614
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a7d4d7f-68f3-41e6-82b0-50b829232de0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 009c1e56-f215-4cd9-9f6c-3dec746fdf49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 414a9d79-49d6-4fce-9ab1-42d44048fcd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 430c4cab-3bbe-4dfd-9317-0b67405b0983
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d094fc43-df04-4a2a-b741-baecbe2c8974
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e001f481-fb13-4c68-b11e-84b29235422f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95d33076-1cdd-488f-8c6d-68aec055dc7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7178d05-8ecd-4730-8a9c-e20e93a16027
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08651237-f253-4688-b341-0e4023bb615f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55aac980-f481-48d5-b86f-41bdc3cd4c6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88b1fde0-c9e4-4a5e-82b3-ffc7a629509a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85aeabc4-7120-4d1c-8070-20f563dd2536
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62dd64ca-0cbd-439c-90d3-13764f1ff814
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1267bae-0af6-4d5d-a0f9-5e37e61793e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a2a2d7a-3a41-4861-84d1-55460e474e72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c40ef250-e7db-4282-97e6-20365aa716eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd558285-cfa0-4e60-84cb-ff438cc1f356
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7cb255b-07c5-46e8-9a63-e18fb78f432d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 489c5655-ce75-42c6-a7f4-181c5891f59e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79fbad9d-ae0b-4ea7-886c-52ae69f16020
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e877c636-3bf4-4b29-b04f-a927f34f9a07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77fc3df9-c267-491b-a3d5-be288141704d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09e65a9a-ca72-4a82-8bd7-ff3d166d6b77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e82e45d-fb26-4893-92ec-d7220c226453
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e87484dc-1611-4e9d-9195-37dcfd66c44b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 064d0f01-44c1-4f95-8880-895adc1719cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8e58182-06a0-4eed-a19c-2e98a7863ec9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 846bec97-e8d4-4f5d-98ef-f7647ec3b264
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 883c92b3-807d-4a8d-9bb2-ee8bcc94d1f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 032c27ea-5656-47b9-a85d-a51ceb69802a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce72ea80-c667-425d-ab4e-1ef2bf340df5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c43eafa5-4674-4d3c-a3ed-0d5ee7f5803c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba82e83a-fb8c-4e5c-8116-f2386f335f41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0268a0c-4caa-4a08-bdd2-521c6bd8fa62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42b5908f-44d5-4419-8bc7-2e422ded148f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc34bb9c-69b7-4604-9498-63ffd111cd29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ea85ad1-fd4e-4410-a2ea-4baa44ac079b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70c5b6b2-4ce1-4321-9766-8a5693caea4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfc34fc4-4ea8-4b6c-b64b-0624efeee756
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 040509bc-45eb-498c-81b4-cca78a2751f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a53f680d-05f1-4ac4-a7b2-6a288f542dab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9799bae0-24ca-4318-b800-76b007e7827b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a2740a7-8943-4daf-b3ad-53561ad8e23e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98d4fe1c-3b76-4df3-927b-cc0262e74483
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f59c230-b170-47dd-9d76-505975d75789
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4269a10-eeff-48be-ba04-fca68a257265
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7bcfcf9-db28-4792-aa5c-e50d111e7c87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5fc11cac-80dc-402a-8985-ffd31c2fa255
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 233d5a53-d144-43fd-a9e9-8bb5effa7841
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a44408cf-d812-4f13-b0c2-f66c1ff7d8d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec6298ff-e0fa-40a4-ab73-c15f9babc957
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3db6db1-a1d2-44a6-8b72-4b8025e5904b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 802e3f4c-fd89-40be-9fdd-8723324ee83c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89d556cd-5142-4227-9000-d1dc80690d66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90e893ad-a8d5-4226-9fb8-5ece418217c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0873991f-9c43-4f15-9bd9-765bb48364a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cdf01c68-a51d-47e4-be4f-26c2c036f2f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd9d18d4-762c-4855-bc16-a7dcd0fdbbd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b746f65f-58d7-4f28-9a29-d020a9e026e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc9b11d7-9e3f-44ca-b886-d495220ae166
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e623133-aea1-4a95-ba55-a1fb0896a137
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c52e9c9-64e1-420f-aeeb-2fa35065746d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd58ddee-b340-4949-bd12-644ee53345ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e71aa515-ce8b-4a23-a63a-2f64f1b3b4e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c28b287-8861-44ec-983a-416470d1ded0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d1b0f64-b992-487b-8b75-781256960e93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0350c32-9700-49e2-9b58-317ff86be7f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0472bb28-c909-49ff-a885-0563adb87fd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df076d46-cac7-415b-9f47-0a6bf5d3ca8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e083e3ab-363f-4db0-9001-182d5800f6ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87d95c7b-2e14-4dc6-b135-5056cde7c888
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69cb05d6-2b4e-4afe-8350-9a0a390a5e31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22e79a43-c3b0-46d5-acaa-8a8b3762ebcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9cf8e4b5-b17b-44b2-9375-54b08847231a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 791e4f44-29cc-4e89-bd55-81dc1dd6f197
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc31e02f-7c27-4aa6-87a0-e87a551404a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae28341e-040d-4d10-a1f9-c196c9fa3bdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fef4dd57-b2ab-4b68-a7b0-3dd627b79153
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f0f6d0c-9f18-4fa9-8999-09193744165d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7f81d0e-622a-41ee-8a8e-ce2724768e2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63a92d83-e285-48a2-be9c-ab1f85bc06d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9db8e0be-24ac-43b1-ab48-6195da5a65ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6070b38c-928b-48db-bb95-40384fb4702b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16258844-97a9-434f-911b-98a116a52c67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86d9c193-1520-412e-a475-3856ed0f109c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cbb73c4f-91c7-42a1-aaf4-46c439681c24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8c33e8d-34c7-46ab-8b96-0d562bcf6e83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2db352ac-d57e-4089-a3d3-e57e7500ee9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c195fcd1-0959-45a3-bb64-7da6c90d1c37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9cc1f417-93de-4c68-aeed-5957392adaf4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 550f35f6-896f-4694-8c0e-884f787634e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2b3ee22-b153-4258-b268-35db84d37585
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d30741f3-5420-450b-997f-d2459a17276c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c14ae6d4-1e8b-4293-81dd-b3ceeb8f57f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04c9256f-b3f3-4c4f-ab51-d0b7d551c5cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 754ab618-8411-4f78-be68-871dad0fdd13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 066a9e1c-55bd-4745-a9e7-69183fbaceb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 736e6726-bb4f-430f-afc2-f5297624d57c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45ee42de-9c63-47d7-a896-f582661aba9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea3b0678-df5f-426f-b6b3-9207dc6432fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ede9df05-b225-4678-a4c0-b77d802c6201
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2bd4c096-49ca-4d18-9490-910fd513eac0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23addecf-852d-499f-bddb-a35b6ecf3924
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24612913-9c6f-436f-a85f-2c244b054340
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8cdc6856-cc72-4650-a445-458fb97b3afe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d3bfda9-bb43-4bce-99dd-f7d9e3ccae6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5322da0-a6ec-45aa-beea-d127c77c7392
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26b075ae-d323-4920-961f-805d2f78b4e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54ac6ef7-8220-448d-ac68-d129cc307d0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 978eb10d-0b9c-45d9-8cd7-e8186e68e9b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ce67dc3-1b5a-46f6-9abc-55f34d8cf514
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4830f9b1-34a2-4383-adb9-6e3759f6f72b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2bd38b7a-5f6d-4160-ba3d-e0b3ed7155d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a83c8900-1602-4417-b670-a24b578d3ab7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 088f15a8-0aa0-490e-b048-f5f6a309d16e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28284734-6344-4316-a2d8-dbc766e6dd66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a394730-64bd-4add-8f08-fb6c27a6897d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9411d960-6e37-4d72-a6a5-5a25d1eb4a84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c619994d-e14e-407a-b69c-ca4606d9877f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a68ecfa0-54f6-4b93-8f22-f7245dced739
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 933f8333-e8c6-42b3-9a4c-d20c2fe28f11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1790d067-172a-4a79-ae52-eb0e5cfafee6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42dde57b-b886-44fd-9a3f-cd197d852fcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c2bd548-fc5b-444a-ae63-3b71468c4655
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ffd93917-b2e0-4cd1-9e3f-327e532d54df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6947c4a-1cb4-4985-8135-12d5644cf4dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d2aca5f-a960-4a42-91c6-4e19a7e3dd46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3e89446-1060-4ba0-9ae4-53da20240da4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f70744f-d591-46b9-aa1f-e2be8f407e1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b774e496-8888-46db-be9e-78703659ef20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93158387-00d9-4ceb-9d53-cb3c4885a4e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01443ff7-81c2-4f8d-ba4f-d7a1e47a6667
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d7e1251-0ee9-49f3-9116-9a5e84ba77c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ccbe68bc-fb84-4bd0-96ee-68c7aca3d871
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d34e83c5-d621-485f-b81a-e686bcfdaae2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd0a7fd6-2047-4e8c-99ee-f34c7eb9f19a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f62a6b3-dd85-42bf-85dd-722bea0c9cb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75abbd04-80c9-4146-945b-43c5c5e0a742
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2261cc09-bb49-4a37-bb67-5bd3890188c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58e986b7-8e82-4174-a26e-fa4c7c463811
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96c58254-ef06-4fb9-8017-e271b175b202
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e58b1d88-5893-4c9a-beac-51348ae37720
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04495844-061e-4ab7-bc58-955665340eca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 617eeef9-e5c4-4b74-b21f-fba762a36077
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0910ffed-c125-4b6d-b249-1722b6c4b685
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d40ffa24-08e8-4268-a198-df21d678f751
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 388d20cd-2ec1-4052-9ffc-097c21b4ee19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a83e832d-7753-4f79-b56a-65604104e80a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ca0c1ea-83ba-4c43-82ac-05f1cdca6e98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48663d14-f54d-40d0-88e5-2190d04481d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56c19a1e-0a92-46a2-9381-6ff8ca4eff5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68ae8a0c-b3ff-4d88-8f3b-7a5c315d9f29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1427fa4-a61d-4248-adb8-009dee8c26ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1046fdd6-9727-4c6b-8420-aa4c2073d45f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9c4a4dc-1857-4610-8684-b9d5a1809610
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72c46eb0-37e5-4293-9440-b8088cfd4e5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79769931-3530-48ac-8f9f-70b66e3069f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f2b2964-86bd-451b-9e90-7938978f30c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b18844c-6ae6-4bc9-b020-0417906aff41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce24f3e8-5541-4d53-9c70-6abea1f0330d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0af9061-195e-4abf-a35d-a3c3fdcbcdfd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb500e4a-eabe-4e53-8816-98e45a7b29a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad71a0f7-1e8c-459e-8234-ed7d216d5e6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77f19055-25a2-41d1-8224-1cdcfd67c477
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f540aac0-55c5-4e88-8d01-e6a5ba4516c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8f23426-1fae-458b-b562-c9425b3ca436
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b511d98c-d0f5-4cf7-b33a-7188aec6787f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8f24881-ded2-45c1-ab95-0308b1ee7c6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 498dda8e-9cc9-45a4-afce-0d4d2619b445
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f2aef8a-a5be-4a2f-805b-3265bf9929c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45d84e86-5763-4fdc-bbb0-1fd051da37a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51323924-d98d-45b0-8a62-fcb03d9c77e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed9194ab-22d7-479b-befa-d9c4b17e3280
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e91e916e-5cd9-4b87-b246-0d9951113d8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5eaa525-4cd7-4a54-95c1-ab9e4613d88c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88789ca8-595f-4888-b274-b1b03b7de052
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26809cb8-3d7a-472f-a17d-7786afa0f8c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28116a4d-addb-4a8c-8d54-383111a320b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d849b87-1d30-415e-abec-d27eb63ed25d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message afb1bbfd-0532-4669-b007-6701feaa08c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a21b8a4-0d6a-4007-a294-088355c9fcf1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d4a3a8c-c7ad-484f-8eef-87e55d558b6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2fc4e700-ceeb-405c-8a2e-5f2679fa2cee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ef5e2ff-84cc-4881-a8d4-d52a5bfc7e25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c2449eb-4cf0-4d51-b4fa-cdd6ed16b0b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d91a0fd2-2814-4f0d-b957-6dfeeaec92cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64000465-9520-4550-b7c3-f965d1afcb91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7dbd8625-a470-4653-ab94-408dfeddf380
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 454a6057-12e1-45b8-b704-87990c70b10a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1776be53-7d24-49af-937c-22931a87eac2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c693ffea-3880-4fcd-9722-7f4c2829f8f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a26b1cb-f78d-4001-b2ba-f61266eeb78d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2cb790bd-ddb9-486a-a563-5e50351fb031
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f29cdd9a-a713-4e36-ada6-51aa3063fb57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0a725f5-e959-4f90-a0d2-94e0fc760bcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12214efc-ad5d-4d40-8bd3-d484b503c6ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69f5aaf3-9375-4607-a557-5497db425e38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18a7ca3a-b818-46e5-bb41-1596fee3db37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac0399fd-a08c-4bc0-8c83-496f05fe7b27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3459446-e34e-4f8e-abda-f8ffa6ce62cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18736e5f-a075-43e2-b2e1-036297d877ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57172a5e-5c2e-40f2-951d-c1f9f72927bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 448c8ad2-9d2b-48fb-9c4f-33a03252ba03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b2db489-391a-45fd-a211-85abdfe185a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4117ac90-2f78-4335-baa6-9e21a78d7ef0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b945c04-fb59-43d3-b82f-15b2a288d1a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b02296b6-c71f-4feb-a705-cf26868ad544
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99ae1d14-1277-4597-8424-dc97295a7476
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0fd278a-d881-4698-9fbe-6ad236a30b37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0f9c989-6c3b-4262-a714-fc43b1aafec1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1aeace72-b7c3-4a15-939f-55200a98247e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c04c6b8-ba64-43c6-a85d-80bf6485f47e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe8f2e90-db9b-4d50-8208-a52dcf52bf29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80c33094-6006-47ee-a074-1abf57cd0661
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e82feaa-cbae-42dc-a605-5cb436573a71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7ecf687-ddf8-45d9-b826-cac2cac1f961
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88ee1204-8f08-4565-bfe4-99a4cbd4a65d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 201e9b73-a5f4-4c53-b77b-969423dbe722
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f33895e-7c27-451c-b23e-0d01ca0e4813
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a43ddd8e-5ab1-46fe-84e1-00335399b955
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b1071d6-20d7-4f32-8ea0-cda92d835a87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f481ab68-fa4a-49ab-bd17-b131f021966a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 854cb856-3bac-4df3-af62-ba62b31fa06b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3881e98-4dc9-46a0-b5b3-5d6dc72359b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 681b333a-25a5-48d7-a572-f43647c54232
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1d59586-0ce7-4d0a-86e9-3b94faf13d61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65287795-f009-4426-9b6f-0504ff219e84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad81d792-2aaf-49b4-b077-7a133a3e2f71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a4d13fb-b053-4211-9ef9-736e14bf913d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3306565-bef9-4115-b4bc-68cd62ebc7f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e81ff798-fd98-4be2-9340-f4b11349c9ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 885efc24-7108-43ee-bfde-2c211e168a62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb36e992-e778-4bc1-993d-336e69367e7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0d887dd-f986-4310-b49e-33587d028fa8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2c28e5b-ba0c-475c-b99c-d80fb85ccd99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b75ca6ca-a214-4e59-a54f-8756255e7642
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message abb08f22-e0cb-4124-a892-ea9072e5c632
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 462e8c71-e857-4760-8770-5490de54e126
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36842873-77dd-46ed-a292-ce46be2d5771
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1aee9f5-cf39-4bbd-9b1f-afdc64e97b3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9bf01e6-1819-4e86-80b6-539745a12846
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9318cf58-c30c-4dca-94a5-79cbc22967f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0fa53beb-9e11-4851-8e16-cfb0b3e428d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a0f224d-73cd-4a82-9c66-d1dc8765e2d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4aa2d6fb-9ab7-4d2f-a607-5154c06c10ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db1d7fe9-e319-4a6f-a0c9-560e5737086b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91477244-a117-4661-86c4-7ac1073711c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c19904a7-bbfe-47c8-801a-d2fe95ce1487
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 127c2062-4a9d-4057-b195-86b3c4b33804
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7bc09a1a-4cf3-43fc-9e2a-5758e72d24f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8f7f3a0-5c8c-42d7-a472-db68fe80fb0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25d067c5-cadf-48e0-9e09-9f66ca1683c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b25187bf-a38b-4208-9af2-adda6b3f9fa6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 304ac035-77ed-47b5-b778-bde154a22c84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a15673d-1d08-4345-af47-d51b005d4626
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d7a08d4-ac3e-4448-8dc9-8b6ab5d42fb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3fc4581-3f78-4bd9-b25a-141cdb22e8ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 664dc2fc-5611-4083-acf9-ec321a0271c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88434c76-f915-4a2c-a36d-e53c63de7d92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58f146ad-ad3b-4b5c-a7ba-6f4a113c02f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f192b8e8-1c5b-4d91-9dee-21e8dd510fde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b43ec9bd-9fe4-45e2-a091-567aae2f7c33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6146802e-2c1b-4c98-86e8-209936bd92ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 596c2437-6680-4202-ad06-48e03c783cfa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb2daf79-4c4e-4752-8773-5760d6576480
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ef21034-282b-4518-9c99-637ce7284195
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99b3d549-5cb6-47ea-bbfc-daa8cd69e721
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b16e63a-71b5-4cf6-aacf-19cbf02595e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20c24d9c-ce46-4c85-832e-713773eca54d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00936746-362f-4433-a96b-073f71e017ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7fdff7d-5e0e-4bd5-b559-cb27d8b6f56f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 326bd10e-de71-486f-8f00-9d2a11e1e1e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76f4d004-d1cd-4534-ad7c-066bcadd3206
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4ff1ee1-1e15-4c92-bd83-e0847fe8f094
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b35da38-8062-4663-89f5-9f06ddeadebf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5cfee2f-f382-4234-97ee-4c4675a2915f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e172a809-808c-4265-bf30-2686c245a8a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7ed4485-992e-40bb-92d5-0ebf72df85cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ace16ce7-4617-436b-811e-064283063616
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1db8aef9-efd8-42c2-9175-3d936ebf0771
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4c14a92-6b10-43c4-8c26-f7163f4cb4b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 888dd8ba-bd04-4582-a47c-1bc531273db6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 191d084a-c302-4efa-b299-d974900139cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f557ed9b-2ca2-4c8e-aa58-84e851a9d2a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d93b6aef-4d7c-465a-8f50-ea650d5ad3ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6a928dd-354e-45a1-bf8f-3f4ec65c2490
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54e35134-6296-4385-9167-c61e772090d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ab56b11-871d-4850-9f05-e08f10b670b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5b7860f-98cd-4d15-af57-8da4a9c06b72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cac11623-4eca-41fd-84b8-6471542665f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe45f9f0-eee8-4fbb-a130-a283a5363ba4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2f27dba-ba05-45e0-af9d-8882b6b95d04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14b05b92-2918-4625-92b0-f2998926d9e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee067795-c827-4d24-aeba-68b3d01f7344
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5183959f-9b04-41db-8e80-877b8c6df308
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ccb268dd-077c-4b5d-87b4-bd6c46a9f98e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e579ab9d-79be-4661-82f1-7b42c58cf9b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 567073bb-bd6f-43aa-9ad9-4905c8fd70b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20be057b-624d-4ea5-9001-f520a2163d1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0bafa342-3bdc-42b1-997b-82de8c28b6e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58f2a948-d96d-46e9-829e-7d3e8dc0f904
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0797144-82bb-4367-b601-726279d283bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9199f03-516a-498f-8561-af5655b43a09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd90d1e9-0834-42e4-af1d-8c6cebd2d9c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 326da29d-89aa-4420-9020-74accf4b234a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da09dc23-fd11-40ca-ae54-37ff81120022
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a4a71d9-7005-4bc2-97b7-97bf8ef733b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e20f1da9-c8a8-4ebc-83db-b9200c920ba3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68d10ed4-d122-4767-85e7-8803986275da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 774ef040-4a66-48fb-8746-f675c36937e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5f176c4-0fd3-4bd3-bea3-d7f06400e9fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dfcbc7d4-69c9-4432-8579-3727d9015796
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 999fd9f0-db81-4a5b-978d-a5ef60796cd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e1e3cda-8e23-45ba-8d24-db50f3ceedb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8062c06-7555-404b-8599-d4b479a0738f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 310d3533-b4a4-4d0f-b7f9-ee904eb0ffb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91191344-4e6a-44af-9ceb-2c5d7ea6aa07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f3976a0-d6ea-4014-adb3-4fbf69f51f93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67af8ea1-e536-4814-83b0-d77b20a7ffc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b99e319-72b6-42fc-a089-54041eee8cfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f49b824b-523c-43fe-bdc3-df995b2cfafc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6590f565-d14b-4a31-a598-5b6983b2a732
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c008edf-1208-4ca8-b16e-0023663933a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f406eaa3-c41f-4876-9a24-8c8995de8238
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 797f835f-6ebb-4a8a-8f95-a5bf12d519ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 825ac21d-f6e7-4518-9c2b-e021ec44f006
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4f30848-d3e2-465d-9195-2d1850fcfd95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f00deaae-e8e2-4124-be83-1e9b5e3a909b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ee5e2b6-5835-43fe-be02-057dd2ecd7e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42b76eed-b42c-45e7-8768-5e2454dce28d
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8690 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_11
Server: localhost:8690
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_11
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_11/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_11/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_11/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_11/test_labels.txt

📊 Raw data loaded:
   Train: X=(6688, 24), y=(6688,)
   Test:  X=(1673, 24), y=(1673,)

⚠️  Limiting training data: 6688 → 800 samples
⚠️  Limiting test data: 1673 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_11 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0803, RMSE: 0.2833, MAE: 0.2456, R²: -0.0014

📊 Round 0 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2462, R²: -0.0005

============================================================
🔄 Round 5 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0793 (↓), lr=0.001000
   • Epoch   2/100: train=0.0823, val=0.0799, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0825, val=0.0805, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0822, val=0.0805, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0820, val=0.0804, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0807, val=0.0799, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 5 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0072
   Val:   Loss=0.0793, RMSE=0.2817, R²=-0.0016
============================================================


============================================================
🔄 Round 6 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0717 (↓), lr=0.000250
   • Epoch   2/100: train=0.0838, val=0.0717, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0838, val=0.0718, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0837, val=0.0718, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0836, val=0.0719, patience=4/15, lr=0.000250
   📉 Epoch 8: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0834, val=0.0717, patience=10/15, lr=0.000125
   📉 Epoch 16: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 6 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0016
   Val:   Loss=0.0717, RMSE=0.2678, R²=-0.0310
============================================================


============================================================
🔄 Round 8 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0834 (↓), lr=0.000063
   • Epoch   2/100: train=0.0805, val=0.0835, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0804, val=0.0836, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0804, val=0.0836, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0804, val=0.0836, patience=4/15, lr=0.000063
   📉 Epoch 8: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0802, val=0.0837, patience=10/15, lr=0.000031
   📉 Epoch 16: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 8 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0003
   Val:   Loss=0.0834, RMSE=0.2888, R²=0.0079
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2460, R²: 0.0007

============================================================
🔄 Round 11 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0855 (↓), lr=0.000016
   • Epoch   2/100: train=0.0797, val=0.0856, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0797, val=0.0856, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0797, val=0.0857, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0796, val=0.0857, patience=4/15, lr=0.000016
   📉 Epoch 8: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0796, val=0.0858, patience=10/15, lr=0.000008
   📉 Epoch 16: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 11 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0000
   Val:   Loss=0.0855, RMSE=0.2924, R²=0.0032
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2460, R²: 0.0007

============================================================
🔄 Round 12 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0885 (↓), lr=0.000004
   • Epoch   2/100: train=0.0793, val=0.0885, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0793, val=0.0885, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0793, val=0.0886, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0793, val=0.0886, patience=4/15, lr=0.000004
   📉 Epoch 8: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0792, val=0.0886, patience=10/15, lr=0.000002
   📉 Epoch 16: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 12 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0005
   Val:   Loss=0.0885, RMSE=0.2975, R²=0.0029
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2461, R²: 0.0006

============================================================
🔄 Round 13 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 13 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0027
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0063
============================================================


============================================================
🔄 Round 14 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 14 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0024
   Val:   Loss=0.0916, RMSE=0.3027, R²=-0.0084
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0015

============================================================
🔄 Round 15 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 15 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0003
   Val:   Loss=0.0811, RMSE=0.2847, R²=0.0072
============================================================


============================================================
🔄 Round 16 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 16 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=0.0011
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0060
============================================================


============================================================
🔄 Round 19 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 19 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0026
   Val:   Loss=0.0783, RMSE=0.2798, R²=0.0004
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0015

============================================================
🔄 Round 23 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 23 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0044
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0077
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0015

============================================================
🔄 Round 27 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 27 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0031
   Val:   Loss=0.0830, RMSE=0.2880, R²=-0.0055
============================================================


============================================================
🔄 Round 28 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 28 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2849, R²=0.0012
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0057
============================================================


============================================================
🔄 Round 32 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 32 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0021
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0020
============================================================


============================================================
🔄 Round 34 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 34 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0025
   Val:   Loss=0.0887, RMSE=0.2978, R²=-0.0020
============================================================


============================================================
🔄 Round 35 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 35 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=-0.0002
   Val:   Loss=0.0901, RMSE=0.3002, R²=0.0072
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

============================================================
🔄 Round 36 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 36 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0020
   Val:   Loss=0.0747, RMSE=0.2733, R²=0.0039
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

============================================================
🔄 Round 37 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0722 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 37 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0017
   Val:   Loss=0.0722, RMSE=0.2686, R²=0.0050
============================================================


============================================================
🔄 Round 39 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 39 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0021
   Val:   Loss=0.0729, RMSE=0.2700, R²=0.0030
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

============================================================
🔄 Round 40 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 40 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0042
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0052
============================================================


============================================================
🔄 Round 44 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 44 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0026
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0032
============================================================


============================================================
🔄 Round 46 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 46 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0043
   Val:   Loss=0.0829, RMSE=0.2880, R²=-0.0144
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

📊 Round 46 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

📊 Round 46 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

📊 Round 46 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

📊 Round 46 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

📊 Round 46 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

📊 Round 46 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

============================================================
🔄 Round 56 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 56 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0014
   Val:   Loss=0.0774, RMSE=0.2782, R²=0.0058
============================================================


============================================================
🔄 Round 57 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 57 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0019
   Val:   Loss=0.0782, RMSE=0.2797, R²=0.0043
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

============================================================
🔄 Round 60 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 60 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0039
   Val:   Loss=0.0779, RMSE=0.2792, R²=-0.0089
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

============================================================
🔄 Round 61 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 61 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0026
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0022
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

============================================================
🔄 Round 63 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 63 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=0.0012
   Val:   Loss=0.0847, RMSE=0.2911, R²=0.0066
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

============================================================
🔄 Round 65 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 65 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0007
   Val:   Loss=0.0802, RMSE=0.2831, R²=-0.0026
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

============================================================
🔄 Round 66 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 66 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0002
   Val:   Loss=0.0727, RMSE=0.2696, R²=0.0022
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

============================================================
🔄 Round 67 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 67 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0039
   Val:   Loss=0.0739, RMSE=0.2719, R²=-0.0182
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

============================================================
🔄 Round 72 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 72 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0011
   Val:   Loss=0.0768, RMSE=0.2772, R²=-0.0024
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

📊 Round 72 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

📊 Round 72 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

============================================================
🔄 Round 79 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 79 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0031
   Val:   Loss=0.0866, RMSE=0.2942, R²=-0.0037
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

============================================================
🔄 Round 83 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 83 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0029
   Val:   Loss=0.0809, RMSE=0.2845, R²=-0.0070
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

📊 Round 83 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

============================================================
🔄 Round 85 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 85 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=0.0004
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0059
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

============================================================
🔄 Round 87 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 87 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0032
   Val:   Loss=0.0826, RMSE=0.2873, R²=-0.0012
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

============================================================
🔄 Round 90 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 90 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0005
   Val:   Loss=0.0850, RMSE=0.2915, R²=0.0064
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

============================================================
🔄 Round 91 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 91 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0012
   Val:   Loss=0.0878, RMSE=0.2963, R²=0.0027
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

============================================================
🔄 Round 93 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 93 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0014
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0029
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

============================================================
🔄 Round 94 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0703 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0703, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0703, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0703, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0703, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0703, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0703)

============================================================
📊 Round 94 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=0.0022
   Val:   Loss=0.0703, RMSE=0.2651, R²=0.0026
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

============================================================
🔄 Round 96 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 96 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0003
   Val:   Loss=0.0917, RMSE=0.3028, R²=-0.0105
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

📊 Round 96 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

📊 Round 96 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

============================================================
🔄 Round 101 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 101 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0008
   Val:   Loss=0.0748, RMSE=0.2735, R²=0.0056
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

============================================================
🔄 Round 104 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 104 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2856, R²=0.0037
   Val:   Loss=0.0791, RMSE=0.2813, R²=-0.0041
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

📊 Round 104 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

============================================================
🔄 Round 112 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 112 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0032
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0007
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

============================================================
🔄 Round 113 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 113 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0022
   Val:   Loss=0.0841, RMSE=0.2899, R²=0.0016
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

============================================================
🔄 Round 116 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 116 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=0.0004
   Val:   Loss=0.0880, RMSE=0.2967, R²=0.0089
============================================================


============================================================
🔄 Round 119 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 119 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0003
   Val:   Loss=0.0776, RMSE=0.2786, R²=0.0083
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

============================================================
🔄 Round 120 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 120 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0006
   Val:   Loss=0.0851, RMSE=0.2918, R²=0.0090
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

============================================================
🔄 Round 122 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 122 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0035
   Val:   Loss=0.0723, RMSE=0.2688, R²=-0.0116
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

============================================================
🔄 Round 125 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 125 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0014
   Val:   Loss=0.0804, RMSE=0.2835, R²=0.0061
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

============================================================
🔄 Round 127 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 127 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0008
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0016
============================================================


============================================================
🔄 Round 128 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 128 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0022
   Val:   Loss=0.0839, RMSE=0.2896, R²=0.0035
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

📊 Round 128 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

============================================================
🔄 Round 132 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 132 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0032
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0250
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

============================================================
🔄 Round 133 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 133 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0006
   Val:   Loss=0.0802, RMSE=0.2831, R²=0.0081
============================================================


============================================================
🔄 Round 135 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 135 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0042
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0061
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

📊 Round 135 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

============================================================
🔄 Round 138 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 138 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0017
   Val:   Loss=0.0744, RMSE=0.2728, R²=0.0044
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

📊 Round 138 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

============================================================
🔄 Round 142 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 142 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0017
   Val:   Loss=0.0739, RMSE=0.2718, R²=-0.0068
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

📊 Round 142 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

============================================================
🔄 Round 146 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 146 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0017
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0046
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

📊 Round 146 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

============================================================
🔄 Round 149 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 149 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0007
   Val:   Loss=0.0802, RMSE=0.2833, R²=0.0022
============================================================


============================================================
🔄 Round 150 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 150 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0035
   Val:   Loss=0.0744, RMSE=0.2727, R²=-0.0076
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

============================================================
🔄 Round 152 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 152 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0023
   Val:   Loss=0.0742, RMSE=0.2723, R²=0.0019
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

============================================================
🔄 Round 153 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 153 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0002
   Val:   Loss=0.0809, RMSE=0.2845, R²=0.0075
============================================================


============================================================
🔄 Round 154 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 154 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0018
   Val:   Loss=0.0806, RMSE=0.2839, R²=0.0029
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

============================================================
🔄 Round 155 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 155 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0032
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0042
============================================================


============================================================
🔄 Round 156 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 156 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0031
   Val:   Loss=0.0766, RMSE=0.2768, R²=-0.0006
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

📊 Round 156 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

📊 Round 156 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

============================================================
🔄 Round 159 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 159 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0021
   Val:   Loss=0.0765, RMSE=0.2765, R²=0.0021
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

============================================================
🔄 Round 160 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 160 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0001
   Val:   Loss=0.0744, RMSE=0.2728, R²=0.0094
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

============================================================
🔄 Round 161 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 161 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0025
   Val:   Loss=0.0839, RMSE=0.2896, R²=0.0023
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

============================================================
🔄 Round 163 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 163 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0002
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0024
============================================================


============================================================
🔄 Round 165 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 165 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0050
   Val:   Loss=0.0856, RMSE=0.2925, R²=-0.0373
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

============================================================
🔄 Round 169 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 169 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2835, R²=0.0018
   Val:   Loss=0.0839, RMSE=0.2897, R²=0.0045
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

📊 Round 169 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

============================================================
🔄 Round 171 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 171 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0043
   Val:   Loss=0.0885, RMSE=0.2975, R²=-0.0275
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

============================================================
🔄 Round 174 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 174 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0024
   Val:   Loss=0.0785, RMSE=0.2801, R²=0.0027
============================================================


============================================================
🔄 Round 175 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 175 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0036
   Val:   Loss=0.0776, RMSE=0.2786, R²=-0.0048
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

============================================================
🔄 Round 178 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 178 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=0.0041
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0041
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

============================================================
🔄 Round 181 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 181 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0037
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0023
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

📊 Round 181 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

============================================================
🔄 Round 187 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 187 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0044
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0180
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

============================================================
🔄 Round 192 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 192 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0010
   Val:   Loss=0.0740, RMSE=0.2720, R²=-0.0049
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

📊 Round 192 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

============================================================
🔄 Round 194 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 194 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0033
   Val:   Loss=0.0794, RMSE=0.2817, R²=-0.0029
============================================================


============================================================
🔄 Round 196 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 196 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0021
   Val:   Loss=0.0753, RMSE=0.2743, R²=0.0028
============================================================


📊 Round 196 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

============================================================
🔄 Round 201 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 201 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=0.0022
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0053
============================================================


📊 Round 201 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

============================================================
🔄 Round 203 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 203 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=-0.0000
   Val:   Loss=0.0901, RMSE=0.3002, R²=-0.0003
============================================================


============================================================
🔄 Round 204 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 204 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=0.0000
   Val:   Loss=0.0883, RMSE=0.2971, R²=0.0017
============================================================


📊 Round 204 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

============================================================
🔄 Round 206 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 206 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0025
   Val:   Loss=0.0833, RMSE=0.2886, R²=0.0016
============================================================


============================================================
🔄 Round 209 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 209 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0011
   Val:   Loss=0.0781, RMSE=0.2795, R²=-0.0027
============================================================


📊 Round 209 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

============================================================
🔄 Round 211 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 211 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0015
   Val:   Loss=0.0789, RMSE=0.2808, R²=0.0028
============================================================


📊 Round 211 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

============================================================
🔄 Round 212 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 212 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0016
   Val:   Loss=0.0863, RMSE=0.2938, R²=0.0030
============================================================


📊 Round 212 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

📊 Round 212 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

============================================================
🔄 Round 214 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 214 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0038
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0045
============================================================


📊 Round 214 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

📊 Round 214 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

============================================================
🔄 Round 218 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 218 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0037
   Val:   Loss=0.0778, RMSE=0.2789, R²=-0.0243
============================================================


📊 Round 218 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

📊 Round 218 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

============================================================
🔄 Round 223 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 223 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2878, R²=0.0009
   Val:   Loss=0.0739, RMSE=0.2718, R²=-0.0001
============================================================


📊 Round 223 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

============================================================
🔄 Round 227 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 227 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0031
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0044
============================================================


============================================================
🔄 Round 229 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 229 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0028
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0010
============================================================


📊 Round 229 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

📊 Round 229 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

📊 Round 229 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

============================================================
🔄 Round 235 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 235 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0023
   Val:   Loss=0.0726, RMSE=0.2695, R²=-0.0114
============================================================


============================================================
🔄 Round 236 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 236 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0019
   Val:   Loss=0.0862, RMSE=0.2935, R²=0.0007
============================================================


📊 Round 236 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

📊 Round 236 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

============================================================
🔄 Round 239 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 239 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0015
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0058
============================================================


============================================================
🔄 Round 240 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 240 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0053
   Val:   Loss=0.0773, RMSE=0.2779, R²=-0.0297
============================================================


📊 Round 240 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

📊 Round 240 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

📊 Round 240 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

============================================================
🔄 Round 246 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 246 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=-0.0001
   Val:   Loss=0.0863, RMSE=0.2938, R²=0.0070
============================================================


📊 Round 246 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

============================================================
🔄 Round 247 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 247 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0031
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0006
============================================================


📊 Round 247 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

📊 Round 247 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

============================================================
🔄 Round 249 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 249 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=0.0017
   Val:   Loss=0.0883, RMSE=0.2971, R²=0.0041
============================================================


============================================================
🔄 Round 250 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 250 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0029
   Val:   Loss=0.0776, RMSE=0.2785, R²=-0.0042
============================================================


📊 Round 250 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

📊 Round 250 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

============================================================
🔄 Round 256 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 256 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0028
   Val:   Loss=0.0831, RMSE=0.2884, R²=-0.0001
============================================================


📊 Round 256 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

============================================================
🔄 Round 260 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 260 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0026
   Val:   Loss=0.0786, RMSE=0.2803, R²=0.0014
============================================================


📊 Round 260 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

============================================================
🔄 Round 261 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 261 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0031
   Val:   Loss=0.0738, RMSE=0.2717, R²=-0.0012
============================================================


📊 Round 261 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

============================================================
🔄 Round 264 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 264 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0010
   Val:   Loss=0.0864, RMSE=0.2939, R²=0.0035
============================================================


📊 Round 264 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

📊 Round 264 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

============================================================
🔄 Round 269 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 269 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0028
   Val:   Loss=0.0720, RMSE=0.2683, R²=-0.0034
============================================================


============================================================
🔄 Round 270 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 270 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2871, R²=0.0048
   Val:   Loss=0.0755, RMSE=0.2748, R²=-0.0204
============================================================


📊 Round 270 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

📊 Round 270 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

============================================================
🔄 Round 276 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 276 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0025
   Val:   Loss=0.0781, RMSE=0.2795, R²=-0.0040
============================================================


============================================================
🔄 Round 277 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0707 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0707, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0707, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0707, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0707, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0708, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0707)

============================================================
📊 Round 277 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2892, R²=0.0007
   Val:   Loss=0.0707, RMSE=0.2659, R²=0.0012
============================================================


📊 Round 277 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

📊 Round 277 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

============================================================
🔄 Round 280 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 280 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0037
   Val:   Loss=0.0807, RMSE=0.2840, R²=-0.0052
============================================================


============================================================
🔄 Round 284 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 284 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0035
   Val:   Loss=0.0770, RMSE=0.2775, R²=-0.0166
============================================================


📊 Round 284 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

📊 Round 284 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0016

============================================================
🔄 Round 290 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 290 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0003
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0098
============================================================


📊 Round 290 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0017

============================================================
🔄 Round 292 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 292 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0029
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0021
============================================================


📊 Round 292 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0017

============================================================
🔄 Round 295 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0722 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 295 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0012
   Val:   Loss=0.0722, RMSE=0.2687, R²=0.0059
============================================================


📊 Round 295 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0017

============================================================
🔄 Round 298 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 298 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0044
   Val:   Loss=0.0726, RMSE=0.2694, R²=-0.0161
============================================================


📊 Round 298 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0017

📊 Round 298 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0017

============================================================
🔄 Round 304 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 304 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0002
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0026
============================================================


============================================================
🔄 Round 305 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 305 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=0.0026
   Val:   Loss=0.0767, RMSE=0.2769, R²=-0.0083
============================================================


============================================================
🔄 Round 306 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 306 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0036
   Val:   Loss=0.0813, RMSE=0.2852, R²=-0.0027
============================================================


📊 Round 306 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0017

============================================================
🔄 Round 309 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 309 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0029
   Val:   Loss=0.0820, RMSE=0.2863, R²=0.0002
============================================================


📊 Round 309 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0017

============================================================
🔄 Round 310 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 310 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0012
   Val:   Loss=0.0809, RMSE=0.2843, R²=0.0051
============================================================


============================================================
🔄 Round 311 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 311 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0000
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0101
============================================================


📊 Round 311 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0017

============================================================
🔄 Round 312 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 312 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0034
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0028
============================================================


📊 Round 312 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0017

============================================================
🔄 Round 317 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 317 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0022
   Val:   Loss=0.0727, RMSE=0.2696, R²=0.0023
============================================================


📊 Round 317 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0017

============================================================
🔄 Round 318 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 318 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0027
   Val:   Loss=0.0801, RMSE=0.2831, R²=0.0012
============================================================


============================================================
🔄 Round 319 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 319 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0037
   Val:   Loss=0.0782, RMSE=0.2796, R²=-0.0095
============================================================


📊 Round 319 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0017

📊 Round 319 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0017

============================================================
🔄 Round 322 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 322 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0015
   Val:   Loss=0.0836, RMSE=0.2892, R²=0.0048
============================================================


📊 Round 322 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0017

============================================================
🔄 Round 323 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 323 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0038
   Val:   Loss=0.0774, RMSE=0.2782, R²=-0.0185
============================================================


📊 Round 323 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0017

============================================================
🔄 Round 324 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 324 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0024
   Val:   Loss=0.0770, RMSE=0.2775, R²=-0.0066
============================================================


📊 Round 324 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0017

============================================================
🔄 Round 327 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 327 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0005
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0059
============================================================


============================================================
🔄 Round 328 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 328 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0037
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0061
============================================================


📊 Round 328 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0017

============================================================
🔄 Round 330 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 330 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0029
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0081
============================================================


============================================================
🔄 Round 331 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 331 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0020
   Val:   Loss=0.0894, RMSE=0.2990, R²=0.0034
============================================================


📊 Round 331 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0017

============================================================
🔄 Round 333 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 333 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0032
   Val:   Loss=0.0807, RMSE=0.2840, R²=-0.0007
============================================================


📊 Round 333 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0017

============================================================
🔄 Round 337 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 337 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2826, R²=0.0060
   Val:   Loss=0.0860, RMSE=0.2932, R²=-0.0447
============================================================


📊 Round 337 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0017

📊 Round 337 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0017

📊 Round 337 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0017

📊 Round 337 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0017

============================================================
🔄 Round 345 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 345 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0017
   Val:   Loss=0.0856, RMSE=0.2926, R²=0.0045
============================================================


📊 Round 345 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0017

📊 Round 345 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0017

📊 Round 345 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0017

============================================================
🔄 Round 348 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 348 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0041
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0060
============================================================


============================================================
🔄 Round 349 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 349 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0035
   Val:   Loss=0.0778, RMSE=0.2790, R²=-0.0086
============================================================


📊 Round 349 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0017

============================================================
🔄 Round 351 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 351 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0023
   Val:   Loss=0.0754, RMSE=0.2746, R²=0.0023
============================================================


============================================================
🔄 Round 352 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 352 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0049
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0143
============================================================


📊 Round 352 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0017

📊 Round 352 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0017

============================================================
🔄 Round 357 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 357 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0012
   Val:   Loss=0.0828, RMSE=0.2878, R²=0.0027
============================================================


============================================================
🔄 Round 359 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 359 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0040
   Val:   Loss=0.0772, RMSE=0.2778, R²=-0.0095
============================================================


📊 Round 359 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0017

📊 Round 359 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0017

📊 Round 359 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0017

============================================================
🔄 Round 363 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 363 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2843, R²=-0.0045
   Val:   Loss=0.0819, RMSE=0.2861, R²=-0.0102
============================================================


📊 Round 363 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0017

============================================================
🔄 Round 364 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 364 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0016
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0035
============================================================


📊 Round 364 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0017

============================================================
🔄 Round 366 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 366 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0037
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0124
============================================================


📊 Round 366 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0017

============================================================
🔄 Round 367 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 367 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0025
   Val:   Loss=0.0739, RMSE=0.2719, R²=-0.0003
============================================================


📊 Round 367 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0017

============================================================
🔄 Round 368 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 368 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0031
   Val:   Loss=0.0755, RMSE=0.2747, R²=-0.0002
============================================================


📊 Round 368 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0017

============================================================
🔄 Round 370 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 370 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=0.0019
   Val:   Loss=0.0763, RMSE=0.2762, R²=-0.0006
============================================================


============================================================
🔄 Round 371 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 371 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0038
   Val:   Loss=0.0846, RMSE=0.2908, R²=-0.0101
============================================================


📊 Round 371 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0017

============================================================
🔄 Round 372 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 372 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=-0.0006
   Val:   Loss=0.0880, RMSE=0.2967, R²=-0.0140
============================================================


============================================================
🔄 Round 373 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 373 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=0.0020
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0010
============================================================


📊 Round 373 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0017

📊 Round 373 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0017

============================================================
🔄 Round 375 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 375 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0022
   Val:   Loss=0.0760, RMSE=0.2757, R²=0.0038
============================================================


📊 Round 375 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0017

📊 Round 375 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0017

============================================================
🔄 Round 377 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0939 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0938, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0938, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0938, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0938, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0938, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0939)

============================================================
📊 Round 377 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2790, R²=0.0047
   Val:   Loss=0.0939, RMSE=0.3064, R²=-0.0088
============================================================


📊 Round 377 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0017

============================================================
🔄 Round 381 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 381 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0029
   Val:   Loss=0.0856, RMSE=0.2925, R²=-0.0004
============================================================


📊 Round 381 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0017

============================================================
🔄 Round 382 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 382 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0023
   Val:   Loss=0.0745, RMSE=0.2729, R²=-0.0057
============================================================


============================================================
🔄 Round 384 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 384 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0026
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0069
============================================================


📊 Round 384 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0017

============================================================
🔄 Round 386 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 386 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=0.0020
   Val:   Loss=0.0798, RMSE=0.2826, R²=0.0037
============================================================


============================================================
🔄 Round 388 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 388 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0010
   Val:   Loss=0.0799, RMSE=0.2826, R²=-0.0039
============================================================


📊 Round 388 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0017

📊 Round 388 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0017

============================================================
🔄 Round 392 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 392 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0013
   Val:   Loss=0.0869, RMSE=0.2948, R²=-0.0054
============================================================


============================================================
🔄 Round 393 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 393 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0028
   Val:   Loss=0.0894, RMSE=0.2991, R²=-0.0043
============================================================


============================================================
🔄 Round 395 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 395 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=0.0000
   Val:   Loss=0.0750, RMSE=0.2739, R²=0.0129
============================================================


📊 Round 395 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0017

============================================================
🔄 Round 398 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 398 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0014
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0043
============================================================


📊 Round 398 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0017

📊 Round 398 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0017

============================================================
🔄 Round 402 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 402 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0010
   Val:   Loss=0.0848, RMSE=0.2912, R²=0.0002
============================================================


============================================================
🔄 Round 403 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 403 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0018
   Val:   Loss=0.0912, RMSE=0.3019, R²=0.0048
============================================================


📊 Round 403 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0017

============================================================
🔄 Round 405 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 405 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0022
   Val:   Loss=0.0790, RMSE=0.2811, R²=0.0032
============================================================


📊 Round 405 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0017

📊 Round 405 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0017

============================================================
🔄 Round 407 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 407 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0000
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0101
============================================================


============================================================
🔄 Round 408 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 408 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0016
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0031
============================================================


📊 Round 408 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0017

📊 Round 408 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0017

📊 Round 408 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0017

📊 Round 408 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0017

============================================================
🔄 Round 418 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0928 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0928, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0928, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0929, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0929, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0929, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 418 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0022
   Val:   Loss=0.0928, RMSE=0.3047, R²=-0.0006
============================================================


📊 Round 418 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0017

============================================================
🔄 Round 420 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 420 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0027
   Val:   Loss=0.0871, RMSE=0.2952, R²=0.0012
============================================================


============================================================
🔄 Round 421 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.1007 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.1007, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.1007, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.1007, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.1007, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.1007, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1007)

============================================================
📊 Round 421 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2760, R²=0.0007
   Val:   Loss=0.1007, RMSE=0.3174, R²=0.0070
============================================================


📊 Round 421 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0017

============================================================
🔄 Round 426 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 426 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0021
   Val:   Loss=0.0761, RMSE=0.2758, R²=0.0006
============================================================


============================================================
🔄 Round 427 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 427 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0034
   Val:   Loss=0.0726, RMSE=0.2695, R²=-0.0022
============================================================


📊 Round 427 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0017

============================================================
🔄 Round 429 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 429 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0005
   Val:   Loss=0.0838, RMSE=0.2895, R²=0.0084
============================================================


📊 Round 429 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0017

📊 Round 429 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0017

📊 Round 429 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0017

============================================================
🔄 Round 434 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 434 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0019
   Val:   Loss=0.0741, RMSE=0.2722, R²=0.0041
============================================================


============================================================
🔄 Round 435 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 435 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0022
   Val:   Loss=0.0734, RMSE=0.2709, R²=0.0021
============================================================


📊 Round 435 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0017

============================================================
🔄 Round 436 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 436 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=0.0019
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0017
============================================================


============================================================
🔄 Round 437 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0981 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0981, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0981, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0981, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0981, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0982, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0981)

============================================================
📊 Round 437 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0012
   Val:   Loss=0.0981, RMSE=0.3132, R²=0.0012
============================================================


============================================================
🔄 Round 440 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 440 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=0.0035
   Val:   Loss=0.0764, RMSE=0.2764, R²=-0.0065
============================================================


📊 Round 440 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0017

📊 Round 440 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0017

============================================================
🔄 Round 443 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 443 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0033
   Val:   Loss=0.0741, RMSE=0.2722, R²=-0.0236
============================================================


📊 Round 443 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0017

📊 Round 443 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0017

============================================================
🔄 Round 447 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 447 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0036
   Val:   Loss=0.0744, RMSE=0.2727, R²=-0.0050
============================================================


============================================================
🔄 Round 449 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 449 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0046
   Val:   Loss=0.0872, RMSE=0.2954, R²=-0.0130
============================================================


============================================================
🔄 Round 450 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 450 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0020
   Val:   Loss=0.0856, RMSE=0.2926, R²=0.0030
============================================================


📊 Round 450 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0018

📊 Round 450 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0018

📊 Round 450 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0018

📊 Round 450 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0018

============================================================
🔄 Round 456 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 456 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=0.0028
   Val:   Loss=0.0828, RMSE=0.2877, R²=0.0000
============================================================


============================================================
🔄 Round 457 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 457 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0010
   Val:   Loss=0.0836, RMSE=0.2892, R²=0.0037
============================================================


============================================================
🔄 Round 458 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 458 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=0.0027
   Val:   Loss=0.0799, RMSE=0.2826, R²=-0.0350
============================================================


📊 Round 458 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0018

============================================================
🔄 Round 459 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 459 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0007
   Val:   Loss=0.0824, RMSE=0.2870, R²=0.0096
============================================================


📊 Round 459 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0018

📊 Round 459 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2458, R²: 0.0018

============================================================
🔄 Round 461 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 461 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0042
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0072
============================================================


📊 Round 461 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2458, R²: 0.0018

============================================================
🔄 Round 466 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 466 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=-0.0009
   Val:   Loss=0.0904, RMSE=0.3007, R²=0.0082
============================================================


============================================================
🔄 Round 468 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 468 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0011
   Val:   Loss=0.0837, RMSE=0.2894, R²=-0.0018
============================================================


============================================================
🔄 Round 469 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 469 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0013
   Val:   Loss=0.0809, RMSE=0.2845, R²=0.0051
============================================================


📊 Round 469 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2458, R²: 0.0018

============================================================
🔄 Round 471 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 471 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0014
   Val:   Loss=0.0748, RMSE=0.2734, R²=0.0019
============================================================


📊 Round 471 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2458, R²: 0.0018

============================================================
🔄 Round 472 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0945 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0944, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0944, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0944, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0944, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0944, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0945)

============================================================
📊 Round 472 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0039
   Val:   Loss=0.0945, RMSE=0.3073, R²=-0.0037
============================================================


📊 Round 472 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2458, R²: 0.0018

============================================================
🔄 Round 473 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 473 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0037
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0024
============================================================


📊 Round 473 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2458, R²: 0.0018

============================================================
🔄 Round 474 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 474 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0020
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0043
============================================================


📊 Round 474 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2458, R²: 0.0018

============================================================
🔄 Round 476 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 476 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2849, R²=0.0039
   Val:   Loss=0.0807, RMSE=0.2840, R²=-0.0280
============================================================


============================================================
🔄 Round 478 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 478 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0040
   Val:   Loss=0.0822, RMSE=0.2868, R²=-0.0377
============================================================


============================================================
🔄 Round 479 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 479 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0023
   Val:   Loss=0.0789, RMSE=0.2808, R²=-0.0149
============================================================


============================================================
🔄 Round 480 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 480 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0000
   Val:   Loss=0.0876, RMSE=0.2960, R²=0.0085
============================================================


============================================================
🔄 Round 482 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 482 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0018
   Val:   Loss=0.0754, RMSE=0.2747, R²=0.0042
============================================================


📊 Round 482 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2458, R²: 0.0018

📊 Round 482 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2458, R²: 0.0018

📊 Round 482 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2458, R²: 0.0018

============================================================
🔄 Round 486 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 486 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0014
   Val:   Loss=0.0783, RMSE=0.2799, R²=-0.0006
============================================================


📊 Round 486 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2458, R²: 0.0018

============================================================
🔄 Round 487 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 487 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0044
   Val:   Loss=0.0754, RMSE=0.2746, R²=-0.0672
============================================================


📊 Round 487 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2458, R²: 0.0018

============================================================
🔄 Round 489 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 489 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0029
   Val:   Loss=0.0799, RMSE=0.2826, R²=0.0010
============================================================


📊 Round 489 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2458, R²: 0.0018

============================================================
🔄 Round 490 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 490 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0009
   Val:   Loss=0.0852, RMSE=0.2920, R²=0.0080
============================================================


📊 Round 490 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2458, R²: 0.0018

📊 Round 490 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2458, R²: 0.0018

📊 Round 490 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2458, R²: 0.0018

============================================================
🔄 Round 499 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 499 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0029
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0118
============================================================


📊 Round 499 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2458, R²: 0.0018

============================================================
🔄 Round 508 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 508 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0006
   Val:   Loss=0.0842, RMSE=0.2902, R²=0.0046
============================================================


============================================================
🔄 Round 509 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 509 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0008
   Val:   Loss=0.0758, RMSE=0.2754, R²=-0.0055
============================================================


📊 Round 509 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2458, R²: 0.0018

📊 Round 509 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2458, R²: 0.0018

📊 Round 509 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2458, R²: 0.0018

============================================================
🔄 Round 515 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 515 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0010
   Val:   Loss=0.0780, RMSE=0.2792, R²=-0.0006
============================================================


📊 Round 515 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2458, R²: 0.0018

📊 Round 515 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2458, R²: 0.0018

📊 Round 515 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2458, R²: 0.0018

============================================================
🔄 Round 520 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 520 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0027
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0015
============================================================


============================================================
🔄 Round 522 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 522 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0035
   Val:   Loss=0.0784, RMSE=0.2800, R²=-0.0020
============================================================


📊 Round 522 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2458, R²: 0.0018

============================================================
🔄 Round 524 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0702 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0702, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0702, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0702, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0702, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0702, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0702)

============================================================
📊 Round 524 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=0.0026
   Val:   Loss=0.0702, RMSE=0.2650, R²=-0.0067
============================================================


📊 Round 524 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2458, R²: 0.0018

============================================================
🔄 Round 527 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 527 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=0.0022
   Val:   Loss=0.0814, RMSE=0.2854, R²=0.0012
============================================================


📊 Round 527 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2458, R²: 0.0018

============================================================
🔄 Round 532 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 532 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0024
   Val:   Loss=0.0834, RMSE=0.2888, R²=0.0027
============================================================


📊 Round 532 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2458, R²: 0.0018

============================================================
🔄 Round 534 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 534 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0027
   Val:   Loss=0.0874, RMSE=0.2956, R²=0.0008
============================================================


📊 Round 534 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2458, R²: 0.0018

============================================================
🔄 Round 535 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 535 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0037
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0025
============================================================


📊 Round 535 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2458, R²: 0.0018

============================================================
🔄 Round 536 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 536 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0027
   Val:   Loss=0.0823, RMSE=0.2870, R²=0.0009
============================================================


📊 Round 536 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2458, R²: 0.0018

📊 Round 536 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2458, R²: 0.0018

📊 Round 536 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2458, R²: 0.0018

============================================================
🔄 Round 539 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 539 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0020
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0075
============================================================


📊 Round 539 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2458, R²: 0.0018

============================================================
🔄 Round 540 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 540 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0018
   Val:   Loss=0.0853, RMSE=0.2920, R²=0.0053
============================================================


📊 Round 540 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2458, R²: 0.0018

============================================================
🔄 Round 541 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 541 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0042
   Val:   Loss=0.0802, RMSE=0.2833, R²=-0.0047
============================================================


📊 Round 541 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2458, R²: 0.0018

============================================================
🔄 Round 543 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 543 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0026
   Val:   Loss=0.0851, RMSE=0.2916, R²=0.0023
============================================================


============================================================
🔄 Round 544 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 544 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0020
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0210
============================================================


📊 Round 544 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2458, R²: 0.0018

============================================================
🔄 Round 545 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 545 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0021
   Val:   Loss=0.0831, RMSE=0.2882, R²=0.0035
============================================================


📊 Round 545 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2458, R²: 0.0018

============================================================
🔄 Round 546 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 546 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0040
   Val:   Loss=0.0749, RMSE=0.2736, R²=-0.0077
============================================================


📊 Round 546 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2458, R²: 0.0018

============================================================
🔄 Round 549 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 549 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0027
   Val:   Loss=0.0755, RMSE=0.2747, R²=0.0021
============================================================


📊 Round 549 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2458, R²: 0.0018

============================================================
🔄 Round 551 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 551 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0036
   Val:   Loss=0.0887, RMSE=0.2978, R²=-0.0036
============================================================


📊 Round 551 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2458, R²: 0.0018

📊 Round 551 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2458, R²: 0.0018

📊 Round 551 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2458, R²: 0.0018

📊 Round 551 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2458, R²: 0.0018

📊 Round 551 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2458, R²: 0.0018

📊 Round 551 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2458, R²: 0.0018

============================================================
🔄 Round 558 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 558 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0048
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0069
============================================================


============================================================
🔄 Round 559 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 559 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0032
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0001
============================================================


============================================================
🔄 Round 560 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 560 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0012
   Val:   Loss=0.0774, RMSE=0.2781, R²=0.0081
============================================================


📊 Round 560 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2458, R²: 0.0018

📊 Round 560 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2458, R²: 0.0018

============================================================
🔄 Round 562 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 562 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0031
   Val:   Loss=0.0829, RMSE=0.2880, R²=0.0007
============================================================


📊 Round 562 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2458, R²: 0.0018

============================================================
🔄 Round 565 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 565 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0022
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0096
============================================================


============================================================
🔄 Round 566 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 566 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0046
   Val:   Loss=0.0838, RMSE=0.2894, R²=-0.0190
============================================================


📊 Round 566 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2458, R²: 0.0018

📊 Round 566 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2458, R²: 0.0018

============================================================
🔄 Round 569 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 569 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0033
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0005
============================================================


📊 Round 569 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2458, R²: 0.0018

============================================================
🔄 Round 570 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 570 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0012
   Val:   Loss=0.0800, RMSE=0.2829, R²=-0.0027
============================================================


============================================================
🔄 Round 571 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 571 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0022
   Val:   Loss=0.0890, RMSE=0.2983, R²=0.0040
============================================================


📊 Round 571 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2458, R²: 0.0019

============================================================
🔄 Round 572 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 572 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0018
   Val:   Loss=0.0801, RMSE=0.2829, R²=-0.0042
============================================================


📊 Round 572 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2458, R²: 0.0019

============================================================
🔄 Round 573 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 573 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0013
   Val:   Loss=0.0860, RMSE=0.2932, R²=0.0032
============================================================


📊 Round 573 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2458, R²: 0.0019

📊 Round 573 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2458, R²: 0.0019

============================================================
🔄 Round 580 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 580 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2836, R²=0.0009
   Val:   Loss=0.0834, RMSE=0.2889, R²=0.0089
============================================================


============================================================
🔄 Round 581 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 581 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0020
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0046
============================================================


📊 Round 581 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2458, R²: 0.0019

============================================================
🔄 Round 583 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0702 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0702, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0702, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0702, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0702, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0701, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0702)

============================================================
📊 Round 583 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=0.0027
   Val:   Loss=0.0702, RMSE=0.2649, R²=-0.0143
============================================================


============================================================
🔄 Round 584 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 584 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0032
   Val:   Loss=0.0779, RMSE=0.2791, R²=-0.0013
============================================================


============================================================
🔄 Round 588 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 588 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0028
   Val:   Loss=0.0857, RMSE=0.2928, R²=-0.0012
============================================================


============================================================
🔄 Round 589 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 589 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0014
   Val:   Loss=0.0736, RMSE=0.2713, R²=-0.0035
============================================================


============================================================
🔄 Round 590 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 590 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0026
   Val:   Loss=0.0876, RMSE=0.2960, R²=0.0021
============================================================


📊 Round 590 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2458, R²: 0.0019

📊 Round 590 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2458, R²: 0.0019

📊 Round 590 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2458, R²: 0.0019

============================================================
🔄 Round 599 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 599 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=-0.0013
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0126
============================================================


============================================================
🔄 Round 600 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 600 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0024
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0026
============================================================


📊 Round 600 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2458, R²: 0.0019

============================================================
🔄 Round 602 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 602 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0008
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0071
============================================================


============================================================
🔄 Round 603 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 603 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=0.0026
   Val:   Loss=0.0782, RMSE=0.2796, R²=-0.0001
============================================================


📊 Round 603 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2458, R²: 0.0019

📊 Round 603 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2458, R²: 0.0019

============================================================
🔄 Round 606 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 606 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0033
   Val:   Loss=0.0757, RMSE=0.2752, R²=-0.0030
============================================================


📊 Round 606 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2458, R²: 0.0019

============================================================
🔄 Round 609 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 609 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=-0.0026
   Val:   Loss=0.0875, RMSE=0.2959, R²=0.0013
============================================================


📊 Round 609 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2458, R²: 0.0019

📊 Round 609 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2458, R²: 0.0019

📊 Round 609 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2458, R²: 0.0019

📊 Round 609 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2458, R²: 0.0019

============================================================
🔄 Round 619 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 619 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0030
   Val:   Loss=0.0875, RMSE=0.2958, R²=0.0018
============================================================


============================================================
🔄 Round 621 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 621 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=-0.0001
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0104
============================================================


📊 Round 621 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2458, R²: 0.0019

============================================================
🔄 Round 625 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 625 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0037
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0037
============================================================


📊 Round 625 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2458, R²: 0.0019

============================================================
🔄 Round 630 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 630 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0055
   Val:   Loss=0.0780, RMSE=0.2792, R²=-0.0157
============================================================


📊 Round 630 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2458, R²: 0.0019

📊 Round 630 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2458, R²: 0.0019

============================================================
🔄 Round 636 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 636 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0037
   Val:   Loss=0.0818, RMSE=0.2861, R²=-0.0027
============================================================


============================================================
🔄 Round 637 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 637 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0046
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0180
============================================================


============================================================
🔄 Round 639 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 639 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0028
   Val:   Loss=0.0867, RMSE=0.2945, R²=0.0022
============================================================


📊 Round 639 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2458, R²: 0.0019

📊 Round 639 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2458, R²: 0.0019

============================================================
🔄 Round 641 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 641 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0000
   Val:   Loss=0.0868, RMSE=0.2945, R²=0.0116
============================================================


📊 Round 641 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2458, R²: 0.0019

📊 Round 641 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2458, R²: 0.0019

============================================================
🔄 Round 646 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 646 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0020
   Val:   Loss=0.0754, RMSE=0.2746, R²=0.0035
============================================================


============================================================
🔄 Round 647 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 647 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0030
   Val:   Loss=0.0732, RMSE=0.2706, R²=0.0007
============================================================


============================================================
🔄 Round 649 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 649 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0039
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0087
============================================================


============================================================
🔄 Round 657 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 657 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0027
   Val:   Loss=0.0866, RMSE=0.2944, R²=-0.0010
============================================================


📊 Round 657 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2458, R²: 0.0019

📊 Round 657 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2458, R²: 0.0019

📊 Round 657 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2458, R²: 0.0019

============================================================
🔄 Round 662 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 662 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2820, R²=0.0035
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0112
============================================================


📊 Round 662 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2458, R²: 0.0019

============================================================
🔄 Round 663 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 663 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0035
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0009
============================================================


❌ Client client_11 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8690 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8690 {grpc_message:"Socket closed", grpc_status:14}"
>
