[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 890101c3-0a00-4825-9291-bc1c688a2e04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 874d469c-7aba-4adc-8271-0b8f5ff2d2f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 943fba67-1101-44e7-8150-80858000010d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4ea40be-3e37-4af2-8981-ef4d27ee8ec1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 473d6f88-ac75-4223-8fe5-2bd5299a5a37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23faa01c-504c-4bdd-9df7-4c26a78e960a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7a37950-6ddc-4bf0-989a-ea18a779aac2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f825b42-4e28-4838-87a2-bf29a7bdfcd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8485dcf-67b4-4e52-ae8e-610928c59b16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd8a39d6-c13a-4d22-87cc-856cc6ee8f62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 711c8530-e6fa-4d8b-aec7-9e5b2cfa50d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d63d9a32-5464-4562-a0ab-d6ef3ebbe46e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34ca4473-2102-483f-86e9-98725395e92a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f31cfbe-f36b-4c0e-bcd0-2df62b864519
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd06e0b7-b1a5-46c1-9973-3797ab3f3e2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01b2e09a-67c3-4122-a335-3342e1587a2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 688633d6-a3f9-42fb-a9a0-b6511dd8e53c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9174b164-11f3-4ef7-9629-ccec2b462de3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5dd3b024-6a4a-48da-8b55-c550baa67c13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2302e02c-b08e-4ee0-8944-027711d7d95a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02bafd93-9196-41cd-b516-e7d679ce785b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e0dcde4-2cb5-4469-a896-e1637449aed9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2221bfb5-317a-49ad-9d12-f1f39b187977
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a8ecbdb-ccf3-4386-8fd6-4c8dae26456c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 171006b4-d058-4339-b349-0abbe2216542
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39afadc7-3e9d-4b99-a082-7960d107312d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e757fc08-24da-490f-a193-d8593d2fd70d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ad0bab0-9597-4ff2-b409-cc0a357833d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ec61c42-9e2f-415c-82af-6b437ab7b19d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea953c04-17ad-4994-ba94-eeeee3068ed2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36ed2029-78ab-4fc4-b2a4-f02276e60eac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31b4dfed-9caa-4f70-b110-bd833c9636e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68468875-994f-4b63-a853-ce09a1dc42c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f935bf92-7531-40d1-a6bf-757349f02d42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e121ff30-6535-44b2-bdb2-3eb03fc6a87a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a268e4f6-beb0-42a3-9270-bd6a08a9facb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b43a60b3-ff6c-4e27-a350-c1f9c4d790c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd6bd63e-614d-4317-9bcd-bc8ebb64570c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32674822-8bfa-439a-b364-2b1b8e2910d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a82b24a3-1f8f-47eb-9a03-af93580d6299
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8fac3d5-7ff8-426f-aba2-bef61fffaf7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c13f204a-157d-432b-92f8-e7e9cb5d4d2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49db64c0-3f76-4ea2-8078-c51fa0ccbbfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c5b6212-c8dd-49a6-a60f-5a6080d4337d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50e0680f-ef4c-4bb5-a3bb-23044cc818d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d86562b-6435-40b4-9beb-5dfea7d74e8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7010c5d8-10ba-4bb7-ae9a-4c462cd91811
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00339509-8d37-4cb5-855f-4b64cd1a5bad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e8ac302-da4f-43e1-8a13-984079c4150a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4569dd6-317f-4d87-b4cb-49b6fb348d97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6871e54-80aa-4e82-ab27-fe8c6ec20133
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5db2c99-4277-45b4-bdfc-684052f26964
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9293c35-bf03-4c6e-ba63-fe4be5802a1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88f0cda8-a49b-4e89-8e3c-e5bbae0d3a62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4cac20e9-f877-433f-98e5-11846bbdf652
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2004d9e8-91ab-465a-bb38-c4a84b595298
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02bf1910-42fe-4def-95ac-cfb30d516c4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1460b038-ad34-4dcc-884a-c20c4e801ef8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5029af57-4b40-4d52-aab2-07d8021ff93d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fbf6d7cc-a9de-4ec1-8d72-e4b060ab138a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 217b517a-0218-4ed7-a7fb-dc77d016e65f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c836e25-5f93-4898-baf2-e799294f045a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 719bbae9-bfd0-417f-a9d9-c61c206fcdf1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f379cf82-4718-42d5-9b69-00210ef05112
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a257a97a-746a-4ea6-a527-e72bdc4079b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0959cd2-9a94-468d-a1ff-b33cec7c8de0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9c001bb-0fd3-434c-8c13-e5d764017514
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f5c325a-3e1e-4f32-ad67-e7378706447a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69d1c815-e220-468b-8a7a-197b030ede15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 894e39be-f146-4cc8-a51f-60d9328b4cd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5dee497b-0175-4976-bf6f-fd8f9511c8e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55b1d6b7-e84e-4768-808c-e8b937092109
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12692b61-17ea-4658-88e8-8ef101152f45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 706759bc-8d31-4bf9-aff5-9b3ba4967c85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e34044c6-cd77-43da-90f8-3b3d01a8a8fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cdf3aefd-ee2e-456b-85d2-e18ae350eeec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e34b618-6d78-4e3d-b2b4-72e4fb5db029
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc0c5241-e71c-46e2-a82d-be3ba922c64a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27d65c64-b01f-466c-90f2-7a4ca93fcb11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8705a7bd-670d-4fe1-9571-db31adc15cbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb5c5d39-491a-4fe8-a6ea-b959b26c6171
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46b279cc-9e96-4216-82a2-833c164bed58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f206cb1c-2227-41d4-94a5-fcdc88ae32a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc9ca68a-44b1-48a4-a341-81fd7facaa79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7eab6aa4-014a-494c-b0c3-c75eac32dec7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 098b2cde-c2ce-468e-bd27-80b4e5cbd25b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ecafc41-2cd5-47b3-b6c9-abf394f69e03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 111d7bed-17fe-4f8b-bce7-720a6706a296
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9d3529b-c890-4452-9df9-20e9fea7e01a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8209343d-f719-418c-a967-c3658ff1fb14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3078841-0889-4844-826a-a2ea78378933
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f13e8103-6a4d-477d-9122-2e2cc72e8e1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ecf9b47-0ea3-4213-91c9-bb7b7603dacd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0f359d2-8d27-4d65-886c-9f4eae291ab4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18ff1af8-8616-4f7a-ab7c-629ff3ee4488
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9aa94a9-f781-4792-85f5-6e59f248bc53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73cfffed-d9a6-42b2-b29f-dd6fa1ebdbad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d51f8145-c9c6-4362-bf33-0951d629c2f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6eee0b7-e860-446d-997d-decf195f65f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e1f451f-96c9-4f45-976e-8f0908fc5cbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a33035e1-5fa0-4d4c-8bf4-ec94ee282eaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1072b7f-3b2a-4656-b118-7c86dba5666a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 121e033c-2d3e-4af4-b4c5-765e7b10a811
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9cfb69f0-c0c3-4661-aabb-f5bf8e511d85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de5bd7e7-a05a-4853-aee5-73f1dad25102
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80a52e27-5ef5-44bd-9b20-b1b9012cbf60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 404bcfe3-9111-495d-b9e0-c00d9dfc1bf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d58196be-f42c-417b-a380-1ed97593007e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0821acfd-ad8b-4dd2-837f-e57064a617b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f69dabd2-4205-449b-8dda-1da4dd43de08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7fb5923-fc67-4194-b086-ffa83888260e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a127edd-a960-4787-b220-03a22fbf3cae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42572089-db21-4d19-b8b2-184849dbc781
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b630853e-2524-4d41-a320-60292ed25ef6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05463c92-2110-432d-aa08-9826b1d4dc44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message acf31815-8f35-4297-abb1-f4e180779707
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 529adb8d-136c-4de9-ae66-eda1e253d2ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3fef04df-4d82-4905-bebb-c29ec95f1ef1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33487e2f-21e7-44ad-813f-f0e3f6f20d46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3dd8e681-7335-4f39-bcce-b16366f9d439
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 235861cb-5b15-4ac9-acef-07d847865034
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6137420e-b983-4e16-9936-ecf7e89bad69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f71a852d-bef0-4978-9e3b-09492a141780
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73ba7ebf-7d3c-406c-a96d-1a7a8d52fc96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48c5e28c-eecc-4660-8031-e4743d17fd90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60609b6c-a41f-4ada-a18d-ef1015995853
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03c12d0a-0c62-4410-8b49-59db8cdb7d3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33157dc6-1106-437b-a7c0-6aa7b72f019d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97ad602e-ab18-466c-bc3d-80013adcd690
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1bd28553-3ce6-493e-9269-b736ede4132f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4cdbfbe9-cc64-4afd-b555-9eccb18c81f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21b64459-be42-4bb1-abba-ca8a45b49bbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 282b3121-363d-4b78-a398-a67a729f00c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd39a8d3-d2b6-4c8b-824d-c8314d32be45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 705d6740-17f5-404d-bea9-ce5a3a0cfee4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7bdfa4d3-a31c-4c33-a5b2-dda29883f3d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2521efdb-9e41-4343-9743-174898b85e2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27124f89-b500-43ab-9309-405ff83a2146
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 177789ff-2967-4547-aef4-741ac1c5e2b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1a96ea4-d9c2-4ae6-969a-5171e844c115
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 988a7993-c4b6-4f56-9583-710d9522dc1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81cafc31-7985-44e2-b942-dc7a6738d7d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e83205e5-b770-4c95-b04e-942902859268
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e864c86e-236c-4a65-8c96-e64697b8ad80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1dfc782-58a3-4051-a9b5-5effc849dd75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d67109d-97f7-4965-a822-5736d60f7d29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89d4b55b-9f7b-4c4b-81f0-6cb58d6b4433
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe34f88e-9032-4620-b821-84bd0c554ad6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7d9c9e6-01e6-4911-b95d-c8a0e4730f22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac82e238-848c-4297-b53b-b1fc07f4b5ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99eac869-4a94-4e8e-9c5a-7f384f8b1e66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d83f073-12e2-462b-bbda-8aed83bcef65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8693d311-4a1c-47af-8281-539a331dc804
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f94b4f7-d4a8-4eba-a74f-a168a3c7695d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b3053ea-ef0f-4eb3-ab3d-8810d2d63000
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c848c54a-5480-4c48-a5fb-31a29a7063f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message addbf07d-7d6b-4a45-9be0-9c39f09be8a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 193e6266-4a66-49b2-970d-efb38d12a91a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e770a93-7ce9-4530-8a1c-9012a8c00dce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 336137b0-b570-42e2-886f-624a70c883ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d6c1a77-6f2a-4ac8-a5b4-62f6139e8048
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9682f0d-2749-49d6-883e-8790621da191
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e993ce93-a8b8-4e83-9b42-1e9afdd93147
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f75a974c-a1af-44f5-bddb-a4c310bf17a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d892ec3-8bb2-4b37-8cc1-f3156d4bb93e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa9d34a3-98c9-4a10-8808-d61f947e4f90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0cb24b9f-b7a1-4cd8-b213-524311207020
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a251190-a855-447e-a5e6-ba7312f70e3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f88c641e-ec29-489e-9277-fb5afd1ea745
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6750615-ceb0-4e7f-8c13-43a996d11a2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c319cfe6-a23c-41a4-b191-7de82a9e5078
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67e89e20-fe92-4ab2-9daf-46a53a1f6993
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe5fc81b-494e-47a0-8c1d-7ee75bdbc9c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7166257b-67a3-45fa-8b1f-c6e2c151c55e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2814f288-4832-48cf-aad2-9fa22d64f125
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d94482a5-971d-4d36-a80e-df5425eaf0e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59535fb5-5733-4787-9efb-51708285e181
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62c6be9e-64f3-4564-8be1-075ce6074e16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb3f8884-5076-44d4-8fba-7432e5595672
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05a6143c-62ae-43e0-886d-ee785cf5d65b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f4ee665-8232-4b3a-b024-577535920e39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c90ee025-3205-4dd6-ad4a-17d3c5dc9202
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9f2e9cb-4518-4ce7-ac06-2ede23f904a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61b8ee94-2b45-4156-b349-689d3990a5b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0200e4a-b85e-4e9e-99a4-4b2a78f77929
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3fdbb3d-935b-4df0-8283-09953ae59035
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d7e8ce0-f1b2-4751-8594-1e1ab7724474
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 714aa5a7-94df-4f4e-91a2-2fa2ec2be701
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6016cfe5-f5ea-4c25-8fb0-6d853a8819f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d71f739d-0dbd-45f4-bf0d-cb1ef0c9e337
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bdf99dc1-f051-4342-868a-11eb28d1f30f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26787d4d-585f-4c26-890b-68bb93ab750a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c83f930d-7182-42de-ad61-f4e296817c2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0fe6a919-b55b-4ddd-84ad-a417557283e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b249eb7-7f66-443a-90e4-1d30a1d6c456
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb361d78-69c2-47b9-a8bd-9511b3c5f86e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fac49902-9c1b-4f91-b055-0283d3b50c25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a2d688b-d524-4dd0-8452-b65236be46f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e545170-9f69-4198-8479-0515e532a8d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed8c074b-9ce6-4411-aefd-bfbaa42dbd88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9711682-bd62-4e49-92a3-45c257f9887a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da574099-1ef2-40a9-b65c-d6e8d3b49b04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75bb7e40-7845-47c1-b5be-9133a31be1a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d8fa40d-d152-49bc-8d5b-99405c0d9640
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7fe39a71-b9eb-41bf-90b5-453ec364c656
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0f2ff2c-c646-4a25-9079-3234bcba73dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d636449-2ba1-4851-b2d8-8115c4c76993
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff1909e9-52f6-493d-aa74-f47f42140287
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0856c4b4-b2c9-4e33-8048-430f23a0b453
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff85720e-73d0-4a41-98fd-be6375c975d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf9e74c2-bcf6-4263-9a94-bef2128de3db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 314dfaca-6508-4682-9362-31a10ed667d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 743a94bf-5999-4380-b2be-6649a854229c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 204a20ce-5f55-40c9-a8c8-8fcce32d1b17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7efc09e2-afd3-433e-8af8-5135a959418e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89499f99-ac05-43fc-bf66-0468529b5a96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f94d9b4c-db9c-4ecb-b412-a9c3397095df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 425a8a46-037f-4625-a483-ac0d53baf1d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42595ae8-489c-4e52-a310-73c3e1c2ebd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 498c81f0-a608-4a7f-b69f-d9be899ed5c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2370744-a654-4ae2-8148-6997461ab996
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f494879-eab4-4c6b-ad6d-82edc171fe10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9076c42-2b99-46ef-a0d0-b382b8144677
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f9a18ed-cc20-4f8c-af79-046440cd2138
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81ac0d30-2f0e-4054-b2af-3899441383fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad0fd90c-b04d-49df-bee7-f20be91005cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f65dd5a-68a0-42d0-a4ac-dd2526401163
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9359674-67c9-41cf-857d-42d0cdf4fcde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e13a7583-852e-4ab2-bd4c-fbac9d135714
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4cc3d411-a76c-47b6-b05a-c55bf89c69d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7ada680-cbbb-4f35-bbe1-067d605eb627
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c510109-319e-4878-96a8-68346242ca0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 435a68af-7ea4-4881-b41f-f3530597d108
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a4697bb-e6ca-4ee1-914a-6178fe9bfb40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 236d462e-a031-4681-b384-5d5f2b48037d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b591ad65-6c1a-4c3c-a130-f645278cc532
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4be07d39-72b0-4449-b69a-76e63a23fa42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69a20397-8455-42f7-ac01-15b59c0f9c4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df1a077d-326a-4ad3-854a-b6c178aebf61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bff8fadc-f1d9-452e-946c-93aaa5f004b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e38b6163-7126-444c-bf2a-a017d1ee39d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02ba4ca4-8c01-4c31-aee7-2bfbddc9ffd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f407c1c-88fd-440a-9a8c-121185330631
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5090759b-ef3f-47b1-88a8-6540f637d62f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12bb54b3-2d2e-4494-977d-bb3eb905e738
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f9788b7-edcd-464e-b6d3-19e5cb747fb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7fcea515-6acc-4cc0-a0e9-46c6d6b3f536
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7adfd6bf-7059-4edb-a6d2-61e2f46a7e82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 480afa3e-08a8-4c47-b591-398e193e68c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74c2eee5-248e-43d3-aef1-3fde2ea2c453
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 929d9eeb-169b-431e-9c5b-9fef510533c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c3f74dd-d4fe-49e2-9bcd-121e0613dc83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 188aed24-2789-434b-973a-9c07f5f62307
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41c13ed3-9970-45fd-9d17-68004e3d00e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 784c61dd-441d-4c8d-a389-3dfa3c87b11e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c76c3e0-b086-4468-bed0-66098e7c428c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 695051c6-67bd-460a-916f-7a677496a9f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f624466-34e5-449e-a6ae-9aaab69e5fcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fde8cf5e-b5c6-4eff-b7c0-07d7026e690d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a67b0454-dfeb-48f6-9264-6439a7484989
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38483f91-06c8-40e8-aa77-0f9676b43c9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72b0d508-d4ac-4e36-8d94-e6c06557808a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 419f6f8f-47e1-4dc3-9691-8b1923f708bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e430e43-dc9e-4c67-abc0-8212fd12a6f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f79a1119-5bf1-47c5-bba4-224569bf7460
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5a8d535-5306-4ac9-855d-858c84fc64f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8421cd49-3017-440c-becb-a60238749dd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 036c29ee-1b74-4292-b646-26433f7794b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7efeb25e-be31-4e2f-bbe5-c78928a3fc81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d972f50-a209-49ba-9b7f-52971ad725a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e333561-6052-4df8-80bc-1fe56663baba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31f1b3aa-e1c7-401a-ac9c-6211f0445212
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 069da3d1-bcae-4175-a09f-bae4b7a9dae7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f459cd6-0395-4a56-bcba-d1e2bf4c7347
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c23cb8d1-8fa8-4c39-88ef-1c89ffcfa937
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a3c6ab6-4116-4c57-b100-75edecdefc30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86946ba7-f0c2-4e23-b0b4-cac4d36d8135
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d4b9740-3067-4e97-b1fe-13bd60df0896
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40400ee5-cc26-48d5-9654-55d68c81fc33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 610d222b-87bc-48ed-954f-d726491c9794
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e2190c9-a026-4c3c-ab90-4436a2e431bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6ec9e70-221d-4ac1-b350-5cc37f3c476e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a175525c-3724-44e9-a841-558118853a82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3fb8ba99-acf0-4d4c-8c42-09aebde3fb1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee554a3b-1803-422f-ba86-b629ba7a9cea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d3dadb7-3806-4fba-ab9e-4a11f8b1fe0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02b82957-57b8-4a59-a6eb-adb34051ae54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b12fadb9-7f13-4903-a166-cf66c22ca5fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74f9fbe1-a544-434f-be85-7f807ef9917f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a67ecc7-f64a-4df2-8e00-ea08b6d80219
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ac2584f-7370-4f0b-9767-5ed4863a5a4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50391dcb-404b-47f9-b817-059ac6e29723
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f0425bf-0558-440f-8f3b-f588cb14958b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message deadef29-e588-425f-b89b-8b123609407c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 813296fb-7d46-4933-8b11-3f6a5b3e532e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51197882-e0ec-4936-a120-ad52c3f560aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 603d8907-5f58-4a0b-9c08-a3b236904971
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ada9be9-bd60-426d-a824-a0ada0bbf605
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a18c8e9-0e4b-4c06-97e2-14a50a8b526c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7aa6ea34-b7e2-46d0-b519-4ca3f8e0509b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8766a9b-605d-47ec-9322-5cfa2b1c7033
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ffdc981-d232-46c2-be68-d7289c80eb08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dcf28f1f-2498-4a80-b111-0a94b0ef5adf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 687ce381-44e2-4b0c-ac0c-4cadaed4b882
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a62661e9-8b9e-4972-8737-6012aedb53b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b093f038-0cdb-44c7-b5a2-76c2d4a1aa15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a22272a-2f96-4bd5-a63e-6dedc4be806c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86851eb6-dabc-4fc2-b329-d1b0dac3f033
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60127ed3-a100-4669-b5ab-12a6bcc0706a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 064e6e38-7abc-4137-aa28-9c3213e9de73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7bb50ea0-fb34-4265-866d-4224e5360034
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 259c2afc-a7a5-4456-b665-8baaf0f12f88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f74b9a6-e119-4a2e-9d54-2cb11b3d82de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8a72067-0925-4dbf-a266-3bcf1fa00953
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7057c72f-224a-4fe3-8b8a-ac246ef2e676
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 443dcea4-c523-4088-a647-c1eb2d568b43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2067094-80e4-450b-9fc9-350cb860a5cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5b2c448-e018-45bc-97b5-f9cd497cf5ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6515df5-9ac1-4eb7-a018-5fecfd360912
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c5085db-a16d-4990-93aa-8eadcb2f7865
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf429f2c-f79a-4e42-a8d3-2ce6a91024a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18f5e1de-9c92-423e-ba45-6abfc148b24e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd1966f9-0a1d-4c43-824b-82f21813660c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c890681-b291-4fe4-8f10-9dc73035657f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44522344-dd31-486e-b6ad-b06a90adb838
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1e221ea-edd2-45ec-9f3f-286ba9713434
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c410f58-fb0e-4b83-936d-8a37d59ec313
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b61dda5-ec56-4c13-9614-9529f85a6dc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c61ad8db-4243-4796-a6a7-bafe456e3dec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49744fd8-8fb6-4761-8c26-9c4373b395a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4ef97c3-f535-45e9-aa13-272aa776fcf5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1cc8f14a-4de0-4c5e-89d9-bbc346fc1488
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e27aa2cb-2228-47c8-9e5c-51fe19c4bea9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86a43c98-24eb-4450-a6aa-695b6b599628
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c141c358-1c24-4f31-80a0-ddab250550c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9947024-6c25-40ef-bc50-083a8ba870bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26438831-c5cd-4888-965d-de9e87bc961b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b874716d-5dc0-4c3e-962a-bb65953bbff3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ccb38fdb-fffa-40a6-bb1c-437088275d55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2803e1e-5887-480f-a19c-ebb8185d91b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b92b6362-9ddb-4e77-9710-077b6dbd0f59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6265b0f5-1ea3-4e58-a38c-93b4bc8dfc7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39ac4868-1aca-4fbf-8da5-07c4450ad66b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03911da8-6946-49d6-b9ce-06b388405ea1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7f2276b-9c36-49e7-aa40-c26d6f3730bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7bbb5321-15b7-4881-a8b0-012d7a2d7218
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f39a074-dbfb-4708-b377-4bf84f6e1229
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f445ec8e-ffbf-45e4-beaf-222c354e841b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed2f547f-8701-4d59-8956-226e437249a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e05853a-4b0a-4e46-9502-9fed4b05878d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53a7537c-c90e-4205-adef-3c71df113ce5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45938311-7beb-456d-a892-079a0d1eb716
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3b2016d-c779-40d5-852c-7a0a71c8861a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f57133bb-5c3f-4617-96da-4507e63c2e44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c62bfce0-0d55-4445-b084-d81aad7de925
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87d446b0-1ab0-4690-8701-10d39a45bde7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6601fc89-0fbb-4de7-ae57-97870c182cbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e03d9a7-d7c7-4f87-aa45-837e6efd8629
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34c97dc3-4157-4e92-808f-9397a2a3a9fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70289f6b-19ad-46f5-aae7-93da1bc30a8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7aba78d1-c9de-4615-b84d-ed970a2f48c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f491bff-fdc9-4cc4-82fd-9eeca4cc32de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42f25fd8-4c66-4df2-af3e-f7080aa6dd09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5433580b-dd0c-4f3a-a684-1fdeb168d665
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d0cc054-912c-4201-bdd5-80c1bf2cf013
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6a8ad3c-126b-47ec-b930-2f302881ebb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ecadabf-e781-487e-a3b4-1f9fa8850e74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb02238f-83ed-4849-bb8e-5447b16312b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c51ae917-d984-4237-bdc0-d0d8a58205c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 443a62ef-bea3-4c31-81e7-d67d2c47d6be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc475f19-7a14-4564-bae5-ca5cc3cbe9a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69a2c840-a346-490f-9b1d-a306524452d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7bcd6a1-de4e-4e9c-b97b-d95c351684e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79754f38-5bcf-4b45-a47e-8b4ec19d0c63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac217209-b736-4ea2-8ef3-65f04ffc6c96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf03669f-104d-4c6b-8abe-ec357de42b26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa36166e-8b5f-426d-be90-47d8af1305c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c54fd875-dd33-4afc-b4ac-34bff5612a81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d62d7013-9974-4659-ac7a-7638d394c645
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06032c62-be5e-4261-bcd2-14109752a8ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a15c5ba-ed38-4638-9bf6-88f396db90f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8550ec2a-7e85-4205-a318-47198c0a3587
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 008db086-3cc0-4390-9bc2-40cd30ae74a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07434982-6fc3-4cc9-8323-f332f1cf152d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38327584-a42b-413f-b1c1-7f555c42a794
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5ec331b-750a-43ca-bc74-93d048033c2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e50d2d5-f1ad-47f3-80ea-878eaf26d4cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f95c0370-eedd-4407-a950-f8bb4dab8efc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cff4e567-193c-4af7-b2e2-7e9dd4f19732
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca00502f-e7c0-4e3b-bb1c-eb922d801a36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f66b2ba-26af-429f-a44a-c739f08858c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e9d332f-cc0a-410b-aa3e-50421238aa3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5dd54cc-2ea1-45fe-8e0e-c3eeb439e229
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09d1866a-5c2b-4164-8c4e-91eee6343827
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d94206df-1d2f-4f3d-8908-f4fed4b513e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6904a361-2043-48a8-80f1-6d9d8f815579
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e27d330-7179-42d8-ab7d-fe55cdfef79e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99ef256c-ca7a-4054-b503-85412c15454b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8381e782-7c11-4058-9bf0-c6707c985e63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a29dd823-ea2f-40f8-9d5e-7615996fe7c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6bfde6d4-e2b8-428a-bad7-8fbc570758fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89cb669e-a384-47ba-bdd1-89f9a34137c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f8bdb78-5b80-485f-817b-e69d423fa8c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e154492-4289-41cc-ac7b-36821f1fb077
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c1046af-2a37-4c14-9e13-56e0c1f52b37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66799d4a-5eaf-40a7-9055-0da55cb910ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b1fd29f-2f55-4f24-a380-7878488fe23e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 209cc20d-91db-4303-a88a-373ddd47b2dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b79a5931-a847-477d-8a57-b50a7387a88d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 170a1a4d-bded-4e93-a3c8-c9c426d10e67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf0cc24c-3432-4d27-bb19-36d8752cde2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45575636-dfe7-4216-a390-829e6fae6720
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59ed519b-f5b5-4c0c-9400-7a9710ea0ce5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8593e05-b6dc-445c-895e-0c289afa8d8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd757243-8fcf-4faa-97a4-26718d73f4c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39139c13-279b-486e-a665-22801acdd86a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fbf4d80e-2481-40a0-b081-c51bb6210ce6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50a6830b-4b84-452f-a830-2431e54322f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8f0ae59-2bf4-45ff-ac7f-06cc5b70877b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a7c5db5-9211-450b-96fb-eaccbe12dff7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 933022e3-b23e-4c0b-b10e-7037e568c8fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad966ef9-6815-4e0b-9062-7cdc5f18eb2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b2a8a8c-7add-4d62-8a77-bb92a457ea7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1519602d-b54d-4521-a471-6d32a4b5f0ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9366c9d0-5829-4f3b-b495-789a30b4db75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1621e92c-1bd2-4484-8a15-b766c1bb2493
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d7ce7fa-b89d-4051-b80f-abc60b7e7fb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7ef1f45-c83e-4259-8b0c-6b38a775c8ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d913913-904f-458e-9067-d0c88c30b97b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88eadb0f-9e8e-4648-8bca-817284a7d2c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfd14123-d7ce-4d81-a93f-178bf3a0a3cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ecd7ff77-6d04-49fb-a084-8c59bbc26ba3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8f779b1-e175-466f-abec-51f66547098e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4768193f-db64-4ba7-9703-304db35a640a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d783a89-8a5d-4e10-af0b-3f8c58f242df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9850a8a-5bbf-4f89-b601-96f696b061db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4482ba9-75f8-49d9-95ee-2b2e3aabeb2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7eef292b-891c-4585-b6a0-1c5f93027fb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5b73401-7965-43fa-b646-db95d3e1a6dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72143c56-e16a-4ffe-bc78-e35d5d80a27a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f8a4034-014c-44e6-8f36-788447663fe0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6187f5fa-5bed-46c5-a600-ad2f3b9314ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f2ec68c-549b-4f37-834c-8ea0be3b0216
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eebb7304-c592-45f8-bc64-7c8b538c59f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22f8199f-2dda-41f8-8722-261dc66ab861
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1bf32c0-3c7a-44be-bf5f-447c28a51895
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 309aba96-f955-40fd-9811-830d920a301e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e3cfbd4-e32c-477c-b067-afc3397022ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9fe8a069-c67a-4d13-8921-e073f4e561d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7e6af37-d535-40f1-8825-f399e2cf73f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3717f030-204b-4883-a8e6-797e5c7416e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff229c31-2dda-4d9f-850b-98d8e0facc29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02169749-88c1-4b2c-bafa-f48bc385f54e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69a11228-5cbc-478d-ad1b-5cdc261bb359
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8790f6fe-4f62-468f-a4b7-f4bc33b9209c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5af6359d-9515-4359-bbb0-511dd5616767
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c222f00-af07-4217-a797-9a3c2cd665a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff2fcdaf-ac17-4bcc-a9b5-a502e8ce9bfe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79866959-5477-416e-98cb-f49a22b4d2ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1230ff08-1bda-4fb5-8335-88e1571e2601
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e2c743f-a8b7-4c37-be60-5c0cb8c7f5ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d18df039-1caf-49a8-b757-cfd42bc90327
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2dc67e54-1c39-4cf3-ae81-b1effe349503
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message abcc0eb8-782b-4691-a48a-3a2d5911c3b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d713e20a-47b3-4377-8333-23a82365abe1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31588eea-3e61-49d4-9e92-35afe54e9fc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3cc28ced-8069-4e2f-8c84-4ae2614589c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5247cb9e-05fe-4caa-b396-40d7e4f492ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 559743c0-425a-407f-92e6-8485e2934d8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9788c389-caa4-4bc6-8065-aeb4c0999b5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36e5c15a-427a-4d9a-b0ab-29bce0b09199
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ea8b5ec-afd0-4c23-84b0-12d2e6584e0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75a23e0f-d825-4420-bc18-3ec9892ff676
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a573806-25a2-4f61-ad2f-a6959b0850bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66c2afa2-51e9-4dff-838f-2d65ba9a9373
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb1877d8-d0e9-4641-aac3-68f3b009eafb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a4d0610-e2aa-4fba-ba06-db4ebae4b07d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74ebabe4-7c2a-4542-9f1f-0e1bb2e07c97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a452dfd-ec7c-462f-b0bc-1fed60ebd6a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ae85af3-931a-4f6d-b889-0c055ebe6dec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f73094f7-8f60-4dce-bf93-3f04a73bfe9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4433e423-95c8-4579-bbdb-a100a733239b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 017e32a8-6e84-4c54-8ea8-087902a3f318
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11991577-22f7-4576-8f79-81474a19357e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9750c19e-d0c8-42a2-a5ab-63dc9c1a50b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c25f088-279e-4b3a-8c07-e929353b5b11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d63062d-d327-4416-b339-a331e939f439
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce87a9f6-d32d-4b01-b103-89a9162af926
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ee523f2-d423-4a80-80b3-d3399d62ac6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6410ae51-77fe-4e41-9afa-6df72f0ab432
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10be060e-da22-4886-80b9-6f7c6d51cea6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a42b915-6270-4df2-8ecc-67e32f72a218
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3bc5328-374c-4c2b-afda-2be4a3371359
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34832cdd-1c96-4ed8-95c6-6059d8589968
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54bcbd1d-f410-44d7-8725-bd83339e89fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb245969-7b6b-4dd3-86b2-168d8333ada1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a03a0e01-75eb-4a73-8284-c6600af167ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e10c34e-e3e8-48e4-b4f9-091ea4783395
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4dd0ccc-b4f4-4427-aa23-2fdbb794168b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ed94153-991a-4279-af26-ef3d3a08e9cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33048c64-8c49-49ff-b502-027881ea1a36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98a4aaca-e756-424d-b8bb-ed12d7bbae53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86b82128-3e48-4367-8fa7-d53bc66132b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b29f5b1-eb2e-419f-b873-5fe4f940c75b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da88d754-52f1-4c68-9fd9-f9caadfbe537
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9a6e4f8-9dbd-4fa3-8f3d-4a21eaeacf8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2c3e3c4-a918-4a37-8188-51a60854a433
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 546807b5-6a19-4bc1-971e-4cacc1486a18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56d5d8ee-e0db-47cc-a5af-d5a56b10e9ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99cc7dbd-115c-4d05-b80d-59265ce0f3ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4cf76a84-53b4-4856-836c-b090aa10f614
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 501269e0-db11-4341-b3cd-6278933c745b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1328369-45df-492d-ad2f-e7420d06a6c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7550f7b-672e-4575-84e1-9fe46fe7170c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa26f922-87cc-459f-9541-5a5eeb3d84d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ca3121a-348c-432d-95de-74777d1eb3f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 745bcae8-703e-45ca-bbc0-838d4ce07db5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3c5f654-6bef-4392-8858-c3309e3301ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e95b2d6-94b5-4725-9afe-c618368437ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2223c4a0-e7f9-4b64-9a67-c4f54bddc488
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40bb4ec4-e651-476f-b2d8-631a545edb2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1b57694-2897-45f3-bb5a-80dd295201e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b21875b1-69f6-4ef0-b704-25debfbd9f76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef6cb8bd-57cb-4292-ad2a-726ddb6d10fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57e0e385-a3a8-406c-a998-54fdf4beda62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e127d7ee-661e-4c74-b4ee-cce6605b3c43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 389b76f5-4ead-4356-a532-cce8d0a7eb2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61a29064-c8eb-4131-9332-885f792bd7fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ab6f8fa-85c1-4ac4-a018-c32f7b73a155
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64446128-b44f-4161-a7a6-0a6c5f5984a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae5877df-b89d-46b1-8ac9-7fd73c475f56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02da2563-a546-44d4-982b-695126a97c93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d5fab7e-7ac7-4d50-9ea1-0fac7feccb88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6d7e065-9a04-4882-8779-20fbe2ea021f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9bfbc6d0-f433-48cd-ad8e-4293f8a35067
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8bd476f4-a04a-4526-b1b3-6cba246f032c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c9b000f-0a94-4d80-93f8-4089cd7fbc9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97055032-3531-490b-b1b4-6920483ce419
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message afb2696e-0d3c-4ac5-b16b-56c8eaa1d63f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d39622e-4616-4391-9fc1-12260d67cf5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 050674ba-a25a-4717-a0c5-16abcc6d29aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1cbe40f9-2bc0-4585-bada-c5861ca6ad79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5aacc724-6512-4291-9f1a-eeebab0f423a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9fb8f29d-0bbd-4878-b319-e3123427c39e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64944490-3806-48be-ae77-71666ad08f40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e6c7cdb-aa40-40df-afb7-649767a1fb59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 410ed7eb-6093-446b-84d8-6cb7d6b439b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5bb7a9f-8b08-4abc-8bb1-40a7c51c8342
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b9095c8-a321-4418-87ba-f8c1dbc5d55c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fff56f86-2a53-42e3-9598-067c350840b4
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8690 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_12
Server: localhost:8690
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_12
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_12/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_12/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_12/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_12/test_labels.txt

📊 Raw data loaded:
   Train: X=(5148, 24), y=(5148,)
   Test:  X=(1287, 24), y=(1287,)

⚠️  Limiting training data: 5148 → 800 samples
⚠️  Limiting test data: 1287 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_12 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 1 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.3240, val=0.1327 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.1032, val=0.0991 (↓), lr=0.001000
   ✓ Epoch   3/100: train=0.0862, val=0.0853 (↓), lr=0.001000
   • Epoch   4/100: train=0.0828, val=0.0861, patience=1/15, lr=0.001000
   • Epoch   5/100: train=0.0830, val=0.0864, patience=2/15, lr=0.001000
   📉 Epoch 9: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0822, val=0.0872, patience=8/15, lr=0.000500
   📉 Epoch 17: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 1 Summary - Client client_12
   Epochs: 18/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0031
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0031
============================================================


============================================================
🔄 Round 3 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0920 (↓), lr=0.000250
   • Epoch   2/100: train=0.0811, val=0.0921, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0810, val=0.0922, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0809, val=0.0923, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0808, val=0.0923, patience=4/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0807, val=0.0923, patience=10/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 3 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0007
   Val:   Loss=0.0920, RMSE=0.3033, R²=0.0067
============================================================


📊 Round 3 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2521, R²: 0.0005

📊 Round 3 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2521, R²: -0.0004

============================================================
🔄 Round 5 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0754 (↓), lr=0.000063
   • Epoch   2/100: train=0.0854, val=0.0754, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0853, val=0.0755, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0853, val=0.0755, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0853, val=0.0754, patience=4/15, lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0851, val=0.0754, patience=10/15, lr=0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 5 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000031 (1 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0012
   Val:   Loss=0.0754, RMSE=0.2745, R²=-0.0012
============================================================


============================================================
🔄 Round 6 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0762 (↓), lr=0.000031
   • Epoch   2/100: train=0.0856, val=0.0762, patience=1/15, lr=0.000031
   • Epoch   3/100: train=0.0855, val=0.0763, patience=2/15, lr=0.000031
   • Epoch   4/100: train=0.0854, val=0.0763, patience=3/15, lr=0.000031
   📉 Epoch 5: LR reduced 0.000031 → 0.000016
   • Epoch   5/100: train=0.0854, val=0.0763, patience=4/15, lr=0.000016
   • Epoch  11/100: train=0.0853, val=0.0764, patience=10/15, lr=0.000016
   📉 Epoch 13: LR reduced 0.000016 → 0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 6 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000031 → 0.000008 (2 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0009
   Val:   Loss=0.0762, RMSE=0.2760, R²=-0.0019
============================================================


============================================================
🔄 Round 7 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0821 (↓), lr=0.000008
   • Epoch   2/100: train=0.0841, val=0.0821, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0841, val=0.0821, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0841, val=0.0821, patience=3/15, lr=0.000008
   📉 Epoch 5: LR reduced 0.000008 → 0.000004
   • Epoch   5/100: train=0.0841, val=0.0821, patience=4/15, lr=0.000004
   • Epoch  11/100: train=0.0841, val=0.0820, patience=10/15, lr=0.000004
   📉 Epoch 13: LR reduced 0.000004 → 0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 7 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0006
   Val:   Loss=0.0821, RMSE=0.2866, R²=-0.0026
============================================================


📊 Round 7 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2520, R²: 0.0002

============================================================
🔄 Round 13 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0799 (↓), lr=0.000002
   • Epoch   2/100: train=0.0848, val=0.0799, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0848, val=0.0799, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0848, val=0.0799, patience=3/15, lr=0.000002
   📉 Epoch 5: LR reduced 0.000002 → 0.000001
   • Epoch   5/100: train=0.0848, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 13 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0009
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0212
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2520, R²: 0.0017

============================================================
🔄 Round 15 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 15 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0025
   Val:   Loss=0.0905, RMSE=0.3009, R²=0.0020
============================================================


============================================================
🔄 Round 16 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 16 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0020
   Val:   Loss=0.0917, RMSE=0.3027, R²=-0.0333
============================================================


============================================================
🔄 Round 17 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 17 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0013
   Val:   Loss=0.0849, RMSE=0.2913, R²=-0.0074
============================================================


============================================================
🔄 Round 18 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 18 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0003
   Val:   Loss=0.0791, RMSE=0.2813, R²=-0.0061
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2520, R²: 0.0012

============================================================
🔄 Round 19 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 19 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0006
   Val:   Loss=0.0884, RMSE=0.2972, R²=0.0021
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0012

============================================================
🔄 Round 21 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 21 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0010
   Val:   Loss=0.0877, RMSE=0.2961, R²=0.0036
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0012

============================================================
🔄 Round 23 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 23 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0017
   Val:   Loss=0.0881, RMSE=0.2969, R²=-0.0068
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0012

📊 Round 23 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0012

📊 Round 23 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0012

📊 Round 23 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 29 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 29 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0010
   Val:   Loss=0.0841, RMSE=0.2899, R²=-0.0044
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 30 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0934 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0934, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0935, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0935, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0935, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0936, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0934)

============================================================
📊 Round 30 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=-0.0061
   Val:   Loss=0.0934, RMSE=0.3057, R²=0.0045
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

📊 Round 30 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

📊 Round 30 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

📊 Round 30 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 36 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 36 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0027
   Val:   Loss=0.0906, RMSE=0.3009, R²=0.0038
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 39 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 39 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=0.0000
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0010
============================================================


============================================================
🔄 Round 40 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 40 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0015
   Val:   Loss=0.0898, RMSE=0.2997, R²=-0.0085
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 41 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0938 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0938, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0938, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0938, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0938, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0937, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0938)

============================================================
📊 Round 41 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0010
   Val:   Loss=0.0938, RMSE=0.3062, R²=-0.0056
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 42 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 42 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0005
   Val:   Loss=0.0877, RMSE=0.2961, R²=0.0013
============================================================


============================================================
🔄 Round 43 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 43 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=-0.0002
   Val:   Loss=0.0755, RMSE=0.2747, R²=0.0001
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

📊 Round 43 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 48 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 48 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0015
   Val:   Loss=0.0913, RMSE=0.3022, R²=-0.0071
============================================================


============================================================
🔄 Round 50 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 50 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0003
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0171
============================================================


============================================================
🔄 Round 51 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 51 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0043
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0012
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 54 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0951 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0951, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0950, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0950, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0950, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0950, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0951)

============================================================
📊 Round 54 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0011
   Val:   Loss=0.0951, RMSE=0.3083, R²=0.0019
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0012

📊 Round 54 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

📊 Round 54 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 57 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 57 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0002
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0030
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 58 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 58 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0045
   Val:   Loss=0.0912, RMSE=0.3020, R²=0.0001
============================================================


============================================================
🔄 Round 59 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 59 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0023
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0205
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 63 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 63 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0010
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0096
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 65 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 65 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0012
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0082
============================================================


============================================================
🔄 Round 67 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 67 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0009
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0058
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0010

📊 Round 67 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 71 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 71 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0002
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0013
============================================================


============================================================
🔄 Round 72 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0718, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 72 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0009
   Val:   Loss=0.0718, RMSE=0.2680, R²=0.0037
============================================================


============================================================
🔄 Round 73 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 73 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0012
   Val:   Loss=0.0903, RMSE=0.3005, R²=-0.0142
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 75 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 75 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2904, R²=0.0030
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0221
============================================================


============================================================
🔄 Round 76 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 76 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0015
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0057
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 78 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 78 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0002
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0016
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

📊 Round 78 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 84 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 84 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0013
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0064
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 89 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 89 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0014
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0163
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 90 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 90 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0013
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0179
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

📊 Round 90 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 94 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 94 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0024
   Val:   Loss=0.0903, RMSE=0.3005, R²=-0.0260
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 96 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 96 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2885, R²=-0.0020
   Val:   Loss=0.0848, RMSE=0.2911, R²=-0.0007
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 97 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 97 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0003
   Val:   Loss=0.0907, RMSE=0.3011, R²=-0.0027
============================================================


============================================================
🔄 Round 99 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 99 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0000
   Val:   Loss=0.0921, RMSE=0.3035, R²=-0.0027
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 100 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 100 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0002
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0015
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 102 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 102 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0007
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0189
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 104 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0974 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0974, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0974, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0974, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0974, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0974, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0974)

============================================================
📊 Round 104 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0008
   Val:   Loss=0.0974, RMSE=0.3122, R²=0.0018
============================================================


============================================================
🔄 Round 105 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 105 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0003
   Val:   Loss=0.0914, RMSE=0.3023, R²=-0.0019
============================================================


============================================================
🔄 Round 106 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 106 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0022
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0264
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

📊 Round 106 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 111 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 111 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0001
   Val:   Loss=0.0762, RMSE=0.2760, R²=-0.0031
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0010

📊 Round 111 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0010

============================================================
🔄 Round 117 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 117 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0005
   Val:   Loss=0.0890, RMSE=0.2983, R²=0.0001
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0010

============================================================
🔄 Round 120 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 120 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0021
   Val:   Loss=0.0834, RMSE=0.2888, R²=0.0074
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0010

📊 Round 120 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0010

📊 Round 120 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0010

📊 Round 120 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0010

📊 Round 120 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0010

============================================================
🔄 Round 126 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 126 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0006
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0078
============================================================


============================================================
🔄 Round 129 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 129 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0008
   Val:   Loss=0.0805, RMSE=0.2838, R²=0.0002
============================================================


============================================================
🔄 Round 133 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 133 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0007
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0188
============================================================


============================================================
🔄 Round 134 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 134 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=-0.0003
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0018
============================================================


============================================================
🔄 Round 137 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 137 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0019
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0042
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

📊 Round 137 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 142 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0949 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0949, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0949, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0949, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0949, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0949, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0949)

============================================================
📊 Round 142 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0014
   Val:   Loss=0.0949, RMSE=0.3081, R²=-0.0214
============================================================


============================================================
🔄 Round 143 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 143 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0038
   Val:   Loss=0.0785, RMSE=0.2801, R²=-0.0025
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 147 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 147 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0012
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0007
============================================================


============================================================
🔄 Round 148 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 148 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0014
   Val:   Loss=0.0892, RMSE=0.2987, R²=0.0049
============================================================


============================================================
🔄 Round 149 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 149 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0035
   Val:   Loss=0.0793, RMSE=0.2817, R²=0.0048
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 152 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 152 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0005
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0120
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 156 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 156 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0000
   Val:   Loss=0.0866, RMSE=0.2943, R²=-0.0034
============================================================


============================================================
🔄 Round 157 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 157 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=-0.0029
   Val:   Loss=0.0891, RMSE=0.2985, R²=0.0078
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0010

📊 Round 157 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0010

📊 Round 157 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0010

============================================================
🔄 Round 161 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 161 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0016
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0037
============================================================


============================================================
🔄 Round 162 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 162 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0002
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0016
============================================================


============================================================
🔄 Round 163 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 163 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0015
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0216
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0010

============================================================
🔄 Round 165 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 165 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0017
   Val:   Loss=0.0890, RMSE=0.2983, R²=-0.0114
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0010

============================================================
🔄 Round 166 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 166 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=0.0007
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0063
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0010

============================================================
🔄 Round 167 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 167 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0034
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0026
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0010

📊 Round 167 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0010

📊 Round 167 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0010

============================================================
🔄 Round 172 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 172 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=0.0016
   Val:   Loss=0.0771, RMSE=0.2777, R²=-0.0159
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0010

📊 Round 172 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0010

============================================================
🔄 Round 175 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 175 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0016
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0086
============================================================


============================================================
🔄 Round 176 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 176 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=-0.0032
   Val:   Loss=0.0888, RMSE=0.2981, R²=-0.0025
============================================================


============================================================
🔄 Round 180 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 180 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0014
   Val:   Loss=0.0906, RMSE=0.3009, R²=-0.0067
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0010

============================================================
🔄 Round 181 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 181 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0007
   Val:   Loss=0.0860, RMSE=0.2933, R²=0.0020
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0010

============================================================
🔄 Round 184 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 184 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0005
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0030
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0010

📊 Round 184 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0010

📊 Round 184 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

📊 Round 184 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 191 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 191 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0003
   Val:   Loss=0.0879, RMSE=0.2965, R²=-0.0120
============================================================


============================================================
🔄 Round 193 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 193 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=0.0003
   Val:   Loss=0.0744, RMSE=0.2728, R²=-0.0022
============================================================


📊 Round 193 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

📊 Round 193 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 196 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 196 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0008
   Val:   Loss=0.0829, RMSE=0.2880, R²=-0.0036
============================================================


============================================================
🔄 Round 198 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 198 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0027
   Val:   Loss=0.0786, RMSE=0.2803, R²=0.0046
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 199 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 199 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0018
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0111
============================================================


============================================================
🔄 Round 200 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 200 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0000
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0010
============================================================


📊 Round 200 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 203 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0933 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0933, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0933, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0933, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0933, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0933, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0933)

============================================================
📊 Round 203 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0008
   Val:   Loss=0.0933, RMSE=0.3055, R²=-0.0033
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 205 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 205 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0029
   Val:   Loss=0.0802, RMSE=0.2833, R²=-0.0173
============================================================


📊 Round 205 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

📊 Round 205 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

📊 Round 205 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

📊 Round 205 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 212 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 212 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0008
   Val:   Loss=0.0874, RMSE=0.2957, R²=-0.0048
============================================================


📊 Round 212 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

📊 Round 212 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 215 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 215 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0006
   Val:   Loss=0.0790, RMSE=0.2811, R²=0.0015
============================================================


============================================================
🔄 Round 217 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 217 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0015
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0092
============================================================


📊 Round 217 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 218 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 218 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0018
   Val:   Loss=0.0783, RMSE=0.2798, R²=0.0062
============================================================


============================================================
🔄 Round 219 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 219 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0021
   Val:   Loss=0.0879, RMSE=0.2964, R²=-0.0216
============================================================


📊 Round 219 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

📊 Round 219 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 221 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 221 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=0.0027
   Val:   Loss=0.0783, RMSE=0.2798, R²=-0.0139
============================================================


============================================================
🔄 Round 222 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 222 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2863, R²=0.0005
   Val:   Loss=0.0900, RMSE=0.3000, R²=-0.0064
============================================================


============================================================
🔄 Round 223 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 223 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0030
   Val:   Loss=0.0879, RMSE=0.2965, R²=0.0082
============================================================


📊 Round 223 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

📊 Round 223 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 229 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 229 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0016
   Val:   Loss=0.0920, RMSE=0.3034, R²=-0.0078
============================================================


============================================================
🔄 Round 233 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 233 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=0.0005
   Val:   Loss=0.0743, RMSE=0.2726, R²=-0.0053
============================================================


📊 Round 233 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 235 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 235 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0004
   Val:   Loss=0.0795, RMSE=0.2819, R²=-0.0101
============================================================


============================================================
🔄 Round 236 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 236 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0014
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0046
============================================================


============================================================
🔄 Round 239 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 239 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=0.0001
   Val:   Loss=0.0891, RMSE=0.2985, R²=-0.0120
============================================================


📊 Round 239 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 240 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 240 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0007
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0022
============================================================


📊 Round 240 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

📊 Round 240 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 246 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 246 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0022
   Val:   Loss=0.0807, RMSE=0.2840, R²=-0.0121
============================================================


📊 Round 246 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

📊 Round 246 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 248 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 248 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2870, R²=0.0028
   Val:   Loss=0.0883, RMSE=0.2972, R²=-0.0151
============================================================


📊 Round 248 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 249 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 249 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=0.0005
   Val:   Loss=0.0888, RMSE=0.2980, R²=-0.0062
============================================================


📊 Round 249 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

📊 Round 249 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0012

============================================================
🔄 Round 254 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 254 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0001
   Val:   Loss=0.0762, RMSE=0.2760, R²=0.0000
============================================================


📊 Round 254 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

📊 Round 254 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0012

============================================================
🔄 Round 258 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 258 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0023
   Val:   Loss=0.0896, RMSE=0.2993, R²=-0.0090
============================================================


📊 Round 258 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

📊 Round 258 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 266 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 266 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0024
   Val:   Loss=0.0796, RMSE=0.2822, R²=-0.0247
============================================================


============================================================
🔄 Round 267 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 267 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2896, R²=0.0011
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0072
============================================================


📊 Round 267 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 268 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 268 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0007
   Val:   Loss=0.0848, RMSE=0.2911, R²=0.0020
============================================================


📊 Round 268 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

📊 Round 268 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 272 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 272 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0020
   Val:   Loss=0.0909, RMSE=0.3015, R²=-0.0094
============================================================


============================================================
🔄 Round 273 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 273 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0012
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0069
============================================================


📊 Round 273 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 274 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 274 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0012
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0048
============================================================


📊 Round 274 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0012

📊 Round 274 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 279 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 279 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=-0.0006
   Val:   Loss=0.0783, RMSE=0.2799, R²=-0.0034
============================================================


📊 Round 279 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 281 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 281 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0008
   Val:   Loss=0.0914, RMSE=0.3024, R²=0.0024
============================================================


📊 Round 281 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 283 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 283 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0076
   Val:   Loss=0.0836, RMSE=0.2892, R²=-0.0382
============================================================


📊 Round 283 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

📊 Round 283 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0012

============================================================
🔄 Round 287 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 287 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0008
   Val:   Loss=0.0851, RMSE=0.2917, R²=0.0030
============================================================


📊 Round 287 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 288 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 288 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0013
   Val:   Loss=0.0865, RMSE=0.2940, R²=0.0040
============================================================


📊 Round 288 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 290 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 290 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0007
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0022
============================================================


============================================================
🔄 Round 291 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 291 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0004
   Val:   Loss=0.0768, RMSE=0.2772, R²=-0.0036
============================================================


📊 Round 291 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 292 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 292 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0015
   Val:   Loss=0.0876, RMSE=0.2960, R²=0.0016
============================================================


📊 Round 292 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

📊 Round 292 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

📊 Round 292 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 298 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 298 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=-0.0004
   Val:   Loss=0.0888, RMSE=0.2979, R²=0.0001
============================================================


============================================================
🔄 Round 300 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 300 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0003
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0053
============================================================


============================================================
🔄 Round 302 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 302 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=-0.0002
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0009
============================================================


📊 Round 302 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 305 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 305 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0025
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0014
============================================================


============================================================
🔄 Round 307 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 307 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0018
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0056
============================================================


============================================================
🔄 Round 310 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 310 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0011
   Val:   Loss=0.0877, RMSE=0.2962, R²=-0.0046
============================================================


📊 Round 310 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 313 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 313 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0021
   Val:   Loss=0.0861, RMSE=0.2934, R²=0.0061
============================================================


📊 Round 313 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

📊 Round 313 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 315 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 315 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0005
   Val:   Loss=0.0748, RMSE=0.2734, R²=-0.0025
============================================================


📊 Round 315 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

📊 Round 315 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 317 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 317 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0006
   Val:   Loss=0.0802, RMSE=0.2831, R²=0.0020
============================================================


📊 Round 317 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

📊 Round 317 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

📊 Round 317 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

📊 Round 317 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

📊 Round 317 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0012

============================================================
🔄 Round 324 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 324 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0037
   Val:   Loss=0.0859, RMSE=0.2931, R²=0.0085
============================================================


============================================================
🔄 Round 325 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 325 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0009
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0060
============================================================


📊 Round 325 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0012

📊 Round 325 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 328 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0704 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0704, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0704, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0704, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0705, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0706, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0704)

============================================================
📊 Round 328 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=-0.0042
   Val:   Loss=0.0704, RMSE=0.2653, R²=-0.0226
============================================================


📊 Round 328 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 330 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 330 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0025
   Val:   Loss=0.0893, RMSE=0.2988, R²=0.0039
============================================================


============================================================
🔄 Round 331 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 331 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0013
   Val:   Loss=0.0906, RMSE=0.3009, R²=-0.0072
============================================================


📊 Round 331 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0012

📊 Round 331 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

📊 Round 331 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 335 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 335 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0013
   Val:   Loss=0.0767, RMSE=0.2769, R²=-0.0008
============================================================


📊 Round 335 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 338 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 338 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0006
   Val:   Loss=0.0857, RMSE=0.2927, R²=0.0005
============================================================


📊 Round 338 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

📊 Round 338 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 341 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 341 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0018
   Val:   Loss=0.0914, RMSE=0.3024, R²=-0.0092
============================================================


📊 Round 341 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 342 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 342 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0009
   Val:   Loss=0.0778, RMSE=0.2788, R²=0.0035
============================================================


============================================================
🔄 Round 343 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 343 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0032
   Val:   Loss=0.0853, RMSE=0.2920, R²=-0.0027
============================================================


📊 Round 343 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 345 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 345 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0015
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0049
============================================================


📊 Round 345 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 348 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 348 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0003
   Val:   Loss=0.0745, RMSE=0.2730, R²=-0.0023
============================================================


============================================================
🔄 Round 350 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 350 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0004
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0046
============================================================


============================================================
🔄 Round 351 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 351 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0016
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0062
============================================================


📊 Round 351 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 352 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 352 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0006
   Val:   Loss=0.0857, RMSE=0.2928, R²=-0.0006
============================================================


📊 Round 352 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 353 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 353 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0021
   Val:   Loss=0.0907, RMSE=0.3011, R²=0.0048
============================================================


📊 Round 353 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 354 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 354 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2892, R²=-0.0003
   Val:   Loss=0.0831, RMSE=0.2882, R²=-0.0049
============================================================


============================================================
🔄 Round 355 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 355 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0004
   Val:   Loss=0.0875, RMSE=0.2957, R²=-0.0069
============================================================


============================================================
🔄 Round 356 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 356 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0014
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0071
============================================================


📊 Round 356 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

📊 Round 356 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

📊 Round 356 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 359 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 359 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=-0.0014
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0007
============================================================


============================================================
🔄 Round 361 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 361 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0003
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0024
============================================================


📊 Round 361 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 362 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 362 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0028
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0072
============================================================


============================================================
🔄 Round 363 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 363 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0038
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0117
============================================================


📊 Round 363 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0010

============================================================
🔄 Round 367 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 367 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0037
   Val:   Loss=0.0763, RMSE=0.2763, R²=-0.0379
============================================================


============================================================
🔄 Round 368 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 368 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0016
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0106
============================================================


============================================================
🔄 Round 369 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 369 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0012
   Val:   Loss=0.0765, RMSE=0.2766, R²=-0.0060
============================================================


📊 Round 369 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0010

============================================================
🔄 Round 370 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 370 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0043
   Val:   Loss=0.0767, RMSE=0.2769, R²=-0.0017
============================================================


📊 Round 370 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0010

📊 Round 370 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0010

📊 Round 370 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0010

============================================================
🔄 Round 375 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 375 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0020
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0265
============================================================


============================================================
🔄 Round 377 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 377 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0007
   Val:   Loss=0.0885, RMSE=0.2974, R²=-0.0032
============================================================


📊 Round 377 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 382 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 382 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0006
   Val:   Loss=0.0879, RMSE=0.2965, R²=0.0005
============================================================


📊 Round 382 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 385 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 385 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0017
   Val:   Loss=0.0867, RMSE=0.2944, R²=0.0057
============================================================


============================================================
🔄 Round 387 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 387 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0013
   Val:   Loss=0.0911, RMSE=0.3018, R²=-0.0099
============================================================


============================================================
🔄 Round 388 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 388 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0044
   Val:   Loss=0.0841, RMSE=0.2901, R²=-0.0062
============================================================


📊 Round 388 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 390 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 390 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0017
   Val:   Loss=0.0861, RMSE=0.2934, R²=0.0060
============================================================


📊 Round 390 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0010

============================================================
🔄 Round 392 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 392 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0006
   Val:   Loss=0.0836, RMSE=0.2892, R²=-0.0137
============================================================


📊 Round 392 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0010

============================================================
🔄 Round 393 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 393 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0004
   Val:   Loss=0.0910, RMSE=0.3017, R²=0.0000
============================================================


============================================================
🔄 Round 395 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 395 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0017
   Val:   Loss=0.0806, RMSE=0.2840, R²=-0.0003
============================================================


📊 Round 395 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0010

📊 Round 395 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

📊 Round 395 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

📊 Round 395 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 400 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 400 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0002
   Val:   Loss=0.0870, RMSE=0.2949, R²=0.0002
============================================================


📊 Round 400 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

📊 Round 400 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

📊 Round 400 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

📊 Round 400 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 404 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 404 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0002
   Val:   Loss=0.0869, RMSE=0.2947, R²=-0.0025
============================================================


📊 Round 404 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 407 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 407 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0042
   Val:   Loss=0.0837, RMSE=0.2893, R²=0.0091
============================================================


============================================================
🔄 Round 408 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 408 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0002
   Val:   Loss=0.0874, RMSE=0.2956, R²=0.0006
============================================================


📊 Round 408 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 409 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 409 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0010
   Val:   Loss=0.0834, RMSE=0.2888, R²=0.0013
============================================================


📊 Round 409 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

📊 Round 409 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 412 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 412 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0015
   Val:   Loss=0.0774, RMSE=0.2783, R²=-0.0133
============================================================


📊 Round 412 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 414 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 414 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0008
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0063
============================================================


============================================================
🔄 Round 418 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 418 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0013
   Val:   Loss=0.0892, RMSE=0.2987, R²=-0.0061
============================================================


============================================================
🔄 Round 420 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 420 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0010
   Val:   Loss=0.0850, RMSE=0.2915, R²=0.0005
============================================================


📊 Round 420 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0012

📊 Round 420 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 423 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 423 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0015
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0022
============================================================


📊 Round 423 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 424 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0711 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0711, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0711, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0711, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0711, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0711, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0711)

============================================================
📊 Round 424 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2944, R²=-0.0009
   Val:   Loss=0.0711, RMSE=0.2667, R²=0.0042
============================================================


============================================================
🔄 Round 427 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 427 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0001
   Val:   Loss=0.0884, RMSE=0.2974, R²=-0.0057
============================================================


============================================================
🔄 Round 428 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 428 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=0.0043
   Val:   Loss=0.0741, RMSE=0.2722, R²=-0.0343
============================================================


📊 Round 428 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 429 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 429 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0009
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0034
============================================================


📊 Round 429 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 430 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 430 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0002
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0050
============================================================


📊 Round 430 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0012

============================================================
🔄 Round 431 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 431 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0031
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0184
============================================================


📊 Round 431 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0012

📊 Round 431 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0012

============================================================
🔄 Round 435 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 435 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0016
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0086
============================================================


============================================================
🔄 Round 436 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 436 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0016
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0124
============================================================


📊 Round 436 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0012

============================================================
🔄 Round 438 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 438 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0025
   Val:   Loss=0.0886, RMSE=0.2976, R²=-0.0375
============================================================


📊 Round 438 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0012

============================================================
🔄 Round 441 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 441 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0009
   Val:   Loss=0.0785, RMSE=0.2801, R²=-0.0164
============================================================


📊 Round 441 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 442 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 442 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=0.0021
   Val:   Loss=0.0755, RMSE=0.2748, R²=-0.0233
============================================================


============================================================
🔄 Round 443 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 443 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0001
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0021
============================================================


📊 Round 443 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

📊 Round 443 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 446 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 446 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0014
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0055
============================================================


📊 Round 446 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 447 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 447 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0023
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0082
============================================================


📊 Round 447 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 450 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 450 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0012
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0062
============================================================


============================================================
🔄 Round 451 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 451 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0014
   Val:   Loss=0.0775, RMSE=0.2784, R²=0.0011
============================================================


📊 Round 451 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 454 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 454 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2892, R²=-0.0012
   Val:   Loss=0.0831, RMSE=0.2882, R²=0.0040
============================================================


============================================================
🔄 Round 455 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 455 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0006
   Val:   Loss=0.0724, RMSE=0.2691, R²=0.0028
============================================================


📊 Round 455 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 456 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 456 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0026
   Val:   Loss=0.0805, RMSE=0.2838, R²=-0.0112
============================================================


📊 Round 456 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 457 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 457 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0016
   Val:   Loss=0.0790, RMSE=0.2811, R²=0.0069
============================================================


📊 Round 457 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

📊 Round 457 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

📊 Round 457 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 463 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 463 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0013
   Val:   Loss=0.0763, RMSE=0.2763, R²=-0.0066
============================================================


📊 Round 463 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

📊 Round 463 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 465 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 465 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0005
   Val:   Loss=0.0842, RMSE=0.2901, R²=0.0019
============================================================


📊 Round 465 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

📊 Round 465 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

📊 Round 465 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 471 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 471 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0027
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0126
============================================================


📊 Round 471 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 474 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 474 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0007
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0037
============================================================


============================================================
🔄 Round 475 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 475 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0043
   Val:   Loss=0.0809, RMSE=0.2845, R²=0.0016
============================================================


============================================================
🔄 Round 476 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 476 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0010
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0048
============================================================


📊 Round 476 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0010

============================================================
🔄 Round 479 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 479 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0001
   Val:   Loss=0.0790, RMSE=0.2810, R²=-0.0004
============================================================


============================================================
🔄 Round 481 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 481 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0041
   Val:   Loss=0.0872, RMSE=0.2954, R²=-0.0055
============================================================


📊 Round 481 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

📊 Round 481 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 484 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 484 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0014
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0112
============================================================


📊 Round 484 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0010

============================================================
🔄 Round 489 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 489 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0015
   Val:   Loss=0.0791, RMSE=0.2812, R²=-0.0037
============================================================


============================================================
🔄 Round 490 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 490 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0016
   Val:   Loss=0.0824, RMSE=0.2871, R²=0.0024
============================================================


============================================================
🔄 Round 494 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 494 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0020
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0028
============================================================


📊 Round 494 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0010

📊 Round 494 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 498 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 498 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=-0.0000
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0028
============================================================


📊 Round 498 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 502 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 502 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0017
   Val:   Loss=0.0757, RMSE=0.2752, R²=0.0059
============================================================


📊 Round 502 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 506 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 506 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0016
   Val:   Loss=0.0878, RMSE=0.2963, R²=0.0013
============================================================


============================================================
🔄 Round 508 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0956 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0956, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0956, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0956, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0956, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0956, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0956)

============================================================
📊 Round 508 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0009
   Val:   Loss=0.0956, RMSE=0.3093, R²=0.0017
============================================================


📊 Round 508 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 510 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 510 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0004
   Val:   Loss=0.0865, RMSE=0.2940, R²=0.0018
============================================================


📊 Round 510 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 511 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 511 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0011
   Val:   Loss=0.0883, RMSE=0.2971, R²=0.0031
============================================================


📊 Round 511 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 513 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 513 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0006
   Val:   Loss=0.0882, RMSE=0.2971, R²=0.0010
============================================================


📊 Round 513 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 514 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 514 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0022
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0006
============================================================


📊 Round 514 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 516 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 516 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=-0.0013
   Val:   Loss=0.0743, RMSE=0.2726, R²=-0.0042
============================================================


📊 Round 516 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 518 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 518 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=0.0006
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0028
============================================================


============================================================
🔄 Round 520 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 520 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0003
   Val:   Loss=0.0816, RMSE=0.2856, R²=-0.0043
============================================================


📊 Round 520 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 524 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 524 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2892, R²=0.0023
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0306
============================================================


============================================================
🔄 Round 525 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 525 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0024
   Val:   Loss=0.0896, RMSE=0.2994, R²=-0.0107
============================================================


📊 Round 525 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 526 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 526 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0001
   Val:   Loss=0.0854, RMSE=0.2923, R²=-0.0028
============================================================


============================================================
🔄 Round 529 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 529 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0031
   Val:   Loss=0.0806, RMSE=0.2840, R²=-0.0312
============================================================


📊 Round 529 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 530 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0929 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0929, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0929, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0929, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0929, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0929, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 530 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0009
   Val:   Loss=0.0929, RMSE=0.3049, R²=0.0032
============================================================


============================================================
🔄 Round 531 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 531 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0002
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0007
============================================================


📊 Round 531 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 532 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 532 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=-0.0016
   Val:   Loss=0.0890, RMSE=0.2984, R²=0.0032
============================================================


📊 Round 532 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 534 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 534 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0024
   Val:   Loss=0.0900, RMSE=0.3000, R²=-0.0335
============================================================


📊 Round 534 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 536 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 536 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2885, R²=0.0000
   Val:   Loss=0.0847, RMSE=0.2911, R²=-0.0031
============================================================


============================================================
🔄 Round 537 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 537 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=0.0011
   Val:   Loss=0.0752, RMSE=0.2743, R²=-0.0051
============================================================


============================================================
🔄 Round 538 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0961 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0961, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0961, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0961, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0961, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0961, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0961)

============================================================
📊 Round 538 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0000
   Val:   Loss=0.0961, RMSE=0.3100, R²=-0.0224
============================================================


============================================================
🔄 Round 539 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 539 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0006
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0177
============================================================


============================================================
🔄 Round 540 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0948 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0948, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0948, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0948, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0948, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0948, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0948)

============================================================
📊 Round 540 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0012
   Val:   Loss=0.0948, RMSE=0.3079, R²=0.0041
============================================================


📊 Round 540 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

📊 Round 540 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 543 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 543 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0027
   Val:   Loss=0.0772, RMSE=0.2778, R²=0.0042
============================================================


============================================================
🔄 Round 544 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 544 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0030
   Val:   Loss=0.0720, RMSE=0.2683, R²=0.0003
============================================================


============================================================
🔄 Round 545 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0939 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0939, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0939, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0939, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0939, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0938, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0939)

============================================================
📊 Round 545 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=0.0008
   Val:   Loss=0.0939, RMSE=0.3064, R²=-0.0034
============================================================


📊 Round 545 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0010

📊 Round 545 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 549 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 549 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0013
   Val:   Loss=0.0874, RMSE=0.2957, R²=-0.0107
============================================================


📊 Round 549 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

📊 Round 549 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 553 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 553 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0007
   Val:   Loss=0.0844, RMSE=0.2906, R²=-0.0036
============================================================


📊 Round 553 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

📊 Round 553 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 556 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 556 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0017
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0200
============================================================


📊 Round 556 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

📊 Round 556 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 559 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 559 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2920, R²=0.0022
   Val:   Loss=0.0767, RMSE=0.2770, R²=-0.0101
============================================================


📊 Round 559 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 562 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 562 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0007
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0030
============================================================


📊 Round 562 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0010

============================================================
🔄 Round 565 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 565 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0011
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0042
============================================================


📊 Round 565 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0010

============================================================
🔄 Round 567 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 567 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0014
   Val:   Loss=0.0861, RMSE=0.2935, R²=0.0033
============================================================


============================================================
🔄 Round 568 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 568 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0011
   Val:   Loss=0.0842, RMSE=0.2901, R²=0.0031
============================================================


📊 Round 568 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

📊 Round 568 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0010

📊 Round 568 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0010

📊 Round 568 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0010

📊 Round 568 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0010

============================================================
🔄 Round 577 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 577 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0007
   Val:   Loss=0.0836, RMSE=0.2892, R²=0.0013
============================================================


📊 Round 577 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0010

============================================================
🔄 Round 579 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 579 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0013
   Val:   Loss=0.0901, RMSE=0.3002, R²=-0.0125
============================================================


============================================================
🔄 Round 580 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 580 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0016
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0103
============================================================


============================================================
🔄 Round 581 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 581 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0022
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0052
============================================================


📊 Round 581 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

📊 Round 581 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

📊 Round 581 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0010

============================================================
🔄 Round 589 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 589 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0010
   Val:   Loss=0.0857, RMSE=0.2928, R²=0.0034
============================================================


📊 Round 589 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0010

============================================================
🔄 Round 592 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 592 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=-0.0033
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0017
============================================================


📊 Round 592 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0011

============================================================
🔄 Round 593 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 593 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0012
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0011
============================================================


============================================================
🔄 Round 594 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0923, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 594 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=0.0010
   Val:   Loss=0.0923, RMSE=0.3038, R²=-0.0039
============================================================


============================================================
🔄 Round 595 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 595 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0023
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0304
============================================================


📊 Round 595 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0010

============================================================
🔄 Round 596 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 596 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0010
   Val:   Loss=0.0884, RMSE=0.2973, R²=-0.0045
============================================================


📊 Round 596 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0010

📊 Round 596 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0010

============================================================
🔄 Round 599 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 599 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0005
   Val:   Loss=0.0849, RMSE=0.2914, R²=0.0011
============================================================


📊 Round 599 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0010

📊 Round 599 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0010

============================================================
🔄 Round 603 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 603 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0000
   Val:   Loss=0.0790, RMSE=0.2811, R²=0.0001
============================================================


📊 Round 603 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0010

📊 Round 603 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0010

📊 Round 603 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0010

📊 Round 603 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0010

============================================================
🔄 Round 612 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 612 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0016
   Val:   Loss=0.0887, RMSE=0.2978, R²=-0.0111
============================================================


============================================================
🔄 Round 614 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 614 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0003
   Val:   Loss=0.0892, RMSE=0.2987, R²=-0.0603
============================================================


📊 Round 614 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0009

📊 Round 614 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0009

============================================================
🔄 Round 618 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 618 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0005
   Val:   Loss=0.0779, RMSE=0.2792, R²=0.0017
============================================================


📊 Round 618 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0009

============================================================
🔄 Round 620 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 620 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0022
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0364
============================================================


📊 Round 620 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0009

============================================================
🔄 Round 621 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 621 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0019
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0130
============================================================


📊 Round 621 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0009

============================================================
🔄 Round 622 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 622 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0014
   Val:   Loss=0.0835, RMSE=0.2890, R²=0.0032
============================================================


📊 Round 622 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0009

📊 Round 622 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0008

📊 Round 622 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0008

============================================================
🔄 Round 626 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 626 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0014
   Val:   Loss=0.0886, RMSE=0.2977, R²=0.0027
============================================================


📊 Round 626 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0009

============================================================
🔄 Round 630 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 630 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0008
   Val:   Loss=0.0901, RMSE=0.3002, R²=-0.0035
============================================================


📊 Round 630 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0008

============================================================
🔄 Round 632 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 632 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0023
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0012
============================================================


============================================================
🔄 Round 633 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 633 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=0.0010
   Val:   Loss=0.0767, RMSE=0.2770, R²=-0.0130
============================================================


📊 Round 633 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0009

============================================================
🔄 Round 634 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 634 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0014
   Val:   Loss=0.0798, RMSE=0.2824, R²=0.0040
============================================================


============================================================
🔄 Round 635 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 635 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0004
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0027
============================================================


📊 Round 635 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0009

============================================================
🔄 Round 638 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 638 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0009
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0050
============================================================


📊 Round 638 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0009

📊 Round 638 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0009

============================================================
🔄 Round 640 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 640 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0002
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0012
============================================================


📊 Round 640 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0009

📊 Round 640 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0009

============================================================
🔄 Round 645 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 645 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0022
   Val:   Loss=0.0896, RMSE=0.2994, R²=-0.0123
============================================================


📊 Round 645 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0009

📊 Round 645 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0009

============================================================
🔄 Round 651 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0946 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0946, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0946, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0946, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0946, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0946, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0946)

============================================================
📊 Round 651 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0011
   Val:   Loss=0.0946, RMSE=0.3076, R²=-0.0076
============================================================


📊 Round 651 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0009

============================================================
🔄 Round 652 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 652 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0010
   Val:   Loss=0.0833, RMSE=0.2886, R²=0.0026
============================================================


📊 Round 652 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0009

============================================================
🔄 Round 655 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 655 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0008
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0038
============================================================


============================================================
🔄 Round 656 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 656 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0009
   Val:   Loss=0.0887, RMSE=0.2979, R²=-0.0041
============================================================


📊 Round 656 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0009

============================================================
🔄 Round 657 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 657 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0016
   Val:   Loss=0.0886, RMSE=0.2976, R²=-0.0171
============================================================


📊 Round 657 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2520, R²: 0.0009

============================================================
🔄 Round 660 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 660 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0004
   Val:   Loss=0.0861, RMSE=0.2935, R²=-0.0022
============================================================


============================================================
🔄 Round 662 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 662 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0018
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0135
============================================================


❌ Client client_12 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8690 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8690 {grpc_status:14, grpc_message:"Socket closed"}"
>
