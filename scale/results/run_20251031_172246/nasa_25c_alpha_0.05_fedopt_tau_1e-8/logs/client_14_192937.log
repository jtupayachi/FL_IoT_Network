[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c6f70af-4142-4444-9192-bd35f2b4c995
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06874b50-1338-498b-b6ac-3658ecc22baf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1445b58-18bb-4523-81ed-6ad7a76dec8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7546c7a-44c7-4023-a392-4912c4534d0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7b2014d-444e-49e2-a086-dc2803097b0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f9e9467-3394-45d0-992d-5027be300eb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ffec7d4-67d7-4d63-a22a-7f532c675191
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fdca1ee1-f5ff-4c26-b535-dad3358ac37a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f07f9ef-c593-430b-a7af-ebe3a6255518
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e9f3858-e1d9-48aa-b341-31c272af3076
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f56cf4aa-47a8-41a8-afd6-87a51c013bf1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f811a7ef-1bf9-4c76-a1c4-f874ae0ea1ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 289f39f4-dacf-4846-9281-b0930bd5dda7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca52cf12-7a6b-4f65-9cbb-fac610c328a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36871090-aff4-43a0-be59-37cf2622ffd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b48cdb6-884d-46d6-bec4-ac12b9ab61fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e192585a-1a8d-4274-8da8-b0e88be32688
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8533d8d1-9fac-43fd-975d-025bc181722c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4410bdd9-37fa-4dda-965b-183d7b4df6f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6d543d9-8bbc-40b5-bd26-2e7ba3486182
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d5a331b-c023-414b-bfa8-61874d7a890a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0bd14243-4942-4b69-a8f2-226f37559b52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5cfb632-7e01-4de1-bd18-01ff349859ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc9fdf0d-dc43-433d-8cda-c55876d65584
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c9843d6-0ba9-47e2-b3f5-99ad41114bf0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eecea4b1-3356-4d29-a968-7d2de0e128d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a25ac3f-65c5-4872-9b66-6742ed7a6248
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d17038c-41ce-4a2e-9022-f9dc03da63eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0e8c80e-b1cc-467f-a570-d37030c6a4bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d349990e-6077-49ad-b634-ce724a95efea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 678de541-14bb-43de-a56b-336b85695cb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3eca662e-9ebc-4056-9c4a-073e7fce16d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message edb346e0-9a0f-4e32-8393-b426bcf6c010
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a63a57fc-51b3-4274-ab6d-c026061102f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 353f2277-e10e-47ce-bbaa-5b706f6157e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1dfcc1c6-9247-404d-b066-d939fb69c197
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 392b576e-1d85-4db1-91c9-fa69e8428e1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0e4f4f7-909e-4518-a6ef-5078b0992cec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db5f8882-9258-4346-886a-b04ef4704844
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 118cc636-ef01-45a3-be0d-c5220633e42c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a20c225-3870-479c-a1c7-32c56917c093
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c372f83-b720-4491-9384-d0bd8576503c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f731961d-c9b4-4fb5-8bde-9e5a7416abdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a429ef0-6a5f-465d-8001-ed6bdc2e83ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d22439d6-bfbe-48e6-aa74-7887577af76d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0325950-c964-4bef-9ef8-71fbdcd64dc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message edb9d008-6dd1-4c8b-8b12-4d7bde4ecac2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca3d529d-d755-45a4-b39f-95b1b5d4da67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d7b95ec-3100-4f9f-97cb-2f455e91c668
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e51dd36-68d8-4db0-be98-ca277c38dff1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2bf4d3a-a282-4f5f-92fe-758b215eff12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d42c8f50-0b1f-4daa-98bc-a55e725f4b38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e277670-306f-4010-92fe-384166066ac0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55358b89-b86b-48a2-ac57-84f9555b0994
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c673991-36e9-4a3b-a6b3-619231162789
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d7400b4-b03c-4eb3-9dbf-c6dc8abba87f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e850ce56-d8cd-412c-a418-65e2e1a7d395
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58b506e9-66d7-4c0b-aca5-629aab7daae2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74e128df-5ebd-471f-9220-0f9a36c28397
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55000601-df5d-482d-84e8-9e3a6a1878a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 818a8b15-0aee-48a1-9a44-d1aa14c5535e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dddb7afe-cbf0-4e92-8be2-b31431803be5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd7cee57-1934-45e0-a4bd-5d59e4d2e7dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80c8484d-7b6d-418c-a50e-81376f7abcda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b738eda-d498-4f15-aa3f-5c5cd185181c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb2cc36d-4bb6-4119-99bf-652d6f411826
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b7e1b57-5c5c-4712-8bfe-2aae6a5b195d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 448c07db-3472-46e5-9b7a-d5b2db24f658
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ecdaa969-9d95-439f-a161-7faa48d0c2ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5708e619-8aaf-4fc7-a2b5-4961d0fddece
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8b7c730-c638-4759-b3af-c7a3ca1e0c33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04294562-6606-4f11-9e99-f0c216d695f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c741d26-2d37-4701-b616-ed16388ea923
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a66d4bc6-b70b-479c-b8ab-4c4d9cf52a5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35dab102-636f-40bb-b12d-cab1737dc454
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20b03e85-fd62-4ba6-aed3-818eb9682808
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9b86162-299f-4a0b-b95b-1357c8031e12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e28ae14c-6630-4e02-bd14-7594232368e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40b0dba8-e96d-49ac-9e95-30eab897f83a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc6b45a1-ed22-4b0a-9fca-25de84c293e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48755e6b-ed2e-4744-b17f-a4b4128e087e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a701c2fc-74a7-475d-b444-2e239dd8b406
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06a5dabc-8e4c-473d-aa64-1ab958730e9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d5b1222-f549-491e-adf4-b4e7a084dfdd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59d09202-3b7b-4f65-8623-b33be4889dc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 919c71ee-3f1a-4576-90b6-165f52f5d7e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5005acd5-5e7d-4aad-8146-9c6fa27d2e69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc70bd85-e26e-4609-81f6-3fc0356f27a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99b8a554-375a-487d-8b62-dbd48b87b76d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23745bb8-8002-4486-949c-27027faa946c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b6047a3-caab-400f-a410-f3260aaad37b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89d5711b-e520-407f-aad3-3dfe15c75878
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee9a76d2-617f-44fa-86b3-4488526ad7a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55dc146b-bde5-452f-b520-fc467687bc74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ea6680f-1566-4500-8da7-abaa3e3ed101
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a90e046-0678-46da-933f-c41bb8e8e3d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cad43f7c-9c1f-4251-9652-2e9a429f841b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15f435d5-f06c-4dde-908d-7fe6823f5f33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51386d87-e9cc-4353-ba29-1c14542f6e1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7e7b20f-32c5-4804-9b83-81169540c17f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf8ab761-4bc6-4596-8bbe-7a04edbe4eaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ed41393-f48e-40e9-b675-ed47d667cc65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a701eb8-4748-4ceb-b917-aa7f1d1ae218
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db09cc44-2a44-4915-b4e9-af17da13cac6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9677a3f7-e434-4a74-992a-f5f95c09008d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d2be307-da3e-4636-a5df-5339bbfb805b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1eba2d3-430f-4b46-bfdb-852772c5b124
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20432053-d96c-4917-868f-41041acf44e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4621bce-f78d-48d4-b86e-5790ba883f39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 063d80aa-74de-49a1-83e8-36b775c0f447
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83ef21da-e943-401f-bac7-09a0c4f6bda7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3fbec030-61e2-489e-91d3-92eeb79392d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46126da6-05bd-4fe9-892d-e4f1cdc51ae2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc290cae-0c94-4a67-a9f7-ee50b81e1442
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4019353f-616b-4657-886c-3ef13ea3e794
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d896bb32-c9e6-4bab-a264-d4e61f1f658c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d09c215c-c5f1-41fe-ae73-588b72320ae7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d31ce902-e242-431d-b9bd-cf54b4582326
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 488d7b4e-5ad9-44ce-835f-28297a28e724
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 791f5ae2-f412-4a2e-9d03-6c979215bd26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39bd43a4-c816-47df-a86a-9aa88229cff2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8786dd11-ea56-4584-b3ed-b3f3667e3557
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6ce4d4d-8474-49c2-9958-4ae398994a43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 236c3f74-6e6c-4424-ab94-b0bb45ee8e33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eaf89cb3-dceb-469f-819c-91b27e7c2f9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45f7ec7b-7227-4395-8944-f8d099472423
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44a22555-b112-493d-8762-50a5dd034f6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a406c7d-006f-4fe1-9f84-418167652347
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f17030c-c17f-4640-9192-02e74184e019
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3f9396b-d3ad-4e29-82ff-3db7797c08a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af621ab9-b19c-438a-b175-8d4fce58bafb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb39bee2-6706-4adb-a084-dfb489845b5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2f63a81-0877-48c6-ae41-aec07bd14708
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4709bf9d-104f-49bb-8b5c-ddb152835f8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 774cccff-e965-4e8d-9163-063d41983cdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3744cc0f-6165-4804-a597-1e26da53e892
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06e66ad7-9d02-4101-9cb7-5979628cea0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58e4f8cd-f369-4973-ab00-f64605c0db6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62800593-960d-46c4-938b-c79948a1a443
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71f2170a-24d6-437b-a552-04e0a3194afd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3c3e944-2fa7-4441-81b3-d7486e604af7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c628c60e-ed3d-4213-8fcf-4f1d62f82f9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af5570c7-9a8a-46bd-b50b-acf3febb121c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1dcc762-aefb-4f35-ba9c-13dcbafc0b35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd00713b-918f-4406-a553-c7b30966891f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a2e4de2-9b59-4aee-8d54-6e86374ed14f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4412e23a-703e-4465-8257-21ee1abaa601
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59531a85-aefd-4220-a9d5-b2ddf5d4a3a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1b1a131-026a-4022-a850-1e609967461a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb158806-eb7d-4392-9f50-c9f54b22b972
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec72c98a-f2f3-4d75-aa31-5b7496231a9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 374b9012-70aa-45d7-9651-ebc620bbcd34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 707de554-0f45-4c28-ae2b-115cd82b8418
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e21333c-cdff-4c19-911b-b50463ab1c4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7712476-8d93-4694-8289-7fcdbd06ed9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd2474a8-8e06-483f-9715-6cceeec116d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e50c87c5-93a3-4525-ad6c-eccd78c46786
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e28b587-9996-47b0-97e9-cd300599d576
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1565cb7-f477-4062-b77a-97937d094205
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f6856fd-a837-41bc-8448-f79b561b68bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a00b79af-bb19-4074-9cdb-10aeb57c1cdd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message faf324c0-a3e8-4678-b80a-594e34da10ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18125012-0c4d-49a3-9f70-78953e509b61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a85e5cc7-ae47-4fc5-8577-2a96eb562120
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6dbbe82-8c31-427c-b38e-977dfc384001
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ba34508-d9a7-4a11-b949-645ef281f579
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d06e12ff-ab62-47ca-a3be-8642f18df240
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65f99212-df50-4211-b065-d6fdf1edd473
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3aa7700-54d5-48d2-b226-3f1131738ec9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e6a75a5-3bd6-4ddd-89b7-79d2d9b786c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db16c21a-18c9-434e-a296-518241fa1983
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f285ab7-3015-4118-b26d-b2fa0f2c37eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 079ca19b-766c-4012-b775-dc5ac6eb1694
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a397147b-5607-4ffb-943b-a0ee81800f26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a73733c-cb2a-4baa-a62e-a45793b9bb66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42057a71-2943-4d3b-8f54-0dd445616c8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e00d6463-c2e3-45ed-9e32-e227d1618559
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5801447-416b-4e58-8195-e41d0ff1045f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2f0619a-6123-480e-b6a5-a8a76ae423f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c38a7699-f67d-4b3d-ba0c-399ed41d977c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ba0a21f-d731-4301-bbe6-1dbf6f73cab3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d2927b5-15c0-4629-bdcf-c4b51dcbc077
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 154a230a-5872-4da4-85a1-8f8a391604a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c6069b7-12fb-4d0c-a8bd-8de3682cb366
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4a2c134-5988-4379-b062-52918bde705b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb5a19a9-6c2b-4dfe-ab8d-f82d920dbab8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82bd0682-08db-4433-986e-2073b3f4a0b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 850732b2-1351-430e-a609-7dc0876c1f15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb16f854-933e-4fd1-8683-15639443ee94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ca1d6a7-751f-4e2c-b994-1bdc6dc3dc95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5482246-20ee-46a0-a742-f268622c5c66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5447cfe7-c5d4-4642-9d71-7739467e6fd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3ca6cf2-bc40-40bd-a5ed-b14ba752c6ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 333af06d-e769-472f-ab99-2e170399571e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 923706fb-b176-441b-85ff-81d10d0c2762
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70532973-eecf-467f-a0ab-f133df377fb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff2c2919-0e47-4a03-9fb7-fbfa6004750f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9fee5638-2c5e-4b85-a920-337dfa77a037
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cdc9d8ae-0879-4a70-8fd3-fc30f7bb20ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e58a4fd-2e21-4efc-a176-07f0e3a09771
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2249bd28-a6d7-4622-98be-d337a3a818ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af0a4455-0d84-40d6-9f12-38a80567f9ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc81ccb2-9a6f-4993-9788-2fab8857b4ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f1907d4-f7f2-4950-9b0c-dd791881776a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75ee134c-a8d7-4450-a9a1-9ff75027e9e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2707187-862a-4208-81bb-288877266e23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b20f7af-8e43-4bbe-8364-cbd9f3f199e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6dbaef7f-ac35-442a-be5d-62ab27e47a47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8cea50f-008e-4083-b646-bd8108490c80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f878e8e-ced9-497a-a6af-55ebbfd2374a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2443608b-9b70-4d62-84d9-2c3c0120ac81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe66af6c-dce4-4f04-bf4f-0255bcd6eede
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e119fd7-c934-4f8d-9b37-0462091a1e17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b799b57-30f7-46a9-a0c7-445bbb9ecb0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 795c1d86-f47e-4547-81ea-2b27ddb29396
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93fc7aa7-d098-4755-8fd5-364f4bfeedb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba847ad9-8401-4213-ba7a-d323c2e92971
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8faff2e4-2801-42eb-80a3-842caffad719
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26dc72fe-45f8-4eb0-b41c-5064c99a6f22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfc517f3-5298-48e6-ac51-b3a66d954c4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5ec08ab-1542-4449-97cb-b15261dfba7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0527b730-ede6-4a08-908b-08802883b1a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a606053-4387-4e4b-818e-bb3ebf36ae8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6313345-f8e3-497d-b529-13dda3718ed4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2da6e9b-04b5-4804-8358-a169fdcd6050
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e8158ad-3f0b-4fc3-b256-43592568eab2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1468565d-c02b-449f-9d3e-c05ac3392037
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c01c4fd-0e81-478d-8f83-4a3f19e935c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7358f70-4073-42a6-aa41-104b8f8f695e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 696b0e3d-436f-494c-b509-d032952393f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 090539b1-7ef7-44e2-8f8c-1a20a94beaf6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d35e41c0-294e-4e07-9770-f0367dc9582b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 601bb9ce-1d51-4b49-a0e0-e730f6893358
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2b65c3f-3c3c-4c39-a374-1f1b044921c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e333d3d6-6b77-42ed-ae4a-1fb5f1f10926
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aeabdc91-b6bd-49dc-b1c4-ed122efe6cc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46774497-01a3-47ea-a838-40f40b4a2f72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2fb03235-eaea-4859-8949-ace8e8ae103f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b794dc7-4f40-4c09-8ff2-c5e99d9fef15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 224b943c-366b-4138-9527-ce27ab65eea9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f478b2b0-d1cf-4575-9bb0-3ed87b1380d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4eade05-b0e2-404c-8b91-07294a08e502
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3149195-7540-4fea-81c5-4642f652e5ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8771d72-5887-4e6b-a380-a2e1d8b57700
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21b9a860-0614-474d-b99f-28decffba751
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71a0167a-d03b-4080-970b-435e7e13caa7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75638002-69ac-4f6e-86e5-cd2516f512e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77796c1a-3df1-428b-b8c3-d4ded559b4c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0e70aaa-baf5-4f9f-8fe1-2b1bb7421b1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09d5bb01-f799-465f-8a65-1982babc6eae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 381026cc-997a-4a64-a977-726dddd1c414
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c09b3606-f83a-45b8-b93c-bfb9f31c607f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b40ee94d-030e-484e-b7ce-539d09e5fbea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69a3be5a-cad0-4da3-8a1f-6a457eb89bd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83ed181f-f62a-4321-8c92-e1a0ca6b196c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56cac743-dd5a-4cef-8d64-c295d6ec6d68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6216c866-7073-425b-a690-124b0afc1e3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message afb4f456-5c6d-449d-ba34-d1bd79d11262
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a351c6f-95da-495d-8ad3-49d2b84c9a8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message acf6ef11-1be7-4903-bba9-bbc3eb891866
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da3929f5-bb9a-438d-9612-56ea7bfd5978
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7321801-8d9e-4a2f-a835-874b6954cddc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59ec4c4e-a6dd-450a-a936-b0349904d1a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f59a2ce2-4cf0-4993-96f8-d6662f1c61af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67896950-89bc-40b5-bcdd-35d52e7fe997
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb2c4dcb-d2fa-4fb5-aabb-31d3d8fbe0cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 951bc7f4-10ca-4432-bbf9-13be8f75e134
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3dcd2e4f-79c1-486e-90a0-582ff7a36f3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 012fb813-89f7-441f-9e9f-5ab83983cfd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5960fea4-c13f-41b0-9a94-2dd9406f1f76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06d6fe6c-b38a-4029-a07c-c3b5aec562c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd25d5cf-9e9d-4436-b1ea-9b5ac124ce70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea321d5a-ae24-49f9-9fe4-28f2905ff762
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e15b6fdf-b6b7-4c2a-9bdb-e1dbbcc1a41a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f994a9b8-37ce-4e70-ab51-b0c62ed16999
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1eb2a0fe-a59e-419a-ba27-38e294f79696
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c1b104c-a189-483b-acd2-ed461a1ff4ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cfb00eff-51cb-40cf-b5fc-befb692e6df4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b797bcb-250a-41fe-a7a9-951f6e1de9c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96a7c180-d1a8-4e80-a907-70abac18e26e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9ef01c8-5134-4e5a-adfd-2067a3125ea4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4c8afab-160f-4238-a503-6c4d52952cb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72ea926a-332e-4f97-9e1d-0505022079f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62eded82-d4ef-4fbb-b33f-ab16ff22419b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aedd91d4-6172-46c8-93cb-68bb9afcc735
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97df7a3b-caaa-464c-94e8-a69885a7d49a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9643cd6b-2300-45c2-b38d-65449916207a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f54b4226-0a2a-4edf-93bb-422474035fbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2365f9a-1949-49e3-b706-5f91bb9689cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6babce01-0d75-4d38-8ff3-02679f94812c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 773c4603-6f8a-4eec-a69e-922548751009
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f5a3456-d485-497b-bdfd-856cc09e7ad3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0896a5bb-b441-4e65-bc3a-1665680f6192
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d27991e6-96bc-43d5-8d04-60cae7f451a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0bf62231-1cbf-4276-a0b9-4d7d71757c11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77dc425c-1301-4530-8129-2b1c986d6678
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2df0e90-ffcc-43c4-843a-71745630fa7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 612c2c95-7845-4295-94cb-052445d49c16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ff81b7d-f9f1-4404-ad72-554582b86bcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a06617b2-9306-468a-bed1-35367567ad78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33e4855b-cb24-4980-95d4-36264fa47b89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55586eb1-3b68-4c09-b631-e3d271b1cc3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5135ad8a-2b4b-43d7-b5c4-bc40d3f77fad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1fce24e9-9c04-48ee-88fa-e68d40c2f030
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bbb49d50-e7ad-4ccd-b478-e48c52eb0048
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55f73d09-08a3-4f5b-8ee6-84b0f847e474
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3541d540-bf28-4d33-9307-6f87c2c379b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5793ea89-883e-4eaa-8bbd-22f52da65dfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b8721ea-daed-493e-bfa6-22350ddf6338
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41ebc559-8b23-4b7d-bf46-a2eec40085d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9403d957-09ff-4a84-948a-356bf3dd05a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f2390d7-e1d8-4987-809e-6176dcb1093c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 029db9f2-77e9-43ef-b5c1-ea36b334b5c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 754ba819-486c-4bac-8b99-5cf8769d0d98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 527ed41e-1f25-42e4-9bd9-c8ded45ee7cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb1bf76e-d670-4b64-aea9-44a41a101bec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3236016c-99be-4e13-8af5-d1d6906f3b49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b854bc10-d4fc-4f74-9203-e7cdd768a170
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea04c41d-f5e5-4828-8cd7-2a03f64986d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88ce1a61-9c35-4c40-a4dd-2e9b1b2f6b19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31d0f7bf-0450-45dd-aa6d-ed6f4482353d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9bfd208a-718e-45d7-9761-7e63f62c2332
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01cff895-8956-43e4-a224-5fc6c21a8006
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 588e6979-a9ad-456b-9e11-1843dccd4fa6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c23ff5e-aea9-47c6-bcd1-3148d6253912
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3dc2c65-e0bc-486b-a432-b903fa46ea37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6052fa1-27b3-4a41-8062-45520376fd2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df38fdbb-4fba-471a-9609-fa01643fac33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea6e5a2c-0ddb-4dd3-8a26-de644a22d7af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8b0241d-6449-4a57-ba7d-3f84e13a7fff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9644487a-8a7a-41b0-8d70-86984668a377
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 948926ea-8b7a-4e04-b485-0904db1686df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e77bfd8-7be4-4757-9ab5-d3343e383059
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f524ca10-6309-4d50-ac16-6c542a1b1fc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f066f2d1-4d8b-44f7-99ef-46da619927a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8e1ac63-93f1-47f1-9756-1a29c73d360f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ece3521-795b-4139-b273-1a17fe62caa6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9bd768d3-7fef-41b0-883a-c8a77a5e7ceb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60857773-7437-431b-9444-0b9a527108de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ab116ae-ff9f-478d-a117-1cdfd78abfe5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1039918e-8157-4cf3-a238-222adbdebd82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9f98994-7a74-4373-b148-d4efacf22955
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 194af6c4-6c0c-4694-a8e3-52a03f777663
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63edd8e1-49fe-41ae-8b10-0af87ba6e3ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9d4dbcd-4c39-4c0f-9bfc-728fac26c9cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2495723-9a90-4001-94dd-d48a2cd9e135
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7e0911b-8671-4476-ad35-a4d65bf1a6c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48a62b63-208a-45d5-81de-18273dd31205
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a94a3807-fed2-4559-899d-4f89b69c55fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2bb4ed02-a0c7-4cab-9701-a2aa10e35171
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5d0df2a-4adb-4ba0-a5b1-d54ee583e8c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a90b4cd0-20c7-488c-a2ef-35489e43d4cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82408532-4709-434f-bbc3-cc4392eec7ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a412d94-096b-40c0-8bcd-131184b35e68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8079f28a-5553-496e-95e4-b3d9fcdb8c48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af2da4b1-eeba-41bd-87d4-213b00ef4a69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ae0afb7-8841-4a2d-b466-aafca4e6fc3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee3a1a37-a29d-47ad-bc0c-e91434971a93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10335a81-5b7e-4fe0-97ee-a3c326429d79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d998db52-2a18-4335-87cc-372b580cc6d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aaffc507-fac4-465a-a5bb-afecb1086e7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13f8761a-ae9e-432b-8307-9e03d18d5fc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61f8b04f-669c-477f-9951-0e07b66df1f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3cada6dd-358c-4d6c-b21e-e9e7db5a25c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d71503d-e2e9-47f4-8acb-d7bd1a4498be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 646e8c67-3f09-436e-9561-ba760dce9880
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2bb11d3c-c99e-4d72-84b5-38109d43af2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd102dea-8b10-472b-acac-51e85f43ba26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de77b22b-aad0-444d-8b97-031701c08e48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d57188e8-21f0-4426-8407-4976d3da6a91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa37d81e-08ca-4903-971d-1b390ebb2373
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2b159fa-b48f-4ca2-9964-e527b79a684c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9933392a-955e-4de1-8d99-0037ca090779
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8988d3f-213e-4652-8333-694a34059af0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0822437-3757-4282-8e75-58f04ec10cc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 016ec3cf-95e3-4e09-9308-2738aa9e2726
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 654c847a-2256-4e07-b416-c5188cb70b30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed563294-0c10-480d-9cad-02f1d714c710
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22259f84-40fa-4a0d-98af-4f60da11209c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6fdde44d-cd42-426f-b612-94e8740236b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5bb506dd-e9f2-4936-9c3c-94162a74db87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96403463-5a27-4c98-87c9-ef3293f38cf1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfd6f116-dc78-4cb7-b057-86fea38a1b8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b034771b-f9f7-441e-b240-1071c42c4573
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8f9ffe3-246c-443d-a121-9304f0891e59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc7c417c-3685-44f5-b9dd-148ae89b007a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae58f0b8-de69-4daa-afc9-c3a3f4822fc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e92233b8-ba81-411f-af76-afd612d9e424
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ece05389-1938-455b-b2fa-6894748a085c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d6310fe-8fa7-4300-b50a-3f2a689437f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b481fdf1-5f6d-4e67-b19e-924a49327229
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27e6c8f3-2f38-4fdf-9949-ca0965e0323d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a84557d-2353-486d-a361-01ee856aef2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5bcd48e6-f671-494e-903c-56fdd51df7c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec9cd043-5722-4cbc-ad9a-f4abb673281b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 076a0767-4a75-4201-8d1e-0036f70d37a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53406e6e-8910-4492-aea1-eee564beb319
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b186949a-b570-4330-a6fa-c4fb0aa997c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2a0be86-b6ab-4be4-8f7e-ddbcd419a9f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 563a1985-e207-4800-9fc9-4af3db8defef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2d858e2-65cf-4749-8d4b-80c05fd6d59b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a95d3f6f-e988-43f9-9f09-c7133e8a6bc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed558857-4430-4bf3-8e7a-03c874796c4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42a44a63-23b6-4d2d-ab28-6c7a2203e9b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 784aca3d-2312-446b-b9ae-76cef023152c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0ea051f-e75a-4cf4-aaf9-1fe1485ea68c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a485254c-415a-4496-88cf-06cceeff3d9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98f56057-22fd-4a18-99a8-e3a9cd681bee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3acc0d6-e684-47ba-8164-a3c1e473b0e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff047e35-7d74-4eab-970d-34d24c640dea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98a731a5-6133-4df7-96e9-46c34d46e76c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0fd0054e-d63d-4b66-8471-844c599b4f17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 998496ba-d6d1-4a98-bc08-f084f0f5e3b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7662d7f4-5926-4332-a9f5-7fbf0d151a54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd8b8974-393a-468c-8d25-3eb8ee77ba8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c95ba4bd-4ee1-472f-9eb3-d7238cd2edec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6cb2b3e0-8a01-4f16-bb2a-62c53453ec1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e588f208-13bd-403a-8716-2dbc017e5de1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f835d66-3b2c-46b6-a6bf-4a39ac31daa2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9fd75f3f-934f-425c-81f7-65265f2028ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eeb8838a-bfba-42f7-9093-4ad6ec99986b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 803c98ce-45dc-4e6d-ace8-d9aa266db589
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b53b48f8-5cea-40dd-b8ac-27cb4f08b438
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9499abc4-29dd-4409-ad24-663257dd01e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ebb9ea94-a853-4c8c-8437-805aa32bf344
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 648eafff-3f97-4c1b-8807-0a9f6c5694e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3a34467-7536-49d1-85a4-448e35590d5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1646e57-0bde-4118-9810-083aabe91d6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f80e2df-cc4b-486d-b9d0-3965afb7ea16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ccc07ab-cbfa-4bc0-baa9-e44a02f5ddb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85f8709e-c42b-4190-8e06-4b4a2a830cb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2cb2d84b-2ef9-442b-a8fb-2aa3741943b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68fec180-798f-4f0c-a57e-f75c6a4aed6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d57f5a0-8142-4315-9491-74520306425a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70fb7d2e-8c97-4724-a0c2-7cc5b5fe61bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c96163d-4223-4326-b8c5-1017a7c8eeec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4f47419-4bdb-4468-b46c-b73875027c2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 568bae3a-7894-4be7-a885-9b499a5465c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c84a78c-be1f-4564-bf37-88a5b37e10b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7373fe9a-ddf1-4034-a524-d3fb0284e842
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3d2d87a-5c41-4ef5-a66e-0a1a06473d13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 867e725f-7204-4a48-a5d5-a186912c1da9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d20dfe34-339d-4d02-a210-2d277eac36d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce310b22-025e-4c1e-baaf-2c0d06b28666
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c206884-82fc-44ce-ab1c-0d2f002abf23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f7787de-fa12-45a6-86f2-d3617f10977e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 916c64b8-11ad-4e40-accb-ad6b4f626e6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3b16355-08a8-4ae2-b259-2fdb8fb456ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7028fbe9-df6c-4846-91b1-d213c5636675
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f580e1a8-7f2a-4ee0-94e0-b523f0026d7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12986866-567b-4fe2-9e82-f653631f8f6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 571ac3d0-2bf4-4452-af2b-3f5065b8b96a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a743db0b-61e4-4cc1-8187-1e2506a3ce31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7aff0793-9011-444a-8fa3-3419f474048c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ad069df-7643-45a0-a0c2-31cfaf047a81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12743480-cf3b-4e2e-9604-c659abd5ddb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5629fbcc-bc88-445c-92b9-a1015e63974a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 874d8cd4-58cc-43f5-8335-068a3090d1cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2db1bcab-d226-40cb-b5f3-4a39ce858238
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 423729c3-2fe8-4ae9-a20d-823d4749f1fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a39b1ca4-7f8d-4e68-be1d-46a7481a1fee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f26686c9-ed14-4d6a-ba6f-6b964ff36c74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e56853d-321e-4f14-aa8f-cd30856252a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98cf3c83-822e-46e5-a9e0-22aeb95643e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 024521b4-03ab-448a-96aa-94859346ae9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c7b6d65-5a8b-4bff-bcae-b589e687d5bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f02ee73-ba15-427e-92da-e51c1e004934
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7bacbd19-708c-41ef-88af-cf6f0364e79d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69f612a8-ab02-417b-bffa-494af48fab5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c8bf810-015b-42c8-97bb-485c0740c1f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b5db145-6848-4a93-ba4c-6d70db97f6e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47b5854e-43e4-46ad-8f70-074d4496b783
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b423129-d8ff-471a-b1e5-04a713b2342a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d349b4fc-e3c3-44d9-9538-7313af9d44ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45815249-e52d-49f9-aa4d-ed66f3d9e189
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68ed091c-dc7d-4b3c-8a02-c3b4329c7a47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6cf27730-7aea-4c4a-bc4d-2f493929ee71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4bfda4d8-7283-4334-ad04-e79472b3a35b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc510853-9eaa-4283-85f9-25aeef403343
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f83c147a-7c6a-4996-ad42-8c433d1b42ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 909b8fbe-9856-4038-8357-bd29880e1897
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1e28cd4-2ecb-4a50-a747-088a41d665d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 790dd2b2-28b6-4be6-9de7-942d821912e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc8c5ba3-7f55-45c0-8886-901eae22c8a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 687c4088-db25-422e-ad77-fb526b470c54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c544c99-3c21-450a-a479-d273232bfc50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ebfb209a-a2ba-474b-b377-a13457ed5ad4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c0969f2-d407-4b99-a849-69aa0395c48e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 936786e3-0929-49a4-a419-c0560f1a00a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message efb0743e-7da1-43ef-ad8c-ff09d8684f66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3add94a2-3344-487a-9d0c-728180188b8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad6f1398-b386-4711-bc71-d78cce42aeaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6a15b9a-74d4-4ff7-9ba2-48a024f95680
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53f8f747-bb4a-4438-b3e3-2c2cb75d5e47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb807ef8-5359-4d47-ae9f-448d361481e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fdc3f5c5-6f7f-4063-b50a-a849214319fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 189c4e66-7dc3-46fd-842b-8c919bd72b06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d36e030b-6b06-4c6d-9fe7-d7ddc794d5a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f99d7ce6-dc96-41c8-a5de-69cc5cb7fb62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f52a858-9134-4b9c-b137-3a1ccd12fb2b
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8690 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_14
Server: localhost:8690
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_14
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_14/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_14/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_14/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_14/test_labels.txt

📊 Raw data loaded:
   Train: X=(5733, 24), y=(5733,)
   Test:  X=(1434, 24), y=(1434,)

⚠️  Limiting training data: 5733 → 800 samples
⚠️  Limiting test data: 1434 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_14 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 3 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0895, val=0.0823 (↓), lr=0.001000
   • Epoch   2/100: train=0.0885, val=0.0825, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0887, val=0.0821, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0880, val=0.0820, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0876, val=0.0820, patience=4/15, lr=0.001000
   📉 Epoch 11: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0869, val=0.0823, patience=10/15, lr=0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 3 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0876, RMSE=0.2959, R²=-0.0002
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0013
============================================================


📊 Round 3 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2486, R²: -0.0009

📊 Round 3 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2487, R²: -0.0005

============================================================
🔄 Round 5 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0835 (↓), lr=0.000500
   • Epoch   2/100: train=0.0869, val=0.0833, patience=1/15, lr=0.000500
   📉 Epoch 3: LR reduced 0.000500 → 0.000250
   • Epoch   3/100: train=0.0867, val=0.0834, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0864, val=0.0833, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0863, val=0.0833, patience=4/15, lr=0.000250
   📉 Epoch 11: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0860, val=0.0833, patience=10/15, lr=0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 5 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000500 → 0.000125 (2 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=0.0045
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0000
============================================================


📊 Round 5 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2486, R²: 0.0007

============================================================
🔄 Round 8 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0867 (↓), lr=0.000125
   • Epoch   2/100: train=0.0868, val=0.0865, patience=1/15, lr=0.000125
   📉 Epoch 3: LR reduced 0.000125 → 0.000063
   • Epoch   3/100: train=0.0868, val=0.0865, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0866, val=0.0865, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0866, val=0.0865, patience=4/15, lr=0.000063
   📉 Epoch 11: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0864, val=0.0864, patience=10/15, lr=0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 8 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000125 → 0.000031 (2 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=0.0008
   Val:   Loss=0.0867, RMSE=0.2944, R²=0.0001
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2486, R²: 0.0006

============================================================
🔄 Round 9 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0794 (↓), lr=0.000031
   • Epoch   2/100: train=0.0882, val=0.0795, patience=1/15, lr=0.000031
   • Epoch   3/100: train=0.0881, val=0.0796, patience=2/15, lr=0.000031
   • Epoch   4/100: train=0.0881, val=0.0797, patience=3/15, lr=0.000031
   • Epoch   5/100: train=0.0881, val=0.0798, patience=4/15, lr=0.000031
   📉 Epoch 7: LR reduced 0.000031 → 0.000016
   • Epoch  11/100: train=0.0879, val=0.0799, patience=10/15, lr=0.000016
   📉 Epoch 15: LR reduced 0.000016 → 0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 9 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000031 → 0.000008 (2 reductions)
   Train: Loss=0.0883, RMSE=0.2971, R²=0.0013
   Val:   Loss=0.0794, RMSE=0.2817, R²=-0.0038
============================================================


📊 Round 9 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2488, R²: -0.0003

📊 Round 9 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2486, R²: 0.0008

📊 Round 9 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

============================================================
🔄 Round 17 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0978 (↓), lr=0.000008
   • Epoch   2/100: train=0.0835, val=0.0979, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0835, val=0.0979, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0835, val=0.0980, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0835, val=0.0980, patience=4/15, lr=0.000008
   📉 Epoch 7: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0834, val=0.0981, patience=10/15, lr=0.000004
   📉 Epoch 15: LR reduced 0.000004 → 0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0978)

============================================================
📊 Round 17 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0019
   Val:   Loss=0.0978, RMSE=0.3128, R²=-0.0118
============================================================


============================================================
🔄 Round 18 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0861 (↓), lr=0.000002
   • Epoch   2/100: train=0.0863, val=0.0861, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0863, val=0.0861, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0863, val=0.0861, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0863, val=0.0861, patience=4/15, lr=0.000002
   📉 Epoch 7: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0863, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 18 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=0.0037
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0046
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0006

📊 Round 18 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

============================================================
🔄 Round 21 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 21 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2975, R²=0.0009
   Val:   Loss=0.0778, RMSE=0.2790, R²=-0.0033
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

============================================================
🔄 Round 23 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 23 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=0.0020
   Val:   Loss=0.0815, RMSE=0.2856, R²=0.0040
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

📊 Round 23 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

============================================================
🔄 Round 30 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 30 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=0.0030
   Val:   Loss=0.0865, RMSE=0.2942, R²=0.0017
============================================================


============================================================
🔄 Round 31 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 31 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0021
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0005
============================================================


============================================================
🔄 Round 32 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 32 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0035
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0006
============================================================


============================================================
🔄 Round 35 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 35 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2952, R²=0.0019
   Val:   Loss=0.0834, RMSE=0.2888, R²=0.0017
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

============================================================
🔄 Round 39 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 39 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=0.0041
   Val:   Loss=0.0861, RMSE=0.2933, R²=-0.0046
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

============================================================
🔄 Round 40 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 40 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=0.0037
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0030
============================================================


============================================================
🔄 Round 41 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 41 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=0.0040
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0020
============================================================


============================================================
🔄 Round 42 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0944 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0944, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0944, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0944, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0944, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0944, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0944)

============================================================
📊 Round 42 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0038
   Val:   Loss=0.0944, RMSE=0.3072, R²=-0.0089
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

============================================================
🔄 Round 43 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0947 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0947, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0947, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0947, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0947, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0948, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0947)

============================================================
📊 Round 43 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0011
   Val:   Loss=0.0947, RMSE=0.3078, R²=0.0058
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

📊 Round 43 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

============================================================
🔄 Round 48 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 48 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2964, R²=0.0023
   Val:   Loss=0.0806, RMSE=0.2839, R²=0.0051
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

============================================================
🔄 Round 49 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 49 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=0.0025
   Val:   Loss=0.0847, RMSE=0.2911, R²=-0.0172
============================================================


============================================================
🔄 Round 50 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 50 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2962, R²=0.0038
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0082
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

============================================================
🔄 Round 55 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 55 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2952, R²=0.0025
   Val:   Loss=0.0834, RMSE=0.2888, R²=0.0036
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

📊 Round 55 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

📊 Round 55 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

📊 Round 55 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

============================================================
🔄 Round 59 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 59 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=0.0018
   Val:   Loss=0.0893, RMSE=0.2989, R²=-0.0169
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

📊 Round 59 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

📊 Round 59 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

📊 Round 59 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

============================================================
🔄 Round 69 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0992 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0992, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0992, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0992, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0992, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0992, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0992)

============================================================
📊 Round 69 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0038
   Val:   Loss=0.0992, RMSE=0.3150, R²=-0.0028
============================================================


============================================================
🔄 Round 70 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 70 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=0.0026
   Val:   Loss=0.0880, RMSE=0.2967, R²=-0.0314
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

============================================================
🔄 Round 72 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 72 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=0.0035
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0053
============================================================


============================================================
🔄 Round 75 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 75 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0044
   Val:   Loss=0.0905, RMSE=0.3008, R²=-0.0034
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

============================================================
🔄 Round 76 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 76 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0045
   Val:   Loss=0.0899, RMSE=0.2999, R²=-0.0072
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

📊 Round 76 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

============================================================
🔄 Round 80 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 80 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=0.0017
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0018
============================================================


============================================================
🔄 Round 84 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 84 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2959, R²=0.0022
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0147
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

📊 Round 84 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

============================================================
🔄 Round 86 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0929 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0929, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0929, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0929, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0929, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0929, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 86 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=0.0026
   Val:   Loss=0.0929, RMSE=0.3048, R²=0.0022
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

📊 Round 86 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

============================================================
🔄 Round 88 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 88 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2959, R²=0.0034
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0002
============================================================


============================================================
🔄 Round 90 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 90 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0036
   Val:   Loss=0.0888, RMSE=0.2980, R²=-0.0003
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

============================================================
🔄 Round 91 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 91 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0022
   Val:   Loss=0.0923, RMSE=0.3038, R²=-0.0257
============================================================


============================================================
🔄 Round 94 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 94 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=0.0021
   Val:   Loss=0.0892, RMSE=0.2986, R²=-0.0003
============================================================


============================================================
🔄 Round 95 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 95 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=0.0020
   Val:   Loss=0.0849, RMSE=0.2913, R²=0.0048
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

============================================================
🔄 Round 96 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 96 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0017
   Val:   Loss=0.0917, RMSE=0.3029, R²=-0.0054
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

============================================================
🔄 Round 98 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 98 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=0.0035
   Val:   Loss=0.0791, RMSE=0.2813, R²=-0.0034
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

📊 Round 98 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

📊 Round 98 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

============================================================
🔄 Round 102 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 102 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2962, R²=0.0042
   Val:   Loss=0.0810, RMSE=0.2845, R²=-0.0192
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

============================================================
🔄 Round 104 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 104 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0039
   Val:   Loss=0.0903, RMSE=0.3006, R²=-0.0026
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

============================================================
🔄 Round 105 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 105 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=0.0025
   Val:   Loss=0.0896, RMSE=0.2994, R²=0.0037
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

============================================================
🔄 Round 106 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 106 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=0.0027
   Val:   Loss=0.0836, RMSE=0.2892, R²=0.0031
============================================================


============================================================
🔄 Round 107 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 107 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=0.0030
   Val:   Loss=0.0854, RMSE=0.2923, R²=0.0005
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

============================================================
🔄 Round 108 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 108 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=0.0016
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0038
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

============================================================
🔄 Round 110 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 110 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=0.0007
   Val:   Loss=0.0858, RMSE=0.2930, R²=-0.0025
============================================================


============================================================
🔄 Round 111 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 111 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2962, R²=0.0041
   Val:   Loss=0.0810, RMSE=0.2847, R²=-0.0082
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

📊 Round 111 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

📊 Round 111 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

============================================================
🔄 Round 115 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 115 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0004
   Val:   Loss=0.0904, RMSE=0.3006, R²=0.0106
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

📊 Round 115 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

📊 Round 115 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

📊 Round 115 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

📊 Round 115 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

============================================================
🔄 Round 126 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 126 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=0.0031
   Val:   Loss=0.0875, RMSE=0.2957, R²=-0.0061
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

============================================================
🔄 Round 131 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 131 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=0.0020
   Val:   Loss=0.0860, RMSE=0.2933, R²=0.0057
============================================================


============================================================
🔄 Round 133 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 133 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=0.0027
   Val:   Loss=0.0837, RMSE=0.2893, R²=0.0027
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

============================================================
🔄 Round 134 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0922 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0922, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0923, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0922)

============================================================
📊 Round 134 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0014
   Val:   Loss=0.0922, RMSE=0.3037, R²=0.0066
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

============================================================
🔄 Round 135 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 135 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=0.0036
   Val:   Loss=0.0849, RMSE=0.2913, R²=-0.0067
============================================================


============================================================
🔄 Round 138 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 138 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=0.0044
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0066
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

============================================================
🔄 Round 139 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 139 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2947, R²=0.0043
   Val:   Loss=0.0844, RMSE=0.2906, R²=-0.0035
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

📊 Round 139 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

📊 Round 139 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

============================================================
🔄 Round 147 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 147 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=0.0039
   Val:   Loss=0.0813, RMSE=0.2852, R²=-0.0244
============================================================


============================================================
🔄 Round 148 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 148 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=0.0022
   Val:   Loss=0.0867, RMSE=0.2944, R²=0.0049
============================================================


============================================================
🔄 Round 149 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0938 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0938, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0938, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0938, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0938, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0939, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0938)

============================================================
📊 Round 149 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=0.0023
   Val:   Loss=0.0938, RMSE=0.3062, R²=-0.0068
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

============================================================
🔄 Round 150 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 150 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=0.0019
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0041
============================================================


============================================================
🔄 Round 151 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 151 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=0.0010
   Val:   Loss=0.0868, RMSE=0.2945, R²=-0.0075
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

============================================================
🔄 Round 153 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 153 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0021
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0090
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

📊 Round 153 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

============================================================
🔄 Round 155 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 155 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=0.0018
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0152
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

📊 Round 155 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

📊 Round 155 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

============================================================
🔄 Round 166 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 166 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=0.0026
   Val:   Loss=0.0854, RMSE=0.2923, R²=-0.0051
============================================================


============================================================
🔄 Round 168 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 168 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=0.0011
   Val:   Loss=0.0835, RMSE=0.2889, R²=0.0079
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

📊 Round 168 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

📊 Round 168 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

📊 Round 168 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

============================================================
🔄 Round 173 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 173 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=0.0041
   Val:   Loss=0.0860, RMSE=0.2932, R²=-0.0168
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

============================================================
🔄 Round 175 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 175 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0022
   Val:   Loss=0.0915, RMSE=0.3025, R²=0.0049
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

============================================================
🔄 Round 176 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 176 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=0.0044
   Val:   Loss=0.0868, RMSE=0.2947, R²=-0.0071
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

📊 Round 176 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

============================================================
🔄 Round 179 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 179 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0033
   Val:   Loss=0.0888, RMSE=0.2981, R²=-0.0009
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

============================================================
🔄 Round 180 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 180 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2962, R²=0.0023
   Val:   Loss=0.0811, RMSE=0.2847, R²=-0.0457
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

============================================================
🔄 Round 181 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 181 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0026
   Val:   Loss=0.0919, RMSE=0.3031, R²=-0.0182
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

============================================================
🔄 Round 183 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 183 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=0.0038
   Val:   Loss=0.0897, RMSE=0.2995, R²=-0.0008
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

📊 Round 183 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

============================================================
🔄 Round 187 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 187 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2978, R²=0.0030
   Val:   Loss=0.0773, RMSE=0.2780, R²=-0.0030
============================================================


============================================================
🔄 Round 188 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0922 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0922, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0922, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0922, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0922, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0922, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0922)

============================================================
📊 Round 188 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0044
   Val:   Loss=0.0922, RMSE=0.3037, R²=-0.0029
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

============================================================
🔄 Round 189 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 189 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2937, R²=0.0036
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0333
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

============================================================
🔄 Round 194 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0898, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0898, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0898, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0898, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0898, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0898, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 194 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0898, RMSE=0.2996, R²=0.0034
   Val:   Loss=0.0728, RMSE=0.2699, R²=-0.0141
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

============================================================
🔄 Round 198 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 198 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0052
   Val:   Loss=0.0915, RMSE=0.3026, R²=-0.0088
============================================================


============================================================
🔄 Round 199 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 199 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=0.0031
   Val:   Loss=0.0824, RMSE=0.2871, R²=0.0017
============================================================


============================================================
🔄 Round 201 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 201 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=0.0032
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0006
============================================================


📊 Round 201 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

📊 Round 201 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

============================================================
🔄 Round 205 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 205 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=0.0021
   Val:   Loss=0.0880, RMSE=0.2966, R²=0.0006
============================================================


📊 Round 205 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

============================================================
🔄 Round 208 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 208 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=0.0027
   Val:   Loss=0.0832, RMSE=0.2884, R²=0.0027
============================================================


📊 Round 208 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

============================================================
🔄 Round 210 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0924 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 210 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0024
   Val:   Loss=0.0924, RMSE=0.3039, R²=0.0022
============================================================


📊 Round 210 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

📊 Round 210 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

📊 Round 210 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

============================================================
🔄 Round 216 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 216 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2977, R²=0.0010
   Val:   Loss=0.0775, RMSE=0.2784, R²=-0.0231
============================================================


📊 Round 216 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

============================================================
🔄 Round 219 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 219 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=0.0016
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0074
============================================================


📊 Round 219 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

============================================================
🔄 Round 221 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 221 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2978, R²=0.0025
   Val:   Loss=0.0771, RMSE=0.2776, R²=0.0044
============================================================


============================================================
🔄 Round 224 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 224 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0032
   Val:   Loss=0.0911, RMSE=0.3018, R²=-0.0059
============================================================


============================================================
🔄 Round 225 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0893, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0893, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0893, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0893, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0893, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 225 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0890, RMSE=0.2983, R²=0.0044
   Val:   Loss=0.0760, RMSE=0.2757, R²=-0.0048
============================================================


============================================================
🔄 Round 226 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 226 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0046
   Val:   Loss=0.0877, RMSE=0.2962, R²=-0.0071
============================================================


============================================================
🔄 Round 227 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 227 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=0.0036
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0054
============================================================


============================================================
🔄 Round 228 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 228 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=0.0028
   Val:   Loss=0.0846, RMSE=0.2909, R²=0.0023
============================================================


📊 Round 228 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

📊 Round 228 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

============================================================
🔄 Round 231 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 231 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=0.0001
   Val:   Loss=0.0890, RMSE=0.2983, R²=-0.0064
============================================================


📊 Round 231 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

📊 Round 231 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

============================================================
🔄 Round 233 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 233 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2957, R²=0.0023
   Val:   Loss=0.0822, RMSE=0.2867, R²=0.0027
============================================================


📊 Round 233 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

📊 Round 233 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

============================================================
🔄 Round 240 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 240 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=0.0015
   Val:   Loss=0.0883, RMSE=0.2971, R²=0.0038
============================================================


📊 Round 240 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

📊 Round 240 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

============================================================
🔄 Round 244 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 244 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=0.0037
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0038
============================================================


📊 Round 244 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

============================================================
🔄 Round 247 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 247 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=0.0010
   Val:   Loss=0.0855, RMSE=0.2924, R²=0.0087
============================================================


📊 Round 247 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

============================================================
🔄 Round 249 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 249 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0004
   Val:   Loss=0.0878, RMSE=0.2963, R²=0.0119
============================================================


============================================================
🔄 Round 250 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 250 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=0.0019
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0020
============================================================


📊 Round 250 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

📊 Round 250 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

📊 Round 250 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

============================================================
🔄 Round 254 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 254 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=0.0023
   Val:   Loss=0.0869, RMSE=0.2947, R²=-0.0040
============================================================


📊 Round 254 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

============================================================
🔄 Round 257 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0947 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0947, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0947, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0947, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0948, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0948, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0947)

============================================================
📊 Round 257 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0035
   Val:   Loss=0.0947, RMSE=0.3078, R²=-0.0183
============================================================


============================================================
🔄 Round 260 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 260 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=0.0040
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0021
============================================================


📊 Round 260 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

============================================================
🔄 Round 262 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 262 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=0.0023
   Val:   Loss=0.0858, RMSE=0.2928, R²=0.0043
============================================================


📊 Round 262 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

============================================================
🔄 Round 263 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 263 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2982, R²=0.0036
   Val:   Loss=0.0762, RMSE=0.2761, R²=-0.0110
============================================================


============================================================
🔄 Round 265 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 265 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=0.0016
   Val:   Loss=0.0847, RMSE=0.2911, R²=0.0060
============================================================


📊 Round 265 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

============================================================
🔄 Round 266 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 266 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2954, R²=0.0005
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0109
============================================================


📊 Round 266 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

📊 Round 266 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

📊 Round 266 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

📊 Round 266 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

============================================================
🔄 Round 276 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0968 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0968, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0968, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0968, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0968, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0968, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0968)

============================================================
📊 Round 276 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=0.0055
   Val:   Loss=0.0968, RMSE=0.3112, R²=-0.0079
============================================================


============================================================
🔄 Round 277 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 277 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=0.0023
   Val:   Loss=0.0857, RMSE=0.2927, R²=0.0031
============================================================


📊 Round 277 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

📊 Round 277 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

============================================================
🔄 Round 281 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 281 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=0.0054
   Val:   Loss=0.0862, RMSE=0.2937, R²=-0.0090
============================================================


============================================================
🔄 Round 282 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 282 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=0.0039
   Val:   Loss=0.0902, RMSE=0.3004, R²=-0.0051
============================================================


📊 Round 282 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

============================================================
🔄 Round 283 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 283 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2952, R²=0.0025
   Val:   Loss=0.0834, RMSE=0.2887, R²=0.0035
============================================================


============================================================
🔄 Round 284 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 284 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0000
   Val:   Loss=0.0917, RMSE=0.3028, R²=-0.0135
============================================================


📊 Round 284 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

📊 Round 284 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

============================================================
🔄 Round 286 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 286 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=0.0031
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0002
============================================================


📊 Round 286 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

============================================================
🔄 Round 289 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 289 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=0.0014
   Val:   Loss=0.0885, RMSE=0.2975, R²=0.0082
============================================================


============================================================
🔄 Round 290 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 290 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=0.0034
   Val:   Loss=0.0868, RMSE=0.2947, R²=-0.0102
============================================================


📊 Round 290 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

📊 Round 290 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

📊 Round 290 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

============================================================
🔄 Round 296 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 296 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0043
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0098
============================================================


============================================================
🔄 Round 297 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 297 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=0.0030
   Val:   Loss=0.0839, RMSE=0.2896, R²=0.0017
============================================================


============================================================
🔄 Round 298 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 298 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0025
   Val:   Loss=0.0879, RMSE=0.2964, R²=-0.0094
============================================================


============================================================
🔄 Round 300 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0957 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0957, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0957, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0957, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0957, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0957, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0957)

============================================================
📊 Round 300 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=0.0039
   Val:   Loss=0.0957, RMSE=0.3093, R²=-0.0012
============================================================


📊 Round 300 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

📊 Round 300 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

============================================================
🔄 Round 304 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 304 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=0.0030
   Val:   Loss=0.0856, RMSE=0.2926, R²=0.0023
============================================================


📊 Round 304 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

============================================================
🔄 Round 306 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 306 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=0.0010
   Val:   Loss=0.0858, RMSE=0.2930, R²=-0.0045
============================================================


📊 Round 306 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

============================================================
🔄 Round 311 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0939 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0939, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0939, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0939, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0939, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0939, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0939)

============================================================
📊 Round 311 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0027
   Val:   Loss=0.0939, RMSE=0.3064, R²=-0.0026
============================================================


📊 Round 311 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

📊 Round 311 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

📊 Round 311 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

📊 Round 311 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0007

============================================================
🔄 Round 321 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 321 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0030
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0151
============================================================


📊 Round 321 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

============================================================
🔄 Round 322 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 322 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=0.0018
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0054
============================================================


============================================================
🔄 Round 324 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 324 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=0.0032
   Val:   Loss=0.0838, RMSE=0.2895, R²=0.0015
============================================================


📊 Round 324 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

📊 Round 324 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

📊 Round 324 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

📊 Round 324 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

📊 Round 324 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

============================================================
🔄 Round 336 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 336 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=0.0021
   Val:   Loss=0.0908, RMSE=0.3013, R²=0.0057
============================================================


📊 Round 336 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

📊 Round 336 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

📊 Round 336 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

📊 Round 336 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

============================================================
🔄 Round 343 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 343 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2962, R²=0.0020
   Val:   Loss=0.0809, RMSE=0.2845, R²=-0.0186
============================================================


📊 Round 343 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

============================================================
🔄 Round 349 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 349 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=0.0016
   Val:   Loss=0.0841, RMSE=0.2899, R²=-0.0103
============================================================


📊 Round 349 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

============================================================
🔄 Round 350 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 350 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2967, R²=0.0018
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0020
============================================================


📊 Round 350 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

============================================================
🔄 Round 351 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0890, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 351 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0890, RMSE=0.2984, R²=0.0029
   Val:   Loss=0.0757, RMSE=0.2751, R²=0.0015
============================================================


📊 Round 351 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

📊 Round 351 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

📊 Round 351 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

============================================================
🔄 Round 354 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 354 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=0.0044
   Val:   Loss=0.0908, RMSE=0.3013, R²=-0.0041
============================================================


📊 Round 354 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

============================================================
🔄 Round 358 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 358 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2921, R²=0.0021
   Val:   Loss=0.0905, RMSE=0.3008, R²=0.0037
============================================================


📊 Round 358 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

📊 Round 358 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

📊 Round 358 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

📊 Round 358 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

📊 Round 358 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

============================================================
🔄 Round 365 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 365 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=0.0014
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0226
============================================================


📊 Round 365 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

📊 Round 365 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

============================================================
🔄 Round 367 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 367 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2977, R²=0.0027
   Val:   Loss=0.0773, RMSE=0.2780, R²=-0.0092
============================================================


📊 Round 367 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

📊 Round 367 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

📊 Round 367 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

📊 Round 367 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

📊 Round 367 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

============================================================
🔄 Round 379 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 379 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2973, R²=0.0027
   Val:   Loss=0.0783, RMSE=0.2799, R²=0.0036
============================================================


============================================================
🔄 Round 380 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 380 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0037
   Val:   Loss=0.0911, RMSE=0.3019, R²=-0.0046
============================================================


📊 Round 380 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

============================================================
🔄 Round 381 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0963 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0963, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0963, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0963, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0963, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0963, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0963)

============================================================
📊 Round 381 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0046
   Val:   Loss=0.0963, RMSE=0.3104, R²=-0.0035
============================================================


📊 Round 381 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

============================================================
🔄 Round 383 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 383 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=0.0009
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0048
============================================================


📊 Round 383 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

============================================================
🔄 Round 390 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 390 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=0.0019
   Val:   Loss=0.0890, RMSE=0.2983, R²=0.0022
============================================================


📊 Round 390 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

============================================================
🔄 Round 391 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0943 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0943, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0943, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0943, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0943, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0943, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0943)

============================================================
📊 Round 391 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0035
   Val:   Loss=0.0943, RMSE=0.3070, R²=-0.0007
============================================================


📊 Round 391 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

📊 Round 391 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

📊 Round 391 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

📊 Round 391 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

============================================================
🔄 Round 396 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 396 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=0.0010
   Val:   Loss=0.0848, RMSE=0.2912, R²=0.0074
============================================================


📊 Round 396 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

============================================================
🔄 Round 398 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 398 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2967, R²=0.0043
   Val:   Loss=0.0798, RMSE=0.2824, R²=-0.0035
============================================================


📊 Round 398 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

============================================================
🔄 Round 399 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0924 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 399 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=0.0020
   Val:   Loss=0.0924, RMSE=0.3040, R²=0.0035
============================================================


📊 Round 399 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

📊 Round 399 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

============================================================
🔄 Round 405 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 405 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=0.0027
   Val:   Loss=0.0880, RMSE=0.2967, R²=0.0037
============================================================


📊 Round 405 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

📊 Round 405 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

============================================================
🔄 Round 410 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 410 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=0.0016
   Val:   Loss=0.0896, RMSE=0.2994, R²=-0.0188
============================================================


============================================================
🔄 Round 412 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 412 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=0.0025
   Val:   Loss=0.0870, RMSE=0.2950, R²=0.0010
============================================================


============================================================
🔄 Round 413 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 413 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=0.0030
   Val:   Loss=0.0847, RMSE=0.2910, R²=0.0024
============================================================


📊 Round 413 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

============================================================
🔄 Round 415 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 415 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2972, R²=0.0020
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.0062
============================================================


📊 Round 415 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

📊 Round 415 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

============================================================
🔄 Round 417 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0944 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0944, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0945, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0945, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0945, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0945, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0944)

============================================================
📊 Round 417 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0022
   Val:   Loss=0.0944, RMSE=0.3073, R²=-0.0107
============================================================


📊 Round 417 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

📊 Round 417 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

============================================================
🔄 Round 421 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0896, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0896, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0896, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0896, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0896, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0896, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 421 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0897, RMSE=0.2995, R²=0.0023
   Val:   Loss=0.0731, RMSE=0.2704, R²=-0.0025
============================================================


📊 Round 421 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

📊 Round 421 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

📊 Round 421 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

============================================================
🔄 Round 424 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 424 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=0.0017
   Val:   Loss=0.0812, RMSE=0.2850, R²=0.0059
============================================================


📊 Round 424 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

============================================================
🔄 Round 425 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 425 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=0.0005
   Val:   Loss=0.0872, RMSE=0.2953, R²=0.0077
============================================================


============================================================
🔄 Round 426 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 426 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=0.0005
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0124
============================================================


📊 Round 426 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

============================================================
🔄 Round 427 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 427 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0011
   Val:   Loss=0.0915, RMSE=0.3025, R²=-0.0064
============================================================


============================================================
🔄 Round 430 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 430 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2977, R²=0.0022
   Val:   Loss=0.0774, RMSE=0.2783, R²=-0.0105
============================================================


📊 Round 430 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

📊 Round 430 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

============================================================
🔄 Round 432 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 432 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=0.0008
   Val:   Loss=0.0865, RMSE=0.2941, R²=0.0096
============================================================


📊 Round 432 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

============================================================
🔄 Round 433 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 433 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0028
   Val:   Loss=0.0907, RMSE=0.3011, R²=0.0030
============================================================


📊 Round 433 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

📊 Round 433 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

============================================================
🔄 Round 435 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 435 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=0.0027
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0038
============================================================


📊 Round 435 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

📊 Round 435 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

============================================================
🔄 Round 441 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 441 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0019
   Val:   Loss=0.0878, RMSE=0.2964, R²=-0.0003
============================================================


============================================================
🔄 Round 442 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 442 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0028
   Val:   Loss=0.0921, RMSE=0.3035, R²=0.0018
============================================================


============================================================
🔄 Round 446 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 446 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0014
   Val:   Loss=0.0911, RMSE=0.3018, R²=0.0083
============================================================


📊 Round 446 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

============================================================
🔄 Round 447 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 447 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=0.0025
   Val:   Loss=0.0894, RMSE=0.2990, R²=0.0040
============================================================


📊 Round 447 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

📊 Round 447 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

============================================================
🔄 Round 453 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 453 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=0.0022
   Val:   Loss=0.0863, RMSE=0.2938, R²=0.0048
============================================================


📊 Round 453 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

📊 Round 453 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

📊 Round 453 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

📊 Round 453 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

============================================================
🔄 Round 458 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 458 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=0.0039
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0069
============================================================


============================================================
🔄 Round 459 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 459 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=0.0012
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0078
============================================================


📊 Round 459 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

============================================================
🔄 Round 460 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0976 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0976, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0977, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0977, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0977, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0977, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0976)

============================================================
📊 Round 460 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0011
   Val:   Loss=0.0976, RMSE=0.3125, R²=-0.0001
============================================================


============================================================
🔄 Round 462 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 462 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0016
   Val:   Loss=0.0919, RMSE=0.3032, R²=0.0068
============================================================


============================================================
🔄 Round 463 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 463 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2978, R²=0.0035
   Val:   Loss=0.0771, RMSE=0.2777, R²=-0.0075
============================================================


📊 Round 463 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

📊 Round 463 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

============================================================
🔄 Round 466 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 466 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0033
   Val:   Loss=0.0879, RMSE=0.2964, R²=-0.0202
============================================================


📊 Round 466 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

============================================================
🔄 Round 467 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 467 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=0.0023
   Val:   Loss=0.0884, RMSE=0.2972, R²=-0.0046
============================================================


📊 Round 467 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

============================================================
🔄 Round 472 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0982 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0982, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0982, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0982, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0982, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0983, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0982)

============================================================
📊 Round 472 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0016
   Val:   Loss=0.0982, RMSE=0.3134, R²=-0.0112
============================================================


📊 Round 472 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

📊 Round 472 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

============================================================
🔄 Round 474 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 474 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=0.0024
   Val:   Loss=0.0881, RMSE=0.2969, R²=-0.0109
============================================================


============================================================
🔄 Round 475 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 475 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=0.0024
   Val:   Loss=0.0873, RMSE=0.2954, R²=0.0046
============================================================


📊 Round 475 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

============================================================
🔄 Round 476 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 476 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=0.0023
   Val:   Loss=0.0839, RMSE=0.2896, R²=0.0028
============================================================


📊 Round 476 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

============================================================
🔄 Round 477 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 477 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2978, R²=0.0028
   Val:   Loss=0.0772, RMSE=0.2778, R²=-0.0091
============================================================


============================================================
🔄 Round 478 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 478 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2973, R²=0.0031
   Val:   Loss=0.0784, RMSE=0.2800, R²=-0.0006
============================================================


📊 Round 478 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

📊 Round 478 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

============================================================
🔄 Round 481 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 481 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=0.0024
   Val:   Loss=0.0879, RMSE=0.2965, R²=0.0049
============================================================


📊 Round 481 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

============================================================
🔄 Round 483 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0922 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0922, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0923, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0922)

============================================================
📊 Round 483 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0039
   Val:   Loss=0.0922, RMSE=0.3037, R²=-0.0208
============================================================


============================================================
🔄 Round 485 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 485 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2977, R²=0.0005
   Val:   Loss=0.0773, RMSE=0.2780, R²=-0.0131
============================================================


============================================================
🔄 Round 487 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 487 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=0.0042
   Val:   Loss=0.0866, RMSE=0.2942, R²=-0.0022
============================================================


📊 Round 487 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

📊 Round 487 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

============================================================
🔄 Round 491 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 491 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0890, RMSE=0.2983, R²=0.0023
   Val:   Loss=0.0760, RMSE=0.2756, R²=-0.0104
============================================================


📊 Round 491 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

📊 Round 491 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

============================================================
🔄 Round 500 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 500 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0035
   Val:   Loss=0.0879, RMSE=0.2965, R²=0.0003
============================================================


📊 Round 500 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

📊 Round 500 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

============================================================
🔄 Round 507 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 507 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0020
   Val:   Loss=0.0877, RMSE=0.2962, R²=-0.0108
============================================================


📊 Round 507 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

============================================================
🔄 Round 509 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 509 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=0.0039
   Val:   Loss=0.0841, RMSE=0.2901, R²=-0.0017
============================================================


📊 Round 509 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

============================================================
🔄 Round 510 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 510 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2954, R²=0.0026
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0311
============================================================


============================================================
🔄 Round 513 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0951 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0951, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0951, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0951, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0951, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0951, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0951)

============================================================
📊 Round 513 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0035
   Val:   Loss=0.0951, RMSE=0.3083, R²=0.0004
============================================================


📊 Round 513 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

============================================================
🔄 Round 517 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0982 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0982, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0982, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0982, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0982, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0982, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0982)

============================================================
📊 Round 517 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0043
   Val:   Loss=0.0982, RMSE=0.3133, R²=-0.0021
============================================================


📊 Round 517 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

============================================================
🔄 Round 520 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 520 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0024
   Val:   Loss=0.0906, RMSE=0.3011, R²=0.0025
============================================================


============================================================
🔄 Round 522 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 522 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=0.0031
   Val:   Loss=0.0843, RMSE=0.2903, R²=0.0023
============================================================


============================================================
🔄 Round 523 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 523 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=0.0036
   Val:   Loss=0.0861, RMSE=0.2935, R²=-0.0113
============================================================


📊 Round 523 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

============================================================
🔄 Round 529 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 529 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=0.0002
   Val:   Loss=0.0846, RMSE=0.2908, R²=-0.0025
============================================================


📊 Round 529 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

📊 Round 529 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

============================================================
🔄 Round 533 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 533 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2973, R²=0.0032
   Val:   Loss=0.0782, RMSE=0.2797, R²=-0.0005
============================================================


📊 Round 533 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

📊 Round 533 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

============================================================
🔄 Round 538 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 538 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2962, R²=0.0014
   Val:   Loss=0.0810, RMSE=0.2845, R²=0.0077
============================================================


📊 Round 538 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

📊 Round 538 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

============================================================
🔄 Round 541 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 541 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=0.0033
   Val:   Loss=0.0850, RMSE=0.2915, R²=0.0010
============================================================


============================================================
🔄 Round 543 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 543 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=0.0031
   Val:   Loss=0.0835, RMSE=0.2890, R²=0.0023
============================================================


📊 Round 543 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

============================================================
🔄 Round 545 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 545 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=0.0015
   Val:   Loss=0.0862, RMSE=0.2936, R²=0.0052
============================================================


📊 Round 545 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

============================================================
🔄 Round 548 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 548 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0010
   Val:   Loss=0.0887, RMSE=0.2978, R²=0.0039
============================================================


============================================================
🔄 Round 549 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 549 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2977, R²=0.0017
   Val:   Loss=0.0775, RMSE=0.2783, R²=0.0077
============================================================


📊 Round 549 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

============================================================
🔄 Round 552 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0950 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0950, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0950, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0950, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0950, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0950, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0950)

============================================================
📊 Round 552 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0026
   Val:   Loss=0.0950, RMSE=0.3083, R²=0.0014
============================================================


============================================================
🔄 Round 555 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 555 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0005
   Val:   Loss=0.0876, RMSE=0.2960, R²=0.0085
============================================================


📊 Round 555 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

============================================================
🔄 Round 557 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 557 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=0.0031
   Val:   Loss=0.0861, RMSE=0.2935, R²=0.0013
============================================================


============================================================
🔄 Round 559 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0973 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0973, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0973, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0974, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0974, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0974, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0973)

============================================================
📊 Round 559 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0002
   Val:   Loss=0.0973, RMSE=0.3120, R²=-0.0033
============================================================


============================================================
🔄 Round 561 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 561 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2979, R²=0.0025
   Val:   Loss=0.0769, RMSE=0.2772, R²=-0.0272
============================================================


📊 Round 561 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

============================================================
🔄 Round 564 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 564 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0020
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0033
============================================================


📊 Round 564 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

============================================================
🔄 Round 566 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 566 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0029
   Val:   Loss=0.0903, RMSE=0.3005, R²=0.0003
============================================================


📊 Round 566 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

============================================================
🔄 Round 569 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 569 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=0.0044
   Val:   Loss=0.0811, RMSE=0.2847, R²=-0.0038
============================================================


📊 Round 569 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

📊 Round 569 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

📊 Round 569 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

📊 Round 569 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

============================================================
🔄 Round 573 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 573 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=0.0024
   Val:   Loss=0.0894, RMSE=0.2991, R²=-0.0107
============================================================


============================================================
🔄 Round 575 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 575 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=0.0024
   Val:   Loss=0.0891, RMSE=0.2985, R²=0.0051
============================================================


============================================================
🔄 Round 576 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 576 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=0.0016
   Val:   Loss=0.0847, RMSE=0.2910, R²=0.0069
============================================================


📊 Round 576 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

============================================================
🔄 Round 582 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 582 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0031
   Val:   Loss=0.0886, RMSE=0.2976, R²=-0.0079
============================================================


============================================================
🔄 Round 584 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 584 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=0.0014
   Val:   Loss=0.0857, RMSE=0.2927, R²=0.0090
============================================================


============================================================
🔄 Round 586 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 586 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=0.0031
   Val:   Loss=0.0880, RMSE=0.2966, R²=0.0011
============================================================


============================================================
🔄 Round 587 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 587 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2976, R²=0.0014
   Val:   Loss=0.0776, RMSE=0.2786, R²=0.0083
============================================================


============================================================
🔄 Round 588 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 588 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=0.0011
   Val:   Loss=0.0907, RMSE=0.3012, R²=0.0048
============================================================


📊 Round 588 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

📊 Round 588 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

============================================================
🔄 Round 591 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 591 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2957, R²=0.0001
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0003
============================================================


📊 Round 591 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

📊 Round 591 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

============================================================
🔄 Round 594 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 594 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0013
   Val:   Loss=0.0874, RMSE=0.2957, R²=0.0079
============================================================


📊 Round 594 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

📊 Round 594 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

📊 Round 594 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

============================================================
🔄 Round 604 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 604 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2959, R²=0.0031
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0030
============================================================


============================================================
🔄 Round 606 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0963 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0963, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0963, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0963, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0964, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0964, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0963)

============================================================
📊 Round 606 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0037
   Val:   Loss=0.0963, RMSE=0.3104, R²=-0.0035
============================================================


📊 Round 606 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

============================================================
🔄 Round 607 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 607 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2952, R²=0.0021
   Val:   Loss=0.0832, RMSE=0.2884, R²=0.0058
============================================================


============================================================
🔄 Round 608 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 608 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2928, R²=0.0020
   Val:   Loss=0.0888, RMSE=0.2980, R²=0.0070
============================================================


📊 Round 608 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

============================================================
🔄 Round 612 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 612 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=0.0044
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0025
============================================================


============================================================
🔄 Round 614 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 614 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=0.0025
   Val:   Loss=0.0913, RMSE=0.3021, R²=0.0009
============================================================


📊 Round 614 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

============================================================
🔄 Round 615 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 615 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0030
   Val:   Loss=0.0874, RMSE=0.2957, R²=0.0027
============================================================


📊 Round 615 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

============================================================
🔄 Round 616 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 616 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=0.0035
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0083
============================================================


📊 Round 616 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

📊 Round 616 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

============================================================
🔄 Round 619 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 619 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=0.0044
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0196
============================================================


📊 Round 619 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

============================================================
🔄 Round 624 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 624 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=0.0036
   Val:   Loss=0.0883, RMSE=0.2972, R²=0.0005
============================================================


📊 Round 624 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

============================================================
🔄 Round 626 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 626 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=0.0033
   Val:   Loss=0.0869, RMSE=0.2949, R²=0.0016
============================================================


============================================================
🔄 Round 629 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 629 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0029
   Val:   Loss=0.0878, RMSE=0.2963, R²=0.0032
============================================================


📊 Round 629 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

============================================================
🔄 Round 634 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 634 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2964, R²=0.0039
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0081
============================================================


📊 Round 634 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

📊 Round 634 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

============================================================
🔄 Round 637 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 637 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=0.0021
   Val:   Loss=0.0813, RMSE=0.2852, R²=0.0034
============================================================


============================================================
🔄 Round 638 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 638 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2972, R²=0.0030
   Val:   Loss=0.0785, RMSE=0.2801, R²=0.0033
============================================================


📊 Round 638 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

============================================================
🔄 Round 639 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 639 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=0.0023
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0060
============================================================


📊 Round 639 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

============================================================
🔄 Round 642 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0931 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0931, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0932, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0932, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0932, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0932, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0931)

============================================================
📊 Round 642 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0015
   Val:   Loss=0.0931, RMSE=0.3052, R²=-0.0030
============================================================


📊 Round 642 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

📊 Round 642 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

📊 Round 642 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

============================================================
🔄 Round 645 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 645 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=0.0027
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0038
============================================================


============================================================
🔄 Round 646 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 646 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=0.0004
   Val:   Loss=0.0901, RMSE=0.3002, R²=-0.0235
============================================================


============================================================
🔄 Round 649 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0922 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0922, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0922, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0922, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0922, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0923, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0922)

============================================================
📊 Round 649 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0041
   Val:   Loss=0.0922, RMSE=0.3036, R²=-0.0315
============================================================


📊 Round 649 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

📊 Round 649 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

============================================================
🔄 Round 654 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 654 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=0.0030
   Val:   Loss=0.0890, RMSE=0.2984, R²=0.0031
============================================================


============================================================
🔄 Round 655 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 655 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=0.0017
   Val:   Loss=0.0925, RMSE=0.3041, R²=-0.0117
============================================================


📊 Round 655 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

============================================================
🔄 Round 659 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 659 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=0.0037
   Val:   Loss=0.0885, RMSE=0.2975, R²=-0.0007
============================================================


📊 Round 659 Test Metrics:
   Loss: 0.0826, RMSE: 0.2875, MAE: 0.2487, R²: 0.0008

❌ Client client_14 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8690 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8690 {grpc_status:14, grpc_message:"Socket closed"}"
>
