[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a4dbdaf-d47e-4062-842d-2cc42ec99baa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dce2a533-d848-4887-a51e-261d8bbcd46d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb0e8ae9-f96b-4d1e-a58c-39a1f908fa37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5728e89-33f3-4584-be8e-f27a2cd5b467
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38969430-1e28-404e-a11e-8ccc36c87468
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e790f08-5568-4fdc-bd24-08967f54ad26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ac91aa7-08d2-4408-9bd8-895ff0dd27d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a58f5371-0c2f-4a8a-a3af-c5fade46ccc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9270b7c7-e5b6-4f38-92e7-ac994ffc263d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7d94656-13d4-4a4e-a5fd-f0594cc67dd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e89a081-db97-4221-bd94-f018daebc54d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c23bb91-99ea-4f98-8961-63c25bd8fd76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14718345-0bb0-4777-ab47-a48375aa2642
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a08d91c-744d-4b10-b323-9e8521c58c92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35db9379-0778-4899-b5fd-5390e59137ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 604784b0-4359-43cd-8e9d-84c6be286bd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7945ecb8-ae5e-4889-8229-16753825358b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f956ca6-84ed-46d0-92e4-84eb9fa08844
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 489ee1f3-86d8-4639-bd1a-83a37a07a491
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02009ca6-2b3d-49c6-aacb-4e0ddb69a135
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0118506d-80d7-4e05-a0e7-de18abb9816b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3ad07ff-304b-4138-8db1-888b3ac3c9b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa462eb7-b2a1-4865-9f94-458aa67590c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02843af1-08a3-44ec-a289-efc925b68d0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 733fb62d-70e6-4e23-b8d2-c64ee1b47165
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f03e3cca-7196-4df1-91a8-202bf247bf02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69b9d887-f0d3-42e5-b11f-a7cd9a4201a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e26d3b31-fd2c-4bf3-8b0a-b3b83bd02cd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c95b101d-d420-4f4c-b1d7-d50d437d6fa5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18dcc8d5-70dc-436f-9ef5-70c150750948
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73e84b61-2c84-4181-b18a-fef0c12ad16b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57fb9e00-c0b3-47f0-af92-0f2a0ca7376a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02cb9d20-79b9-4243-9666-9216347f08c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1cdfff0-719a-4bdd-a4f3-fa9c311e2419
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f45c43e0-aea9-4e7a-a6e5-d5ad5b65b71d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56e6dd4e-8b86-449e-b2c0-ebebdf3481c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a938327-14a6-496f-9f0e-e0950e87fc1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57f2cbf5-93bc-43a1-a609-1f06edcb724b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 885abaf7-f93f-4675-9bd9-f15518d32046
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e36871cc-46d5-4538-9eff-97097b8fa4b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b85081d-1908-4999-8b4e-ec385f072148
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4382c59-f521-4d3b-a9b1-648740b7091b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f039edae-5fa2-41fd-a5c9-68d7161e451c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b31f6e67-dac7-4c21-b9e5-e72d2e812b7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd164f70-c1fa-4066-8ab7-a733ee2c94fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8ad59c9-4270-4d2f-ab64-f9fe5764e696
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 803d3e7c-923e-4a3d-9394-0a4bacea71ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 269b67ec-7042-46f5-8c60-368dd1809227
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aabe1593-b2c1-4ffc-93bd-3ff197387e29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e97c57c-d260-4fd4-a169-ebacc3b446f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94d3e435-a760-41c4-b9f1-93e4081b3d01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 056740a0-9c99-4b91-9c7b-fa4fa08d242b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14ada7f8-f745-419e-aaa0-d1cd76942ab1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7965a0e4-55dd-4fa8-be2b-b4c63f6e904f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7db60860-cb98-4d7c-8fe8-47a7465e1ba3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 781f1789-2a40-4368-a2ca-b090942f4b9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10084f19-96ba-4f77-b4d9-40f68d0e68b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73a073dc-b85e-422f-a4fc-058086534250
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d588e128-3d34-44c0-b196-929c89a7acdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a74546d-7a90-4962-ad84-3b79740aa918
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f454ea46-dc6d-4875-8d5a-a8416956972a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8cf5340-1007-460d-85fa-a89b1f4db9d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f645efd-8be5-4134-8b6e-e7518a018d54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6729b975-a6fa-4ba4-b5a2-8d81efaddf14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02d59774-75c3-462a-a5fe-ceedd9ea7cf5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b2bdde5-06dd-45fc-aa2d-c751ed8f458b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 316f76ef-5eae-4848-9c85-068e7f644b58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9cf7be6b-8b89-446f-9234-96f17f0674df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74759c45-7009-48d7-a011-4748c1558729
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d5092e4-1ead-433e-a523-f2e10f9a77eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 312f7995-6119-465a-a7b4-79ee3a796a94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d4c9a9d-012d-4aa5-9cbc-360f49541dd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5924e405-5035-40c7-b4c8-c6db5260c3ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message baa8300f-65f4-4c82-bb32-c1f44cac6808
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cbf4278d-d2f9-4b48-809c-8c049652fc1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c444266-352b-43da-904e-a42ba696ef8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4615879-22ba-4362-99c2-3b33694864bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fcdb8821-67e1-41cc-bf59-38f7e238ecb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c88b7672-220f-40f1-9340-8e0361736f3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f527913-87af-41aa-a529-a8188fe25ff2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message add5dcc1-0d1e-4ca6-a73a-1d8a986d7f57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bbe43e6b-a692-453b-a887-dceca0e6f2d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ea61196-3953-4566-895e-ad922434fddb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 722d73de-8a39-4e21-b693-4c73d01d62c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf5ac056-3bd4-4670-a1c5-e8c9d445f267
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d4ef621-5b6d-42f4-bb74-e699004373e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4427f971-0057-49f6-8bd0-56443cf294f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53c43623-302a-4510-9272-d62140b02593
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 556364ac-7924-405c-90ef-4e6876b3d5a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a6c7b00-40b2-4e60-9792-b16e681c7e0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82868405-3c6a-4b0f-96e1-5e0b4b6d499c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5de75aba-91d8-4598-b2af-eadea5921f53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ac1e1c6-91b8-422f-89d3-d0c93fce4214
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3f5e828-1cbb-4749-a975-ac609c2c1a96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18121e74-ac7e-4a23-8869-1769d2b5cf5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3549664e-990e-4204-924c-adfb5cbe20c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c6018ef-ba1a-4b50-b0fd-b115e01a33be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 028713c1-a054-43b2-a51c-404f35a0e8bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0084e56b-8562-413b-a5a6-0668cc19173a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20706996-4d30-4ae9-8811-28ef8d88046b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6f1b0e0-1b75-435e-bab6-2b940ea38326
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73f63c62-a094-411a-aa13-2ee6d1a25797
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad49f1a6-0970-4805-978c-ff13887e3d95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6acc382b-c515-4d22-8dca-5625d78ab0d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66758093-f9a3-4355-9462-7a3639490273
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6965bf3f-1376-412e-8688-1a8b2f0b111f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2aff3bd0-22e9-4912-9f96-3043bc9a3535
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a343073c-cc30-41a2-8df6-50ebe1b028f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9fc9215a-5ef1-4b07-9265-e13649d8be24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91bd5095-1dfb-4b09-9d13-1a4956d02756
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message acf73dde-6c7d-4738-a41b-2f269d3ebe64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 988de1a7-23e4-4878-a48b-3573a9bea32d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58524cd0-41c2-4096-b25c-0832c65aed21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6c3a75e-addd-41f0-9001-62a5dee624c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c716b4b6-fb2e-44ba-8123-9a9f49cc205e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d487da0e-ba70-4be4-99be-e6baba3ddfa2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93a40b19-5d31-41c2-8ef5-8bd8114391c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4fdf689-954f-4b3a-b91e-154162bd6a20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bcb3255f-06e4-446b-a00b-b74d99530085
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4098ff27-91f0-40b3-b15c-73f8f62cd925
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c340c8c1-fa0b-47e3-a42f-616fed88d66d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c930f8a-ebb5-4c59-9d5b-67a8e190c4c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3366ad1-0ac9-42a6-9ec8-f04922024025
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3ea7bd1-fec6-458c-8147-489ee1fbe15c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b3a54ff-1e07-4691-9fef-d0ecc0817aed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fda98920-e14a-45e4-8f90-378b148ec638
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4236b382-f0d3-472d-8882-32aa3ca5a5fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99e18970-ea47-4755-9843-4ab6b8730e22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68ce5816-302f-4bfc-a318-b15b2e3a2f20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 157fb133-15d2-4d28-b87c-ca6040cfe33f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6529408-f5b2-4ca6-99f1-24db42835b68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c86dd00-795b-4638-9e9a-d3369a833072
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e350601-b58b-4e9e-bf63-7f2c2638a87d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d6d1a4e-8022-47cb-9ab6-d1b55eb83956
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c65399b-e309-464c-86ee-4b40582b8949
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a8600ec-0434-4c4e-9486-13a7735898b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55c4956c-c69b-4492-a7cd-753296545d8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0307360f-a6a1-4785-b958-a2006f4b8891
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f1dd20a-f1cc-4f42-b40c-923bea54cf64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c5603f9-c338-4cf2-a0f2-f794ebc1ef98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8c43a25-2f54-481d-afe9-347658ccb4ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72fca5bd-fc44-4bdc-98a4-7c37173d3d9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd104785-2f7c-47a3-a0c0-d8f7619db0b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4cc8bc2-d72b-4cdd-b609-4004c9a79ec5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11420d74-7237-45d3-9ba9-75986c36b1d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b9f6948-7b22-4039-901c-cbb1e6fb9b43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f923633-add7-46ca-9397-e54e4eb2ac09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da40d54f-ab7b-4428-b47d-0d84c333d986
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd6ed88d-91e8-47d9-8752-16220d8b1a75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2a0e644-27c8-4f17-872c-bcaf7bf74aa6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad57fdf5-3dfe-48c5-bb09-286bcc2d5075
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79139ba3-aadd-496c-ba4d-ee26528284d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2cad4f2-cbf7-4665-961d-74555547d9d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07626607-67ed-4d79-a3d4-20bf2305cd33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1de080bb-3436-4a68-a45b-cee9baaf2245
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fde06b7e-36e4-4960-959c-1dcfa58a067e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af8b55d0-8041-4ddc-8f11-293d0802104d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7397a2c5-127d-435f-8383-4fe5a76f725e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 326179e9-d22c-4cc5-b4af-eeda187e9a57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a5a9c54-8fe3-4c89-9ef2-b8d8ad037594
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98271f70-dafa-4d84-ab0d-a7eb6b48b7be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6157fb0-1e8b-4663-a6cb-afd47a777c46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6ab34d3-5c8c-4cd6-a354-a1aa86677a1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 198049c8-3bf9-483b-99ef-88a31ded74d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec0b3f3a-4dd5-4ad4-b8be-ea052314cbab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4998df85-9a60-4541-83f7-836700f4c719
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1bff5f68-e7b4-4d24-9ac9-a547193a4126
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ea3c2a5-2d04-4756-92ec-b7b52f87df45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7663762f-4dc9-4208-aec3-6c1a14a9d52a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bddcae8f-8b1d-464c-a85c-b53e854c869d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2be32eef-e3cc-4856-b388-163425ef1e9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a48947be-a120-4c1a-a0b0-04d98a80e8a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 654cecc2-c697-4de4-8e3d-1a6f0c758009
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17dd57db-29f3-4768-98ac-fadc655d32db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c62956d-02f0-4df5-a717-238be1b3c7ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80aa5276-dab6-4053-a9df-fbbbc3097ba1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48f149e1-7b0a-4ccf-82f5-acb9f8259543
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf21cc05-aca6-42df-ba85-e0ab389cae41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4042d575-026a-4022-816e-c93d2d76a7d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7cc3714a-00b4-48f3-83b0-09335ebf6fcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a25a8913-03f6-4c66-b890-cdb8240d9cbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f314a9be-3936-4f7b-a4e4-281d86a8afaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bfc8bc7a-3f86-4755-916d-200af97bea27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8846ffd-6779-449b-9639-139195766f89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 198b02c6-fd00-4c4f-a013-aeb6d6da74ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98bf3878-ef90-485d-b221-2dbf3f62d539
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0597f31e-1920-48cb-89f7-70d8379cd505
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b64d7fb-65c8-4c33-b868-77d35cd2699a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4117bfa-8e9d-4763-8eac-2ebfcc6296eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 388aba24-bab8-416a-b42e-50570a1e51d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e86b2055-70f6-4bf0-9fab-353db6188f08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8185e775-8b63-4eab-b264-4fc27158a2ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message abdf380e-46fe-401b-ab01-25788960c08a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5a0ca09-2778-47a8-8e29-e6efd724f1cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf2a0b0f-5212-4eae-b21b-30178f05b3c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ff9862d-5904-4169-bff5-aab81ba9c5a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15241320-f541-4d19-994a-bcf3c5ae91c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 514e66e3-7505-4bd6-b2d0-4d71d86cd745
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d1f9b1c-d9fd-412f-a25e-68f0cdf6d3cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d99c6ca-8ee2-4ba1-8b06-1a712294983e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a02cdc60-34f8-4bd6-ab69-a158cee5d02b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e471a6ca-66fe-428e-affe-60fdf810b97e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2871a199-9d15-4dbe-b9a5-5beaabb2a6d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90dea549-7ad8-497b-a8b2-ef2c4749a424
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca81d49d-e906-4fa8-bab0-662909381306
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 969924f5-1cd9-4917-b03a-09d79f60011d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 647baa2e-9359-40dd-bcf7-5e0dca1852b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c94b381-d9c9-49d9-9ed5-5198ff39bce3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b882e3c5-3982-42c0-acd0-48c2f2bef457
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9978a50-601e-47af-b06d-e3c3ae437a68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9cc12e59-ef23-44f9-8d9b-a94c370ab2dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2385519a-1e55-48ae-a601-8a8764664ad6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 986a841e-6ce3-40ed-aabc-23ecb5d5c820
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e89b8ef8-5954-478b-94f9-fbaeea13d2ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05955c9e-67ac-4937-90b1-f27dfbf167e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dccb4229-0dcc-46a5-a415-9f08023590ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dddd2d9c-6f6d-46a7-b832-3614aa550a06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b995bcaa-4944-465c-af01-8fcda7874b44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3fe7a2a4-aad0-4b53-8250-e6a2cd89bcff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a349ae49-b9eb-40fa-8ff5-95f493140edb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 975a6d41-af7a-4cc0-9b33-9326ecc6991b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05648d51-5436-4c17-a148-5cc7bec94d4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef0a460a-1168-4267-bcbf-6682cf0fce0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9684a59b-5a5f-4d3c-a2a9-fc1a66478b06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 921f9525-d589-4b1d-bb47-a0a79e0d2aac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e4d037f-70fa-402e-9bb7-00a8110de226
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f9f227c-93c6-456b-ae78-53a3583379bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1048c311-f879-4355-85b4-4184056dee14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18d8fe6e-77a2-4f4f-bb5e-af3eafea6ea1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a2f32d7-3db9-4621-97e5-4a661cde2506
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13fcde1d-6837-4253-b387-f6a96c9c8737
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d6f9695-f29e-4e57-ad80-53cd573ef7ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c76d119c-a399-4662-87d4-b80190f42520
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f0d1f80-a3e9-41ff-9e02-f0db62fd2b9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b863f849-c621-43ab-a3ca-fa05a74d51d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0517bfaa-084a-40f1-94a3-610ed9df1ed3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0620cb28-afee-482f-97e0-a676b64905dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a7bff38-8bd1-428a-a497-6c14c595129f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b66bf1e-11e5-42eb-87cb-6f31afae909f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b55a20d-8e54-4f24-b51f-edfd7a1f49bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d186e67-ee85-403b-bbcd-221802c4733c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b635558-511f-4aeb-8a90-6c11f0b6b673
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9cb53876-929f-403b-a1b3-989e9fa97fb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2a00a2b-72a1-435f-94f6-c3a5695008c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57edb9c7-3ae0-45b4-91ec-00cde42edd30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c21fb62-acd6-4a1d-8e43-87e310b908e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1bb955d-e3a0-439e-abd0-e9c1f5d14c9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c44aa240-ea55-48d2-af76-4603bab22e1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84f5f6a2-7da6-4699-8849-105787a4b811
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f97a4a0-b391-4d33-8cd7-d863a8720d53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 611e7993-eb4e-47b0-a416-17fa37ddbea4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f865ec02-f957-43a2-9ac3-b56a1cf78238
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 746d2c84-8767-4211-9c6e-ddbef2d217c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a0bde4f-7d73-46e3-bf9a-020ee724b152
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59ca0eda-eb8f-44c4-a61a-2b29c435d0b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8559417-a19e-442e-a061-c075fa17995c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a7d79f2-e739-4790-b968-77db60445baa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca573153-25f5-417e-8dd0-081c82e2a723
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d01df26-eaea-4bdb-ab48-598181544c13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec511d24-58ad-427b-a31f-f856ad312f4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2535da26-b0fb-4ed2-8120-542983f35bdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66aecb24-a0e3-41aa-97e4-fc0e4c382238
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 797f6fcf-cce0-42f4-97b9-6c7ba5794359
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79084778-6941-42ec-b79f-004de3b2b07e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0cccbfc9-a87a-46c4-9780-91428de9372a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b775cd3e-7173-4421-8a08-95bdaf430b8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0554aa14-4627-4d72-b886-65196227138a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0aca19c0-49ab-4a8c-b04f-744ab302860c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b18f221c-d473-4462-9569-16928c52ee90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 933b95fb-8c72-417e-8d56-580cfb9f7292
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f493fef-32fa-4dc8-bee3-cf8d953249f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ba68314-6791-4931-9726-7cf6299800da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88ce55ff-3f8f-4372-a5cb-a549deec8eab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a1ffe14-6fa7-42dc-a962-959b8d241ef8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef7df9ac-cfe8-44a5-b11b-ac773cda04ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93f5d675-634f-4628-a935-57371248177e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02bb8f28-9f48-4006-81d5-eb2f1bcab3ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 185d33df-3233-4872-abd2-18bc23e9c282
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7cc623a8-8441-4d3c-84a6-bcbca8f7001b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2888afd7-b525-4dbc-bd33-d5d9577084ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message efaad7f1-8cd7-480f-8182-de57a74acbd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d1a2442-366d-4059-ab95-feed34f9f7ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d492e579-557f-40a8-aefc-eaa74fe00076
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2591bb8a-390e-480d-84e4-2acb0bd4ed12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0fed8ae-cfc8-4d2c-a1a9-2d1e27d2d58a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bef716bb-1921-441b-96cd-7a69caacacdb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b05a3ac-be50-40d1-af40-a3d988f5217a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a102f1d6-4031-44fd-bd28-b976e3746154
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9a864ef-528a-4a58-9ffb-74951e9b51ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b516970b-5169-42c2-882a-65652dbb39b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f6616d4-2dee-46b8-b134-0282780d9d2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d07e8de7-3810-4154-946f-13947e23bedc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78309c7a-8de5-41f2-9d09-87049972c9ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1bff14e5-2ca7-4bec-9ca6-568b467adb5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 504cf6b9-e4c0-46fc-a5fb-b9fc60371719
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46bec5c6-640e-48d8-bbf4-7c43d7939080
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8656d594-ce95-49d1-a681-b6fd2b8534b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a921ae4d-47f9-4822-8f7e-474c56e90ea8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c0cc58c-517b-4e50-8e41-5957da017d95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c79b8d95-e248-4c4c-90ed-9ac29f934fd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91c6a44a-7748-4e96-bb7f-4976c519ff66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b141987-3245-48d5-b9d1-7a31387c2534
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d5f5114-e33b-4667-9a4e-a5fc08228b27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 321c78f1-17cf-4b55-b951-fd45c6f5989b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 571f7ce9-c99c-4c54-991e-7f063d9d90d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 418448d7-2790-417b-88be-bada6e589227
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1cd6d6bb-3ae2-4ac7-a540-8a4ddae1cebc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24a28fb5-89da-415f-a105-679a0faa1ea0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e060c809-75b1-447e-a09a-93d25c12e9e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d075b861-e263-4317-99bc-955c422f0628
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4150beb3-284d-4892-aae1-bdefbeb55e44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d27db95-39f1-45ff-8eaf-5414e80cd50e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09fcb39b-e037-4856-ae60-ecd73c48e029
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1de0c741-0bf3-4af2-9f13-ab606314de3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63023679-6645-47a0-b1a7-7d2ccdbdd854
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c57bfaa9-0127-4d1d-9380-fbb6243fe44d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f811f96-9e9f-4790-ae10-8fa2f6eb9300
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65fd10ca-c8da-4cb9-beeb-babab24ed20d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7bf1755d-b894-489b-8ab2-2d749a21417d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e2da994-fab3-43bd-a22d-9f0471477b30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e34b94c3-f794-49b5-b6ab-2833b0b1598d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 156be064-0c2b-4304-b293-be13a6068674
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2fe1dcb2-7f90-4a9f-b831-09283e9dd603
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f7e2205-4164-494e-b97d-4ae1948f94c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc10b5a5-02bc-49b6-b8da-f4274d2c54fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55e41936-4682-4e06-a55c-9a5ead20954e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d38ccafb-2554-47f0-8ae8-a66513ff2c00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46c431ed-07e9-4c01-b5f2-4f4cb1e01d66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc3d8509-db0c-44df-821b-fa17af1a3ead
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d40973a1-2d9f-4504-a0ed-7291b6608f8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8fb9eb47-2286-430e-b599-bb10609c4ba4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ceab17d1-8f52-40c6-a6d7-4da99a82ebc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fae3126f-9f95-4512-8547-99908db30a9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 681f7b24-4804-41e9-9c25-fe21b1cd3787
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b38456c-d7f6-447e-aa9f-4b1171a20c7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 768f4c35-8564-43e7-8eca-6f543728b517
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a0241b7-cfa4-4a89-9eb4-6d777923fb43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa739bd4-70b0-4809-9d53-9681e40e0723
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4fe5de03-391c-4bac-be19-05eebc549cde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cddc0c64-7bed-4f8e-8bc9-51771c608407
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e27bb917-45a6-4670-ae6c-1088efef1078
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2cb6dcff-e9b0-4889-80b5-c7c43630cb3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19f4bf9f-e2dd-4e08-a195-57e80c6322d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e26bf8b-3ab7-44af-87a8-4b2245e197c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c3ab254-d439-4e32-a149-1e4e03286f06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04a02572-5f2e-4b61-bc2d-257adbc64ea3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02ccc078-daeb-47b7-ae7e-dfd88e3d8bad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d16b8731-5c89-494a-8182-3a7d5686b650
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f605878-268b-424c-9c1d-7f156c0692d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4996065-570d-45c6-9df3-9d93a0966bf0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3c6e480-d938-4193-8dde-0986171e9d5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6398033f-45ca-4253-b4b0-75c637c7319e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a69abc0f-689e-460c-999f-09e6d3968a5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5d1362a-f755-4643-a3ff-4961c0fe3006
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d8c07a0-5d10-43d6-99ec-ef2a20b38bcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4c23ec4-e56f-43d9-a7e4-9713a4e526b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d6be8a7-0ba6-417b-8f11-e8e444ade598
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a76ce5d-45a9-4138-9149-8fdfd05ce39b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b7b1261-e4a1-4b10-b643-18fe0a2fcbd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1b34926-2293-42ce-8484-d7fb8b64d5fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2876737d-0355-42af-9b8a-50b087cd8f02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8dcda819-b290-49a3-80a1-aaf590f3ad70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0f1f522-9466-4fb5-b658-32388e772fd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce796278-2eb0-46ff-ac0a-b43ec96e7a70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c447c87-72c9-48fe-b9c5-5bd1583820ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04fdd8c9-86ca-449c-9535-838bc0975d29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4c930d1-80f2-41bc-b03e-0973b90321f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f00d5e2-beeb-48b5-bc74-520682d75216
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a30cebed-ff4d-40a2-b0ac-28bb7d80e40a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8195d91f-fe4d-4d8a-a3fc-0c61ce88185f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 087e7b19-35d6-420f-94d7-6ff1f559fe22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e19d97c-4f86-4c3f-b068-358cc4f42bf8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad5190e5-871c-4529-aa6f-aa0a14aa7de6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e83e90f-c67e-4dcd-8a6f-469224fd56ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d56af91-0fb1-47e1-aa24-3269a581fc49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37a3db44-331c-4392-befe-bf243d0828fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 591cdb40-c74a-47a7-baca-2eeb14c14ccf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7107f02-025f-4217-85cf-7ecbe1015f0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4fb3ac29-9a7b-4ce6-93a8-f294e5e2f233
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 531cf006-7a1b-4989-9c6f-889ebb8c424b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51c2a9ce-14a9-4645-a7af-e3cc7f72b57b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98961de1-5748-4604-be1a-3e5bcc469821
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dea20a42-13c9-482f-94a1-efd3074fe0b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46c36491-c357-4bed-a18b-c6d33c2d510f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b36409d3-2676-4981-82e5-72767d6c9f59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1bd3df1-371a-47a2-a382-17f4dd4c3380
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e23c7f69-4629-406c-9a13-8763055a45b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f63469a-b9c4-453e-8b24-0ffe82a4f62b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed7b3ec7-76fe-424c-bc49-b26e6e36ee3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f066d7d4-91af-4345-b60f-5dd8e932c72f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 448ae14b-860e-47ba-b8a3-f31a0e16885a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9aa5cf69-1019-4636-98b2-ad6cba9f51d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6dabc7a4-9c64-474f-82a4-a51ba6163e5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94d9ccf1-b724-41f2-b6e2-cbaa76186560
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1d101a6-9d56-410f-9d80-20d23381f731
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71c0be4b-15d0-40da-b969-50c2b652bc9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed02bef0-033c-4061-b488-1477c9499910
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9aa0878d-a3c6-4fc7-8b2d-6cd5ca3c2890
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6ee4c0c-4856-4b93-a6ec-03a30088af40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15133f6d-d3ec-4de2-850f-a305f06b8a00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23ae2848-f501-4001-b3b9-7bab5cb824a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8dce9335-f36c-4fe6-96ff-6b34a919532b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4596954-855e-429f-a1d9-e26e62d8ea40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 673bf842-ed0f-4af5-a790-8f8becfafedc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 388e8ac1-e539-419b-8419-c142942e8cdb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf3425bf-3a0f-4b58-afca-77a99ddcd19a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2fca0bd-cb0b-4b8a-b48d-c4d9b4258f5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1cad2a17-a760-4359-a6d7-2da216d4b486
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a38148d0-9a8a-49c5-bb43-f8b65c076423
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 930bc9a8-4b02-43e1-aafa-92a2abf33a5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42ccc2aa-f582-4384-841f-43f1a1311709
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 130811e2-40aa-4cd6-9c65-c03b01d64a3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f18a480d-9a3e-4f9b-8889-db548a804192
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a6e32ad-47b8-459c-9c08-e6706a98aff3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8eb1876-2ea9-45f4-95a5-89e0825e0595
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80173f8b-5e10-4c32-a9d7-b04f20d59a14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2191aadc-863f-41c1-9594-f02349c8e19f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a281dd8a-667a-4479-ae78-39665195ebd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7220c91c-b284-44cf-b684-475fbbe85425
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd460ad5-bf5f-4c1f-9408-f68dd24a09b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f05f275-34d2-4ae8-a7ab-2ac44edee1be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cdc01e91-35bf-4e21-9975-72d0d9900582
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 590333f3-e14c-48de-bc33-accf25ea9494
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d62164ed-7bf3-42f0-ae07-0a6112f967a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 074c700d-5f1c-4fe7-b338-2548bde57e8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f05ce7b-8933-4cb5-9a8d-f3e2e5b4fcdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64481b5e-48ed-49b2-9aa2-47e88795a6e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25a9884d-5d59-42b4-8e0b-abb7a985cff0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c628257a-283d-4edd-87e9-bd7b547e0743
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb48a81c-0fff-4729-b08b-3a0c694bf082
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d398f5ef-3d2c-4456-ba66-7f496f626ab5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f71b607-8498-4ed2-a0a1-2ce712647727
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5bf804f-a737-48b3-8148-fabc4b004af7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20f0e40b-4c71-40c6-baa4-e07bf774ca96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43b84554-6d09-469e-bcf8-2e54042e65e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe62fdf7-231f-45ec-9c6a-62dae7f25489
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1178516-d729-43ff-8e17-00d6c4b27718
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e8447e7-6778-482e-a36f-d01aad036c02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12e6cda4-8112-40dc-b876-889fffe5d5a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2dcae4a-4b5c-4229-a76a-2ef15046fda7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e136c31-cd59-411b-83bd-48d30f39ff58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7f21b80-b60f-439f-a200-eebef210d2b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message acf73ea4-c6b2-46d4-ab50-6242e629b4c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 507b8373-c481-498c-af4b-9ca9913f9210
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed3b5ec5-6420-4441-94ee-1a9d9f0be35c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed41b524-cff3-43a9-b8b6-2667ec295581
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c165ce8-5cd1-49a9-a92d-e8d1b490bac3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67719bd2-e209-499c-97e3-cb3d4ae61de6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a319b4a5-7e21-4db2-9c0e-148c300ebac6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a1a2979-4b40-4d81-ad84-722835127ed3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79fb4baf-e86c-46c4-bc92-0469edfa62e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 346ae647-2b63-43e3-95e7-e21e9fb9c7ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfdc4bd1-416f-4176-9b57-4848cb8177f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22e75e7e-3bba-45cf-9f4a-f678ce883923
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa85a6b9-4e18-4dd7-9724-d6f49c4c38c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66ccc837-dc34-45f4-a5de-94d3556c6f1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 054ff09d-4354-4885-a8d0-81a83bedd523
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b678fbe-d724-4a4c-ab20-efa0dd70a00a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93aaafdf-757b-45cd-8181-f9c109fadf69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c309d694-a4c7-406e-8b12-b773c0b4c73d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86946e3d-856b-4812-bc36-39619b1abeff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2af307ee-5e13-4e47-bca9-cf77e18a013a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4578cfa-fcaf-4e84-be9f-0b9f07a33948
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 921ce601-1cd3-47bf-bcde-50ffd25da00c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d162558-0f71-48f4-9707-562f48fcde61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5b954e4-b8b9-48dc-8ea5-096de982eb02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac10f01f-8f05-4b73-8168-fcdc985e0e1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c65fdd86-1d19-46e7-b860-7374329e66ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 686d10e5-8ce1-418e-b269-57d31b21897b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2954d29-4862-49bd-a684-02246a4843e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b20f4b3-521f-4eb3-89d8-3e678dc483e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85438255-0da1-4f07-8a5a-4e0a911d89f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 850cd3b3-1a70-4543-b9b0-4fbdb425f815
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc853c4a-8158-44bd-a12e-8fbc8900e198
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06709358-9c8e-4161-a972-293f97733e95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 176759b2-24c2-4b89-a466-6401a1f67b44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5d63bdb-aa48-440d-83c8-33f24a12dc73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea14ba12-8ec8-477d-b19f-9152d1750404
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99d803ee-3c3d-41b9-98fb-024fc15a9091
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08b475ec-340e-411a-9e89-e5c5d87664ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bcc56eba-d78a-4997-9e35-60ec7d07735f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d19301c8-5f23-4122-92c7-64d3e536414c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ca18829-2ad3-4959-8f8a-3fd073073945
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83c73a52-d927-449a-a28a-41d032068dd4
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8690 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_17
Server: localhost:8690
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_17
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_17/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_17/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_17/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_17/test_labels.txt

📊 Raw data loaded:
   Train: X=(4164, 24), y=(4164,)
   Test:  X=(1042, 24), y=(1042,)

⚠️  Limiting training data: 4164 → 800 samples
⚠️  Limiting test data: 1042 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_17 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 2 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0853 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0873, val=0.0844 (↓), lr=0.001000
   ✓ Epoch   3/100: train=0.0864, val=0.0837 (↓), lr=0.001000
   • Epoch   4/100: train=0.0851, val=0.0835, patience=1/15, lr=0.001000
   • Epoch   5/100: train=0.0848, val=0.0835, patience=2/15, lr=0.001000
   • Epoch  11/100: train=0.0821, val=0.0835, patience=8/15, lr=0.001000
   📉 Epoch 15: LR reduced 0.001000 → 0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 2 Summary - Client client_17
   Epochs: 18/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=-0.0002
   Val:   Loss=0.0837, RMSE=0.2894, R²=-0.0105
============================================================


📊 Round 2 Test Metrics:
   Loss: 0.0803, RMSE: 0.2834, MAE: 0.2451, R²: 0.0080

============================================================
🔄 Round 4 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0792 (↓), lr=0.000500
   • Epoch   2/100: train=0.0849, val=0.0795, patience=1/15, lr=0.000500
   • Epoch   3/100: train=0.0846, val=0.0796, patience=2/15, lr=0.000500
   • Epoch   4/100: train=0.0845, val=0.0796, patience=3/15, lr=0.000500
   • Epoch   5/100: train=0.0843, val=0.0796, patience=4/15, lr=0.000500
   📉 Epoch 7: LR reduced 0.000500 → 0.000250
   • Epoch  11/100: train=0.0833, val=0.0793, patience=10/15, lr=0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 4 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000500 → 0.000250 (1 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0061
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.0112
============================================================


============================================================
🔄 Round 7 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0792 (↓), lr=0.000250
   • Epoch   2/100: train=0.0850, val=0.0793, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0849, val=0.0794, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0848, val=0.0795, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0848, val=0.0795, patience=4/15, lr=0.000250
   📉 Epoch 6: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0844, val=0.0796, patience=10/15, lr=0.000125
   📉 Epoch 14: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 7 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0849, RMSE=0.2915, R²=0.0070
   Val:   Loss=0.0792, RMSE=0.2815, R²=0.0079
============================================================


============================================================
🔄 Round 8 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0805 (↓), lr=0.000063
   • Epoch   2/100: train=0.0847, val=0.0805, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0847, val=0.0804, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0847, val=0.0804, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0847, val=0.0804, patience=4/15, lr=0.000063
   📉 Epoch 6: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0846, val=0.0804, patience=10/15, lr=0.000031
   📉 Epoch 14: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 8 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0075
   Val:   Loss=0.0805, RMSE=0.2838, R²=-0.0031
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2452, R²: 0.0075

📊 Round 8 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2453, R²: 0.0067

📊 Round 8 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2453, R²: 0.0063

============================================================
🔄 Round 14 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0881 (↓), lr=0.000016
   • Epoch   2/100: train=0.0823, val=0.0881, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0823, val=0.0881, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0822, val=0.0881, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0822, val=0.0881, patience=4/15, lr=0.000016
   📉 Epoch 6: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0822, val=0.0882, patience=10/15, lr=0.000008
   📉 Epoch 14: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 14 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0138
   Val:   Loss=0.0881, RMSE=0.2968, R²=0.0020
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0117

============================================================
🔄 Round 16 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0942 (↓), lr=0.000004
   • Epoch   2/100: train=0.0809, val=0.0942, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0809, val=0.0942, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0809, val=0.0942, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0809, val=0.0942, patience=4/15, lr=0.000004
   📉 Epoch 6: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0809, val=0.0942, patience=10/15, lr=0.000002
   📉 Epoch 14: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0942)

============================================================
📊 Round 16 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0115
   Val:   Loss=0.0942, RMSE=0.3069, R²=-0.0063
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2448, R²: 0.0114

============================================================
🔄 Round 18 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 18 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0107
   Val:   Loss=0.0778, RMSE=0.2789, R²=0.0090
============================================================


============================================================
🔄 Round 21 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 21 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0118
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0054
============================================================


============================================================
🔄 Round 24 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 24 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0105
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.0120
============================================================


============================================================
🔄 Round 25 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 25 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0106
   Val:   Loss=0.0853, RMSE=0.2921, R²=0.0076
============================================================


============================================================
🔄 Round 26 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 26 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0106
   Val:   Loss=0.0861, RMSE=0.2934, R²=0.0120
============================================================


============================================================
🔄 Round 29 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 29 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0088
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0182
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2448, R²: 0.0113

============================================================
🔄 Round 31 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 31 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0088
   Val:   Loss=0.0903, RMSE=0.3004, R²=0.0110
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2448, R²: 0.0113

============================================================
🔄 Round 34 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 34 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0115
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0067
============================================================


============================================================
🔄 Round 35 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 35 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0114
   Val:   Loss=0.0829, RMSE=0.2880, R²=0.0073
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0113

📊 Round 35 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0113

============================================================
🔄 Round 37 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 37 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0103
   Val:   Loss=0.0906, RMSE=0.3010, R²=0.0069
============================================================


============================================================
🔄 Round 38 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 38 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=0.0102
   Val:   Loss=0.0812, RMSE=0.2849, R²=0.0102
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0113

📊 Round 38 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0113

============================================================
🔄 Round 42 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 42 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0107
   Val:   Loss=0.0821, RMSE=0.2866, R²=0.0106
============================================================


============================================================
🔄 Round 44 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 44 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0149
   Val:   Loss=0.0917, RMSE=0.3028, R²=-0.0043
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0113

============================================================
🔄 Round 47 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 47 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0119
   Val:   Loss=0.0852, RMSE=0.2919, R²=0.0065
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2448, R²: 0.0113

============================================================
🔄 Round 49 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 49 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0098
   Val:   Loss=0.0732, RMSE=0.2705, R²=0.0161
============================================================


============================================================
🔄 Round 51 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 51 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0099
   Val:   Loss=0.0815, RMSE=0.2854, R²=0.0152
============================================================


============================================================
🔄 Round 52 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 52 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=0.0091
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0113
============================================================


============================================================
🔄 Round 53 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 53 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=0.0089
   Val:   Loss=0.0727, RMSE=0.2696, R²=0.0179
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2448, R²: 0.0113

📊 Round 53 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2448, R²: 0.0113

============================================================
🔄 Round 57 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 57 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=0.0126
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0025
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2448, R²: 0.0113

📊 Round 57 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2448, R²: 0.0113

============================================================
🔄 Round 61 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 61 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0114
   Val:   Loss=0.0902, RMSE=0.3003, R²=0.0083
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2448, R²: 0.0113

============================================================
🔄 Round 65 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 65 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0096
   Val:   Loss=0.0871, RMSE=0.2951, R²=0.0155
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0113

📊 Round 65 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0113

📊 Round 65 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0113

============================================================
🔄 Round 70 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 70 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0081
   Val:   Loss=0.0878, RMSE=0.2963, R²=0.0206
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0113

📊 Round 70 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0113

📊 Round 70 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2448, R²: 0.0113

============================================================
🔄 Round 74 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 74 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0106
   Val:   Loss=0.0840, RMSE=0.2898, R²=0.0119
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2448, R²: 0.0113

📊 Round 74 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2448, R²: 0.0113

============================================================
🔄 Round 77 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 77 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0063
   Val:   Loss=0.0805, RMSE=0.2838, R²=0.0079
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2448, R²: 0.0113

============================================================
🔄 Round 79 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 79 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0080
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0159
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2448, R²: 0.0113

============================================================
🔄 Round 80 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 80 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0127
   Val:   Loss=0.0886, RMSE=0.2976, R²=0.0044
============================================================


============================================================
🔄 Round 82 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 82 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0107
   Val:   Loss=0.0806, RMSE=0.2840, R²=0.0098
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2448, R²: 0.0113

============================================================
🔄 Round 83 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 83 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0115
   Val:   Loss=0.0853, RMSE=0.2921, R²=0.0090
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2448, R²: 0.0113

============================================================
🔄 Round 84 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 84 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=0.0090
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0154
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2448, R²: 0.0113

============================================================
🔄 Round 88 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 88 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0083
   Val:   Loss=0.0832, RMSE=0.2885, R²=0.0168
============================================================


============================================================
🔄 Round 92 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 92 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0120
   Val:   Loss=0.0917, RMSE=0.3028, R²=-0.0041
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2448, R²: 0.0113

============================================================
🔄 Round 93 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 93 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0118
   Val:   Loss=0.0791, RMSE=0.2813, R²=0.0043
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2448, R²: 0.0113

📊 Round 93 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2448, R²: 0.0113

============================================================
🔄 Round 97 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 97 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0109
   Val:   Loss=0.0798, RMSE=0.2825, R²=0.0108
============================================================


============================================================
🔄 Round 98 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 98 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0095
   Val:   Loss=0.0901, RMSE=0.3002, R²=0.0162
============================================================


============================================================
🔄 Round 99 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 99 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0101
   Val:   Loss=0.0908, RMSE=0.3013, R²=0.0092
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2448, R²: 0.0113

============================================================
🔄 Round 101 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 101 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=0.0089
   Val:   Loss=0.0885, RMSE=0.2975, R²=0.0174
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2448, R²: 0.0113

============================================================
🔄 Round 103 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 103 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0122
   Val:   Loss=0.0787, RMSE=0.2806, R²=0.0042
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2448, R²: 0.0113

📊 Round 103 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2448, R²: 0.0113

📊 Round 103 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2448, R²: 0.0113

📊 Round 103 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2448, R²: 0.0113

============================================================
🔄 Round 110 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 110 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0101
   Val:   Loss=0.0845, RMSE=0.2908, R²=0.0138
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2448, R²: 0.0113

============================================================
🔄 Round 114 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 114 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0104
   Val:   Loss=0.0778, RMSE=0.2788, R²=0.0108
============================================================


============================================================
🔄 Round 118 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 118 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0136
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0038
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0113

============================================================
🔄 Round 119 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 119 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0102
   Val:   Loss=0.0826, RMSE=0.2874, R²=0.0125
============================================================


============================================================
🔄 Round 120 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 120 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0101
   Val:   Loss=0.0782, RMSE=0.2796, R²=0.0144
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0113

📊 Round 120 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0113

📊 Round 120 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2448, R²: 0.0113

============================================================
🔄 Round 124 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 124 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0104
   Val:   Loss=0.0813, RMSE=0.2852, R²=0.0053
============================================================


============================================================
🔄 Round 125 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 125 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0077
   Val:   Loss=0.0877, RMSE=0.2961, R²=0.0146
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0113

============================================================
🔄 Round 127 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 127 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=0.0109
   Val:   Loss=0.0872, RMSE=0.2953, R²=0.0092
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0113

============================================================
🔄 Round 128 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 128 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2878, R²=0.0122
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0053
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0113

📊 Round 128 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2448, R²: 0.0113

📊 Round 128 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2448, R²: 0.0113

📊 Round 128 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2448, R²: 0.0114

============================================================
🔄 Round 135 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0972 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0972, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0972, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0972, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0972, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0972, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0972)

============================================================
📊 Round 135 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0103
   Val:   Loss=0.0972, RMSE=0.3117, R²=0.0129
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2448, R²: 0.0114

============================================================
🔄 Round 139 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 139 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0109
   Val:   Loss=0.0883, RMSE=0.2972, R²=0.0104
============================================================


============================================================
🔄 Round 140 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0922 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0922)

============================================================
📊 Round 140 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0103
   Val:   Loss=0.0922, RMSE=0.3036, R²=0.0135
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2448, R²: 0.0114

📊 Round 140 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2448, R²: 0.0114

📊 Round 140 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2448, R²: 0.0114

============================================================
🔄 Round 145 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 145 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0083
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0211
============================================================


============================================================
🔄 Round 146 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 146 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2885, R²=0.0129
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0054
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2448, R²: 0.0114

📊 Round 146 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2448, R²: 0.0113

📊 Round 146 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2448, R²: 0.0113

📊 Round 146 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2448, R²: 0.0113

📊 Round 146 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2448, R²: 0.0113

📊 Round 146 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2448, R²: 0.0113

============================================================
🔄 Round 158 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 158 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0125
   Val:   Loss=0.0865, RMSE=0.2941, R²=0.0047
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2448, R²: 0.0113

============================================================
🔄 Round 160 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 160 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0091
   Val:   Loss=0.0853, RMSE=0.2921, R²=0.0161
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0113

📊 Round 160 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0113

📊 Round 160 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0113

📊 Round 160 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2448, R²: 0.0113

============================================================
🔄 Round 167 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 167 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0118
   Val:   Loss=0.0879, RMSE=0.2965, R²=-0.0000
============================================================


============================================================
🔄 Round 172 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 172 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0097
   Val:   Loss=0.0791, RMSE=0.2813, R²=0.0146
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0113

============================================================
🔄 Round 173 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 173 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0087
   Val:   Loss=0.0857, RMSE=0.2928, R²=0.0183
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0113

============================================================
🔄 Round 178 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0942 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0942, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0942, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0942, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0942, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0942, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0942)

============================================================
📊 Round 178 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0115
   Val:   Loss=0.0942, RMSE=0.3069, R²=0.0088
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2448, R²: 0.0113

============================================================
🔄 Round 180 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 180 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=0.0104
   Val:   Loss=0.0756, RMSE=0.2750, R²=0.0122
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2448, R²: 0.0113

============================================================
🔄 Round 182 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 182 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=0.0111
   Val:   Loss=0.0885, RMSE=0.2975, R²=-0.0116
============================================================


============================================================
🔄 Round 184 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0943 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0943, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0943, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0943, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0943, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0944, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0943)

============================================================
📊 Round 184 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0109
   Val:   Loss=0.0943, RMSE=0.3071, R²=0.0053
============================================================


============================================================
🔄 Round 186 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 186 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0128
   Val:   Loss=0.0822, RMSE=0.2868, R²=0.0037
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2448, R²: 0.0113

============================================================
🔄 Round 188 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 188 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0124
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0068
============================================================


============================================================
🔄 Round 189 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 189 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0117
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0054
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2448, R²: 0.0113

============================================================
🔄 Round 190 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 190 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=0.0104
   Val:   Loss=0.0768, RMSE=0.2771, R²=0.0106
============================================================


📊 Round 190 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2448, R²: 0.0113

📊 Round 190 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2448, R²: 0.0114

📊 Round 190 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2448, R²: 0.0114

📊 Round 190 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2448, R²: 0.0114

============================================================
🔄 Round 199 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0967 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0967, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0967, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0967, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0967, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0967, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0967)

============================================================
📊 Round 199 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=0.0113
   Val:   Loss=0.0967, RMSE=0.3110, R²=0.0100
============================================================


============================================================
🔄 Round 201 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 201 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0112
   Val:   Loss=0.0858, RMSE=0.2928, R²=0.0060
============================================================


📊 Round 201 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2448, R²: 0.0114

============================================================
🔄 Round 203 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 203 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0102
   Val:   Loss=0.0790, RMSE=0.2811, R²=0.0135
============================================================


============================================================
🔄 Round 204 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 204 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0107
   Val:   Loss=0.0777, RMSE=0.2787, R²=0.0087
============================================================


============================================================
🔄 Round 206 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 206 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0128
   Val:   Loss=0.0787, RMSE=0.2806, R²=0.0025
============================================================


============================================================
🔄 Round 207 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 207 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2932, R²=0.0100
   Val:   Loss=0.0736, RMSE=0.2713, R²=0.0157
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2448, R²: 0.0114

============================================================
🔄 Round 208 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 208 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0117
   Val:   Loss=0.0826, RMSE=0.2875, R²=0.0081
============================================================


📊 Round 208 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2448, R²: 0.0114

============================================================
🔄 Round 209 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 209 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=0.0127
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.0038
============================================================


============================================================
🔄 Round 210 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 210 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0120
   Val:   Loss=0.0817, RMSE=0.2857, R²=0.0044
============================================================


============================================================
🔄 Round 217 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 217 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=0.0109
   Val:   Loss=0.0767, RMSE=0.2769, R²=0.0099
============================================================


============================================================
🔄 Round 218 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 218 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0125
   Val:   Loss=0.0842, RMSE=0.2902, R²=0.0051
============================================================


============================================================
🔄 Round 221 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 221 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0114
   Val:   Loss=0.0894, RMSE=0.2990, R²=0.0067
============================================================


📊 Round 221 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2448, R²: 0.0114

📊 Round 221 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2448, R²: 0.0114

📊 Round 221 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2448, R²: 0.0114

📊 Round 221 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2448, R²: 0.0114

============================================================
🔄 Round 226 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 226 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=0.0087
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0183
============================================================


📊 Round 226 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2448, R²: 0.0114

📊 Round 226 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2448, R²: 0.0114

============================================================
🔄 Round 231 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0939 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0939, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0939, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0939, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0939, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0938, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0939)

============================================================
📊 Round 231 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0126
   Val:   Loss=0.0939, RMSE=0.3064, R²=0.0019
============================================================


============================================================
🔄 Round 232 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 232 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0109
   Val:   Loss=0.0860, RMSE=0.2933, R²=0.0115
============================================================


📊 Round 232 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2448, R²: 0.0114

📊 Round 232 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2448, R²: 0.0114

============================================================
🔄 Round 237 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 237 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0102
   Val:   Loss=0.0803, RMSE=0.2833, R²=0.0077
============================================================


📊 Round 237 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0114

============================================================
🔄 Round 241 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0934 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0934, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0934, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0934, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0934, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0934, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0934)

============================================================
📊 Round 241 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0117
   Val:   Loss=0.0934, RMSE=0.3056, R²=-0.0077
============================================================


============================================================
🔄 Round 242 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 242 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0108
   Val:   Loss=0.0891, RMSE=0.2986, R²=0.0099
============================================================


📊 Round 242 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0114

============================================================
🔄 Round 246 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 246 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0104
   Val:   Loss=0.0885, RMSE=0.2975, R²=0.0123
============================================================


📊 Round 246 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2448, R²: 0.0114

============================================================
🔄 Round 248 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 248 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0116
   Val:   Loss=0.0889, RMSE=0.2982, R²=0.0061
============================================================


📊 Round 248 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0114

📊 Round 248 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0114

============================================================
🔄 Round 256 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 256 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0112
   Val:   Loss=0.0874, RMSE=0.2957, R²=0.0106
============================================================


📊 Round 256 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0114

📊 Round 256 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0114

📊 Round 256 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2448, R²: 0.0114

============================================================
🔄 Round 262 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 262 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=0.0100
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0158
============================================================


📊 Round 262 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2448, R²: 0.0114

📊 Round 262 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2448, R²: 0.0114

============================================================
🔄 Round 264 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 264 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0120
   Val:   Loss=0.0873, RMSE=0.2954, R²=-0.0179
============================================================


============================================================
🔄 Round 265 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 265 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0078
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0004
============================================================


============================================================
🔄 Round 266 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 266 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0117
   Val:   Loss=0.0832, RMSE=0.2884, R²=0.0025
============================================================


📊 Round 266 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0114

============================================================
🔄 Round 269 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 269 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0108
   Val:   Loss=0.0854, RMSE=0.2923, R²=0.0118
============================================================


============================================================
🔄 Round 270 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 270 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=0.0103
   Val:   Loss=0.0919, RMSE=0.3032, R²=0.0082
============================================================


============================================================
🔄 Round 271 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 271 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0109
   Val:   Loss=0.0867, RMSE=0.2945, R²=0.0106
============================================================


📊 Round 271 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

📊 Round 271 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

============================================================
🔄 Round 276 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 276 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0131
   Val:   Loss=0.0888, RMSE=0.2981, R²=0.0032
============================================================


============================================================
🔄 Round 277 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 277 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0087
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0048
============================================================


📊 Round 277 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

============================================================
🔄 Round 278 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 278 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2916, R²=0.0115
   Val:   Loss=0.0771, RMSE=0.2777, R²=0.0092
============================================================


============================================================
🔄 Round 280 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 280 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0115
   Val:   Loss=0.0798, RMSE=0.2824, R²=0.0093
============================================================


============================================================
🔄 Round 282 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 282 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0130
   Val:   Loss=0.0883, RMSE=0.2972, R²=0.0040
============================================================


📊 Round 282 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0114

📊 Round 282 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0114

============================================================
🔄 Round 284 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 284 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0122
   Val:   Loss=0.0761, RMSE=0.2759, R²=-0.0006
============================================================


============================================================
🔄 Round 287 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 287 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0106
   Val:   Loss=0.0842, RMSE=0.2902, R²=0.0065
============================================================


📊 Round 287 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0114

============================================================
🔄 Round 293 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 293 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0113
   Val:   Loss=0.0794, RMSE=0.2817, R²=0.0017
============================================================


============================================================
🔄 Round 294 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 294 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=0.0087
   Val:   Loss=0.0795, RMSE=0.2819, R²=0.0163
============================================================


📊 Round 294 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

============================================================
🔄 Round 295 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 295 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0096
   Val:   Loss=0.0897, RMSE=0.2995, R²=0.0158
============================================================


📊 Round 295 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

============================================================
🔄 Round 297 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 297 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=0.0126
   Val:   Loss=0.0744, RMSE=0.2728, R²=0.0012
============================================================


📊 Round 297 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0114

============================================================
🔄 Round 302 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0932 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0932, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0932, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0933, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0933, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0934, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0932)

============================================================
📊 Round 302 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0105
   Val:   Loss=0.0932, RMSE=0.3053, R²=-0.0125
============================================================


============================================================
🔄 Round 303 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 303 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2904, R²=0.0128
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0002
============================================================


📊 Round 303 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

============================================================
🔄 Round 307 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 307 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0130
   Val:   Loss=0.0901, RMSE=0.3002, R²=-0.0050
============================================================


============================================================
🔄 Round 308 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 308 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0103
   Val:   Loss=0.0894, RMSE=0.2990, R²=0.0131
============================================================


📊 Round 308 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

📊 Round 308 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

============================================================
🔄 Round 310 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 310 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0086
   Val:   Loss=0.0879, RMSE=0.2965, R²=0.0089
============================================================


📊 Round 310 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0114

📊 Round 310 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0114

============================================================
🔄 Round 312 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 312 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=0.0098
   Val:   Loss=0.0751, RMSE=0.2741, R²=0.0151
============================================================


📊 Round 312 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0114

============================================================
🔄 Round 313 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 313 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0103
   Val:   Loss=0.0894, RMSE=0.2990, R²=-0.0161
============================================================


============================================================
🔄 Round 314 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 314 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0106
   Val:   Loss=0.0882, RMSE=0.2970, R²=0.0093
============================================================


📊 Round 314 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

============================================================
🔄 Round 319 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 319 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=0.0108
   Val:   Loss=0.0728, RMSE=0.2698, R²=-0.0303
============================================================


============================================================
🔄 Round 320 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 320 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=0.0119
   Val:   Loss=0.0769, RMSE=0.2772, R²=0.0058
============================================================


============================================================
🔄 Round 321 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 321 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0105
   Val:   Loss=0.0850, RMSE=0.2915, R²=0.0136
============================================================


📊 Round 321 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

============================================================
🔄 Round 323 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 323 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0119
   Val:   Loss=0.0850, RMSE=0.2915, R²=0.0067
============================================================


📊 Round 323 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

============================================================
🔄 Round 324 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0975 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0975, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0975, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0975, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0975, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0975, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0975)

============================================================
📊 Round 324 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0115
   Val:   Loss=0.0975, RMSE=0.3123, R²=0.0073
============================================================


📊 Round 324 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

============================================================
🔄 Round 326 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 326 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0123
   Val:   Loss=0.0833, RMSE=0.2887, R²=0.0063
============================================================


============================================================
🔄 Round 327 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 327 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0123
   Val:   Loss=0.0810, RMSE=0.2845, R²=0.0031
============================================================


📊 Round 327 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

============================================================
🔄 Round 329 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 329 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=0.0093
   Val:   Loss=0.0780, RMSE=0.2793, R²=0.0120
============================================================


📊 Round 329 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

============================================================
🔄 Round 334 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 334 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0128
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0003
============================================================


📊 Round 334 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

============================================================
🔄 Round 335 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 335 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0093
   Val:   Loss=0.0854, RMSE=0.2922, R²=0.0163
============================================================


============================================================
🔄 Round 336 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 336 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0118
   Val:   Loss=0.0863, RMSE=0.2938, R²=0.0085
============================================================


============================================================
🔄 Round 337 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 337 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0077
   Val:   Loss=0.0852, RMSE=0.2920, R²=0.0102
============================================================


📊 Round 337 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

📊 Round 337 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

============================================================
🔄 Round 339 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 339 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0145
   Val:   Loss=0.0838, RMSE=0.2896, R²=-0.0050
============================================================


📊 Round 339 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

============================================================
🔄 Round 342 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 342 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0108
   Val:   Loss=0.0854, RMSE=0.2922, R²=0.0122
============================================================


📊 Round 342 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

============================================================
🔄 Round 344 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 344 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0091
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0101
============================================================


📊 Round 344 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0114

============================================================
🔄 Round 346 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0670 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0670, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0670, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0670, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0671, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0671, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0670)

============================================================
📊 Round 346 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2959, R²=0.0090
   Val:   Loss=0.0670, RMSE=0.2589, R²=0.0059
============================================================


📊 Round 346 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

📊 Round 346 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0114

📊 Round 346 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2448, R²: 0.0114

📊 Round 346 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0114

📊 Round 346 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0114

============================================================
🔄 Round 352 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0966 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0966, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0966, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0966, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0966, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0965, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0966)

============================================================
📊 Round 352 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0123
   Val:   Loss=0.0966, RMSE=0.3107, R²=0.0011
============================================================


============================================================
🔄 Round 354 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 354 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2927, R²=0.0119
   Val:   Loss=0.0747, RMSE=0.2734, R²=0.0008
============================================================


📊 Round 354 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0114

============================================================
🔄 Round 355 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 355 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=0.0111
   Val:   Loss=0.0780, RMSE=0.2793, R²=0.0046
============================================================


============================================================
🔄 Round 356 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 356 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0100
   Val:   Loss=0.0776, RMSE=0.2786, R²=0.0149
============================================================


📊 Round 356 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0114

📊 Round 356 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0114

============================================================
🔄 Round 361 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 361 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0092
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0192
============================================================


📊 Round 361 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2448, R²: 0.0114

============================================================
🔄 Round 362 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 362 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0110
   Val:   Loss=0.0883, RMSE=0.2971, R²=0.0111
============================================================


============================================================
🔄 Round 364 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 364 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0101
   Val:   Loss=0.0765, RMSE=0.2766, R²=0.0109
============================================================


📊 Round 364 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2448, R²: 0.0114

============================================================
🔄 Round 365 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 365 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0121
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0028
============================================================


============================================================
🔄 Round 366 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 366 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=0.0105
   Val:   Loss=0.0824, RMSE=0.2870, R²=0.0121
============================================================


📊 Round 366 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2448, R²: 0.0114

📊 Round 366 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2448, R²: 0.0114

============================================================
🔄 Round 368 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 368 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0123
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0052
============================================================


============================================================
🔄 Round 371 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 371 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=0.0108
   Val:   Loss=0.0755, RMSE=0.2749, R²=0.0115
============================================================


============================================================
🔄 Round 373 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 373 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0113
   Val:   Loss=0.0908, RMSE=0.3014, R²=0.0051
============================================================


============================================================
🔄 Round 374 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 374 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=0.0094
   Val:   Loss=0.0811, RMSE=0.2847, R²=0.0148
============================================================


============================================================
🔄 Round 378 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 378 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0121
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0057
============================================================


============================================================
🔄 Round 379 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 379 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0121
   Val:   Loss=0.0866, RMSE=0.2943, R²=0.0065
============================================================


📊 Round 379 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0114

============================================================
🔄 Round 380 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 380 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0121
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0037
============================================================


📊 Round 380 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0114

============================================================
🔄 Round 382 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 382 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0117
   Val:   Loss=0.0807, RMSE=0.2840, R²=0.0008
============================================================


📊 Round 382 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0114

============================================================
🔄 Round 384 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 384 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0137
   Val:   Loss=0.0874, RMSE=0.2957, R²=0.0013
============================================================


📊 Round 384 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0114

============================================================
🔄 Round 386 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 386 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=0.0097
   Val:   Loss=0.0778, RMSE=0.2789, R²=0.0151
============================================================


📊 Round 386 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0114

============================================================
🔄 Round 389 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 389 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=0.0118
   Val:   Loss=0.0824, RMSE=0.2871, R²=0.0085
============================================================


📊 Round 389 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0114

📊 Round 389 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0114

📊 Round 389 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0114

============================================================
🔄 Round 396 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 396 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0124
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0073
============================================================


📊 Round 396 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

============================================================
🔄 Round 402 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 402 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0116
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0087
============================================================


📊 Round 402 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

============================================================
🔄 Round 403 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 403 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0114
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0099
============================================================


============================================================
🔄 Round 404 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 404 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0107
   Val:   Loss=0.0863, RMSE=0.2938, R²=0.0106
============================================================


📊 Round 404 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

📊 Round 404 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

============================================================
🔄 Round 409 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 409 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2897, R²=0.0116
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0089
============================================================


📊 Round 409 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

============================================================
🔄 Round 410 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 410 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0079
   Val:   Loss=0.0775, RMSE=0.2784, R²=0.0116
============================================================


📊 Round 410 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

📊 Round 410 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

📊 Round 410 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

============================================================
🔄 Round 416 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 416 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0091
   Val:   Loss=0.0846, RMSE=0.2909, R²=0.0108
============================================================


📊 Round 416 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

📊 Round 416 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

📊 Round 416 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

============================================================
🔄 Round 422 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 422 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0096
   Val:   Loss=0.0878, RMSE=0.2963, R²=0.0158
============================================================


📊 Round 422 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

📊 Round 422 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

============================================================
🔄 Round 426 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 426 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0117
   Val:   Loss=0.0848, RMSE=0.2913, R²=0.0092
============================================================


📊 Round 426 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

============================================================
🔄 Round 430 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 430 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0132
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0072
============================================================


📊 Round 430 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0116

📊 Round 430 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0116

============================================================
🔄 Round 433 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 433 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0131
   Val:   Loss=0.0753, RMSE=0.2744, R²=0.0026
============================================================


============================================================
🔄 Round 434 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 434 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0095
   Val:   Loss=0.0776, RMSE=0.2786, R²=0.0160
============================================================


📊 Round 434 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0116

============================================================
🔄 Round 435 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 435 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2923, R²=0.0122
   Val:   Loss=0.0755, RMSE=0.2747, R²=0.0066
============================================================


📊 Round 435 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0116

============================================================
🔄 Round 437 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0955 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0955, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0955, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0955, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0955, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0955, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0955)

============================================================
📊 Round 437 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0134
   Val:   Loss=0.0955, RMSE=0.3091, R²=-0.0042
============================================================


📊 Round 437 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0116

============================================================
🔄 Round 439 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 439 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0115
   Val:   Loss=0.0869, RMSE=0.2948, R²=0.0093
============================================================


📊 Round 439 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0116

============================================================
🔄 Round 442 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 442 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0125
   Val:   Loss=0.0897, RMSE=0.2995, R²=0.0053
============================================================


📊 Round 442 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

📊 Round 442 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

============================================================
🔄 Round 446 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 446 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0104
   Val:   Loss=0.0828, RMSE=0.2877, R²=0.0140
============================================================


============================================================
🔄 Round 449 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 449 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0105
   Val:   Loss=0.0797, RMSE=0.2824, R²=0.0140
============================================================


============================================================
🔄 Round 450 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 450 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0088
   Val:   Loss=0.0883, RMSE=0.2971, R²=0.0188
============================================================


============================================================
🔄 Round 452 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 452 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0099
   Val:   Loss=0.0907, RMSE=0.3012, R²=0.0139
============================================================


============================================================
🔄 Round 454 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 454 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0092
   Val:   Loss=0.0757, RMSE=0.2752, R²=0.0151
============================================================


📊 Round 454 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

============================================================
🔄 Round 456 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 456 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0110
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0108
============================================================


📊 Round 456 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

📊 Round 456 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

📊 Round 456 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

📊 Round 456 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

============================================================
🔄 Round 465 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 465 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0091
   Val:   Loss=0.0790, RMSE=0.2811, R²=0.0107
============================================================


📊 Round 465 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

📊 Round 465 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

📊 Round 465 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

============================================================
🔄 Round 473 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 473 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0095
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0096
============================================================


📊 Round 473 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

============================================================
🔄 Round 478 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 478 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0111
   Val:   Loss=0.0860, RMSE=0.2933, R²=0.0111
============================================================


📊 Round 478 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

📊 Round 478 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

============================================================
🔄 Round 480 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 480 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0108
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0125
============================================================


📊 Round 480 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

============================================================
🔄 Round 481 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 481 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0117
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0110
============================================================


📊 Round 481 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

📊 Round 481 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

============================================================
🔄 Round 486 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 486 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0110
   Val:   Loss=0.0761, RMSE=0.2759, R²=0.0111
============================================================


📊 Round 486 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

============================================================
🔄 Round 488 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 488 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0110
   Val:   Loss=0.0798, RMSE=0.2824, R²=-0.0021
============================================================


📊 Round 488 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

============================================================
🔄 Round 491 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 491 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0095
   Val:   Loss=0.0817, RMSE=0.2859, R²=0.0065
============================================================


📊 Round 491 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

============================================================
🔄 Round 495 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 495 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0131
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0007
============================================================


============================================================
🔄 Round 496 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 496 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0093
   Val:   Loss=0.0853, RMSE=0.2921, R²=0.0006
============================================================


📊 Round 496 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

📊 Round 496 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

============================================================
🔄 Round 502 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 502 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0118
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0042
============================================================


============================================================
🔄 Round 503 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 503 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0098
   Val:   Loss=0.0789, RMSE=0.2808, R²=0.0170
============================================================


📊 Round 503 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

📊 Round 503 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

============================================================
🔄 Round 512 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0962 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0962, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0962, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0962, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0962, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0962, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0962)

============================================================
📊 Round 512 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0133
   Val:   Loss=0.0962, RMSE=0.3102, R²=0.0000
============================================================


📊 Round 512 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

📊 Round 512 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0116

============================================================
🔄 Round 515 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 515 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0127
   Val:   Loss=0.0890, RMSE=0.2983, R²=0.0049
============================================================


📊 Round 515 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

📊 Round 515 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0116

📊 Round 515 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

============================================================
🔄 Round 522 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 522 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0121
   Val:   Loss=0.0843, RMSE=0.2903, R²=0.0065
============================================================


📊 Round 522 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

============================================================
🔄 Round 523 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 523 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0108
   Val:   Loss=0.0890, RMSE=0.2984, R²=0.0119
============================================================


============================================================
🔄 Round 530 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 530 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0108
   Val:   Loss=0.0787, RMSE=0.2806, R²=0.0117
============================================================


============================================================
🔄 Round 531 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 531 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0093
   Val:   Loss=0.0768, RMSE=0.2772, R²=0.0195
============================================================


📊 Round 531 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

📊 Round 531 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

============================================================
🔄 Round 535 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 535 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0120
   Val:   Loss=0.0790, RMSE=0.2811, R²=0.0080
============================================================


============================================================
🔄 Round 537 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 537 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=0.0113
   Val:   Loss=0.0867, RMSE=0.2945, R²=0.0109
============================================================


============================================================
🔄 Round 538 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 538 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0114
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0009
============================================================


📊 Round 538 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0116

============================================================
🔄 Round 539 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 539 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0118
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0078
============================================================


============================================================
🔄 Round 542 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 542 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0107
   Val:   Loss=0.0891, RMSE=0.2985, R²=0.0130
============================================================


📊 Round 542 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

============================================================
🔄 Round 544 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 544 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2935, R²=0.0117
   Val:   Loss=0.0726, RMSE=0.2695, R²=0.0025
============================================================


============================================================
🔄 Round 545 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 545 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0122
   Val:   Loss=0.0925, RMSE=0.3041, R²=0.0058
============================================================


============================================================
🔄 Round 547 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 547 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0099
   Val:   Loss=0.0731, RMSE=0.2703, R²=0.0150
============================================================


============================================================
🔄 Round 548 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 548 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0123
   Val:   Loss=0.0760, RMSE=0.2758, R²=0.0014
============================================================


📊 Round 548 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

📊 Round 548 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

============================================================
🔄 Round 550 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 550 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0110
   Val:   Loss=0.0846, RMSE=0.2908, R²=0.0022
============================================================


📊 Round 550 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

============================================================
🔄 Round 554 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 554 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0103
   Val:   Loss=0.0863, RMSE=0.2939, R²=0.0149
============================================================


============================================================
🔄 Round 558 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 558 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0126
   Val:   Loss=0.0875, RMSE=0.2959, R²=0.0060
============================================================


============================================================
🔄 Round 560 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 560 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=0.0117
   Val:   Loss=0.0750, RMSE=0.2739, R²=0.0079
============================================================


📊 Round 560 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

============================================================
🔄 Round 561 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 561 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0095
   Val:   Loss=0.0761, RMSE=0.2758, R²=0.0156
============================================================


============================================================
🔄 Round 562 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0922, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 562 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0094
   Val:   Loss=0.0920, RMSE=0.3034, R²=0.0010
============================================================


============================================================
🔄 Round 563 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 563 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0115
   Val:   Loss=0.0888, RMSE=0.2980, R²=0.0040
============================================================


============================================================
🔄 Round 566 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 566 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0129
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0157
============================================================


============================================================
🔄 Round 567 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0712 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0712, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0712, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0712, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0712, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0712, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0712)

============================================================
📊 Round 567 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=0.0114
   Val:   Loss=0.0712, RMSE=0.2669, R²=0.0104
============================================================


============================================================
🔄 Round 568 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 568 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0123
   Val:   Loss=0.0765, RMSE=0.2766, R²=0.0058
============================================================


============================================================
🔄 Round 570 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 570 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=0.0103
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0151
============================================================


📊 Round 570 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

============================================================
🔄 Round 571 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 571 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0113
   Val:   Loss=0.0885, RMSE=0.2975, R²=0.0079
============================================================


📊 Round 571 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

============================================================
🔄 Round 572 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 572 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0101
   Val:   Loss=0.0842, RMSE=0.2901, R²=0.0156
============================================================


📊 Round 572 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

📊 Round 572 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

📊 Round 572 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

📊 Round 572 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

📊 Round 572 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

============================================================
🔄 Round 579 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 579 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0106
   Val:   Loss=0.0807, RMSE=0.2840, R²=0.0123
============================================================


📊 Round 579 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

============================================================
🔄 Round 582 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 582 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0086
   Val:   Loss=0.0771, RMSE=0.2777, R²=-0.0006
============================================================


📊 Round 582 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

============================================================
🔄 Round 585 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0703 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0703, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0703, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0703, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0703, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0703, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0703)

============================================================
📊 Round 585 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2945, R²=0.0090
   Val:   Loss=0.0703, RMSE=0.2651, R²=0.0197
============================================================


📊 Round 585 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

📊 Round 585 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

============================================================
🔄 Round 589 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 589 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0126
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0026
============================================================


============================================================
🔄 Round 592 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 592 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0120
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0039
============================================================


📊 Round 592 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

📊 Round 592 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

============================================================
🔄 Round 595 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 595 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0118
   Val:   Loss=0.0830, RMSE=0.2880, R²=-0.0204
============================================================


============================================================
🔄 Round 597 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 597 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=0.0129
   Val:   Loss=0.0783, RMSE=0.2797, R²=-0.0051
============================================================


📊 Round 597 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

📊 Round 597 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

📊 Round 597 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

📊 Round 597 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

============================================================
🔄 Round 602 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 602 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=0.0112
   Val:   Loss=0.0737, RMSE=0.2714, R²=-0.0035
============================================================


📊 Round 602 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

============================================================
🔄 Round 605 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 605 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0085
   Val:   Loss=0.0759, RMSE=0.2755, R²=0.0097
============================================================


📊 Round 605 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

📊 Round 605 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

📊 Round 605 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

📊 Round 605 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

============================================================
🔄 Round 612 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 612 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=0.0088
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0166
============================================================


📊 Round 612 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

============================================================
🔄 Round 613 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 613 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0110
   Val:   Loss=0.0875, RMSE=0.2958, R²=0.0021
============================================================


============================================================
🔄 Round 614 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 614 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0136
   Val:   Loss=0.0903, RMSE=0.3005, R²=-0.0105
============================================================


📊 Round 614 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

============================================================
🔄 Round 615 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 615 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0111
   Val:   Loss=0.0901, RMSE=0.3001, R²=0.0062
============================================================


📊 Round 615 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

============================================================
🔄 Round 616 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0936 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0936, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0936, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0936, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0936, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0935, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0936)

============================================================
📊 Round 616 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0091
   Val:   Loss=0.0936, RMSE=0.3059, R²=0.0182
============================================================


============================================================
🔄 Round 617 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 617 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0108
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.0037
============================================================


📊 Round 617 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0114

============================================================
🔄 Round 619 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 619 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0119
   Val:   Loss=0.0865, RMSE=0.2942, R²=-0.0070
============================================================


============================================================
🔄 Round 623 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 623 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0118
   Val:   Loss=0.0866, RMSE=0.2943, R²=0.0086
============================================================


📊 Round 623 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2448, R²: 0.0114

📊 Round 623 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2448, R²: 0.0114

============================================================
🔄 Round 627 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 627 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0108
   Val:   Loss=0.0765, RMSE=0.2766, R²=0.0122
============================================================


📊 Round 627 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2448, R²: 0.0114

============================================================
🔄 Round 632 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 632 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0076
   Val:   Loss=0.0812, RMSE=0.2849, R²=0.0192
============================================================


============================================================
🔄 Round 635 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 635 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0102
   Val:   Loss=0.0806, RMSE=0.2839, R²=0.0096
============================================================


📊 Round 635 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2448, R²: 0.0114

============================================================
🔄 Round 637 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 637 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0127
   Val:   Loss=0.0882, RMSE=0.2970, R²=0.0055
============================================================


📊 Round 637 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2448, R²: 0.0114

📊 Round 637 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0114

============================================================
🔄 Round 640 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 640 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=0.0124
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0058
============================================================


============================================================
🔄 Round 643 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 643 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0109
   Val:   Loss=0.0879, RMSE=0.2965, R²=0.0106
============================================================


============================================================
🔄 Round 644 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 644 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0104
   Val:   Loss=0.0848, RMSE=0.2913, R²=0.0032
============================================================


📊 Round 644 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0114

============================================================
🔄 Round 646 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 646 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=0.0116
   Val:   Loss=0.0823, RMSE=0.2870, R²=-0.0099
============================================================


📊 Round 646 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0114

📊 Round 646 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0114

============================================================
🔄 Round 658 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 658 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0107
   Val:   Loss=0.0873, RMSE=0.2955, R²=0.0066
============================================================


📊 Round 658 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

📊 Round 658 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

============================================================
🔄 Round 660 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 660 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0122
   Val:   Loss=0.0825, RMSE=0.2873, R²=0.0071
============================================================


📊 Round 660 Test Metrics:
   Loss: 0.0800, RMSE: 0.2829, MAE: 0.2448, R²: 0.0115

============================================================
🔄 Round 663 - Client client_17
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 663 Summary - Client client_17
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0127
   Val:   Loss=0.0884, RMSE=0.2974, R²=0.0056
============================================================


❌ Client client_17 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8690 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8690 {grpc_message:"Socket closed", grpc_status:14}"
>
