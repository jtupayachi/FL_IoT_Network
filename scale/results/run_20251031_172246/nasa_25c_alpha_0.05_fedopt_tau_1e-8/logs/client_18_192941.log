[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e67d149-dc5b-4105-b17b-37a5aa96636c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8dbb9de0-57cb-43a4-9e55-ffa4963eafce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d92f844-4670-4e85-89f2-3a6281c691f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 636c6b5e-a3d7-4b92-bcb6-416d0f989c7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30057a68-0d2d-49c3-b72f-27da07f08f3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08888267-215a-46f4-b8ba-21645de482c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23d6498e-311b-494b-be8b-fc147808e40d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c40c10d8-a6cb-4e88-bc49-1b103ae8fb07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5193f7d-a74b-4cc7-aca1-126390e7f667
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d09ab580-674a-4e30-b3ba-8de7fb346c4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03e70bf9-f443-4a0f-a1cd-b5347f967cb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2150f413-3ec0-4777-bd16-e8ea5bfde6ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 518c9da7-7e01-4f04-be7e-443cefc8d724
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45eed436-e9e4-43f6-8cee-7082dab2e92f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 909d7009-b2ae-4b67-9f88-215d8eba494f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c5e3ee2-ed64-4e5e-a90c-36c7791ad70f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8494dbb6-f0cc-406e-9269-b7ae367ab41d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a618677c-117c-4713-88c1-5cc438447dbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 355e49e1-e38e-4724-a4f1-63f9260fe35a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 124b488f-c750-4606-ba0a-1bc9682764ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 342d3f95-1ae6-4256-8dd0-300d3e50f26d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b713e5e2-61a6-4e57-81c9-3a2d03b5ea7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4206db11-7b29-475c-82c7-07eb93b2effc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ebc618bf-46ad-445e-b818-808799ab646a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0bbf053b-18c3-4a7a-9743-8d367aecc56c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message feacade5-40e0-470d-a5b7-7f87dbe2fbe3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b7be42b-ac13-43c0-ac02-b2c187c85b6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f64cc5e-5e27-4121-bcd2-98b9d5272609
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22c50772-ad40-44d2-a0dc-539507cd7787
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d2e9bcb-c2e6-49f0-8726-b4ae2df67de0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24e76ca4-0239-41d8-8927-cd12c67d7bc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45c96407-14a8-47b8-a784-9ce58abd39cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6b7c082-56f8-417f-918b-be304dd8d969
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2c28d63-119a-4217-977d-3ba9545beb66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8c7c9db-7185-4721-9360-e23883694b65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2cc942d-0bc2-4e2c-9642-e06a38b8de01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a4863a0-9b15-49b1-a0e4-6e30bbbbd859
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1dee2ae9-963c-47fa-99e1-d6c31c819db2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40bc4a67-d8e8-4501-a212-042d94971821
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee608f0f-97ea-4703-b32e-65b815dc5d65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fbb12e1f-2110-4d9a-9437-be694de11859
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 118f9878-ba07-49d5-8935-cd160d64b68d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be2803af-82a7-4d18-bf39-8e5832d17d03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ada7daf0-46c3-4fd1-907a-a14ba6db2c12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07c6c4d6-756c-42c3-8d19-38959500c60b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d83df62-1faa-4135-acc3-7f0197bc36bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bdddcf39-979d-4226-bb24-772920e2cc3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ece24d6-56fa-4073-870c-3ed065ab92c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 395ce8dc-01a9-4aaf-843c-3d47489e39d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfd14962-9eea-4cc4-a531-ee813b8e3095
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64c9aaad-9f05-4ca5-9cbb-cd091452782d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e5b6697-23ee-4e78-9ecc-ebac19e23582
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 698ee6ad-dbd7-4a5f-a88f-26587f082e7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e0e2302-5db8-4af4-89ed-783881db9c4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7be44bab-f20e-4500-93eb-6158cb133aab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d0d395e-0430-4c0f-bcfd-6524d72d9217
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f4d4d1a-614c-4b84-a81d-4c32c5bf3034
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a6dca97-44e7-45e1-b77e-28e08d88676e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5de8d86d-9265-4f81-9dc8-21a9b8191796
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a0db8fa-3b0f-4831-a8ab-8c86222de935
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ae4a53b-da68-4e36-a08c-300321274c6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63a718f3-372a-4703-986c-763c3b9ece6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 572626ea-0c90-487c-8698-28724c11742e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b88547e-cbda-4ecf-ad57-85d7dc0877d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62db0867-6498-4779-8feb-a5a55d552a09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9064c67b-a340-4450-983f-f32871c0fd23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a170510-e729-4a88-99c9-d5a0d6e77ac8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e114a744-6671-42f4-b55f-de3543470030
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e004360-aa22-4e53-991d-a3078d914ede
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 375ec467-3b74-455e-b101-30fedccef31d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5dd1c1e1-b32a-48bf-938b-a2ff0cf5903d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aebb4fa9-2685-489d-9fa0-497b3d16bbfa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f883d43-ccd2-43a6-bb1e-b88bcf1a02ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b10d0a73-c169-4bdb-9873-8292aed8d1cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45d34687-aad7-422d-8216-4ea0e86256c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a03889b4-848d-4afe-8ee3-91df3f53a2d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc9b7d7a-487b-4207-ade4-12507f7d4c27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa9e7d5e-9c4c-40e2-a803-b18ea9a8fb67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eca72c61-ed7f-40a0-acb3-1072677cf033
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4530abf8-9bbe-4e11-93ce-055ff421fe9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 134d4286-574b-4ca1-87e8-385e722a5413
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e054cf31-087c-4e0b-8cc4-ea6ade27274e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d18f3aae-2646-4ea4-81a3-5409a778cfb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0a0d1f3-150b-49a2-853f-c8803e176c89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d2e6ec1-7bab-4179-a70f-ae08a9fd01a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39d38076-53e1-44d4-a9c3-a2ea94f7da56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aea0cc62-8836-47f3-9b9f-9bfa684826c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e569212f-e456-48a5-b32f-54d704dd28ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 068059cb-1e67-4031-8b1f-0d29e84bbe27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9549c6d-d391-487b-a2e5-9900b92aa466
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c03a6c8-a9da-43e3-950a-10adcde885a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b5b84af-4690-4fbd-bc5f-ff420d28145b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2dea47e-4b89-4fb8-9b2b-59cdcb93f4ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00d94ead-af6d-45ad-a43f-6f76f0332445
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de9f732e-e7a2-4e9c-b1db-f0d6c4bbf3d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8c4f4df-2271-412e-a714-24eb71ad0293
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2eb67f76-0348-49e3-9580-afe6d64e8faa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba96ecf6-7d04-45bb-a601-9a9fc9bd4a03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b638bdce-031e-4ac5-9fc5-415e3ee6e463
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82dd5546-5910-4134-8a57-7b0bd863be5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a014c505-685d-43dd-8b0d-a8f8ee31d866
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02ae6138-a85b-4589-b840-a25cefcc8457
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6d217ab-71df-4980-a2f1-41e5de9da523
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc2f457e-d5b6-4e83-858d-9e53f68bf77e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5215635f-e215-4b8d-b393-163667f30c1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bbcf93e8-6520-46f3-8af9-6b554541daff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20639fde-30eb-486e-ab10-a96240d1c635
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26c43429-acd5-4ec6-b8b0-ed5c8fc3c320
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26511d8c-e323-4d44-83cf-352b7822ab85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b81ba2a7-83c4-4d26-aaba-7303b91d07f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76e9d1d6-90a9-4fc7-a7c0-103d6d7a555a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2156b0b9-a5d2-41d0-8460-073dff5ddaf9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5b249d8-7fc9-416e-9a58-93ec74ab9d99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c67adb7-a6a4-4535-aa73-e02fca1e3ea1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5da37a3c-5c7b-4f8f-9f25-2e976ab99934
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95033c61-d230-4816-8d9b-da7cd9b45239
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51710000-2be4-4add-91a7-bb531a0a5ba8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 491566c7-2188-43d6-afcd-dce391bf37fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a9496f5-6ec2-4d28-a2c6-eeca7a04166f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9d00655-44fb-4247-9a2e-6d867583d633
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e020be06-6351-47ae-b6a1-c8fed01e8d0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d125c28a-c36b-4025-981c-cac59df35e60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 839c6745-f9d4-41d9-a9bb-d48da930ca4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ef101c8-c23f-440c-a98c-f3240facb1fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f251aa4c-41b7-49f4-b2bc-81f6062a2b61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28fad8fc-3b74-43b1-9537-d1e57dab2bf0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3772410a-78be-48b9-8c98-828c55ed3eb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 667c7b4e-8649-4424-93ec-b9bf30ca57df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd8308d9-8e60-4fe3-9019-916914eb5b40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 732f1272-9eef-48a2-a35c-7d168490b5e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 980fbbfb-91d2-42bd-9ce7-2020ddfc1675
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1bb2278-24f8-4254-879f-db7b8b0bb331
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb89ce43-89b4-4818-b13e-832dffc4a382
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56963298-484f-4a0f-8f2c-44780aba3788
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a34dc0a4-60fd-4a8a-8e07-6ff66c8ad637
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4229934-50ec-464c-9bd5-5fc2a6e3e33a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1baf49ea-41e1-4b7c-ba07-ec8ea63f35ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f7ef112-ac8b-416e-9e9c-f1eafa0a937c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 046f4557-5edc-4610-9ebe-8763a117e8b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8f94819-c535-4a7b-841f-3fd8b2df0831
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9002e76-7e35-4178-971f-184f2aaeeeda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f6cea20-4777-48ee-ae0d-52a5cd357c1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac9ea45a-a379-4c2b-ba05-706bc7ff5ebb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91517ee2-7139-4abd-9db0-c53a4efbed5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef21632e-cff3-45b2-b352-242140015876
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ec53e0c-48c6-4ecf-a3b1-3dc107b5b33f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0069882d-ba43-4a68-8b2e-675c364db160
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 944e07af-7207-4db4-b64b-bc88dfb42ee4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b3a0262-69de-4587-93e8-b70e3149063f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3e52910-70a8-4b6a-b956-cd14084e521f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 378834c2-4027-4bbf-8b11-2fc7031896d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89408b6c-e41b-4cbf-9995-765087de3e1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 092c326e-3733-41f2-889b-147df94868a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 122054e4-8300-4681-8f08-223d1ee473d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33607e7b-8b3e-4194-9cef-cc4031dcf8ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd7551fa-1cdf-4a37-bab3-59dacc4bd45a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 392f7325-5427-47b9-bc7f-71a37c7b9ec2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d189ff0-74c4-4481-9fd8-141d9bf7e873
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0acd82de-26f9-4fd4-9e02-d945a91913cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a431dd1f-0d67-432f-929c-f219aaa546f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9a47f64-076e-4cf5-867d-41170f453ffb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80c4ed71-e198-42a4-981a-152d9a717928
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0fd1fe4d-ef8d-4585-ada6-0d554e29a073
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d50f75d-11e7-403c-94a5-e605eda3a17c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89ec1902-98e8-457c-975c-31c8d7ac6cb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 027bff6c-9441-4fa3-83ae-945d95b1d790
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eda767d9-3757-4a95-8e58-79f86cf08aeb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0a07c55-a5ce-422f-9686-f82d3acc297f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16eef09a-face-4e59-a7b7-24c9da5927c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72ef4e27-dcfa-4a65-8f83-c1cd5519f968
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31c00f29-2206-4e1c-9fc7-79bf19f1e23d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9d5b730-b771-4e98-be2a-76053fbffee4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6fe1a140-b376-474c-8245-b64037125a8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6867bf1-ba95-48c8-a407-418f9e1dff4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d6e50cc-4c17-423b-a45b-08bc190fb83b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb10fd2d-902b-4e50-ac3c-ab456299f9b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19273a76-1c6b-4ddb-959c-98a49d9df8f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf33066f-bf9c-418b-973a-60fd30ebc2d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81b0c41c-958e-440e-b6ae-0acc0ec28375
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a79229d-7821-43ec-b775-de64a72d9f86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ffcbd2a8-c013-4e1b-96cd-4a923d5b6429
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47770b48-68e9-43a6-9d67-47e85d448f3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 046cb91d-960e-4e4b-999b-ff377e200010
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ebaeda15-5941-40a7-9bf3-a0ff8ea9c6a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91fdfea7-d0bc-46a1-b11f-5c30fe4f7edf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3258c55-3649-4e87-9a29-cf16424c3c30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2bb10c9c-74e6-4964-bcab-f7983208b031
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aabe3687-a7a3-4ace-b8ad-40ded671e816
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a77c4c94-652b-4a21-8a84-42ca0866de85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a94c8e3d-abaa-4b31-b003-0ad8faa72dfa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c212fc01-347e-47bd-b367-d6ffa41f1503
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31b3d543-dde1-4607-825f-b6146a5d1650
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba74a08d-b857-4838-a291-3b8a673db9c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff1c8d6b-f017-415e-94c8-192ca447f29d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3a5f3ec-e1fc-4e98-8d2b-9a0c38c10153
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3becdad-1580-44b7-9921-81ef45763dae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 873eb2c2-3674-449a-b92a-0a36197e025e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d8aada7-7a18-4c1b-9b6b-eb82defc05cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31d397c6-eec6-4841-b764-7b91bb3b7871
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message afff36f3-eb88-409d-8c17-5eba52de02e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d86deab-4222-4100-9a6e-753f53c315da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7cdafc57-46b5-4ed8-91af-b2657712649f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f665924-c258-4f70-ba22-0ced7a6243fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 748aa02d-67d3-4ebd-bc1f-14992f47bce0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e0af606-22fa-4b6a-8cf8-a13a16edf882
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4263e9df-1d9b-4551-b6ac-9d7c136a0d24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8ba66c2-bc30-4145-9533-0f27d7c679b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 004f5075-b9fa-48cd-9e2f-3484f160afc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1395292b-86cf-4174-abb0-dbb1b79b1f6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 568396e6-d526-419d-8dce-8ba73730e0ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa648349-3a0e-4c80-a409-ec1be13fe5a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06226481-c5c3-4178-aa00-1421b6c91b20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b7c446d-69f5-4e41-bbfe-d22ad6dd91be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1bc7c31f-4f41-4aa6-96cf-81e1aea0abec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a130fd5d-3d3a-4dfa-bf65-19f484aa17f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dca43a97-696c-4784-8dcb-8006d61c41ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5aa7dc1-4a6d-4b80-bc97-d26a14256c62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8df8ab4-bf54-434c-a843-4e707bdd7a79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1abd28c6-ab51-42d6-b9f8-611949653e5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43624647-68df-4e39-9ebd-3f0a15764329
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55fb7359-e31e-4967-ba09-4c44d13c8ae3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7967ff76-006e-413c-883e-038497012484
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bca8ef5a-b098-4a68-998a-70810eb89c94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 340f41bb-59c0-4670-9bf5-0890263c5abe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed392a61-ce57-40d5-aa54-8270b4af00cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a0e18c8-2b00-48d0-8a01-89429a4b42ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a3cb508-a44f-4cac-ab93-268572c46ec0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9928617c-e4f6-4e0d-bb68-c4604c7de603
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f187ec3-0318-4964-9943-568025e19c26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 308d63d7-1f14-4fdc-a433-d0128c013a04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b19424b-59ec-4231-b522-24cf62182eb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 886e7ad2-ba5e-4386-82e6-db9b19d43c84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81e78206-bea2-4e44-9646-feb420138387
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f98e9b1-cab3-4352-9b4f-cf3afd79e870
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d0b6621-7d50-4347-86f6-d42eaf4d69e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60b7df34-8d7f-4156-88d7-f98b9d3340e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 599faf1f-16b3-4c55-a59f-ad67d210f265
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 787c7a97-d05f-40b5-a965-627b4ea81cd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc77d287-989c-4ace-9697-b261b5b55833
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2fd50f8b-68bb-4caa-8c9c-167b8c3c8b68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f10ea755-e99b-40dc-91dd-b8449b879df7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69289903-5d82-41ae-ab45-c376772e176b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c4c1eef-fe48-4bb3-9570-dab2066bd010
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78ef8cf1-fdcc-419d-a9b8-bb20cfc3039c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba153b14-0f7b-4707-abb0-5a1e549aca82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9395e798-a7a2-4b7a-9a43-8e2f8440b7da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f3db027-21b0-4b54-8b49-46e0f84cef75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73157fdd-39d1-4899-abe1-1890d2a1ff03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52447a55-2d25-433e-a92f-d4efe70b274e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b960ef61-0e07-4f8f-bff5-a7aa8a334dc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f03c441-d989-485f-a405-cc706db4541b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51256410-3f77-46a6-aaa7-d3e0504d9ecd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0d1fb2d-d6ff-49e0-9ce1-1252a2ed843b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e8627b5-6d88-4c12-8651-3e103b090aa4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c3d7a10-fc68-4fe8-8333-bde778556329
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05c8eb23-a3ac-4585-96e6-1b513473a41e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 868391eb-1d39-4252-a34f-88f81f94f675
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf28c9de-5b89-4451-bd61-fc34cd1942d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 445453b0-117c-4e34-aefc-56cf346d71b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d02ed325-dd14-469e-b571-96065be50004
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c28493f5-1b5a-4e4f-9c10-7bd0f9e5485c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 068bff49-3993-4b21-869e-47d0438cb8a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b99085e-3be0-481a-b699-3c305da8c049
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 890e03c8-b03f-472b-99d2-502b0644e8dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80948a5a-27d7-4a72-a6b7-9646e4e9d425
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ebefc0c7-b013-4954-a99f-05caaad2c6de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04f6ec97-5391-42dc-a3e3-f5ab315129ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25952ae0-d8a6-408e-9d95-f5eff4041217
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c935ed3f-3fe0-4edf-9570-9c284a3b991b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d61698aa-75fd-4111-81f8-f2a434c9f696
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e129ea2d-2226-4dc4-aa0d-8b9b83557650
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3729e787-ff5b-40b7-b57b-109907a4b472
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da2c41e4-63a5-43a1-9314-0a73c456f9b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7ad7d92-139d-439e-94d9-7fa5e0812293
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2429646-3a9b-491d-b25e-81781ff6f66d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d9d52bf-8ef4-4b25-a39d-8e8f62c25a55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e2507e6-57fe-4671-bc69-dfafb0e80ddb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ddac2428-137b-42ec-8b61-5bc8025f65a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7808da3f-4d41-42bf-a7d4-326602a35677
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfd9470c-7285-453e-9755-30f1dbba4eb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e77ffde8-aec0-4fcf-83fa-84154d383e69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ffb8cc33-27ca-4e52-a86d-2f3fa483855b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 831aade4-9ea5-4769-af5b-d89ee05cb89b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9ed52ef-b989-400e-b3a4-113b25d12047
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9912f5e-dd3c-4dd2-b610-6cee288ccef2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46a020c6-0093-423f-bf7d-0315a209c700
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b172e8e9-7948-4999-a916-ddedbf1329e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f6ad572-7183-4347-beb6-727006f96245
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message edd3b0fd-7363-4d65-b818-619007f2ce1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 190ea86d-ddd5-4d01-ad1f-d7fe079d6d8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c25ab535-fc95-4ca6-8414-a91aaa8e4b5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 456989f5-3611-4cc9-b746-a2b61f132e04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93d4099c-19ec-48bb-8c17-7c43e13e9cf0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d75470b-2ef9-43c6-abdb-1570f5e329f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6cc90bc6-580b-4f7a-9bea-bf87f47967a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24d0fc8b-2a1e-4eaa-8036-2b5700ad06ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f4d9fc2-4737-46ee-b4c7-4dc1fec65d73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec966ea7-4bb3-42ee-926b-2708e6c61d76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18d9ea0e-8b81-473d-acf3-aa4574276652
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f175bbbf-c981-410f-8b23-9068365d616f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message efc65e12-b7fb-46e9-b574-f7cfc70f4c58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a34b172-17c9-4639-8f2d-a30d4c6a4e34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c704a4b3-f121-4cb5-88af-5b0fdade2d3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6bc9cb1a-4b4d-4c09-a7c4-0e2b70494f81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56317680-c63f-4d4b-87fb-2d143bbd8013
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d538349f-f237-4948-b724-b0e5d6635755
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08b28490-17bd-4e90-9769-76523df1d308
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a95abdb-815d-4681-ab44-ffc6d1db0aa4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f495d652-94e7-4942-aae0-7a94c6506bbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0efb9ce-22a9-48ee-ab39-5a7af8cf1584
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9181c388-59d5-4421-9048-01928d5e6580
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2cd4afb4-d924-4a5e-b82c-9cf53669cf5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61d3d5cf-6d90-4c5a-850a-8814c2a99cc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 759041bc-de9a-4f9c-a7da-cbb8df633f91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3fde2102-2b24-4e75-8ee7-2c443402402e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b300245-2d0d-49df-bedb-40e395728c5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 534fff03-7034-4ef2-b067-39540776f823
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8dd20b08-c2e4-40dd-b48e-083c8029ac64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 974ee49f-2162-4b0e-b6bd-2e5c5972f9b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70d65bea-401e-4b44-a081-215ebf785906
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c9e7b1c-efa2-4f3b-87e3-f6714106b9cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6172badf-b850-4620-a63b-9b3c1a43765b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 645d0cd4-cf22-42f7-a7c1-2e70452b6d67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81987fc0-3cd6-4228-af9c-e11c3bb2229d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ffe4d88-fbdf-46a4-be02-b93944fb5d7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d0bcfe5-730d-4560-9673-20bd5aa5f1bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f798008-6aec-4d95-8549-70b9ac826b8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50ad70f6-a682-4eb2-9606-e3a27e364938
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c5b7b93-540f-4836-a2b0-1822701c3181
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9fb11cb1-745b-4a46-ad9c-39ff4afbb4c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c44c746b-9f10-45f2-a5c0-909d4c61b220
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2d2955b-2670-4341-9499-43c5d05c0d82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a421747f-a5ce-425a-a696-9d39b220f5b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 789cab73-56f9-4329-92f1-fd1eb46b6f3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7352eaa1-469b-40f7-9a9c-143b00eccdff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 208c99c7-d3e0-4bfa-be17-2e431c5896a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72034d41-8384-4230-9301-14078d210f57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9aec8052-db0c-4f41-ac69-dbe421f4e093
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e837468d-2b2e-492c-ae41-69b2864ce687
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 745495a1-a6c4-4f24-997c-51d43aca8109
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91f50543-800e-464a-a643-d4e18807bebb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2130defa-fd02-4b5f-ae53-df456add4485
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 922d2508-caee-42a6-ad7e-542fe125f26b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a805d1c-dca2-42ce-81da-cb996e043288
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c652c0a3-9137-4951-a1ea-bdd62c9cd3d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50f21127-2623-4c64-8915-400a9b542700
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a8921b0-99b1-45c4-8321-650d760214e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33dc017e-d7d4-4454-86a0-a51bc9e5abb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b03f2167-3b6d-4cf5-a5c3-c4719ee684d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7530886e-ff82-4158-a3ec-50d1bf1c9122
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c63a127-7147-4408-b17c-e181ab0b3338
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21f4e7bb-8736-457f-80f9-8187d0d5a6eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67369945-aaed-46d2-b82c-5787702e02a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c337bc6c-cedf-4213-9622-9b3e135ceb44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d8a548d-e7d2-4b78-9aa4-cfb78338bee9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08461c13-9c79-4de9-b090-3592bca3522a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b06b6257-25ee-4242-82c1-e8b0519e6b47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8bab338b-bc50-4e01-9ed3-5013ba486e02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4de96cf7-d330-4c1f-a2bf-66f5b9ff2c4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44fa2596-a847-4a6f-a84e-71dfd993db48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a40f9f3-f14e-48a3-ab0f-12ef494a3375
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dbcab10a-7aa6-466f-8b27-eab586d13b34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 974e5c98-14d8-4500-9128-28fbedae3878
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a988e19e-44b8-4641-b387-7eda62cf329f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59b16408-a86e-4ae8-9e47-a8ae89b8acb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b819bd32-bcab-42fc-abdb-c7cc9434c7a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49b4fb71-bbe6-407d-9c59-a5839529d2c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f62b2c02-149f-42bd-8f1a-1a26bff0e908
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9021272-ad41-46be-8028-063f0678db8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13d223b7-e2f4-47db-ab7d-a45265c04e18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7ccfcfb-12b8-466a-90ae-86dc9f3489d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37910ce0-03c5-4ef4-aaba-3888a5c5f046
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0b46c47-7d2e-4815-a2f7-bcd0168ecbc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76dc226e-476b-4c29-85e6-d888659d4837
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dff52515-bdde-442a-9b78-e40dbf8c615f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2214ec55-7df4-449a-854d-6016b6e337e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49703bab-4527-477f-b6c1-c8cfc8110d87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0129d837-ea0f-4e11-9497-9c0765fcbffc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 737aabc7-2a98-409c-9580-1ee05485a6ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49633ce4-52d6-4506-8186-dcacd7911fb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0df59155-ca73-44b4-bb15-ac394113fb1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5f2ce68-6d10-45ce-bd46-3cef92fb349f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a97ae27-ecba-44c3-9cff-ed363d250055
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4042a19-a4a0-4292-8700-f2b69ba41cfc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aee9ef1a-5993-4daf-8f0b-b3bd4db60220
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e5383ff-b698-4aef-8cec-82f97756c9ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d613793-8ade-4ccc-80c5-674f8562786d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8370821c-4a6e-4f11-adbc-2a91ef11879c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b4a29c6-6991-4809-bd53-8f3d6b7bffe2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 740cb0d7-3224-4056-aad5-a32336fc95e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a53071cc-34fe-4f89-bf50-fe97c0d01950
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12321336-3679-4faa-afcf-c1ccf2f396c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b524b62-03bb-4f3a-9035-eb16ebd9e13f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90ec2f51-5738-4bd4-8b68-ea37f7f1bef6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d86e8358-dc04-49e9-815f-ce6bd21c0f90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2021964-6386-4709-ac4f-d4582f31aa48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8b504bc-855f-4219-bfbf-f7ce49653afc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa750965-fe11-46ac-a1cd-5835f62876fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20edd3bc-4e1e-4bc4-ab2e-4d4f3168a162
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9baac52-88fa-4d89-a04f-a36232ecf142
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 758a9e96-a873-47e6-b9c7-c9c1a3980ba0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21582a22-4244-4337-a3fd-24100dfa4acf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message afd73993-d31a-4aca-8de9-afee4c2f81d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9eb3bcf5-52c8-43a0-a682-3cd17d4f49d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3329b434-1aef-457c-8a9d-6f446c7a50ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53521333-99cb-42a7-af23-2e0399f2fc5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3df80c10-6482-4f95-8186-aa4cacf30b91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0120cc3-4665-4a49-a71d-5612eb97fcd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8354660d-8045-4f57-8750-ff452ea678f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf1ed3d0-0961-4f6d-95d9-3b80a72ee1ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8966f198-dfef-4ac9-bbf3-89ee93cbcaa2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 555d629a-013c-4aeb-89a7-b98719bc77f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9268e66e-08e1-4b29-8162-c6d28a1905fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e14f2e2e-fe5e-49c8-a238-5847e5fd1588
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09fabaee-40f2-49e8-8ea3-9c68cf0dcf49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dbb6b29d-848d-494d-8236-1a9d10ba820a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8a4bbfd-2677-46b5-ba4e-ff3bddde02c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89e0e79b-89bc-4d12-a180-77f4a6a88c22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77f5fd2d-ca0d-41cb-bf07-d888945ba21c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84706d56-0281-457b-970b-56a780d23a5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed44e30e-3f13-4784-827c-d3ade22a6d17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0a87007-26df-443a-91de-53c863c839c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df850fa1-35c1-4ec6-9c3e-87d038ebd3ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3fd299db-0974-49cb-8c79-463c78884a66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad687e9d-5d5e-4d70-b27d-ab4f6cd926ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c288639-0195-4e6d-b510-acc6a421a244
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac0f6175-88a2-4043-9675-fe955d0ac89f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ccb24fb1-2c78-48d2-9020-b415c54e0fa6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0889d3ca-8fe0-47c6-a377-3eb7d91dd46c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de23a040-f447-4247-ba59-c1da2c7aa6cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 479639cc-0fcd-4bcf-9cc3-8f63079f0e64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc6a3d98-992f-4b5c-a064-cc95179853cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b3c6105-a452-46b4-be7b-adc5f85deb2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74531c32-01c9-475d-8782-bb5dd52baf93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56d78193-aa8f-4cb2-ae22-be2dfa0707aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a49df9a-ab46-413e-866c-d15df44ef795
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81f286c6-0069-44d1-bf8d-1f2250fba04d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9e58b5f-1078-442e-b0c1-ffcf0f3289ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7cab1955-25fe-4295-b6a7-eed38fffe61a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91385622-a9aa-4db2-b85c-c9d06728658d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6572cc9-c690-469f-babf-151b3b1ca779
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d12ab3a-eb62-4362-809b-24ae23252742
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5290f434-de20-45f7-bbf3-e97d8b2f2ad3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ce6c9a4-41ba-432f-b199-f011a12b0940
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 199d99d7-92f6-4e8c-bef1-24a6f4c581d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e37466a5-757f-40ce-9986-bdf7adc0c75d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea5d543a-6ccc-4528-a57b-f0ba032cedf0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b40a0a69-b45c-4fd5-8189-94363f0f4a1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc9aa4f4-289e-4f84-8166-7bd8cddcdc4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0979d9dc-d7ba-4dc8-b540-d2b610c85fd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b19873a3-ad53-4fa1-a12f-70f8d443326b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed80c5de-46b7-487f-983e-33d7bef1b657
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5a07126-de7c-4962-bb09-5b0688f62ef1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f21c0f13-3f7f-4216-b3a2-fe57b04dc36b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 025420c3-0f4d-4bb8-9e8c-78acd1ecac30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 827a98c1-ae54-4f68-9a45-dc3fe498c35a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message daf71450-45e0-4d05-94c1-93a46beb7786
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c923f017-429c-498a-8b22-bf7cd46dc95a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f52cf19c-0af3-4566-bd86-af8d8ca8c80e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e5a457c-2be4-4ea3-b32f-f0d745eda836
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2bd47561-3304-4709-bb1d-e3dfc5bdbcea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96d1116d-5d18-4d55-bcc7-8fe00a692218
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 605262d0-2ade-41a7-9ed0-3c882795a6bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4729fc31-a8e7-4858-98cc-5b91051339be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80eacd22-c1bf-428d-88f1-82526f17fe9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ddb3a53-9594-4f8d-b32a-4e9f0a9febd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93f445f6-4d8f-44ba-addf-f47d545b9957
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f67eecaf-4368-41ee-b16c-36ab135bb68e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6180b505-c01d-4432-ae19-9ca568958f66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 197219fe-58cf-40c1-ae29-9bff4d11e55e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96049e54-940d-4a0f-9268-1383b909f669
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb450e78-475e-46ea-a4bc-9dc36821b235
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 142970f9-dccf-4884-b5f9-9bcf445e07f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98a58aba-f4ee-4885-a9d3-270b4ffe6d24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a3b6265-5a03-4373-9398-47cf0e9cf1e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1dab0aad-785f-43bb-817b-9ed7a63c0fcd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4521a63e-64f0-45ed-8cbe-71e7f4d82d04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4fc18b86-7314-4aa1-bfdb-6d5eb8ee4895
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15b2ce0d-575f-4f80-928c-dd34bc79b6ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 281cad5f-ba40-449f-a98c-6bd520e3daf9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31851e9e-a400-475f-b456-e1e4589a2be4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0c536e4-cd1a-473b-8e21-27c46c493f73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b6a51c3-b065-4778-a7fa-9b60bf27cdf2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70885c3b-1b73-42d4-9b70-d9f5c62a2ce8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f038c9e4-8e01-4efb-9777-639c5a68ceaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f1f1ec4-faad-49be-86b3-993093060ff8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50f45642-f1bd-4e13-8ab2-08facedcbb25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 996ef0a6-ecbd-4e7a-9a8a-6cef96c82f4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 389d6096-684e-49b8-8a24-5da3db8e9f05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f677aaa-6d84-4417-81e3-e05c4ba9e719
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21aaefdb-c007-4a37-ba13-f4be89352fd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fefdfd86-d71c-40f4-bfcf-6e20ba5e655a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 055a66e8-ee22-45bc-95ab-903a0a0f973e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da8cf61d-cbdc-4950-ba9c-b61c93111ab1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bcd0a0cd-0f1b-469e-9fd0-d40abffbb68c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eaff68e5-fde8-4e58-bb8a-d5e2e7812f44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16afa89a-ee10-4cf6-9fed-794a52b78c2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d168c43-14eb-4718-b5d4-bd724a95c615
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb22b8bb-e6dd-401f-9c13-13a6724d8498
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a74def4-d9c2-43f6-9ff3-843cac76440e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db389595-0af2-48ad-b4e9-e1371a62065e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f064c084-8b13-4dc4-8054-c256a678f13a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00fd8334-52f5-481c-9cac-87aaed9ef26a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c692107-041c-4b92-9c45-9a97d9f38c6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 159b5bc2-17ed-4543-8f00-cca6b670ff79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 237cbf4a-5e5c-4497-a582-58a9caae176e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eecfd742-8c34-4c28-9e24-cdc186ad63c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b47b5ee0-44ce-4bda-9b3b-c5ec1a2634fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a79ae2f-95d1-4335-94f5-a273de77e374
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message acf682c5-211d-4fdb-a2d3-ee2d1d5e3fa4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aaa61512-bb4a-435c-bdba-dcfa69149756
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d1afc8c-4435-48ab-9f6e-196c40065790
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5cfcb07d-c89e-47a0-bab2-f228aa537031
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc3f9a6b-af43-419d-977d-b6265dc60380
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8ef3157-2986-4aa4-8485-eaac87534317
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b2a004e-7bc1-40fe-b8fd-b51b76b17cbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c95979c9-8e04-4bad-b847-f12adc0c182f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab2f261a-ffa2-40f3-94c7-4e46a1b1c740
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 030d3a7a-9a2a-403f-acaf-9561cef668cb
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8690 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_18
Server: localhost:8690
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_18
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_18/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_18/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_18/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_18/test_labels.txt

📊 Raw data loaded:
   Train: X=(3505, 24), y=(3505,)
   Test:  X=(877, 24), y=(877,)

⚠️  Limiting training data: 3505 → 800 samples
⚠️  Limiting test data: 877 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_18 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2406, R²: -0.0103

============================================================
🔄 Round 4 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0761 (↓), lr=0.001000
   • Epoch   2/100: train=0.0818, val=0.0767, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0818, val=0.0765, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0816, val=0.0765, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0813, val=0.0766, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0803, val=0.0775, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 4 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0086
   Val:   Loss=0.0761, RMSE=0.2759, R²=-0.0148
============================================================


📊 Round 4 Test Metrics:
   Loss: 0.0775, RMSE: 0.2783, MAE: 0.2398, R²: -0.0045

============================================================
🔄 Round 10 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0757 (↓), lr=0.000250
   • Epoch   2/100: train=0.0824, val=0.0753, patience=1/15, lr=0.000250
   ✓ Epoch   3/100: train=0.0822, val=0.0751 (↓), lr=0.000250
   • Epoch   4/100: train=0.0821, val=0.0749, patience=1/15, lr=0.000250
   • Epoch   5/100: train=0.0820, val=0.0749, patience=2/15, lr=0.000250
   • Epoch  11/100: train=0.0817, val=0.0746, patience=8/15, lr=0.000250
   • Epoch  21/100: train=0.0814, val=0.0746, patience=9/15, lr=0.000250
   📉 Epoch 22: LR reduced 0.000250 → 0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 10 Summary - Client client_18
   Epochs: 27/100 (early stopped)
   LR: 0.000250 → 0.000125 (1 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0139
   Val:   Loss=0.0746, RMSE=0.2731, R²=0.0155
============================================================


📊 Round 10 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0034

📊 Round 10 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2399, R²: -0.0050

============================================================
🔄 Round 15 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0884 (↓), lr=0.000125
   • Epoch   2/100: train=0.0787, val=0.0882, patience=1/15, lr=0.000125
   📉 Epoch 3: LR reduced 0.000125 → 0.000063
   • Epoch   3/100: train=0.0785, val=0.0881, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0784, val=0.0882, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0783, val=0.0882, patience=4/15, lr=0.000063
   📉 Epoch 11: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0779, val=0.0885, patience=10/15, lr=0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 15 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000125 → 0.000031 (2 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0009
   Val:   Loss=0.0884, RMSE=0.2974, R²=-0.0041
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.0774, RMSE: 0.2783, MAE: 0.2397, R²: -0.0039

============================================================
🔄 Round 17 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0778 (↓), lr=0.000031
   • Epoch   2/100: train=0.0818, val=0.0777, patience=1/15, lr=0.000031
   📉 Epoch 3: LR reduced 0.000031 → 0.000016
   • Epoch   3/100: train=0.0817, val=0.0776, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0817, val=0.0775, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0817, val=0.0775, patience=4/15, lr=0.000016
   📉 Epoch 11: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0816, val=0.0773, patience=10/15, lr=0.000008
   📉 Epoch 19: LR reduced 0.000008 → 0.000004
   • Epoch  21/100: train=0.0815, val=0.0772, patience=9/15, lr=0.000004
   📉 Epoch 27: LR reduced 0.000004 → 0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 17 Summary - Client client_18
   Epochs: 27/100 (early stopped)
   LR: 0.000031 → 0.000002 (4 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0043
   Val:   Loss=0.0773, RMSE=0.2780, R²=0.0039
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.0774, RMSE: 0.2783, MAE: 0.2397, R²: -0.0040

📊 Round 17 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0038

============================================================
🔄 Round 21 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0771 (↓), lr=0.000002
   • Epoch   2/100: train=0.0818, val=0.0771, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0818, val=0.0770, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0818, val=0.0770, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0817, val=0.0770, patience=4/15, lr=0.000002
   📉 Epoch 8: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0817, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 21 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0013
   Val:   Loss=0.0771, RMSE=0.2776, R²=-0.0260
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0038

============================================================
🔄 Round 22 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 22 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=-0.0031
   Val:   Loss=0.0890, RMSE=0.2983, R²=-0.0143
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0038

📊 Round 22 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0038

📊 Round 22 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0038

📊 Round 22 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0037

============================================================
🔄 Round 27 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 27 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0010
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0149
============================================================


============================================================
🔄 Round 28 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 28 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0021
   Val:   Loss=0.0834, RMSE=0.2888, R²=0.0054
============================================================


============================================================
🔄 Round 29 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0714 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0714, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0714, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0714, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0714, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0714, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0714)

============================================================
📊 Round 29 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0032
   Val:   Loss=0.0714, RMSE=0.2672, R²=-0.0248
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0037

============================================================
🔄 Round 30 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 30 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0009
   Val:   Loss=0.0724, RMSE=0.2690, R²=-0.0037
============================================================


============================================================
🔄 Round 31 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 31 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0001
   Val:   Loss=0.0794, RMSE=0.2818, R²=0.0015
============================================================


============================================================
🔄 Round 32 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 32 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0000
   Val:   Loss=0.0755, RMSE=0.2748, R²=-0.0097
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0036

📊 Round 32 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0037

📊 Round 32 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0036

📊 Round 32 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0036

============================================================
🔄 Round 41 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 41 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0023
   Val:   Loss=0.0828, RMSE=0.2878, R²=0.0013
============================================================


============================================================
🔄 Round 42 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 42 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0006
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0044
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0036

============================================================
🔄 Round 43 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 43 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0011
   Val:   Loss=0.0751, RMSE=0.2740, R²=-0.0024
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0036

📊 Round 43 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0037

📊 Round 43 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0037

📊 Round 43 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0037

============================================================
🔄 Round 50 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 50 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0007
   Val:   Loss=0.0764, RMSE=0.2764, R²=-0.0011
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0037

============================================================
🔄 Round 52 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 52 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0031
   Val:   Loss=0.0853, RMSE=0.2920, R²=-0.0264
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0037

============================================================
🔄 Round 53 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 53 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0000
   Val:   Loss=0.0757, RMSE=0.2752, R²=0.0005
============================================================


============================================================
🔄 Round 54 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 54 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0017
   Val:   Loss=0.0788, RMSE=0.2808, R²=-0.0078
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0037

============================================================
🔄 Round 55 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 55 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0009
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0020
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0037

============================================================
🔄 Round 57 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 57 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0007
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0006
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0036

============================================================
🔄 Round 60 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 60 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0014
   Val:   Loss=0.0834, RMSE=0.2887, R²=-0.0238
============================================================


============================================================
🔄 Round 61 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 61 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0013
   Val:   Loss=0.0834, RMSE=0.2887, R²=0.0043
============================================================


============================================================
🔄 Round 62 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 62 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0002
   Val:   Loss=0.0869, RMSE=0.2947, R²=-0.0034
============================================================


============================================================
🔄 Round 64 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 64 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0024
   Val:   Loss=0.0793, RMSE=0.2815, R²=-0.0086
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0036

📊 Round 64 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0035

📊 Round 64 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0035

📊 Round 64 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0036

============================================================
🔄 Round 75 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 75 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0006
   Val:   Loss=0.0754, RMSE=0.2746, R²=-0.0038
============================================================


============================================================
🔄 Round 76 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 76 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0011
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0023
============================================================


============================================================
🔄 Round 80 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 80 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2857, R²=0.0009
   Val:   Loss=0.0782, RMSE=0.2797, R²=-0.0080
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0036

📊 Round 80 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0036

============================================================
🔄 Round 82 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 82 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0005
   Val:   Loss=0.0776, RMSE=0.2786, R²=-0.0023
============================================================


============================================================
🔄 Round 85 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 85 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=0.0008
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0011
============================================================


============================================================
🔄 Round 86 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 86 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0021
   Val:   Loss=0.0835, RMSE=0.2889, R²=0.0028
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0037

📊 Round 86 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0036

📊 Round 86 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0036

📊 Round 86 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0036

📊 Round 86 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0036

📊 Round 86 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0036

📊 Round 86 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0036

============================================================
🔄 Round 94 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 94 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0021
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0115
============================================================


============================================================
🔄 Round 96 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0704 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0704, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0704, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0704, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0704, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0704, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0704)

============================================================
📊 Round 96 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0012
   Val:   Loss=0.0704, RMSE=0.2653, R²=-0.0032
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0036

📊 Round 96 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0036

📊 Round 96 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0036

📊 Round 96 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0036

============================================================
🔄 Round 111 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 111 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0023
   Val:   Loss=0.0908, RMSE=0.3013, R²=-0.0066
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0036

============================================================
🔄 Round 113 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 113 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0013
   Val:   Loss=0.0813, RMSE=0.2852, R²=0.0069
============================================================


============================================================
🔄 Round 114 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 114 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0004
   Val:   Loss=0.0774, RMSE=0.2783, R²=-0.0006
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0035

📊 Round 114 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0035

============================================================
🔄 Round 117 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 117 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0020
   Val:   Loss=0.0747, RMSE=0.2733, R²=0.0111
============================================================


============================================================
🔄 Round 121 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 121 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0002
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0109
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0035

============================================================
🔄 Round 123 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 123 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=-0.0021
   Val:   Loss=0.0903, RMSE=0.3005, R²=-0.0015
============================================================


============================================================
🔄 Round 124 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 124 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0024
   Val:   Loss=0.0800, RMSE=0.2829, R²=-0.0088
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0035

============================================================
🔄 Round 127 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 127 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0015
   Val:   Loss=0.0817, RMSE=0.2857, R²=0.0051
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0035

============================================================
🔄 Round 129 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 129 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0011
   Val:   Loss=0.0824, RMSE=0.2871, R²=0.0038
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0035

============================================================
🔄 Round 132 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 132 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2829, R²=0.0020
   Val:   Loss=0.0846, RMSE=0.2908, R²=-0.0059
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0036

============================================================
🔄 Round 133 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 133 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0016
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0061
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0036

============================================================
🔄 Round 136 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0937 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0937, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0937, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0937, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0937, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0937, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0937)

============================================================
📊 Round 136 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0011
   Val:   Loss=0.0937, RMSE=0.3061, R²=-0.0021
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0036

📊 Round 136 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0037

📊 Round 136 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0037

============================================================
🔄 Round 142 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0718, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0719, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 142 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2885, R²=-0.0010
   Val:   Loss=0.0718, RMSE=0.2680, R²=0.0009
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0036

============================================================
🔄 Round 144 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 144 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0001
   Val:   Loss=0.0771, RMSE=0.2777, R²=-0.0022
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0036

📊 Round 144 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0036

============================================================
🔄 Round 147 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 147 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=-0.0009
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0037
============================================================


============================================================
🔄 Round 149 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 149 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0009
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0060
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0036

📊 Round 149 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0036

============================================================
🔄 Round 155 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 155 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0022
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0063
============================================================


============================================================
🔄 Round 156 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0699 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0699, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0699, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0699, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0699, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0699, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0699)

============================================================
📊 Round 156 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=-0.0004
   Val:   Loss=0.0699, RMSE=0.2644, R²=0.0027
============================================================


============================================================
🔄 Round 158 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 158 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=-0.0020
   Val:   Loss=0.0872, RMSE=0.2953, R²=0.0088
============================================================


============================================================
🔄 Round 159 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 159 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=-0.0018
   Val:   Loss=0.0880, RMSE=0.2966, R²=0.0056
============================================================


============================================================
🔄 Round 162 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 162 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0015
   Val:   Loss=0.0773, RMSE=0.2780, R²=-0.0099
============================================================


============================================================
🔄 Round 164 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 164 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0012
   Val:   Loss=0.0725, RMSE=0.2693, R²=0.0026
============================================================


============================================================
🔄 Round 165 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 165 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0021
   Val:   Loss=0.0778, RMSE=0.2789, R²=0.0038
============================================================


============================================================
🔄 Round 167 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 167 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0020
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0080
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0035

============================================================
🔄 Round 168 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 168 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0005
   Val:   Loss=0.0757, RMSE=0.2752, R²=0.0040
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0034

📊 Round 168 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0034

============================================================
🔄 Round 172 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 172 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0011
   Val:   Loss=0.0769, RMSE=0.2772, R²=0.0031
============================================================


============================================================
🔄 Round 174 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 174 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0004
   Val:   Loss=0.0804, RMSE=0.2836, R²=0.0004
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0034

============================================================
🔄 Round 179 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 179 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0003
   Val:   Loss=0.0737, RMSE=0.2715, R²=-0.0013
============================================================


============================================================
🔄 Round 181 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 181 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=0.0022
   Val:   Loss=0.0794, RMSE=0.2817, R²=-0.0135
============================================================


============================================================
🔄 Round 182 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 182 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=-0.0024
   Val:   Loss=0.0881, RMSE=0.2969, R²=-0.0090
============================================================


============================================================
🔄 Round 183 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 183 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0014
   Val:   Loss=0.0796, RMSE=0.2822, R²=-0.0060
============================================================


============================================================
🔄 Round 185 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 185 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=0.0005
   Val:   Loss=0.0842, RMSE=0.2901, R²=-0.0113
============================================================


============================================================
🔄 Round 186 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 186 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0001
   Val:   Loss=0.0725, RMSE=0.2692, R²=0.0016
============================================================


============================================================
🔄 Round 187 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 187 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2842, R²=0.0002
   Val:   Loss=0.0818, RMSE=0.2861, R²=-0.0151
============================================================


============================================================
🔄 Round 190 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 190 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0018
   Val:   Loss=0.0763, RMSE=0.2762, R²=-0.0075
============================================================


============================================================
🔄 Round 191 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 191 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0006
   Val:   Loss=0.0776, RMSE=0.2786, R²=-0.0023
============================================================


============================================================
🔄 Round 192 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 192 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0000
   Val:   Loss=0.0839, RMSE=0.2897, R²=0.0017
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0036

📊 Round 192 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0036

============================================================
🔄 Round 194 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 194 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0019
   Val:   Loss=0.0756, RMSE=0.2749, R²=-0.0060
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0036

============================================================
🔄 Round 196 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 196 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0015
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0044
============================================================


📊 Round 196 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0036

============================================================
🔄 Round 200 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 200 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=-0.0043
   Val:   Loss=0.0867, RMSE=0.2945, R²=-0.0198
============================================================


📊 Round 200 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0036

📊 Round 200 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0036

============================================================
🔄 Round 203 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 203 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2826, R²=0.0015
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0037
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0036

============================================================
🔄 Round 204 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 204 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0014
   Val:   Loss=0.0813, RMSE=0.2852, R²=-0.0054
============================================================


📊 Round 204 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0036

📊 Round 204 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0036

============================================================
🔄 Round 208 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 208 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0036
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0154
============================================================


============================================================
🔄 Round 209 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 209 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=0.0002
   Val:   Loss=0.0826, RMSE=0.2873, R²=0.0001
============================================================


📊 Round 209 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0036

============================================================
🔄 Round 212 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 212 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0001
   Val:   Loss=0.0767, RMSE=0.2769, R²=0.0010
============================================================


📊 Round 212 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0036

============================================================
🔄 Round 213 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 213 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0007
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0048
============================================================


📊 Round 213 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0036

📊 Round 213 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0035

📊 Round 213 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0036

============================================================
🔄 Round 217 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0714 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0714, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0715, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0715, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0715, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0717, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0714)

============================================================
📊 Round 217 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0053
   Val:   Loss=0.0714, RMSE=0.2672, R²=-0.0229
============================================================


📊 Round 217 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0036

============================================================
🔄 Round 219 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 219 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=0.0001
   Val:   Loss=0.0762, RMSE=0.2760, R²=0.0011
============================================================


📊 Round 219 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0036

📊 Round 219 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0036

📊 Round 219 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0035

============================================================
🔄 Round 225 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 225 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0012
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0037
============================================================


============================================================
🔄 Round 226 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 226 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0005
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0038
============================================================


📊 Round 226 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0036

============================================================
🔄 Round 227 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 227 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0012
   Val:   Loss=0.0735, RMSE=0.2711, R²=-0.0042
============================================================


📊 Round 227 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0035

📊 Round 227 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0036

============================================================
🔄 Round 229 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 229 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2856, R²=0.0013
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0062
============================================================


📊 Round 229 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0036

============================================================
🔄 Round 230 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 230 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0011
   Val:   Loss=0.0731, RMSE=0.2704, R²=0.0025
============================================================


📊 Round 230 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0036

============================================================
🔄 Round 233 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 233 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0027
   Val:   Loss=0.0874, RMSE=0.2957, R²=-0.0095
============================================================


📊 Round 233 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0036

📊 Round 233 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0036

============================================================
🔄 Round 236 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 236 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0008
   Val:   Loss=0.0775, RMSE=0.2785, R²=0.0049
============================================================


============================================================
🔄 Round 237 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 237 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0006
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0211
============================================================


============================================================
🔄 Round 238 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 238 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=-0.0031
   Val:   Loss=0.0794, RMSE=0.2817, R²=0.0001
============================================================


============================================================
🔄 Round 239 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 239 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0003
   Val:   Loss=0.0796, RMSE=0.2822, R²=-0.0011
============================================================


============================================================
🔄 Round 240 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 240 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=-0.0006
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0041
============================================================


============================================================
🔄 Round 243 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 243 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0003
   Val:   Loss=0.0739, RMSE=0.2719, R²=-0.0104
============================================================


📊 Round 243 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0037

============================================================
🔄 Round 244 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 244 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0004
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0396
============================================================


📊 Round 244 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0037

============================================================
🔄 Round 245 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 245 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0021
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0068
============================================================


============================================================
🔄 Round 248 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 248 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=-0.0004
   Val:   Loss=0.0878, RMSE=0.2963, R²=0.0003
============================================================


📊 Round 248 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0036

📊 Round 248 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0036

============================================================
🔄 Round 250 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 250 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2810, R²=0.0007
   Val:   Loss=0.0891, RMSE=0.2985, R²=-0.0018
============================================================


============================================================
🔄 Round 251 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0715 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0715, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0715, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0715, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0715, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0714, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0715)

============================================================
📊 Round 251 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0002
   Val:   Loss=0.0715, RMSE=0.2673, R²=0.0020
============================================================


============================================================
🔄 Round 252 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 252 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=-0.0004
   Val:   Loss=0.0843, RMSE=0.2903, R²=0.0028
============================================================


============================================================
🔄 Round 253 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 253 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=0.0019
   Val:   Loss=0.0926, RMSE=0.3042, R²=-0.0079
============================================================


📊 Round 253 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0037

============================================================
🔄 Round 254 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 254 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0018
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0084
============================================================


============================================================
🔄 Round 256 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 256 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=-0.0010
   Val:   Loss=0.0794, RMSE=0.2819, R²=0.0002
============================================================


📊 Round 256 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0037

📊 Round 256 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0037

============================================================
🔄 Round 259 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 259 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=-0.0018
   Val:   Loss=0.0858, RMSE=0.2929, R²=0.0021
============================================================


📊 Round 259 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0036

============================================================
🔄 Round 261 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 261 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=-0.0030
   Val:   Loss=0.0823, RMSE=0.2868, R²=-0.0257
============================================================


📊 Round 261 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0036

============================================================
🔄 Round 262 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 262 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0005
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0206
============================================================


📊 Round 262 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0035

============================================================
🔄 Round 263 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 263 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0019
   Val:   Loss=0.0806, RMSE=0.2840, R²=-0.0057
============================================================


📊 Round 263 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0035

============================================================
🔄 Round 268 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 268 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2822, R²=0.0013
   Val:   Loss=0.0862, RMSE=0.2937, R²=-0.0052
============================================================


📊 Round 268 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0036

============================================================
🔄 Round 269 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 269 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0010
   Val:   Loss=0.0847, RMSE=0.2910, R²=0.0058
============================================================


============================================================
🔄 Round 271 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 271 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0022
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0137
============================================================


📊 Round 271 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0036

📊 Round 271 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0037

============================================================
🔄 Round 273 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 273 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0001
   Val:   Loss=0.0812, RMSE=0.2849, R²=0.0023
============================================================


📊 Round 273 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0037

📊 Round 273 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0036

📊 Round 273 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0036

============================================================
🔄 Round 281 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 281 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0011
   Val:   Loss=0.0791, RMSE=0.2813, R²=-0.0025
============================================================


============================================================
🔄 Round 286 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 286 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=-0.0004
   Val:   Loss=0.0872, RMSE=0.2953, R²=0.0028
============================================================


📊 Round 286 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0036

============================================================
🔄 Round 289 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 289 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0016
   Val:   Loss=0.0834, RMSE=0.2887, R²=-0.0046
============================================================


============================================================
🔄 Round 291 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 291 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2806, R²=0.0011
   Val:   Loss=0.0899, RMSE=0.2998, R²=-0.0081
============================================================


============================================================
🔄 Round 292 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 292 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0008
   Val:   Loss=0.0884, RMSE=0.2973, R²=-0.0025
============================================================


📊 Round 292 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0037

📊 Round 292 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0037

============================================================
🔄 Round 296 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 296 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0002
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.0016
============================================================


============================================================
🔄 Round 297 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 297 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0002
   Val:   Loss=0.0725, RMSE=0.2692, R²=-0.0066
============================================================


📊 Round 297 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0036

============================================================
🔄 Round 299 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0684 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0684, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0684, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0684, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0684, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0683, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0684)

============================================================
📊 Round 299 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0003
   Val:   Loss=0.0684, RMSE=0.2615, R²=-0.0020
============================================================


📊 Round 299 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0036

============================================================
🔄 Round 300 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 300 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0015
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0048
============================================================


============================================================
🔄 Round 301 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 301 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0004
   Val:   Loss=0.0748, RMSE=0.2735, R²=-0.0047
============================================================


📊 Round 301 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0036

📊 Round 301 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0037

============================================================
🔄 Round 310 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 310 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0001
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0006
============================================================


📊 Round 310 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0036

📊 Round 310 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0036

============================================================
🔄 Round 313 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 313 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0003
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0034
============================================================


============================================================
🔄 Round 318 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 318 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=-0.0025
   Val:   Loss=0.0775, RMSE=0.2784, R²=-0.0103
============================================================


📊 Round 318 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0036

📊 Round 318 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0036

📊 Round 318 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0036

============================================================
🔄 Round 322 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 322 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0003
   Val:   Loss=0.0769, RMSE=0.2773, R²=0.0012
============================================================


📊 Round 322 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0036

📊 Round 322 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0036

============================================================
🔄 Round 328 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 328 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=0.0013
   Val:   Loss=0.0778, RMSE=0.2789, R²=-0.0049
============================================================


📊 Round 328 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0036

============================================================
🔄 Round 329 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 329 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0003
   Val:   Loss=0.0779, RMSE=0.2792, R²=0.0033
============================================================


📊 Round 329 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0037

📊 Round 329 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0037

============================================================
🔄 Round 332 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 332 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0005
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0033
============================================================


============================================================
🔄 Round 334 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 334 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0005
   Val:   Loss=0.0754, RMSE=0.2746, R²=-0.0036
============================================================


============================================================
🔄 Round 335 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 335 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0001
   Val:   Loss=0.0758, RMSE=0.2753, R²=0.0017
============================================================


============================================================
🔄 Round 336 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 336 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0001
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0009
============================================================


📊 Round 336 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0036

============================================================
🔄 Round 337 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 337 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0012
   Val:   Loss=0.0891, RMSE=0.2986, R²=-0.0033
============================================================


📊 Round 337 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0036

============================================================
🔄 Round 338 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 338 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0009
   Val:   Loss=0.0793, RMSE=0.2815, R²=-0.0052
============================================================


📊 Round 338 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0036

============================================================
🔄 Round 340 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 340 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0004
   Val:   Loss=0.0786, RMSE=0.2803, R²=-0.0111
============================================================


📊 Round 340 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0036

📊 Round 340 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0036

============================================================
🔄 Round 345 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 345 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0007
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0049
============================================================


============================================================
🔄 Round 347 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 347 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2835, R²=0.0017
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0109
============================================================


📊 Round 347 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0035

📊 Round 347 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0035

📊 Round 347 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0035

📊 Round 347 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0035

📊 Round 347 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0035

============================================================
🔄 Round 353 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 353 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0009
   Val:   Loss=0.0887, RMSE=0.2979, R²=-0.0013
============================================================


📊 Round 353 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0035

📊 Round 353 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0035

📊 Round 353 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0035

📊 Round 353 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0035

📊 Round 353 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0035

============================================================
🔄 Round 362 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 362 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0012
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0034
============================================================


============================================================
🔄 Round 363 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 363 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=-0.0000
   Val:   Loss=0.0864, RMSE=0.2940, R²=0.0020
============================================================


📊 Round 363 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0034

============================================================
🔄 Round 368 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0701 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0701, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0701, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0701, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0701, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0701, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0701)

============================================================
📊 Round 368 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0005
   Val:   Loss=0.0701, RMSE=0.2648, R²=-0.0009
============================================================


============================================================
🔄 Round 372 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 372 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0008
   Val:   Loss=0.0738, RMSE=0.2717, R²=0.0046
============================================================


📊 Round 372 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0034

📊 Round 372 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0034

📊 Round 372 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0034

📊 Round 372 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0034

============================================================
🔄 Round 378 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 378 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0006
   Val:   Loss=0.0813, RMSE=0.2852, R²=-0.0044
============================================================


📊 Round 378 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0035

============================================================
🔄 Round 379 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 379 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0012
   Val:   Loss=0.0892, RMSE=0.2987, R²=-0.0038
============================================================


📊 Round 379 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0035

============================================================
🔄 Round 381 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0678 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0678, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0678, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0678, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0678, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0677, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0678)

============================================================
📊 Round 381 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0023
   Val:   Loss=0.0678, RMSE=0.2603, R²=-0.0170
============================================================


============================================================
🔄 Round 382 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 382 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0044
   Val:   Loss=0.0725, RMSE=0.2692, R²=-0.0337
============================================================


📊 Round 382 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0035

============================================================
🔄 Round 383 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 383 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2835, R²=0.0034
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0117
============================================================


============================================================
🔄 Round 384 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 384 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0012
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0179
============================================================


📊 Round 384 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0034

📊 Round 384 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0034

============================================================
🔄 Round 387 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 387 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0005
   Val:   Loss=0.0767, RMSE=0.2770, R²=-0.0023
============================================================


📊 Round 387 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0034

============================================================
🔄 Round 388 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 388 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0002
   Val:   Loss=0.0801, RMSE=0.2831, R²=0.0028
============================================================


📊 Round 388 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0035

============================================================
🔄 Round 389 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 389 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0005
   Val:   Loss=0.0744, RMSE=0.2728, R²=0.0002
============================================================


============================================================
🔄 Round 390 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 390 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0024
   Val:   Loss=0.0760, RMSE=0.2757, R²=-0.0010
============================================================


============================================================
🔄 Round 391 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 391 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0012
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0074
============================================================


📊 Round 391 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0034

============================================================
🔄 Round 392 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 392 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0005
   Val:   Loss=0.0757, RMSE=0.2751, R²=-0.0008
============================================================


📊 Round 392 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0034

============================================================
🔄 Round 395 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 395 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0005
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0005
============================================================


============================================================
🔄 Round 397 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 397 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0017
   Val:   Loss=0.0841, RMSE=0.2899, R²=-0.0053
============================================================


📊 Round 397 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0035

📊 Round 397 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0035

============================================================
🔄 Round 403 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 403 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0046
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0209
============================================================


============================================================
🔄 Round 404 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 404 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0005
   Val:   Loss=0.0822, RMSE=0.2867, R²=0.0025
============================================================


============================================================
🔄 Round 405 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 405 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0000
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0011
============================================================


📊 Round 405 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0035

============================================================
🔄 Round 406 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0931 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0931, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0931, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0931, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0931, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0930, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0931)

============================================================
📊 Round 406 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2792, R²=0.0011
   Val:   Loss=0.0931, RMSE=0.3051, R²=-0.0035
============================================================


📊 Round 406 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0034

📊 Round 406 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0035

============================================================
🔄 Round 411 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 411 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0006
   Val:   Loss=0.0887, RMSE=0.2979, R²=-0.0005
============================================================


============================================================
🔄 Round 415 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 415 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0011
   Val:   Loss=0.0816, RMSE=0.2856, R²=-0.0026
============================================================


============================================================
🔄 Round 417 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 417 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0004
   Val:   Loss=0.0830, RMSE=0.2881, R²=0.0030
============================================================


📊 Round 417 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0036

============================================================
🔄 Round 418 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 418 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0016
   Val:   Loss=0.0788, RMSE=0.2807, R²=0.0077
============================================================


📊 Round 418 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0036

============================================================
🔄 Round 423 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 423 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0023
   Val:   Loss=0.0829, RMSE=0.2878, R²=-0.0136
============================================================


============================================================
🔄 Round 424 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 424 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0005
   Val:   Loss=0.0848, RMSE=0.2912, R²=0.0007
============================================================


📊 Round 424 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0036

============================================================
🔄 Round 427 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 427 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0005
   Val:   Loss=0.0796, RMSE=0.2822, R²=0.0026
============================================================


============================================================
🔄 Round 429 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 429 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0015
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0042
============================================================


============================================================
🔄 Round 431 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 431 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0002
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0103
============================================================


📊 Round 431 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0037

📊 Round 431 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0037

============================================================
🔄 Round 436 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0955 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0955, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0955, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0955, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0955, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0955, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0955)

============================================================
📊 Round 436 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2781, R²=-0.0014
   Val:   Loss=0.0955, RMSE=0.3091, R²=0.0056
============================================================


📊 Round 436 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0037

============================================================
🔄 Round 438 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 438 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0003
   Val:   Loss=0.0745, RMSE=0.2729, R²=0.0027
============================================================


============================================================
🔄 Round 441 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 441 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=-0.0007
   Val:   Loss=0.0743, RMSE=0.2725, R²=0.0050
============================================================


📊 Round 441 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0036

📊 Round 441 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0036

📊 Round 441 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0036

============================================================
🔄 Round 444 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 444 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0010
   Val:   Loss=0.0773, RMSE=0.2780, R²=-0.0136
============================================================


============================================================
🔄 Round 445 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 445 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0014
   Val:   Loss=0.0783, RMSE=0.2798, R²=-0.0046
============================================================


📊 Round 445 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0036

============================================================
🔄 Round 448 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0722 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 448 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0002
   Val:   Loss=0.0722, RMSE=0.2687, R²=-0.0028
============================================================


============================================================
🔄 Round 449 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 449 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0004
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0024
============================================================


============================================================
🔄 Round 451 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 451 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0009
   Val:   Loss=0.0816, RMSE=0.2856, R²=0.0052
============================================================


📊 Round 451 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0036

============================================================
🔄 Round 452 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 452 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0012
   Val:   Loss=0.0739, RMSE=0.2719, R²=-0.0081
============================================================


📊 Round 452 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0036

============================================================
🔄 Round 455 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 455 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0008
   Val:   Loss=0.0776, RMSE=0.2786, R²=-0.0056
============================================================


📊 Round 455 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0036

============================================================
🔄 Round 461 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0938 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0938, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0938, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0938, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0938, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0938, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0938)

============================================================
📊 Round 461 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2788, R²=0.0023
   Val:   Loss=0.0938, RMSE=0.3063, R²=-0.0176
============================================================


============================================================
🔄 Round 462 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 462 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0004
   Val:   Loss=0.0831, RMSE=0.2882, R²=-0.0028
============================================================


📊 Round 462 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0035

============================================================
🔄 Round 463 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0715 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0715, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0715, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0715, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0715, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0715, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0715)

============================================================
📊 Round 463 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0021
   Val:   Loss=0.0715, RMSE=0.2673, R²=0.0035
============================================================


📊 Round 463 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0035

============================================================
🔄 Round 464 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 464 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0021
   Val:   Loss=0.0765, RMSE=0.2766, R²=-0.0143
============================================================


📊 Round 464 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0035

📊 Round 464 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0035

============================================================
🔄 Round 466 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 466 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0033
   Val:   Loss=0.0774, RMSE=0.2782, R²=-0.0072
============================================================


📊 Round 466 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0035

============================================================
🔄 Round 468 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 468 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0008
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0245
============================================================


============================================================
🔄 Round 469 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 469 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0024
   Val:   Loss=0.0884, RMSE=0.2973, R²=-0.0083
============================================================


📊 Round 469 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0035

============================================================
🔄 Round 471 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 471 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0016
   Val:   Loss=0.0745, RMSE=0.2729, R²=0.0006
============================================================


📊 Round 471 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0035

============================================================
🔄 Round 472 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 472 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0025
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0109
============================================================


📊 Round 472 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0034

📊 Round 472 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0035

📊 Round 472 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0034

📊 Round 472 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0034

============================================================
🔄 Round 477 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 477 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0001
   Val:   Loss=0.0851, RMSE=0.2917, R²=0.0014
============================================================


============================================================
🔄 Round 479 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 479 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0001
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0016
============================================================


============================================================
🔄 Round 481 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 481 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0010
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0032
============================================================


📊 Round 481 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0035

============================================================
🔄 Round 482 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 482 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2877, R²=0.0003
   Val:   Loss=0.0738, RMSE=0.2717, R²=-0.0071
============================================================


============================================================
🔄 Round 484 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 484 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=-0.0012
   Val:   Loss=0.0775, RMSE=0.2783, R²=0.0037
============================================================


============================================================
🔄 Round 485 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 485 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2813, R²=0.0012
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0065
============================================================


📊 Round 485 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0035

============================================================
🔄 Round 486 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 486 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0002
   Val:   Loss=0.0831, RMSE=0.2882, R²=0.0022
============================================================


📊 Round 486 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0035

============================================================
🔄 Round 489 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 489 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0000
   Val:   Loss=0.0831, RMSE=0.2883, R²=0.0017
============================================================


📊 Round 489 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0035

============================================================
🔄 Round 493 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 493 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=-0.0015
   Val:   Loss=0.0917, RMSE=0.3028, R²=-0.0139
============================================================


📊 Round 493 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0034

============================================================
🔄 Round 494 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 494 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0028
   Val:   Loss=0.0750, RMSE=0.2739, R²=0.0015
============================================================


============================================================
🔄 Round 496 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 496 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0005
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0032
============================================================


📊 Round 496 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0034

============================================================
🔄 Round 497 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 497 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0016
   Val:   Loss=0.0779, RMSE=0.2791, R²=0.0001
============================================================


============================================================
🔄 Round 498 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 498 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0007
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0016
============================================================


📊 Round 498 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0035

📊 Round 498 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0034

============================================================
🔄 Round 504 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 504 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0017
   Val:   Loss=0.0767, RMSE=0.2770, R²=-0.0126
============================================================


📊 Round 504 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0035

============================================================
🔄 Round 509 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 509 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=-0.0018
   Val:   Loss=0.0863, RMSE=0.2937, R²=-0.0090
============================================================


============================================================
🔄 Round 510 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 510 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0020
   Val:   Loss=0.0883, RMSE=0.2972, R²=-0.0050
============================================================


============================================================
🔄 Round 511 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 511 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0011
   Val:   Loss=0.0830, RMSE=0.2882, R²=-0.0093
============================================================


📊 Round 511 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0036

============================================================
🔄 Round 513 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0717, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0717, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0717, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0717, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 513 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0008
   Val:   Loss=0.0717, RMSE=0.2678, R²=-0.0322
============================================================


📊 Round 513 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0036

📊 Round 513 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0035

📊 Round 513 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0036

============================================================
🔄 Round 519 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 519 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0007
   Val:   Loss=0.0861, RMSE=0.2935, R²=0.0003
============================================================


📊 Round 519 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0035

============================================================
🔄 Round 520 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0713 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0712, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0712, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0712, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0712, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0712, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 520 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0007
   Val:   Loss=0.0713, RMSE=0.2669, R²=-0.0030
============================================================


📊 Round 520 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0035

============================================================
🔄 Round 523 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 523 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0010
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0350
============================================================


📊 Round 523 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0035

============================================================
🔄 Round 525 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 525 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=0.0007
   Val:   Loss=0.0839, RMSE=0.2896, R²=-0.0093
============================================================


============================================================
🔄 Round 526 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 526 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0008
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0029
============================================================


📊 Round 526 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0035

📊 Round 526 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0035

============================================================
🔄 Round 528 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 528 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0019
   Val:   Loss=0.0830, RMSE=0.2882, R²=-0.0093
============================================================


============================================================
🔄 Round 529 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 529 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0006
   Val:   Loss=0.0765, RMSE=0.2766, R²=-0.0013
============================================================


============================================================
🔄 Round 531 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 531 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=-0.0024
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0034
============================================================


📊 Round 531 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0035

📊 Round 531 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0035

============================================================
🔄 Round 534 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 534 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0013
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0041
============================================================


📊 Round 534 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0035

📊 Round 534 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0035

📊 Round 534 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0035

============================================================
🔄 Round 540 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 540 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=-0.0003
   Val:   Loss=0.0884, RMSE=0.2974, R²=0.0030
============================================================


📊 Round 540 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0034

============================================================
🔄 Round 543 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 543 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0013
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0228
============================================================


📊 Round 543 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0034

============================================================
🔄 Round 545 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 545 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0001
   Val:   Loss=0.0867, RMSE=0.2944, R²=0.0014
============================================================


📊 Round 545 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0034

============================================================
🔄 Round 547 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 547 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0000
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0023
============================================================


📊 Round 547 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0034

============================================================
🔄 Round 548 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 548 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=-0.0011
   Val:   Loss=0.0805, RMSE=0.2838, R²=0.0065
============================================================


📊 Round 548 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0034

📊 Round 548 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0034

============================================================
🔄 Round 551 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 551 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0003
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0000
============================================================


📊 Round 551 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0035

============================================================
🔄 Round 555 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0645 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0645, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0645, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0645, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0645, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0645, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0645)

============================================================
📊 Round 555 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0002
   Val:   Loss=0.0645, RMSE=0.2540, R²=0.0025
============================================================


📊 Round 555 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0035

============================================================
🔄 Round 557 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 557 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0002
   Val:   Loss=0.0847, RMSE=0.2911, R²=-0.0102
============================================================


============================================================
🔄 Round 558 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 558 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0009
   Val:   Loss=0.0762, RMSE=0.2761, R²=0.0042
============================================================


📊 Round 558 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0035

📊 Round 558 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0035

============================================================
🔄 Round 561 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 561 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=-0.0006
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0074
============================================================


============================================================
🔄 Round 564 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 564 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0009
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0015
============================================================


📊 Round 564 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0034

📊 Round 564 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0035

============================================================
🔄 Round 567 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 567 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0015
   Val:   Loss=0.0733, RMSE=0.2708, R²=-0.0042
============================================================


📊 Round 567 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0035

============================================================
🔄 Round 568 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 568 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0011
   Val:   Loss=0.0862, RMSE=0.2935, R²=0.0046
============================================================


📊 Round 568 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0035

============================================================
🔄 Round 569 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 569 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0038
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0377
============================================================


📊 Round 569 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0035

============================================================
🔄 Round 570 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 570 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0013
   Val:   Loss=0.0814, RMSE=0.2852, R²=-0.0183
============================================================


📊 Round 570 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0034

============================================================
🔄 Round 571 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 571 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=0.0021
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0071
============================================================


============================================================
🔄 Round 572 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 572 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0008
   Val:   Loss=0.0724, RMSE=0.2690, R²=-0.0022
============================================================


============================================================
🔄 Round 573 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 573 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0006
   Val:   Loss=0.0747, RMSE=0.2733, R²=0.0055
============================================================


📊 Round 573 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0034

📊 Round 573 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0034

📊 Round 573 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0034

📊 Round 573 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0035

============================================================
🔄 Round 577 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 577 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0009
   Val:   Loss=0.0776, RMSE=0.2786, R²=-0.0011
============================================================


📊 Round 577 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0034

============================================================
🔄 Round 579 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 579 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0002
   Val:   Loss=0.0733, RMSE=0.2708, R²=0.0012
============================================================


📊 Round 579 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0035

============================================================
🔄 Round 583 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 583 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0004
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0026
============================================================


📊 Round 583 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0035

============================================================
🔄 Round 585 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 585 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0008
   Val:   Loss=0.0738, RMSE=0.2716, R²=-0.0063
============================================================


📊 Round 585 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0035

============================================================
🔄 Round 587 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0945 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0945, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0945, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0944, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0944, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0944, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0945)

============================================================
📊 Round 587 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=-0.0001
   Val:   Loss=0.0945, RMSE=0.3074, R²=-0.0024
============================================================


📊 Round 587 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0034

============================================================
🔄 Round 591 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 591 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0000
   Val:   Loss=0.0841, RMSE=0.2899, R²=0.0020
============================================================


============================================================
🔄 Round 593 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0678 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0678, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0678, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0678, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0678, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0678, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0678)

============================================================
📊 Round 593 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0011
   Val:   Loss=0.0678, RMSE=0.2604, R²=0.0077
============================================================


📊 Round 593 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2397, R²: -0.0035

============================================================
🔄 Round 594 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 594 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0000
   Val:   Loss=0.0798, RMSE=0.2824, R²=-0.0150
============================================================


============================================================
🔄 Round 597 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 597 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0043
   Val:   Loss=0.0855, RMSE=0.2923, R²=-0.0185
============================================================


============================================================
🔄 Round 598 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 598 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0033
   Val:   Loss=0.0784, RMSE=0.2800, R²=-0.0192
============================================================


📊 Round 598 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0034

============================================================
🔄 Round 599 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 599 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=-0.0025
   Val:   Loss=0.0878, RMSE=0.2963, R²=0.0034
============================================================


📊 Round 599 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0034

📊 Round 599 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0034

📊 Round 599 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0033

============================================================
🔄 Round 605 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 605 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0013
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0122
============================================================


📊 Round 605 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0033

============================================================
🔄 Round 606 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0709 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0709, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0709, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0708, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0708, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0708, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0709)

============================================================
📊 Round 606 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0012
   Val:   Loss=0.0709, RMSE=0.2662, R²=-0.0031
============================================================


📊 Round 606 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0033

📊 Round 606 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0033

============================================================
🔄 Round 613 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 613 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0003
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0015
============================================================


============================================================
🔄 Round 614 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0722 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 614 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2884, R²=0.0011
   Val:   Loss=0.0722, RMSE=0.2687, R²=-0.0066
============================================================


📊 Round 614 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0032

============================================================
🔄 Round 616 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 616 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0004
   Val:   Loss=0.0785, RMSE=0.2801, R²=0.0047
============================================================


📊 Round 616 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0032

📊 Round 616 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0032

============================================================
🔄 Round 618 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 618 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0007
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0028
============================================================


============================================================
🔄 Round 620 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 620 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0018
   Val:   Loss=0.0796, RMSE=0.2822, R²=-0.0213
============================================================


============================================================
🔄 Round 621 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 621 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0008
   Val:   Loss=0.0776, RMSE=0.2785, R²=-0.0006
============================================================


============================================================
🔄 Round 622 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 622 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0022
   Val:   Loss=0.0833, RMSE=0.2885, R²=-0.0170
============================================================


📊 Round 622 Test Metrics:
   Loss: 0.0774, RMSE: 0.2781, MAE: 0.2396, R²: -0.0031

============================================================
🔄 Round 627 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 627 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0006
   Val:   Loss=0.0903, RMSE=0.3006, R²=-0.0052
============================================================


📊 Round 627 Test Metrics:
   Loss: 0.0774, RMSE: 0.2781, MAE: 0.2396, R²: -0.0031

============================================================
🔄 Round 630 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 630 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0011
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0029
============================================================


============================================================
🔄 Round 631 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 631 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=0.0017
   Val:   Loss=0.0761, RMSE=0.2759, R²=-0.0053
============================================================


📊 Round 631 Test Metrics:
   Loss: 0.0774, RMSE: 0.2781, MAE: 0.2396, R²: -0.0031

📊 Round 631 Test Metrics:
   Loss: 0.0774, RMSE: 0.2781, MAE: 0.2396, R²: -0.0031

============================================================
🔄 Round 638 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 638 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0004
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0031
============================================================


============================================================
🔄 Round 640 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 640 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0009
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0005
============================================================


📊 Round 640 Test Metrics:
   Loss: 0.0774, RMSE: 0.2781, MAE: 0.2396, R²: -0.0031

============================================================
🔄 Round 644 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 644 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0002
   Val:   Loss=0.0752, RMSE=0.2743, R²=0.0014
============================================================


📊 Round 644 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0032

📊 Round 644 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0032

📊 Round 644 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0032

============================================================
🔄 Round 647 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 647 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0009
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0007
============================================================


📊 Round 647 Test Metrics:
   Loss: 0.0774, RMSE: 0.2781, MAE: 0.2396, R²: -0.0032

📊 Round 647 Test Metrics:
   Loss: 0.0774, RMSE: 0.2781, MAE: 0.2396, R²: -0.0032

============================================================
🔄 Round 650 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 650 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0012
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0042
============================================================


📊 Round 650 Test Metrics:
   Loss: 0.0774, RMSE: 0.2781, MAE: 0.2396, R²: -0.0032

============================================================
🔄 Round 655 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 655 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0007
   Val:   Loss=0.0783, RMSE=0.2799, R²=0.0044
============================================================


📊 Round 655 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0032

============================================================
🔄 Round 656 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 656 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0018
   Val:   Loss=0.0784, RMSE=0.2799, R²=-0.0091
============================================================


📊 Round 656 Test Metrics:
   Loss: 0.0774, RMSE: 0.2781, MAE: 0.2396, R²: -0.0032

📊 Round 656 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0032

============================================================
🔄 Round 658 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 658 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=0.0029
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0200
============================================================


📊 Round 658 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0032

📊 Round 658 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2396, R²: -0.0033

❌ Client client_18 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8690 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8690 {grpc_message:"Socket closed", grpc_status:14}"
>
