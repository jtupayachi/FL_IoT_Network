[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37d970c3-8a68-432b-b4b4-7490ac170899
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 570d6c5e-379c-4472-a45e-95b84de8ffe0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8e792a2-0739-4f89-89c3-ef39a0cfd9db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d957717f-3e8c-46a4-80e9-1f559b15d6c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d805341e-0ff6-4b71-a55b-374eb185c41c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4feeacfb-e0da-4e9d-a6b7-cb5e7ba8e858
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c56e9ee-c378-45c8-8cf6-bc09d9de76be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 613b914d-c1ba-44b9-af54-a26a75bb3972
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1dc591ba-9ffd-4884-8458-e00637386dd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b2d51fb-5460-4959-bfaf-c241bfe09fbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1298df4-30d8-4913-b043-dbf743d6dbb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d06774b3-962a-4cc8-bab1-5eb390413f1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11c2aaff-7407-4789-af79-40762dc33714
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 046dbfe8-6987-40b2-91d3-1104ff49eaee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f44956c4-3434-4a99-998a-b2a4f7ff7057
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7304f051-f713-4214-beea-56ab1cf3d1b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db6958d7-2f25-4406-a6f9-aecdf366668e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 681fb643-b0a3-48af-8847-80642ce414bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8cb29dd-6a7d-40a4-85d9-954c731e1730
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de03eb09-17b4-4f41-a4d1-c0d83e74341f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8b52e44-a894-4ee1-884a-9bf7eaa5f21a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 885e852a-e743-46de-9cd0-540bcf148fff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad21e2ee-6118-4a6a-b456-f76a8520981e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 757ebd38-7b5f-4b81-b630-250ff9847204
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a153259-07af-4814-a289-47282be4177c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39622079-83f7-4f6f-8c3d-73f60c00df1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ecfdbafa-3fc4-4184-9735-ae9153f2f07a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa8d17f7-42ae-4419-832f-87d712dc6efd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4458f1e0-c651-4a9c-a94a-f9ae0adcc575
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9fc35037-be75-4289-83cd-54cc65822c41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5bb80c0-7217-4df6-b876-c54b67ca1855
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4ff8fcc-59d0-41a6-81f0-48846dd429e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e3a6fdc-f338-45b7-8496-f94cb64e56ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1cd1b874-abfb-4722-bd19-76246241c2e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bbd293ff-8c62-4a4d-ac98-b68e214cf919
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dde65e83-f338-42d4-8eb2-cda043e41bba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 937c5196-8a86-45b0-9269-b7343d5b3159
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dbaa7cf3-418f-478e-86c7-73face884f18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e54b4bbb-8aea-4fd1-a2f7-5303f6e03513
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7be0aa6c-4643-4f91-ae78-1424fae7b238
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ebe35fac-de87-4cdc-8f30-ae72d954cf7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5b137e0-59e2-4a7b-9a2d-d3434f197271
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7025f180-ac85-4f64-84a9-f0c7c7fbd309
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8274fcd-305c-4ae9-b487-c83a0a43ff2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8118aed2-fffa-46a9-a89f-fe0510b36997
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2178673b-0ddd-43e7-afe8-f85794dec0aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 978609a9-9355-4c70-8e2d-392108acfaef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc69d4eb-d6a6-4435-8e91-cd27019108d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10d13e7e-83ba-4454-b27b-97069a033887
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8db24434-7ade-430a-8ae2-9dd37b5b1214
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c07fe7d-c303-4f58-846e-bc85fd37558a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a90857ce-1e30-433d-b849-b186610e3d19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9652864-1f28-4a23-84b9-eed9ed671be2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07f49267-6f88-454c-9a2c-3ec7f5f0603b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4bbfb6d8-7ee6-4343-981e-9ea22e65725d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e57ebb61-5203-4b89-946f-318ed7a06a60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8cd12b9-542a-4bae-9aa8-2f96c857c659
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02ccd069-7fdc-4e85-9fb9-251738d48cb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfdbff81-d8bb-4935-9412-c889332eed77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a52d0bdd-0038-487e-895a-6bcd72091459
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df171a3d-0d10-4f59-b454-7d04804d5567
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f748257a-b92f-4682-8672-3661317a7696
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 841e4027-3171-4656-81dd-1797343b142b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df4c03d7-1ae4-40e9-b711-a89a48c3612c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6fd7b761-46a6-455a-9220-69db6e9784ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2f929cc-5ca1-4d22-b41f-52430c37fe70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f8db8b3-94d6-47d8-8346-5eadf4edd935
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84573abd-19e5-41ee-97a8-9ad35be67707
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea7c9353-99b6-432e-b91b-ec628b7e4eb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54c29380-eb2e-454e-a8f8-896619e4d060
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c70937ff-8bcf-4ac1-bd0d-72316f6cfe0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3afe7b2-d3e8-446b-b594-15b911a72cb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 939dea20-709f-473a-9e0d-013630724c43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba70539e-df80-4921-a845-da7422fd9589
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69d5fa06-286b-4b32-8581-c7ae41c509cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d399a50-f6f7-4663-a2f0-84e698d461d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92c8ac72-9ee1-41c8-9ee5-c91fd1915cbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad8fe981-5e51-428d-b6f2-b0477a9d40bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf28746c-716d-42e4-a81f-529a7e0365c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfd8e9d8-908f-491d-a689-db02b8685621
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8e4f5d1-8e4f-41fb-8109-c9114e23d55c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90d6b85b-79cd-494c-9f3d-96469c3f631d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f20871f-d404-42f3-8490-90027748dfcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04dbb620-e4c9-4a97-89f3-f18a55b76b0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4cc670e9-b42b-4507-ae57-5ae3d33ce3c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ae3f0d0-e272-48d1-83a3-4dd849dbdfe4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5ce8cee-a966-4ba5-bdd8-f8e05767c8d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 160c709e-fec0-43b0-a59b-3764cc9f7694
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c328f4f-d6be-4d8b-87f3-dc6fa0a44611
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a622d1bb-5e63-446f-98e5-0f60c078a05c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 684e7470-c85b-44ce-97c7-39fe7dc4b1c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 901a26d2-3f18-4425-ae04-48c9bed0a0f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c257fd9f-ccfd-4ede-8813-231eafde8d7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29dd596e-9e67-45b7-9f3d-02d331a048b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cce7afce-f8b4-4f42-9fbd-929aa1682f1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eacefce7-e769-432a-9bf5-53f034bac955
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b570a40-4033-4d26-a048-ff51e95e68e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 119d000c-78e6-4704-8b20-810fefbed014
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72a3bc76-6afa-43a0-9568-1c6ffdc33c8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb835976-6e3e-41f9-b87d-982ed24e080d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1ef77dc-2ca9-434e-a40c-403d240c920b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a193fb3-5a9e-49b2-9551-7eaa188e877d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98164168-b24a-4c6c-9628-080fc7ba1214
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66425fe1-8515-457c-a1ad-cac1e4292da3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85b6cf90-1794-4f10-9b2d-2d94685e26da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e92b00d6-b7f6-42ea-ac4c-abe9229ad4bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e28c9543-b4d0-402a-9f99-da03760d9e27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa0ce9e4-140f-4164-b05a-b476948521cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 801cb650-9d4a-49ae-ade7-ecbeab689f2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2deb7932-5f64-4a7e-975d-ac145c0266fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc4f2193-2513-4874-bf83-bad8518d12fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e9bd55c-6742-4a0d-ae1c-bfda270bd383
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1088d9b-643e-483e-9b48-e908ba445f08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4856895e-8b50-4ebb-bdb2-afd77b03200d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab840f82-6150-4421-8f76-0c264c584df7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf5f38f9-9fd4-4172-ad13-73116412717c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6c1a39d-6d05-4c4b-8ab8-67b3eb1051a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3dd2c988-7dd3-4519-9d76-72b860638353
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c992856-00f9-4a86-aee9-c303e2225300
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc7ae790-8c74-47b2-891b-44b3913ab692
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18f554b7-f8fb-4a55-897c-55a5505a6334
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f0f86af-9d91-4954-9676-1921b6a7868b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97b0bea3-0c27-4e4c-9fb2-2a04c5d629d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a72e1b7a-e5c0-49a7-999a-e673579a252d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac40c92c-00b6-4089-8b9a-06f26f337cae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d6e59a2-d230-4212-898b-8cc264e506b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3198443a-416d-44f1-889a-77863ee982b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d03c3378-2f12-4895-aeed-a7eda489ebc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cda3988e-e44f-4e97-b67e-76dcbeb5e28c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a2c7f52-f13b-4b40-b6b2-2e30bfa3f482
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d14bdf6b-5c46-4272-a0ee-c2d6c01565c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01ff1137-6dc8-4900-89cb-3d4c175f4b43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72e9bc64-d860-448f-8176-9f0271a8d33d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c8405f1-b7cb-4617-bbe0-bad2d29235d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12a6e9c5-d584-4a68-9e6c-72eb061912b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b031c488-5cbb-435b-a220-374e9ef3e7ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f25f5329-d319-4a73-ac8d-24552d09a82b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81908c07-f441-4731-b335-79c6088f9e6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af962b4d-0689-415e-8716-bb14f986aa85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bffb10be-9cc1-4548-b2d3-586957068a28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5beca667-9618-4202-b0a6-b07eea2b3fcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76fdbaf0-ee6a-47cc-a5fb-cd0b43d92416
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3bb171ad-bf17-47ef-8a97-339ba8a19a40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7d41a39-850d-42c0-a71b-0b3893125d32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cabc400d-fef7-49cc-9b68-fb5a60b9b397
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab3aadcc-2e9e-4872-bc77-c63e7aec176f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e92aee91-0612-43dc-9124-7133523fad17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1afbe35-d121-4264-949c-7d4b3c29a969
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e539c271-b8a0-4b84-a8ef-93ad130d6396
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 364b4f0f-7212-4b34-88fa-42edcb376109
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38093ff3-c5a3-439d-85de-f5d1fa0e079c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fcbcbe3c-45f4-41a7-9ff8-537fe9bcf267
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26be94a7-9b56-449b-944e-afb4671baf94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8421afe8-03cb-461c-9bc9-64a3112ad9f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb0d06ad-2dae-4d48-884f-22fa0610cdc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6edc2b10-598a-4608-a4d2-b97112b18a3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff7364ae-5726-491b-a135-1ab67612dcfe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cdd5f53e-2235-42d7-803f-b05e3ca84cc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a17aa072-2621-4a01-8976-005d2e3ce83d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61ccd7a0-09aa-4d50-b0ed-d3586d796fd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6dd6df1-5052-40f1-af36-2751a7804031
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92246c99-f55e-4733-92ee-37843438bd61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26a550d0-06cd-46f0-8b33-439c0db7e84d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 434026ac-3fb6-469b-acce-0ffc61df6154
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3e6e6aa-4f88-435c-b5ef-9350fc74234e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd2e3363-1baa-4fe4-aaf9-11deb8881b48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4a4ff11-26b5-4fe3-a8c2-f29fe2d9df00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85c6015b-51cc-4ade-8807-913664626e03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a04caec5-dd06-457a-a9ef-7b926e2eb8fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63d88b0a-a2ef-4561-9bc6-142041731a99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4979362-7305-48b9-a6e4-6e60e1e9630d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 860d664e-5477-4881-a4bf-af1bcbe05c50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 529ed2a8-3615-48b3-96c3-dbeb7e0b3b03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09472ec9-1fcf-4e17-b61c-6f5b92e57f6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4b7f6b8-7c6b-460c-8fac-86299271e6f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35532851-0e3d-4207-a44c-944769bb2acc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7975bfe6-0cb1-4765-b38a-9562c2288824
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e45e514-6f3f-41d8-a1c3-c306bb7dc1a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cae3214d-c21c-490f-841c-1f63db129e82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3cb4130f-285e-45fa-a614-d99b76e6cd92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c6da3f2-5e09-4c63-a043-595423f7a891
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 974c744b-10e9-4501-a061-1d8b1a221aaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88d50f78-9def-4fe8-8d56-bbef1edeafdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8005d384-96c7-4a90-9e4e-7c4928cf363f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df328924-7e69-4795-8fac-3fa9726f90be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 255fdfba-27eb-4d66-95e0-50110b455e7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1dd249f-67f5-435f-ad7c-9ce369a2b305
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c932a93-294c-4559-af0e-b23b82fa541d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff8e31d5-7aa8-41a0-b185-65d9f4acc47e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f4c610b-7663-4425-b28c-cd1f2072b177
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf319aae-ee26-4bc4-995a-b4dddf6393aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd76993a-103a-4a49-ae0a-cab962fd0c4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43e40ed4-759b-40db-85ea-d6c4b0747b54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 053ceec0-812f-4ade-8b88-03f9a6e4168c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 388838cc-400c-4679-bfe2-1e0015b4ef79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 991d961e-89aa-4bf6-8bf6-8b86a9f37135
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5dc456a-cc81-48ca-95ac-8e88b6ad79e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e40e9af-3059-42ca-a886-007c5190e686
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e9f35d8-0d20-4a27-9515-a083e21402e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd2513d3-5265-420d-89cd-fb1732f05ab1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87d4cc4a-b6e5-4312-8676-d61833e792de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6dda21a2-daa2-4aba-9403-98c748ed24df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba1847d7-8de9-405b-ae05-fa9936506d84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d6cd80d-d8cd-42be-b301-b0fac2a850e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e9d35c9-f159-4649-aac3-ad71ddff76ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d373a00d-b895-4b0b-953e-75a5b550c7f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18714591-489b-4692-886f-20eeba688da1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93428b33-c60e-478e-aac6-932bb391978b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 461d4522-1ea7-484b-8c28-7c53b6931352
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae756f93-4678-4ac2-a890-53ef7519ddd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d117b640-05cf-47f8-9067-138d3c1d618d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3dc87d5b-ef9a-45ab-814c-a74709107e84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec8ef12b-f4aa-40d2-8399-81b7db62783b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c35040a-402e-469f-b56e-93795c6a7a9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a8fe14f-0651-464e-a726-93dfc9c45343
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23eee70a-f970-415d-8d1a-2acf6731ecdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d34f18f1-0997-4462-9c7c-6e5f1b6ffc7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9de66d08-cc83-484a-8a22-e3e2a15a57e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc90c19d-cc5a-480e-bdbf-bc355835d5ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 046bd699-d14e-4012-ab23-1dbb76a6bde1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33e66fbe-4002-4d3a-8535-0e71e1240e60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6632a80-9cad-4111-8787-6e8bb475ae7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb2e2305-d2c0-4b8a-893f-ed3275d110e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ca7a846-b7bb-464b-8747-2354955dcc16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db4f138b-17f4-432b-9617-9b89c1a23a27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd82893b-da96-4c45-a913-80ae7e0b6233
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8fff0be-6d89-4575-9328-f7092f709b6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eab29baf-835e-448e-adef-67ed339f7f63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25eaad29-2f39-4640-a3e7-41b25df95153
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b96ebfae-70b3-4929-9e73-cf4cae74ad1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e679fae-a441-4462-9d59-d54ce74f5e9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 364337af-815e-4cdf-84b2-f5162ad09313
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9c1eb84-56e2-4e1f-9f09-d053951eb2e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd9372ea-9a98-4370-bb1c-2e8f77fc071d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a038ea3c-8a79-4b29-ba6a-586410719073
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c037f85-94c7-4323-a4e2-af8abc611369
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dadd95fe-71b3-417b-ba32-32984c1800e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94d87564-bb01-4e94-ac84-a8797395cde5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2daacf78-e899-4aed-bef3-b499dee12acc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message beedd23a-f609-4fb0-8c6c-654d794b82b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ffd1e8d5-1c02-452d-9e6b-906d75815fcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7786a0f4-99da-40c1-b93d-bb3c7117801b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message faa8ad8f-ad67-4f6a-8f0d-aaba1f8e2337
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1284cc01-64ef-4847-8086-13ae2b296d28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c900c064-5172-4217-9dab-30ea8e3a3391
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b443372-1ebe-4b48-a331-5568990567c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cdea7a25-f6d3-4f65-baa5-d8521810023d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 340f074d-d2fb-46e4-8f73-c2c137567fea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb2cd4b7-0d61-46eb-ae3d-c0891e4b873a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0395e21-046c-4f42-a8fe-fa0b17c25351
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa395b8f-fa97-4f7f-bff4-e8a5d3d33fbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8c729e1-b91b-41fb-9890-b4dc4932ce5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 823bd780-f796-4674-ae8c-174045fc7caa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18ea2665-9cfb-42eb-8ffe-83b39b2cf221
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a49d5af-02a0-4b79-8402-69e84ab024fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10630788-6d98-4e31-991c-45d9edfcb3b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1714417f-2d73-4973-910e-c6dd8d68c3c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7942aed2-04f1-45aa-a214-c38233f195b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45e34069-2739-40d1-9ff6-a1b90a2748dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0bd5bb3-fc15-4ef1-96ab-3f5c1c456e30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df349312-4b07-43d4-a39b-f74696e2cd73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7aa5ea3-64d2-4c81-b948-cb5b6bf8dd7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 650ef9aa-d653-449a-aa92-ca4223afa33a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81d2bf6c-e34f-4dc7-a715-03d0f969e15a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c51eb7af-157a-4027-9cd9-d577f9811fa7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8bbe0bfa-5a45-49fe-a93e-a62bebb3ec27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be8b6adb-a8c0-4042-97b6-97d9ca8a5495
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f96bb9d4-54f5-4985-9354-2d4ed05e88fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6b1e06c-d771-4f6b-b609-89a499e521b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2987d9d3-6922-4aea-b385-b7c097bbd3c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6c17bcf-295f-464b-a66e-9bb8cc6fa2ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52edcf8d-88fe-42e9-89d1-e259cdc095bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c76f709-45ed-4272-bd45-52e8355dda40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e10f77c-f860-4d56-bdc1-3b5ec2709ee2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf1d079c-e8f3-4c1f-b547-70126fcc93a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08937530-996b-49d6-9c2a-8acef9c1904a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95d585ce-d35e-4b32-8086-b1a3117b104b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b260345-47d5-4eb1-8afe-8b99b186b41c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc93a4f6-8ca1-4efa-bb34-50141d30ffd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d8f403e-9955-4c76-8dfb-91385b60e682
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2595d580-29e6-42a1-9f17-ed020a2bb2ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a4a413d-9065-4e46-9b5a-7a0575a1d3e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e63ebe4-a7b6-4934-8714-58febda1b3a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb95838b-6c69-4d3a-aa66-4417ab99788f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a509bfc8-fe09-4c77-87c8-a0c0da7a2950
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a3ef7ee-3d14-49d8-a021-cbd7324e1579
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 164e443c-5f2b-4043-b47e-b03827a812a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a456c513-93fe-4c9f-aaae-427ad46d0887
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cee5adbf-1724-4ca5-920c-d4fa39aa1015
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aee9f5fb-ef36-40ae-bde2-9b04deb72716
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce546d3e-1848-4c7b-9104-bfc6bb694ecb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64e53a00-b6ea-48a0-b399-ac375f97807c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43d89acb-dfb7-4d94-a911-338cabce6b97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8300d001-2689-4ea7-be4c-ebf04fef8fc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4175a51-a732-421f-9676-28b43b899493
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d949261c-f5c7-4f81-a338-1977b845dd4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 087605a2-74cd-41f0-9cc8-803cc40c4bf6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dbc147f6-5a6f-49a4-929d-ce9c92f73aeb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55aa6a69-41a2-4c7f-b510-672ceed73ca3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05b0f63e-cbdf-4d6f-be74-6012107064ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 812b3fdb-8476-430c-aa7c-6fe3f518d0c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5633b0db-e693-4432-8778-79b719a250d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36b93187-34d4-457c-bef3-9e4b6741b74a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33129546-2c7c-46fa-8908-0eb3669091ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88f334d5-5f72-4aff-a89f-c2d656ebf6d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b623ce4-e809-4f56-bea0-39cf8195e845
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 282e5f4b-0122-40b4-989f-60bfa23aebc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac29ce78-623e-4934-8b77-fcc3c88de2c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1bf08be2-f4d4-4cf9-abbf-6fe194020507
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e3cedcd-d193-4a19-b930-1e191f91ca21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0dfc4c78-7230-44fb-b347-8ef168d881ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5967760-5847-4240-bdf7-23a1bc396bf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c145f40-22b1-4990-9d0d-08b88f553b89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 696ddac6-2196-47e4-8796-2832a629f774
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07c18e5a-7a34-48bc-bb08-c377af1b8cb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a0f9955-bde8-465c-ac07-5c73d9b63af2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ddd78d3c-2b4d-4225-b293-a8051132ca81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5164873e-fc4b-4151-bc1e-324f93cdc50a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c1da7f3-64f7-4e77-907c-488297b041fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bcdbeb9b-9722-4eb6-81d3-297caf2194ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8cf35d2e-bf57-4551-91e6-2a1d05235ee1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49615c16-2d27-42a6-b091-9d96bd3bcd47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 048ada87-17ee-4701-9bf3-0460f5caa551
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 988666b0-316c-4a5f-b300-29709918d09a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9584a5d1-1861-4d76-8f98-4cb8e6eff5c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b514a39a-8a9a-4f57-9037-9564243ab225
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf72a6a7-5669-4eb4-96c3-b50ea646c1ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef6099cc-89dd-44ab-a0ce-7fd936db967c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7bc3e8ab-f265-4d8b-bb4b-f50bf74f063e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c31fd86b-7149-4fab-a913-c2b55c463b0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a7e636e-96a3-405f-82e8-04ba9f9b9851
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d42579c2-bf7e-494f-83ca-4529cbb0b764
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26bd1c21-c234-4bf5-9e34-5f393666ebad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18abca0c-777b-46ab-bb46-016fbfdd9002
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38652dc5-c11b-42f1-a3d9-a1382f3fa9f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83de6851-aaac-41a3-b77a-0c091c95ba68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91130a43-3cdb-49c7-b84e-9130eddce9ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8697faf7-d7c1-460c-a108-1e1eea90edeb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2f0f794-8c76-4629-b58a-8912f592173e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 179077ef-2dc6-4558-aaf8-14f99d59fd5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1784cf4d-4391-49dd-b416-808401a18d80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a448a77-8a09-4c13-8a29-4ffb76d6f25a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6943969-a49c-4573-82a1-cd676df111ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f8d5569-44de-4088-a029-65b6a8a2258f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31925ac1-7fcd-49c0-bbfd-c88ccee69e1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e7e4a66-7556-4556-a7fa-23589bd4b472
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c51b5db8-c9a6-47f4-89c4-8a35ce1f010a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 479776ce-371e-4194-8fd8-3a8d311e0741
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa755caf-164f-4fe8-a542-db735e8dfe0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea798ef7-f20d-4164-b36a-2bcec8efe3e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f52e621f-0fe4-4e7d-b299-98bf20d65884
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6196fbf2-a97b-4271-ae71-3044238e3b66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9608d958-2a6e-4ab1-806d-f4b249325d71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b944494-c481-463f-8722-0055b3168a07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40763173-6cad-41af-852f-dcef58eea73e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b1b6010-dc51-457a-8e06-bd5072cda7f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8868314-bdd6-4846-9674-48d1651b7118
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11c6203c-de06-4143-a283-967cc88d6cf1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4735da6e-bdc4-40a5-820e-ecb24ee00953
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 149221e6-d26e-43ea-891d-e66bfa866c0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 821e1000-8117-484c-9a73-a6b48ba7da22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2181fd1-127f-446f-b628-03f081062f99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa03f3d1-8bb6-4882-a4f9-04cf528e9f00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 914e6a45-100b-425a-9516-eef2701c1eff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3824d934-348a-4a67-93ad-fe8323202906
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 636ab6d8-6317-47c4-b7b6-ddf02365c282
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message abc57fd0-bc1e-4210-ba0b-ae02431979ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 258391d4-883f-4c49-99f9-b63817af7936
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4238c599-85fd-4d3d-a880-2eedea067849
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27f145bf-d2ad-4054-8c9f-5f04761814df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7f4012a-9e70-4349-9f88-29a5d4e594ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message edcd65ea-67cd-4d73-91b2-edda30d4f9a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd012035-b6c4-4bfa-accd-90002a862060
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6188ec1f-01c5-444a-b660-63f10345af8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61fa594c-0683-4785-b0f5-b8176e87e90c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bfe7e4e9-5851-409c-98d4-e10ab13327da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26d0cc8c-b955-40c8-a563-e5fc474be7d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b5775bf-25bb-4073-8e66-2128d4ddda36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06888ddc-134e-4891-9fdc-30cea03507b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b48fb6a-e555-4b50-9013-229fd7fa39e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d86e28c-dfa3-4cda-badc-e63cba47d23e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0fd9ab97-2048-49df-9981-f5eca2c7fbd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 018569df-d7b9-4eef-8c29-94d483fef383
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 903900d7-d001-4bed-99cf-a05f1dc87e7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c8c687e-1e9f-445e-834c-ba574fb5d157
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb8c73fe-8f01-4c35-95ab-d063b9df75f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f98c8e8b-2c52-4461-82fb-aaa3eae47fd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98cc5776-9df9-4e1a-9005-2c8a3827cbeb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2aaa6df-5050-4350-810f-77b2fbfba344
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff7cd499-1a33-40d5-8140-e84d4760b484
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a00c18c-1c1d-4ffa-9377-69ed1776ce55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b43df6f9-7167-4e5c-8f15-4cd8d15294c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97196112-8a4b-4baa-9af8-de213115c08d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57e6c2ca-cde3-47f2-a5db-e5fef810cccc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1dd7dc26-e968-4fe9-bb4b-9d2167aeef77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f628a16-f717-4c01-8102-41db3dc75fb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9afe3a06-171b-45dc-b97f-d2af44ad4f66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5256dc7a-933c-4b4a-a46f-215743a17920
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e45513c4-acb8-4659-9b14-be83753e0ff5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5da220bb-8e29-4f01-a0bb-73166002cd84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92643b04-7a1a-4bb1-899a-cf17c628d225
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8dfcf609-1a34-4ee8-8f22-0ed745bf36c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b8543e2-45f8-4302-9719-8689848c2bcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46fb2d65-063e-4bd6-85bd-7b083982c123
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93b07001-d812-42fe-bbea-5caa9073c1c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1667f3d5-cfce-4edb-879b-37d91b058d0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ee6e6ab-585d-493c-99e5-914b2aa1648d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb521867-0d41-4560-ac1a-b9fbeb9a0e6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d026ad5-1b38-452c-ac91-dc4dea81e53c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b3f9491-b079-454a-97b0-ac2aeedc86ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eab76748-4052-4261-93c4-5c3b6fcfd1dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e825696-9015-4b43-8107-776dd86bb897
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62621caa-ca17-4266-afe1-440526cf11a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a253c99-d7d3-4ac1-8820-63d083d55612
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e5c47b5-56e5-4d03-ad82-9f14592dda36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f770dfe2-64aa-4ad1-b535-59a46e94227a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8cbf4284-0da9-4465-9533-5ba338ae7dc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27e28043-233a-483d-b1cc-3f188555fa8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79376825-7691-43ef-aaed-23f10f96bf6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f8566d9-910a-47dc-9979-961cc1d96082
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 589e9f94-3a8d-4b60-9ce6-59f67f1c1853
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd2992b0-fd8e-464f-81e4-fa4b66bf2627
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53cc78a6-892d-4624-a0da-1c5001ec05b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cff869b8-45f2-4b1a-bec1-4135ce02928c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9a7fff6-0034-43b6-a986-44135949b512
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message edadf44d-5e54-45f2-be56-d71b9232a30c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20087f81-cf1f-4237-baa1-f55470f43b93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4234fb5-72e8-449c-bc02-054b077c2e97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c1b65e5-3716-49f6-acfe-2ab529721adf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 724bc096-8937-460e-ad42-9b2c8071b343
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1a45e68-33b2-4d5d-a5d2-484c4630c388
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 507aef3a-69d3-4747-be8e-48fdbad447ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e53b8cfe-bc5f-49b0-81b4-fe7dee39599e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61accda8-d5a1-4cbd-8652-db7c8d4f30ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02307040-8e45-44dd-9d77-7c15c776398c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cab567db-308e-4377-a6dd-f9a5c7ffe1aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b58c25c-2423-4580-8a70-2cd5f5b6b0c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de69b969-bb39-4a63-a3a9-4518c08f99f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19db7427-c778-4e88-a553-28ee5210b513
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf6ec15d-d8ab-42e5-a20f-c729ac85f595
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d476945e-76df-409b-8890-07a52c7157fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a6c345f-7754-4cfa-86ab-ce4b3bcd5313
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4101fc40-9208-44f9-bd34-dfa0f38e3f83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e4539af-5201-439b-a99e-0fc9fdd32429
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76f0282f-756a-4fd3-9d75-ee6318b628ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec28a366-2f1f-476f-a2d8-94dad34dcb5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9fb3ee0-0588-459a-9f22-785ddcec602c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f051aa6-c483-447c-8b57-115a3168f37f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c65675e1-1d29-43bd-946d-0f255d260dff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25d1cd92-5039-4bf4-b465-e4cc9062ac77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e8f7bee-df7f-42fe-b392-35132c2ed4e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 728d1a29-ff0f-4897-a7d2-96a6ddb97fbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e30c8591-fffb-4637-8983-85b4b481b46a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 858c557c-6083-457e-9c24-d87102774736
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cbb1daf6-dc68-45c8-8e30-dc50bfdcb375
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6cf6215c-12f7-4e09-8f37-4c00d764bf55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54b12c36-511a-4768-83e1-3750280d98d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4138b9ab-6abe-4101-8d2a-62e93a5d0cba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message baee9d07-90e7-467e-8d27-d71172bd1bd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1534905d-6351-4988-905f-1e90b2c9b768
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a564a2b-d98d-4c1e-ad1d-3701b611b43c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f880f81a-ac89-4a10-875d-c48fc69f4bcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c40d3108-8f5d-4690-b731-4263dcff8df8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd184adf-f28a-4ee8-880f-5b2d1ec07498
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8fdf9579-55fe-4403-bf48-20040c041ec0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0777aff8-9eb0-4aa7-99a9-7bd7d2db41b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5712e8ad-fc6a-45ed-86f3-3a2b61fd940d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 545e958b-a556-4b4c-aa10-81acb4d78ddc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82645fe3-5406-4007-a9fb-1675c348a9c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 216d1101-dac2-4d2a-86bf-d440d6fd376d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2f76dd4-f5fd-4401-83be-7d1c917be3fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1127e3c-f1c5-4a27-86b9-c4efc13e97e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81955c34-245b-4be1-bec3-8e8ca30d7315
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f8abd5f-1446-4344-94bc-f7ec1ef9ac3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a162f2a-0061-4f07-abe7-9a0c8a34bbf5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae655d92-0256-4cbd-acf2-c4ba6cf5d70b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78001cc4-d9b3-4751-b1df-146d27d3015d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30ca51f8-1aeb-4d6a-a94e-862c2732f2f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f5cf937-58d3-4c21-8225-14ad2a17ce5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21f7f274-a9af-4b0e-bc0d-192bae91739e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4c0bc93-4a3c-43a5-bbff-176e08eb4747
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28400c50-b898-4649-9fdf-44b0f1e2d2b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 139c21c6-162e-4021-b510-14ab8e735bec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f026707b-9f98-4857-9e2b-390b0c8af5fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 796596af-e547-4a7c-91a9-7dce884b153d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1be4cc3d-0eb7-4c59-8120-90c7f14deef5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3f1574c-a1b5-400d-8778-47f70d9da17c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a820190c-0eae-40e8-8d9a-b51fa6873535
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f1bec11-f8f8-4cd0-a44c-b12b7ede676a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f7c04b6-fdc9-455f-9003-f2b4154694c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de7d606f-8b78-459f-8076-6b6340f22060
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5ade833-947a-482d-aea6-602b2688311c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c484dc5a-7155-4f40-9114-eab0126ed492
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4def6015-e916-4262-81be-59e705230f6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d69a1ee-99a6-47c4-b7bb-c1ff48576741
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd0082b5-a9f4-441f-9318-5e48cfece1f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35af7017-50aa-43bb-9bd9-efad040ff2db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95cb0161-6986-43a5-aed2-189b6b1e9847
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 559cc0a9-2e58-4bf9-b027-15f39b1d03f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a39b417-7a82-4d45-b488-1ab4cb765d66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33022f72-aefb-4afc-88c6-c943bb2fdb46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cabf32ae-9597-480a-9409-1ae85353139b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2353e638-39b0-4ac8-a58d-cebf4f8840f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d748906-d5bd-4f0f-8e20-6ca91ea82c63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c55e0e80-fdcb-4cb0-9790-0f21c8acb75a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42d2b9c5-8d29-4141-9478-f1e7a6a1597a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4391c1a6-f444-4308-8c63-4cf4a713a4e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05741d55-c862-434e-a54d-a03d5e96c3e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1fef5f3-f027-4dfa-836d-523405e0d2aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44807834-ba9b-4fcc-8be3-9054d82acb2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8012312-57bd-4860-9d4f-82ff8f7a98dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91dca9ad-9908-40d3-b627-89e98cb9c0b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message affc9934-db52-4377-a0d7-36257af37510
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c27d8b13-f58b-47b2-9a6d-639e7481fad9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3029821e-5660-4d54-b9b1-594fdaef6aca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfab5782-5363-4da5-8fc2-9b807a3a8952
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29cd05a7-c679-4933-9652-86d67408f2c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cbc055b4-6f89-49a4-9ba2-0ea12f5edbde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 016d53f9-f5fd-402f-882f-966c8fae543e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 529cc961-03aa-4c04-bcd4-2e65e8a173c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc7d7e47-84ea-49df-a6e6-366614c3cdbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 994a0c48-2aed-492e-996f-bf3b5ad9ca31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6674fe3-df64-4764-bd31-780f7a9623ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64e14fcf-4695-486b-a6c7-d40aca7e1185
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dcf5e758-dfe7-4b14-9883-d256536bc08b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 931cb47d-3be3-4d38-ab5b-d789da7df02d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb4ee473-89e3-4d5d-b0a3-5b654476e386
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce4cee91-13dc-4de9-9b27-51084d074f05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60c0e6a8-0573-4ee7-afba-42b4d894ebb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91642ef2-b22a-46ba-b6c3-3bdcef5f2557
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2dd2ac1d-f8a7-4ab1-b1a5-fb6c13e7d51d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d0dcd0e-58bb-42ac-9ba3-6d282e1ed206
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 737ee14b-dae8-4f0e-be16-321746296fc5
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8690 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_1
Server: localhost:8690
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_1
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_1/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_1/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_1/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_1/test_labels.txt

📊 Raw data loaded:
   Train: X=(6065, 24), y=(6065,)
   Test:  X=(1517, 24), y=(1517,)

⚠️  Limiting training data: 6065 → 800 samples
⚠️  Limiting test data: 1517 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_1 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2436, R²: -0.0010

📊 Round 0 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2435, R²: 0.0017

📊 Round 0 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2437, R²: 0.0002

============================================================
🔄 Round 5 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0894 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0871, val=0.0875 (↓), lr=0.001000
   ✓ Epoch   3/100: train=0.0851, val=0.0869 (↓), lr=0.001000
   • Epoch   4/100: train=0.0843, val=0.0869, patience=1/15, lr=0.001000
   • Epoch   5/100: train=0.0843, val=0.0870, patience=2/15, lr=0.001000
   📉 Epoch 9: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0817, val=0.0880, patience=8/15, lr=0.000500
   📉 Epoch 17: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 5 Summary - Client client_1
   Epochs: 18/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0073
   Val:   Loss=0.0869, RMSE=0.2949, R²=0.0011
============================================================


📊 Round 5 Test Metrics:
   Loss: 0.0810, RMSE: 0.2845, MAE: 0.2436, R²: -0.0002

📊 Round 5 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2436, R²: 0.0006

============================================================
🔄 Round 7 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0776 (↓), lr=0.000250
   • Epoch   2/100: train=0.0865, val=0.0776, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0863, val=0.0776, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0862, val=0.0776, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0860, val=0.0775, patience=4/15, lr=0.000250
   📉 Epoch 11: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0856, val=0.0776, patience=10/15, lr=0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 7 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000125 (1 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=0.0022
   Val:   Loss=0.0776, RMSE=0.2786, R²=-0.0064
============================================================


============================================================
🔄 Round 8 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0798 (↓), lr=0.000125
   • Epoch   2/100: train=0.0858, val=0.0798, patience=1/15, lr=0.000125
   📉 Epoch 3: LR reduced 0.000125 → 0.000063
   • Epoch   3/100: train=0.0858, val=0.0797, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0857, val=0.0797, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0857, val=0.0796, patience=4/15, lr=0.000063
   📉 Epoch 11: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0856, val=0.0794, patience=10/15, lr=0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 8 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000125 → 0.000031 (2 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=0.0006
   Val:   Loss=0.0798, RMSE=0.2825, R²=0.0018
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2438, R²: -0.0017

============================================================
🔄 Round 10 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0811 (↓), lr=0.000031
   • Epoch   2/100: train=0.0854, val=0.0813, patience=1/15, lr=0.000031
   📉 Epoch 3: LR reduced 0.000031 → 0.000016
   • Epoch   3/100: train=0.0853, val=0.0814, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0853, val=0.0815, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0853, val=0.0815, patience=4/15, lr=0.000016
   📉 Epoch 11: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0852, val=0.0816, patience=10/15, lr=0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 10 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000031 → 0.000008 (2 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=0.0009
   Val:   Loss=0.0811, RMSE=0.2849, R²=-0.0108
============================================================


============================================================
🔄 Round 11 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0914 (↓), lr=0.000008
   • Epoch   2/100: train=0.0831, val=0.0914, patience=1/15, lr=0.000008
   📉 Epoch 3: LR reduced 0.000008 → 0.000004
   • Epoch   3/100: train=0.0831, val=0.0914, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0831, val=0.0914, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0831, val=0.0914, patience=4/15, lr=0.000004
   📉 Epoch 11: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0831, val=0.0914, patience=10/15, lr=0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 11 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0001
   Val:   Loss=0.0914, RMSE=0.3023, R²=0.0020
============================================================


============================================================
🔄 Round 12 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0818 (↓), lr=0.000002
   • Epoch   2/100: train=0.0854, val=0.0818, patience=1/15, lr=0.000002
   📉 Epoch 3: LR reduced 0.000002 → 0.000001
   • Epoch   3/100: train=0.0854, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 12 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0009
   Val:   Loss=0.0818, RMSE=0.2861, R²=-0.0026
============================================================


============================================================
🔄 Round 13 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0939 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0939, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0939, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0939, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0939, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0939, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0939)

============================================================
📊 Round 13 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0006
   Val:   Loss=0.0939, RMSE=0.3064, R²=-0.0023
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2435, R²: 0.0014

📊 Round 13 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0009

============================================================
🔄 Round 16 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 16 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=0.0000
   Val:   Loss=0.0771, RMSE=0.2776, R²=0.0067
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.0809, RMSE: 0.2843, MAE: 0.2435, R²: 0.0012

============================================================
🔄 Round 18 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 18 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0017
   Val:   Loss=0.0855, RMSE=0.2923, R²=-0.0090
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

============================================================
🔄 Round 21 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 21 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=0.0015
   Val:   Loss=0.0764, RMSE=0.2764, R²=-0.0038
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

============================================================
🔄 Round 22 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 22 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0018
   Val:   Loss=0.0897, RMSE=0.2995, R²=0.0016
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

📊 Round 22 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

📊 Round 22 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

============================================================
🔄 Round 27 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 27 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0013
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0026
============================================================


============================================================
🔄 Round 29 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 29 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0016
   Val:   Loss=0.0836, RMSE=0.2892, R²=0.0026
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

============================================================
🔄 Round 30 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 30 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0022
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0000
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0006

============================================================
🔄 Round 32 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 32 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0009
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0020
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0006

============================================================
🔄 Round 33 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 33 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0021
   Val:   Loss=0.0890, RMSE=0.2983, R²=-0.0050
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0006

============================================================
🔄 Round 35 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 35 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0018
   Val:   Loss=0.0865, RMSE=0.2942, R²=0.0020
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0006

📊 Round 35 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0006

📊 Round 35 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2436, R²: 0.0006

============================================================
🔄 Round 38 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 38 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0022
   Val:   Loss=0.0819, RMSE=0.2863, R²=0.0001
============================================================


============================================================
🔄 Round 40 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 40 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0021
   Val:   Loss=0.0824, RMSE=0.2871, R²=0.0007
============================================================


============================================================
🔄 Round 42 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 42 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0018
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0017
============================================================


============================================================
🔄 Round 43 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 43 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=0.0003
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0024
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0006

============================================================
🔄 Round 44 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 44 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0007
   Val:   Loss=0.0850, RMSE=0.2915, R²=0.0014
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0006

📊 Round 44 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0006

============================================================
🔄 Round 48 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 48 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0024
   Val:   Loss=0.0896, RMSE=0.2994, R²=-0.0081
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0006

📊 Round 48 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0006

============================================================
🔄 Round 53 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 53 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2928, R²=0.0012
   Val:   Loss=0.0793, RMSE=0.2817, R²=-0.0016
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

============================================================
🔄 Round 54 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 54 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0020
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0177
============================================================


============================================================
🔄 Round 55 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 55 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0027
   Val:   Loss=0.0854, RMSE=0.2923, R²=-0.0188
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0006

📊 Round 55 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0006

============================================================
🔄 Round 59 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 59 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=0.0014
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0090
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0006

📊 Round 59 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0006

============================================================
🔄 Round 62 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 62 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=-0.0013
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0486
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0006

============================================================
🔄 Round 63 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 63 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0007
   Val:   Loss=0.0891, RMSE=0.2985, R²=0.0015
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0006

============================================================
🔄 Round 64 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 64 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0007
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0174
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2436, R²: 0.0006

📊 Round 64 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2436, R²: 0.0006

============================================================
🔄 Round 67 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 67 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=0.0013
   Val:   Loss=0.0785, RMSE=0.2801, R²=-0.0026
============================================================


============================================================
🔄 Round 69 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 69 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0013
   Val:   Loss=0.0811, RMSE=0.2847, R²=-0.0021
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2436, R²: 0.0006

============================================================
🔄 Round 71 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 71 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0019
   Val:   Loss=0.0838, RMSE=0.2894, R²=0.0014
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2436, R²: 0.0006

📊 Round 71 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0006

📊 Round 71 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0006

============================================================
🔄 Round 78 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 78 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0002
   Val:   Loss=0.0860, RMSE=0.2932, R²=-0.0276
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0006

📊 Round 78 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0006

📊 Round 78 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0006

============================================================
🔄 Round 81 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 81 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=0.0001
   Val:   Loss=0.0874, RMSE=0.2957, R²=0.0016
============================================================


============================================================
🔄 Round 82 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 82 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0013
   Val:   Loss=0.0881, RMSE=0.2968, R²=0.0039
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

============================================================
🔄 Round 83 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 83 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=0.0018
   Val:   Loss=0.0760, RMSE=0.2756, R²=-0.0078
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

============================================================
🔄 Round 84 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 84 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0036
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0073
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0006

📊 Round 84 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

📊 Round 84 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

============================================================
🔄 Round 88 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 88 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0001
   Val:   Loss=0.0842, RMSE=0.2902, R²=0.0089
============================================================


============================================================
🔄 Round 91 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 91 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0017
   Val:   Loss=0.0851, RMSE=0.2917, R²=0.0022
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0006

📊 Round 91 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0006

============================================================
🔄 Round 95 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 95 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=0.0025
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0018
============================================================


============================================================
🔄 Round 97 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 97 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0017
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0004
============================================================


============================================================
🔄 Round 98 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 98 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0000
   Val:   Loss=0.0905, RMSE=0.3009, R²=-0.0164
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0006

============================================================
🔄 Round 105 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 105 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0033
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0058
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0006

📊 Round 105 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0006

============================================================
🔄 Round 109 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0940 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0940, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0940, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0940, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0940, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0940, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0940)

============================================================
📊 Round 109 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0005
   Val:   Loss=0.0940, RMSE=0.3066, R²=-0.0023
============================================================


============================================================
🔄 Round 111 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 111 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0040
   Val:   Loss=0.0831, RMSE=0.2882, R²=-0.0072
============================================================


============================================================
🔄 Round 113 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 113 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0015
   Val:   Loss=0.0884, RMSE=0.2973, R²=-0.0115
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2436, R²: 0.0006

============================================================
🔄 Round 115 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 115 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0019
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0109
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2436, R²: 0.0005

============================================================
🔄 Round 117 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 117 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0007
   Val:   Loss=0.0852, RMSE=0.2919, R²=0.0028
============================================================


============================================================
🔄 Round 119 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 119 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0029
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0029
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2436, R²: 0.0005

📊 Round 119 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2436, R²: 0.0005

📊 Round 119 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2436, R²: 0.0006

============================================================
🔄 Round 122 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 122 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0018
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0141
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2436, R²: 0.0006

📊 Round 122 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2436, R²: 0.0006

============================================================
🔄 Round 125 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 125 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0024
   Val:   Loss=0.0842, RMSE=0.2903, R²=-0.0041
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2436, R²: 0.0006

============================================================
🔄 Round 127 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 127 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0024
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0082
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2436, R²: 0.0006

📊 Round 127 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2436, R²: 0.0006

📊 Round 127 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2436, R²: 0.0006

============================================================
🔄 Round 131 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 131 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0015
   Val:   Loss=0.0885, RMSE=0.2975, R²=-0.0033
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0006

============================================================
🔄 Round 133 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 133 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=0.0020
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0006
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0006

============================================================
🔄 Round 134 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 134 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0021
   Val:   Loss=0.0880, RMSE=0.2967, R²=-0.0026
============================================================


============================================================
🔄 Round 136 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 136 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0028
   Val:   Loss=0.0854, RMSE=0.2923, R²=-0.0035
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

📊 Round 136 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

============================================================
🔄 Round 142 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 142 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=0.0002
   Val:   Loss=0.0806, RMSE=0.2839, R²=0.0088
============================================================


============================================================
🔄 Round 144 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 144 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0032
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0053
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

============================================================
🔄 Round 146 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 146 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=0.0016
   Val:   Loss=0.0775, RMSE=0.2783, R²=0.0029
============================================================


============================================================
🔄 Round 148 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 148 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0021
   Val:   Loss=0.0891, RMSE=0.2985, R²=0.0000
============================================================


============================================================
🔄 Round 149 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 149 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0015
   Val:   Loss=0.0840, RMSE=0.2899, R²=0.0034
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0006

============================================================
🔄 Round 151 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 151 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2916, R²=0.0006
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0013
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0006

============================================================
🔄 Round 152 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 152 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0017
   Val:   Loss=0.0852, RMSE=0.2919, R²=0.0025
============================================================


============================================================
🔄 Round 157 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 157 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0016
   Val:   Loss=0.0889, RMSE=0.2982, R²=0.0027
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2436, R²: 0.0006

============================================================
🔄 Round 158 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 158 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0029
   Val:   Loss=0.0781, RMSE=0.2795, R²=-0.0215
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2436, R²: 0.0006

📊 Round 158 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2436, R²: 0.0006

============================================================
🔄 Round 161 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 161 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=0.0011
   Val:   Loss=0.0740, RMSE=0.2719, R²=0.0059
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2436, R²: 0.0006

============================================================
🔄 Round 162 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 162 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=0.0023
   Val:   Loss=0.0768, RMSE=0.2770, R²=-0.0037
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2436, R²: 0.0006

============================================================
🔄 Round 163 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 163 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0003
   Val:   Loss=0.0904, RMSE=0.3006, R²=-0.0019
============================================================


============================================================
🔄 Round 164 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 164 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0003
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0115
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2436, R²: 0.0006

============================================================
🔄 Round 166 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 166 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0027
   Val:   Loss=0.0838, RMSE=0.2894, R²=-0.0119
============================================================


============================================================
🔄 Round 168 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 168 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=0.0030
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0068
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2436, R²: 0.0006

============================================================
🔄 Round 171 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 171 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0023
   Val:   Loss=0.0826, RMSE=0.2874, R²=0.0003
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2436, R²: 0.0005

📊 Round 171 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2436, R²: 0.0005

============================================================
🔄 Round 175 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 175 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0003
   Val:   Loss=0.0886, RMSE=0.2977, R²=-0.0437
============================================================


============================================================
🔄 Round 177 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 177 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=0.0015
   Val:   Loss=0.0750, RMSE=0.2738, R²=-0.0043
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2436, R²: 0.0005

============================================================
🔄 Round 180 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 180 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0012
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0157
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2436, R²: 0.0006

============================================================
🔄 Round 182 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 182 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0006
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0068
============================================================


============================================================
🔄 Round 183 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 183 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0008
   Val:   Loss=0.0780, RMSE=0.2794, R²=0.0039
============================================================


============================================================
🔄 Round 184 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 184 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=0.0004
   Val:   Loss=0.0841, RMSE=0.2901, R²=-0.0153
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2436, R²: 0.0006

============================================================
🔄 Round 185 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 185 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=0.0004
   Val:   Loss=0.0794, RMSE=0.2817, R²=-0.0189
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0006

📊 Round 185 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0006

📊 Round 185 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0006

============================================================
🔄 Round 191 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 191 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=0.0029
   Val:   Loss=0.0754, RMSE=0.2745, R²=-0.0053
============================================================


📊 Round 191 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

============================================================
🔄 Round 193 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 193 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=0.0018
   Val:   Loss=0.0806, RMSE=0.2838, R²=0.0023
============================================================


============================================================
🔄 Round 196 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 196 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0015
   Val:   Loss=0.0859, RMSE=0.2932, R²=0.0035
============================================================


============================================================
🔄 Round 197 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 197 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0014
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0115
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

============================================================
🔄 Round 199 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 199 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0019
   Val:   Loss=0.0880, RMSE=0.2966, R²=0.0022
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

📊 Round 199 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

📊 Round 199 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

📊 Round 199 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

============================================================
🔄 Round 203 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0948 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0948, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0948, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0948, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0948, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0948, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0948)

============================================================
📊 Round 203 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0034
   Val:   Loss=0.0948, RMSE=0.3078, R²=-0.0040
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

📊 Round 203 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

============================================================
🔄 Round 205 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 205 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=0.0029
   Val:   Loss=0.0787, RMSE=0.2806, R²=-0.0031
============================================================


============================================================
🔄 Round 207 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 207 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0020
   Val:   Loss=0.0890, RMSE=0.2984, R²=0.0010
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

============================================================
🔄 Round 211 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 211 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0016
   Val:   Loss=0.0879, RMSE=0.2965, R²=0.0025
============================================================


📊 Round 211 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

📊 Round 211 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

============================================================
🔄 Round 215 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 215 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0045
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0090
============================================================


============================================================
🔄 Round 220 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 220 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=0.0028
   Val:   Loss=0.0767, RMSE=0.2770, R²=-0.0049
============================================================


============================================================
🔄 Round 221 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0932 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0932, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0932, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0932, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0932, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0932, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0932)

============================================================
📊 Round 221 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0010
   Val:   Loss=0.0932, RMSE=0.3052, R²=-0.0083
============================================================


📊 Round 221 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

============================================================
🔄 Round 223 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 223 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0000
   Val:   Loss=0.0799, RMSE=0.2826, R²=0.0088
============================================================


📊 Round 223 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

============================================================
🔄 Round 225 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 225 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0007
   Val:   Loss=0.0838, RMSE=0.2896, R²=-0.0134
============================================================


📊 Round 225 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

============================================================
🔄 Round 230 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 230 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=0.0021
   Val:   Loss=0.0772, RMSE=0.2779, R²=-0.0069
============================================================


============================================================
🔄 Round 231 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0938 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0938, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0938, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0938, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0938, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0938, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0938)

============================================================
📊 Round 231 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0016
   Val:   Loss=0.0938, RMSE=0.3062, R²=0.0005
============================================================


📊 Round 231 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

============================================================
🔄 Round 232 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 232 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0030
   Val:   Loss=0.0910, RMSE=0.3016, R²=-0.0143
============================================================


============================================================
🔄 Round 233 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 233 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0003
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0297
============================================================


============================================================
🔄 Round 235 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 235 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=0.0007
   Val:   Loss=0.0812, RMSE=0.2850, R²=0.0029
============================================================


============================================================
🔄 Round 236 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 236 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2916, R²=0.0025
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0006
============================================================


📊 Round 236 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

============================================================
🔄 Round 239 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 239 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0002
   Val:   Loss=0.0900, RMSE=0.3000, R²=-0.0527
============================================================


============================================================
🔄 Round 243 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 243 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0029
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0017
============================================================


============================================================
🔄 Round 244 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 244 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0004
   Val:   Loss=0.0854, RMSE=0.2922, R²=0.0047
============================================================


📊 Round 244 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0008

============================================================
🔄 Round 246 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 246 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0011
   Val:   Loss=0.0919, RMSE=0.3031, R²=0.0051
============================================================


============================================================
🔄 Round 247 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 247 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=0.0008
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0066
============================================================


============================================================
🔄 Round 249 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 249 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=0.0018
   Val:   Loss=0.0806, RMSE=0.2840, R²=-0.0123
============================================================


📊 Round 249 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

============================================================
🔄 Round 252 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 252 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0004
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0002
============================================================


📊 Round 252 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0008

============================================================
🔄 Round 253 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 253 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0016
   Val:   Loss=0.0891, RMSE=0.2985, R²=0.0030
============================================================


============================================================
🔄 Round 254 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 254 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=0.0004
   Val:   Loss=0.0834, RMSE=0.2888, R²=0.0026
============================================================


📊 Round 254 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0008

============================================================
🔄 Round 256 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 256 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=0.0001
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0049
============================================================


📊 Round 256 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0008

📊 Round 256 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0008

============================================================
🔄 Round 260 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 260 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=0.0021
   Val:   Loss=0.0761, RMSE=0.2758, R²=-0.0113
============================================================


📊 Round 260 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

============================================================
🔄 Round 261 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 261 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0029
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0094
============================================================


📊 Round 261 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

============================================================
🔄 Round 263 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 263 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=0.0006
   Val:   Loss=0.0833, RMSE=0.2886, R²=0.0066
============================================================


📊 Round 263 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

============================================================
🔄 Round 264 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 264 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=0.0017
   Val:   Loss=0.0830, RMSE=0.2881, R²=0.0008
============================================================


📊 Round 264 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

============================================================
🔄 Round 265 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 265 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=0.0020
   Val:   Loss=0.0777, RMSE=0.2788, R²=-0.0029
============================================================


📊 Round 265 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

📊 Round 265 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

============================================================
🔄 Round 268 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 268 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0010
   Val:   Loss=0.0844, RMSE=0.2904, R²=-0.0049
============================================================


============================================================
🔄 Round 270 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 270 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0025
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0024
============================================================


============================================================
🔄 Round 272 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 272 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0018
   Val:   Loss=0.0847, RMSE=0.2911, R²=0.0028
============================================================


📊 Round 272 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0008

============================================================
🔄 Round 273 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 273 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0017
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0012
============================================================


📊 Round 273 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0008

📊 Round 273 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0008

============================================================
🔄 Round 279 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 279 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0012
   Val:   Loss=0.0832, RMSE=0.2885, R²=0.0006
============================================================


📊 Round 279 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0008

============================================================
🔄 Round 283 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0929 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0929, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0929, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0929, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0929, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0930, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 283 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0025
   Val:   Loss=0.0929, RMSE=0.3048, R²=-0.0183
============================================================


============================================================
🔄 Round 284 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 284 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0018
   Val:   Loss=0.0862, RMSE=0.2935, R²=0.0022
============================================================


============================================================
🔄 Round 289 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 289 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0029
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0018
============================================================


📊 Round 289 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0008

============================================================
🔄 Round 291 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 291 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0018
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0066
============================================================


📊 Round 291 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0008

📊 Round 291 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0008

📊 Round 291 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0008

============================================================
🔄 Round 294 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 294 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0034
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0069
============================================================


📊 Round 294 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0008

============================================================
🔄 Round 298 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 298 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=0.0026
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0053
============================================================


📊 Round 298 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

📊 Round 298 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0008

============================================================
🔄 Round 302 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 302 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0015
   Val:   Loss=0.0826, RMSE=0.2874, R²=0.0021
============================================================


============================================================
🔄 Round 303 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 303 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0044
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0096
============================================================


============================================================
🔄 Round 306 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 306 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0009
   Val:   Loss=0.0912, RMSE=0.3020, R²=0.0058
============================================================


📊 Round 306 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0008

📊 Round 306 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0008

📊 Round 306 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

============================================================
🔄 Round 312 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 312 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0010
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0024
============================================================


============================================================
🔄 Round 313 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 313 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=0.0000
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0364
============================================================


============================================================
🔄 Round 314 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 314 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0001
   Val:   Loss=0.0857, RMSE=0.2927, R²=0.0098
============================================================


============================================================
🔄 Round 317 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 317 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=0.0023
   Val:   Loss=0.0730, RMSE=0.2702, R²=-0.0006
============================================================


============================================================
🔄 Round 319 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 319 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0018
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0185
============================================================


📊 Round 319 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0008

📊 Round 319 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0008

📊 Round 319 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0008

============================================================
🔄 Round 323 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 323 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0017
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0003
============================================================


📊 Round 323 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0008

📊 Round 323 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0008

📊 Round 323 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0008

============================================================
🔄 Round 331 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 331 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0040
   Val:   Loss=0.0906, RMSE=0.3009, R²=-0.0056
============================================================


📊 Round 331 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0008

📊 Round 331 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0008

============================================================
🔄 Round 335 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 335 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0019
   Val:   Loss=0.0781, RMSE=0.2794, R²=-0.0109
============================================================


📊 Round 335 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0008

📊 Round 335 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0008

============================================================
🔄 Round 337 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 337 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=0.0025
   Val:   Loss=0.0751, RMSE=0.2741, R²=-0.0007
============================================================


📊 Round 337 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

============================================================
🔄 Round 341 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 341 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=0.0005
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0082
============================================================


============================================================
🔄 Round 342 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 342 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0014
   Val:   Loss=0.0859, RMSE=0.2930, R²=0.0024
============================================================


============================================================
🔄 Round 343 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 343 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2916, R²=0.0007
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0008
============================================================


📊 Round 343 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

📊 Round 343 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

============================================================
🔄 Round 346 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 346 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0022
   Val:   Loss=0.0840, RMSE=0.2898, R²=0.0015
============================================================


📊 Round 346 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

============================================================
🔄 Round 348 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 348 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0019
   Val:   Loss=0.0918, RMSE=0.3030, R²=-0.0139
============================================================


📊 Round 348 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

📊 Round 348 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

============================================================
🔄 Round 350 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 350 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0006
   Val:   Loss=0.0853, RMSE=0.2920, R²=0.0058
============================================================


📊 Round 350 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

📊 Round 350 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

============================================================
🔄 Round 355 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 355 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0017
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0029
============================================================


📊 Round 355 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

============================================================
🔄 Round 357 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 357 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=0.0022
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0010
============================================================


📊 Round 357 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

============================================================
🔄 Round 358 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 358 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2892, R²=0.0008
   Val:   Loss=0.0876, RMSE=0.2961, R²=0.0043
============================================================


============================================================
🔄 Round 360 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 360 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0004
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0068
============================================================


📊 Round 360 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

============================================================
🔄 Round 361 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 361 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=0.0051
   Val:   Loss=0.0873, RMSE=0.2954, R²=-0.0114
============================================================


============================================================
🔄 Round 362 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 362 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0026
   Val:   Loss=0.0802, RMSE=0.2833, R²=-0.0015
============================================================


============================================================
🔄 Round 363 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 363 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0025
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0064
============================================================


📊 Round 363 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0006

📊 Round 363 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

============================================================
🔄 Round 366 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 366 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0005
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0069
============================================================


📊 Round 366 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

============================================================
🔄 Round 368 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 368 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=0.0004
   Val:   Loss=0.0771, RMSE=0.2777, R²=-0.0277
============================================================


📊 Round 368 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

============================================================
🔄 Round 371 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 371 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2904, R²=0.0027
   Val:   Loss=0.0849, RMSE=0.2913, R²=-0.0187
============================================================


📊 Round 371 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0006

============================================================
🔄 Round 373 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 373 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0007
   Val:   Loss=0.0769, RMSE=0.2772, R²=0.0049
============================================================


============================================================
🔄 Round 374 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 374 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=0.0014
   Val:   Loss=0.0770, RMSE=0.2775, R²=0.0048
============================================================


📊 Round 374 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0006

📊 Round 374 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

============================================================
🔄 Round 380 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 380 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0008
   Val:   Loss=0.0865, RMSE=0.2942, R²=0.0015
============================================================


📊 Round 380 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

============================================================
🔄 Round 382 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 382 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0013
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.0053
============================================================


📊 Round 382 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

============================================================
🔄 Round 384 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 384 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0024
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0032
============================================================


📊 Round 384 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

============================================================
🔄 Round 389 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 389 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0018
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0027
============================================================


📊 Round 389 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

📊 Round 389 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

============================================================
🔄 Round 392 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0942 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0942, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0942, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0942, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0942, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0942, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0942)

============================================================
📊 Round 392 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0008
   Val:   Loss=0.0942, RMSE=0.3070, R²=0.0048
============================================================


============================================================
🔄 Round 393 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0938 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0938, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0938, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0938, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0938, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0938, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0938)

============================================================
📊 Round 393 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0009
   Val:   Loss=0.0938, RMSE=0.3063, R²=-0.0023
============================================================


📊 Round 393 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

📊 Round 393 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

📊 Round 393 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

============================================================
🔄 Round 399 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 399 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0015
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0041
============================================================


📊 Round 399 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

📊 Round 399 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

📊 Round 399 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0008

📊 Round 399 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

============================================================
🔄 Round 403 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 403 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2954, R²=0.0027
   Val:   Loss=0.0733, RMSE=0.2707, R²=-0.0098
============================================================


============================================================
🔄 Round 407 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 407 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=0.0026
   Val:   Loss=0.0857, RMSE=0.2928, R²=-0.0011
============================================================


📊 Round 407 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

============================================================
🔄 Round 410 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 410 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=0.0019
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0016
============================================================


============================================================
🔄 Round 411 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 411 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0031
   Val:   Loss=0.0860, RMSE=0.2932, R²=-0.0038
============================================================


============================================================
🔄 Round 412 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 412 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0019
   Val:   Loss=0.0895, RMSE=0.2992, R²=-0.0054
============================================================


📊 Round 412 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0008

============================================================
🔄 Round 415 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 415 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2928, R²=0.0037
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0052
============================================================


📊 Round 415 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0008

📊 Round 415 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0008

📊 Round 415 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0008

============================================================
🔄 Round 421 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 421 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0020
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0018
============================================================


📊 Round 421 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0008

============================================================
🔄 Round 422 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 422 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=0.0033
   Val:   Loss=0.0743, RMSE=0.2726, R²=-0.0104
============================================================


============================================================
🔄 Round 423 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 423 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0003
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0082
============================================================


📊 Round 423 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0008

📊 Round 423 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0008

============================================================
🔄 Round 427 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 427 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0035
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0095
============================================================


============================================================
🔄 Round 428 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 428 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0018
   Val:   Loss=0.0862, RMSE=0.2936, R²=0.0029
============================================================


============================================================
🔄 Round 429 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 429 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=0.0017
   Val:   Loss=0.0766, RMSE=0.2767, R²=-0.0061
============================================================


============================================================
🔄 Round 430 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 430 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0041
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0067
============================================================


============================================================
🔄 Round 431 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 431 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0008
   Val:   Loss=0.0868, RMSE=0.2947, R²=0.0021
============================================================


============================================================
🔄 Round 432 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 432 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0024
   Val:   Loss=0.0888, RMSE=0.2979, R²=0.0006
============================================================


📊 Round 432 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0009

📊 Round 432 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0009

============================================================
🔄 Round 437 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 437 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0014
   Val:   Loss=0.0854, RMSE=0.2923, R²=-0.0216
============================================================


============================================================
🔄 Round 438 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 438 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0029
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0016
============================================================


📊 Round 438 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0009

============================================================
🔄 Round 439 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 439 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0016
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0031
============================================================


============================================================
🔄 Round 440 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 440 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0020
   Val:   Loss=0.0879, RMSE=0.2965, R²=-0.0035
============================================================


📊 Round 440 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0008

============================================================
🔄 Round 442 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 442 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0020
   Val:   Loss=0.0841, RMSE=0.2899, R²=-0.0187
============================================================


📊 Round 442 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0008

============================================================
🔄 Round 446 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 446 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0025
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0041
============================================================


============================================================
🔄 Round 448 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 448 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0002
   Val:   Loss=0.0827, RMSE=0.2875, R²=0.0093
============================================================


============================================================
🔄 Round 449 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 449 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0009
   Val:   Loss=0.0838, RMSE=0.2894, R²=0.0070
============================================================


📊 Round 449 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0008

📊 Round 449 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0008

📊 Round 449 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0008

============================================================
🔄 Round 453 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 453 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=0.0018
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0024
============================================================


📊 Round 453 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0008

============================================================
🔄 Round 456 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 456 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0018
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0002
============================================================


📊 Round 456 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0008

📊 Round 456 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0008

============================================================
🔄 Round 464 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 464 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0016
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0006
============================================================


📊 Round 464 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0008

============================================================
🔄 Round 466 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 466 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=0.0011
   Val:   Loss=0.0775, RMSE=0.2784, R²=0.0058
============================================================


============================================================
🔄 Round 468 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 468 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0002
   Val:   Loss=0.0855, RMSE=0.2924, R²=0.0061
============================================================


============================================================
🔄 Round 470 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 470 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0028
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0051
============================================================


📊 Round 470 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

============================================================
🔄 Round 472 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 472 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=0.0035
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0045
============================================================


📊 Round 472 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

============================================================
🔄 Round 474 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 474 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0047
   Val:   Loss=0.0903, RMSE=0.3004, R²=-0.0116
============================================================


============================================================
🔄 Round 475 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 475 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0024
   Val:   Loss=0.0779, RMSE=0.2792, R²=0.0004
============================================================


📊 Round 475 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

📊 Round 475 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

📊 Round 475 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

📊 Round 475 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

📊 Round 475 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

📊 Round 475 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

============================================================
🔄 Round 482 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 482 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=0.0014
   Val:   Loss=0.0758, RMSE=0.2752, R²=-0.0049
============================================================


============================================================
🔄 Round 483 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 483 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0021
   Val:   Loss=0.0802, RMSE=0.2833, R²=0.0018
============================================================


📊 Round 483 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

============================================================
🔄 Round 484 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 484 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=0.0026
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0023
============================================================


📊 Round 484 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

📊 Round 484 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

============================================================
🔄 Round 488 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 488 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0007
   Val:   Loss=0.0823, RMSE=0.2868, R²=0.0075
============================================================


📊 Round 488 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

📊 Round 488 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

📊 Round 488 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

📊 Round 488 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

📊 Round 488 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

============================================================
🔄 Round 495 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 495 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2903, R²=0.0039
   Val:   Loss=0.0853, RMSE=0.2920, R²=-0.0053
============================================================


📊 Round 495 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

============================================================
🔄 Round 496 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0961 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0961, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0961, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0961, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0961, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0961, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0961)

============================================================
📊 Round 496 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0044
   Val:   Loss=0.0961, RMSE=0.3100, R²=-0.0063
============================================================


============================================================
🔄 Round 497 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 497 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=0.0022
   Val:   Loss=0.0828, RMSE=0.2877, R²=0.0014
============================================================


============================================================
🔄 Round 499 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 499 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0012
   Val:   Loss=0.0780, RMSE=0.2794, R²=0.0022
============================================================


📊 Round 499 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

============================================================
🔄 Round 501 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 501 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=0.0031
   Val:   Loss=0.0734, RMSE=0.2709, R²=-0.0031
============================================================


📊 Round 501 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

============================================================
🔄 Round 503 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 503 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0011
   Val:   Loss=0.0815, RMSE=0.2854, R²=-0.0134
============================================================


============================================================
🔄 Round 504 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 504 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=0.0033
   Val:   Loss=0.0844, RMSE=0.2906, R²=-0.0029
============================================================


📊 Round 504 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

============================================================
🔄 Round 505 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 505 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=0.0008
   Val:   Loss=0.0797, RMSE=0.2824, R²=-0.0090
============================================================


============================================================
🔄 Round 506 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 506 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0012
   Val:   Loss=0.0898, RMSE=0.2997, R²=-0.0063
============================================================


============================================================
🔄 Round 508 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 508 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0024
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0006
============================================================


📊 Round 508 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0008

📊 Round 508 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0008

📊 Round 508 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0008

📊 Round 508 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0008

============================================================
🔄 Round 513 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 513 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=0.0027
   Val:   Loss=0.0777, RMSE=0.2787, R²=-0.0046
============================================================


📊 Round 513 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0008

============================================================
🔄 Round 516 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 516 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0018
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0205
============================================================


📊 Round 516 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0008

============================================================
🔄 Round 517 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 517 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0014
   Val:   Loss=0.0871, RMSE=0.2951, R²=0.0047
============================================================


============================================================
🔄 Round 519 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 519 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2904, R²=0.0028
   Val:   Loss=0.0848, RMSE=0.2913, R²=-0.0012
============================================================


📊 Round 519 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0008

============================================================
🔄 Round 520 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 520 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0018
   Val:   Loss=0.0889, RMSE=0.2981, R²=0.0028
============================================================


📊 Round 520 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0008

============================================================
🔄 Round 521 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 521 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0017
   Val:   Loss=0.0852, RMSE=0.2919, R²=0.0026
============================================================


============================================================
🔄 Round 525 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 525 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0010
   Val:   Loss=0.0851, RMSE=0.2918, R²=-0.0148
============================================================


📊 Round 525 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

============================================================
🔄 Round 526 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 526 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0038
   Val:   Loss=0.0895, RMSE=0.2991, R²=-0.0063
============================================================


📊 Round 526 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

============================================================
🔄 Round 530 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 530 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0016
   Val:   Loss=0.0870, RMSE=0.2950, R²=0.0019
============================================================


📊 Round 530 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

============================================================
🔄 Round 536 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 536 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0021
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0110
============================================================


📊 Round 536 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

============================================================
🔄 Round 539 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 539 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0007
   Val:   Loss=0.0779, RMSE=0.2791, R²=0.0068
============================================================


============================================================
🔄 Round 540 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 540 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2935, R²=0.0016
   Val:   Loss=0.0776, RMSE=0.2786, R²=0.0023
============================================================


📊 Round 540 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0008

============================================================
🔄 Round 541 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 541 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2944, R²=0.0015
   Val:   Loss=0.0757, RMSE=0.2751, R²=-0.0024
============================================================


============================================================
🔄 Round 543 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 543 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0004
   Val:   Loss=0.0850, RMSE=0.2915, R²=0.0076
============================================================


📊 Round 543 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

============================================================
🔄 Round 544 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 544 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0027
   Val:   Loss=0.0802, RMSE=0.2833, R²=-0.0006
============================================================


📊 Round 544 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

============================================================
🔄 Round 545 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 545 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=0.0024
   Val:   Loss=0.0759, RMSE=0.2755, R²=-0.0008
============================================================


📊 Round 545 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

============================================================
🔄 Round 546 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 546 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0001
   Val:   Loss=0.0910, RMSE=0.3017, R²=-0.0047
============================================================


📊 Round 546 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

📊 Round 546 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

============================================================
🔄 Round 548 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 548 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0019
   Val:   Loss=0.0839, RMSE=0.2896, R²=0.0019
============================================================


📊 Round 548 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

============================================================
🔄 Round 553 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 553 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0013
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0152
============================================================


📊 Round 553 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

📊 Round 553 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

📊 Round 553 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

📊 Round 553 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

📊 Round 553 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

============================================================
🔄 Round 561 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 561 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=0.0009
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0044
============================================================


============================================================
🔄 Round 562 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 562 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0015
   Val:   Loss=0.0839, RMSE=0.2897, R²=0.0037
============================================================


📊 Round 562 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

============================================================
🔄 Round 564 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 564 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0007
   Val:   Loss=0.0895, RMSE=0.2992, R²=0.0000
============================================================


📊 Round 564 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

📊 Round 564 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

📊 Round 564 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

📊 Round 564 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

📊 Round 564 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

📊 Round 564 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

============================================================
🔄 Round 573 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 573 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0035
   Val:   Loss=0.0884, RMSE=0.2973, R²=-0.0042
============================================================


📊 Round 573 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

============================================================
🔄 Round 574 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 574 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=0.0026
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0025
============================================================


📊 Round 574 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

============================================================
🔄 Round 575 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 575 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0003
   Val:   Loss=0.0838, RMSE=0.2896, R²=-0.0143
============================================================


📊 Round 575 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

============================================================
🔄 Round 577 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 577 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0021
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0011
============================================================


📊 Round 577 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

📊 Round 577 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

📊 Round 577 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

📊 Round 577 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

📊 Round 577 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

============================================================
🔄 Round 590 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 590 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0001
   Val:   Loss=0.0909, RMSE=0.3015, R²=0.0073
============================================================


📊 Round 590 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

============================================================
🔄 Round 592 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 592 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0013
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0024
============================================================


📊 Round 592 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

============================================================
🔄 Round 595 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 595 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0025
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0003
============================================================


📊 Round 595 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

============================================================
🔄 Round 596 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 596 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0019
   Val:   Loss=0.0863, RMSE=0.2939, R²=0.0021
============================================================


============================================================
🔄 Round 598 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 598 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0039
   Val:   Loss=0.0839, RMSE=0.2896, R²=-0.0094
============================================================


============================================================
🔄 Round 599 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 599 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=0.0016
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0036
============================================================


============================================================
🔄 Round 600 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 600 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0020
   Val:   Loss=0.0900, RMSE=0.3000, R²=-0.0031
============================================================


📊 Round 600 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2436, R²: 0.0007

📊 Round 600 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2435, R²: 0.0007

============================================================
🔄 Round 604 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 604 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0032
   Val:   Loss=0.0879, RMSE=0.2966, R²=-0.0026
============================================================


============================================================
🔄 Round 607 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 607 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0007
   Val:   Loss=0.0864, RMSE=0.2939, R²=0.0023
============================================================


============================================================
🔄 Round 612 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 612 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=0.0015
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0011
============================================================


============================================================
🔄 Round 613 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 613 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=0.0001
   Val:   Loss=0.0860, RMSE=0.2933, R²=0.0037
============================================================


============================================================
🔄 Round 614 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 614 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0007
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0049
============================================================


📊 Round 614 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2436, R²: 0.0006

📊 Round 614 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2436, R²: 0.0006

============================================================
🔄 Round 619 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 619 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=0.0016
   Val:   Loss=0.0844, RMSE=0.2906, R²=0.0014
============================================================


📊 Round 619 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2436, R²: 0.0005

📊 Round 619 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2436, R²: 0.0005

============================================================
🔄 Round 622 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 622 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=0.0021
   Val:   Loss=0.0788, RMSE=0.2806, R²=-0.0056
============================================================


============================================================
🔄 Round 623 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 623 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0042
   Val:   Loss=0.0902, RMSE=0.3003, R²=-0.0057
============================================================


📊 Round 623 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2436, R²: 0.0005

📊 Round 623 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2436, R²: 0.0005

📊 Round 623 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2436, R²: 0.0005

============================================================
🔄 Round 628 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 628 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0003
   Val:   Loss=0.0909, RMSE=0.3015, R²=0.0043
============================================================


============================================================
🔄 Round 629 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 629 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=0.0027
   Val:   Loss=0.0873, RMSE=0.2954, R²=-0.0130
============================================================


============================================================
🔄 Round 631 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 631 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0003
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0023
============================================================


============================================================
🔄 Round 634 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 634 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0015
   Val:   Loss=0.0898, RMSE=0.2997, R²=0.0043
============================================================


============================================================
🔄 Round 635 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 635 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2935, R²=0.0020
   Val:   Loss=0.0776, RMSE=0.2785, R²=0.0004
============================================================


📊 Round 635 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2436, R²: 0.0005

📊 Round 635 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2436, R²: 0.0005

============================================================
🔄 Round 637 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 637 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=0.0016
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0046
============================================================


============================================================
🔄 Round 638 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 638 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=0.0006
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0083
============================================================


📊 Round 638 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2436, R²: 0.0006

📊 Round 638 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2436, R²: 0.0005

📊 Round 638 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2436, R²: 0.0005

============================================================
🔄 Round 644 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 644 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0027
   Val:   Loss=0.0910, RMSE=0.3016, R²=-0.0100
============================================================


📊 Round 644 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2436, R²: 0.0006

============================================================
🔄 Round 647 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 647 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0008
   Val:   Loss=0.0869, RMSE=0.2948, R²=0.0028
============================================================


📊 Round 647 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2436, R²: 0.0006

============================================================
🔄 Round 651 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 651 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0023
   Val:   Loss=0.0868, RMSE=0.2947, R²=-0.0011
============================================================


📊 Round 651 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2436, R²: 0.0006

============================================================
🔄 Round 653 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 653 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0038
   Val:   Loss=0.0863, RMSE=0.2937, R²=-0.0047
============================================================


📊 Round 653 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2436, R²: 0.0005

📊 Round 653 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2436, R²: 0.0006

📊 Round 653 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2436, R²: 0.0006

📊 Round 653 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2436, R²: 0.0006

📊 Round 653 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2436, R²: 0.0006

============================================================
🔄 Round 662 - Client client_1
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 662 Summary - Client client_1
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0005
   Val:   Loss=0.0854, RMSE=0.2922, R²=0.0038
============================================================


❌ Client client_1 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8690 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8690 {grpc_status:14, grpc_message:"Socket closed"}"
>
