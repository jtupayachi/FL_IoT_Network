[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 140f3b18-a595-4619-8345-90d58804a114
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f89e28e9-f570-4a1e-a4c1-df5cc94894f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11220f4e-0c85-4ea6-a923-9d9883488263
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d08867bc-4622-42ec-842f-99372da3ef09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e559364c-4e1c-4e6f-81e1-9e4be846b331
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28e81def-e4d5-448e-b92c-55bf2d58b97c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81d9eb85-cb0d-41ea-9a1f-52efb9a8c69b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 221d8fa8-678c-40bd-adfe-645983316e0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7194d83-5529-4d9a-9f9a-542e50ca3039
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70457246-54fd-444d-a89f-f0302c995425
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b758e46-79fa-4cd3-85af-1d75a1f515b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6eb4e28d-99e9-42da-a388-487c6cefffef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 575087e6-a9cf-4cfb-9616-2047091c89e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cfc4ab06-8b51-406d-8666-1f52df00eda7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6aa77322-61f5-4b9a-b931-b508e2c8dae4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ced69804-e20d-4653-b5ad-3445a651eb08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f7800e7-491b-40fb-8b28-4537db5dc637
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41513295-1e37-4ab3-854b-bc9d4407df2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a1f139d-e0b2-4c83-b3fc-eb5ab64d0880
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5dc0723-5795-4660-8fef-a6f42f1cf3d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae2d57d6-35e5-4fdf-b7ab-e638c772a222
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0fbe4c1-ad3f-4b99-8251-43f7903863ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75b38465-4903-4d96-9c35-f0155141d804
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc1128e0-e6b8-49ed-a6c9-277e07782da6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 008b6bba-78d6-4a7a-82b0-b0bbf817e617
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98d6ee8c-bb24-41c5-ab4f-c8554226860f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f4fd936-718c-4f7d-8bd5-513ef2267dec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 706bad8f-68a3-4cb9-9985-e08fb8985916
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee94de80-01d0-4711-bb4e-d731b36345aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 181a6118-79f2-40de-be4a-3d1899be5065
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15140ca8-b751-4f80-bc5f-b29c66785fef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68ade57f-7335-42e5-a1eb-b31615e36f9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4671512-8d3b-4a67-b38b-b1d675a54e76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee24183e-a2a2-475a-ad33-1361badf6e96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ebdc61f5-35cb-4c96-8850-142d4ebd51a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52b43a6f-bf7b-4703-96ba-e288844618a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7403d9f1-c31b-439f-a375-2e1e16c3e9d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76386219-f521-4ba9-a790-24e1b576a61a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 549b7d57-d1d9-4098-975e-002dbce8e189
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11a1ce91-51d8-41ee-92ac-2354f7b20b05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3cf6aea7-1713-43b0-b770-9a30de9028cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b16ca6dd-4028-4393-937c-c4fd3f5f027c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2389038-ec1e-4646-b29d-1594d44b09a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98f4d51e-e8c7-4c5b-9559-f23cf7e31962
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eae0a5a5-d1aa-40e1-a634-4b7eed3edc12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec08c328-d2ad-470b-8f2e-bac56dc3d982
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00c5a921-a10b-4303-a8ab-9fc1567fa35d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a61ccad1-3e2d-48b4-b7fe-5676c5704f3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b27b12a8-f57f-4a2c-ad60-814e6946472b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92e8b7f4-98d1-451c-8f4f-0e58d602bb46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f408b4df-fd06-4b0d-957f-5e3198f89f81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26a6ca8b-be77-42cc-84f7-98898d7e205f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4692188a-df18-4e8b-8563-12c5a3ffbce6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83d5b2fa-e26f-4a38-959e-6102a33aa88d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27c1dbed-0db3-49f9-b4cf-bbb89d765da2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a25e3ee-c88e-45b9-bd18-66197d6e9964
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2eb9d2c7-29a7-4068-a878-b84871baffeb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a11fba5c-c179-4de6-a1ac-070c3fdd8cff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf81e31f-1c2f-4338-add2-a4e418f1b23c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a20d43b6-bee3-449c-b415-40a58c0dd94d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b1d2ef9-5f28-444c-a389-437d6acee751
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9397c35-570f-4618-9258-875c36203c8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f150057-157b-490f-b160-3d2e4acece5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3431045a-1c9b-4f7c-a5f8-eaddbceaaacf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74f9a26b-055b-4f36-bb62-6ce5e5b29d48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18a95764-9dca-457e-afde-81c77bfd9512
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ad1eb30-a206-4fd7-b9fb-bce1ed252d90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4422c6ee-a5c9-4b43-bb1b-89188bc51f63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3705716-e7f7-481d-bbee-77d455a4fa89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ceccb44-f270-4c34-a750-df1f949dba73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9777f36-9c93-4560-bff5-d83442f9c7b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35343c6a-d587-4e94-9921-df259751d28b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a20317a-d3bd-4d9a-a029-e8d12f056e37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e48cd016-9a5b-4118-8863-e80891957830
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41811877-111d-4cd4-8af8-22471e93d98e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ebf410c-d633-4967-9a4c-404778c18d38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41c57f5d-5565-42ca-8fd3-8c909e736483
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3153c45-2550-4784-b054-37cbeb485c31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1fe7200-f6d9-4b5d-9136-5801596c22c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0da05ddb-74ac-4bd8-9934-03ddcab0038c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1994863-f57b-4d15-b179-102c08e75edc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7e65911-b42c-445e-b705-6a3e6c95aeb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12764f58-c947-486b-acff-87de28e2940e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dad8a163-5a0f-4494-9a84-4563b5076b47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0d89cc5-4796-4ebe-90ac-5506b13523ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96336eef-0929-470e-ac8b-fd227343c492
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49211e09-d898-4dcc-8ab7-399189707d86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e6789a4-2b3e-4775-bdd6-2d9ea1648bb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3bb113f2-750d-4775-9c80-4a987c3a5edf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a129f0ba-666f-4701-a045-3de02e39649f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0f3c2da-9dd1-4c12-bd6d-1ab95eb793e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54ed86ee-45d5-4525-883f-6ca4507dc989
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2faa2f6-4c7c-46ab-99f4-a5af9c1fcb43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b43927b5-0351-4a4c-9109-a3622c89d847
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ce81379-af85-46c3-a483-3239c241f5ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3748a55-baf9-4182-9f56-da0e3f45bb0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9975cac6-9eda-4dd7-9ce2-5c579322f525
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34dd3d93-89c2-4f15-b605-8555130184db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06897302-b559-4844-918d-58f73e7f2a36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1ecbe4e-3b40-4b17-9e9d-d4d215d2db62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 838dcf23-f380-4292-a387-39c871183282
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d9bb3ef-a40b-4f61-80c8-c0e087b98219
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e83c099-ef8f-4cdb-b813-db7a2f0ef62b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6817a0d-42c7-446e-9823-47f4e0cadf2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e2d8bc5-78d4-4426-b65e-34fa206a67a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0203825a-d5d3-45e6-b42b-f7aa80919749
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe0116ce-5e04-4faa-8cb1-d8736dc757c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message caf8d69d-f38c-424b-bdd5-a57300ea2fa6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2984b213-42ef-49ab-9580-3a328945ae89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10de464d-cb7f-41fc-b17a-5552674bfe21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06f77306-0e22-4b00-9801-1b32bf948c31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 291e6cb0-7de3-419b-beed-9e87caba3eb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 090acae3-5280-4c3d-bc88-3db89b54147d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4770c95-32d3-4ce5-b91f-6b240e26aa65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ee35fe0-4e66-448c-8cec-70858292349c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc969ff8-6aed-407b-9024-e68462de7c81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66d1ba8c-add7-481f-a42d-ab69abca5b45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82843883-3a03-4740-b275-0d752e6ab6c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30a45e92-b1d6-4902-8d03-e63eb176389c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b731ad49-8678-4661-96a4-10a87bfdf62e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66064ca2-8dbe-4283-9c17-a9e2ee29fbe7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30eaf718-54eb-4497-b2ca-647557b8627c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 878c1fc1-606a-45bb-9f53-a560f7758362
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5b4c3cb-adc0-4eca-96d4-84322b9c8f33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ac4d072-fc27-4267-a994-a1b8029d5223
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb43dcf0-efb4-4bed-991b-b0db9e834f55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42f1b29a-9b12-44fc-81f5-9d62ae1d8257
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68f7743b-1052-4152-aaae-71d2a9704c16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3205066a-8c13-47a8-918b-48758871ae40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e90977e6-c7e5-4f2d-91ac-78c47e585d10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b38a89c-1fdf-4019-b83d-8ae0797a14da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea29310e-a7a8-4519-ae74-d770eb2abf2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77a84eee-e5d4-456a-9927-bd8f58b48003
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9dd7ffef-e345-4cd9-9a9d-7a7851570c5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47227e2c-e30d-450e-9dc7-0889fdd28919
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e478bbc-79ee-499b-a201-8379173e71d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03bd8836-5cad-412e-9572-71da69f26ce4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e87a89e-9d3e-4042-b0af-28770e9bbddb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99f19152-e1fb-4145-ac93-695e394198ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6c4036a-d17a-4a97-9308-dcade4f91092
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message defd2598-32b1-4885-932f-065a33b048e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1250261d-1162-4916-88ed-d9b96ef35cf0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50955be2-d360-48d4-a65e-eda6a70a1333
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1387ffd4-53ff-483f-ad6a-56e28de33848
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2ca3090-aeda-44c4-9710-bb89c1e27f73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09da7c8b-54e2-4710-b319-24fd99c10462
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d49bc2a-83cf-4694-b41f-e48fb4486fd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae645943-b294-4ae6-9141-777e14641c85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c45d09eb-9290-4f49-ab5d-671c9895d2f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eda9da98-a0df-4634-bb0b-a88de1cf8a50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 560bc042-94a1-45ec-b8ef-e4b20babe347
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f445ae3-e3e3-495f-93ad-eda922d4708b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3993a8ca-c12f-495c-9c1f-da1db12dc94a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 050d0258-ec2b-43d2-9e10-3d22a165ed60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f59be979-dc78-40ea-aefc-2f98288b5e65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e2f96cb-8669-4c1a-b256-fa4a12625573
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85b07804-df3c-4d69-b099-ec3e1f2fb5cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46a13b32-958f-497e-b157-4e9e8f01c802
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b889d5d-121a-4162-965e-662ee47dd60e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32cbb59c-0fe9-4392-82c2-deefd89b9862
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bda5733f-8ad4-446f-af15-565d2237e159
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dee57b74-4390-4eb0-b58a-01d19e31105b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a08e5f4-adf7-4568-a605-504ffdd47f28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d846d008-4092-45bf-9dc3-43c5a827a6b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 456afc61-a750-4037-ad18-cd1216c9d956
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69e1a41d-d19e-4764-80a7-98f10811c0a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31a7cce8-2779-4f14-8499-77cfbe9aa933
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4dc19c2c-0f11-49c8-b43f-a8084cb203aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80821532-3616-48d1-baac-52dee01a492e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0dfecf44-01c7-4b18-99d5-944202efb7b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e65ca4e4-2449-4617-a349-43f811c92e4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ddba7408-0af2-4b15-bb04-4d7f76129696
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 169398aa-66da-4171-b64a-d4591f83dd2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09fcfb79-ec26-45d2-b96d-d6942793c1ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31399123-24ba-4fd6-8cd0-68a826bcab54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f73a39c-1aaf-458c-855f-7b23b08ab3ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 666b4e69-5b6d-4c24-b7f1-9d9f2d8ff5b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f4896c6-b6d7-44ec-8ccc-732dc129068e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64ffeb2d-7b28-4e33-83ba-33871ecddf98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5487a377-7e96-4a76-b08e-0c4d2817a68e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7869206-7522-4ecf-9dc4-65c22385369b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0df8244c-6a63-483d-8567-f2797ad4de92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66d694e7-2f55-45b7-af9d-dca9c2455684
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b34fe57b-81a7-4567-a147-93d829b1bc07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14e85977-3465-4326-a886-08451965e041
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 174bc7c5-760a-4657-a396-5f8f4f44fb8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30b79b72-d2dd-4333-868d-a9071397277f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 834b9294-847d-4aa1-818f-0ab427ae7873
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aae581d4-560b-4e80-98b0-15ccf0764153
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4baaff1-4285-4438-a3e2-da3b6eeb6cd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c98212c-cd56-4454-b4a9-18225b7908e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b530a3d-695c-43d7-a495-1d95b7e68ef1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e047f80f-e43d-4b6b-b68c-aae02c9d1f66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16f6c2c1-b4b5-4336-928c-b5286739178a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d12b6fc1-175b-4d7e-b743-9280a2089ef2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93a06508-37d7-41f9-9151-fe36193866a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b48e6ff-268f-41ab-b993-09929a5cd1f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfcbc481-5ab8-405a-9095-b6fb7afd3b86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85f0804e-9ec1-492f-8e91-a7aa3080e904
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50a03fbc-7e15-4a38-9313-e8aa9d2648fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ab68ed3-fd75-4002-abcb-5f8c469cbfd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e7bcf8e-a17f-4a62-9376-8c0b4ad03e14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6dadb1c7-3695-4d06-b6b4-a7d921629f73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7fad625e-5945-4a94-8913-95b9c5cf4308
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a84d7a17-04a9-438f-a53d-2a80a91d6494
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3588f726-9c76-4f9c-825b-89b060e4d9b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42a54f3e-ebf3-450d-a518-7e0b220b0ce2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54c68e0d-87a5-42ec-9a98-3518cab689db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b6f467a-7e16-458f-8944-17d50187510c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7343fa5f-7bec-4245-8170-6350c2fa2ead
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message acbf84ff-1760-4733-8f1c-178ceefa267f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 526e87e0-5bfd-4d19-a758-7ab4e98bb6ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 165c1437-23a9-4ca2-a5ec-73911a2cec3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36b65b49-7ced-497a-95b4-1f46e0935fb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0eff6cc-f8b3-422f-9e7e-c300b5abe077
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 373ed6fc-3022-4d89-bc6e-0baac18cb58f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f53131e-fe96-4c87-8654-9dbc77f663a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b41ad4ee-1434-4e79-9233-d4bcd52a8317
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca0c2c45-c72c-4c1e-9e6c-8de76f80eafa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1925f3eb-e042-4eae-b0c3-1e4b7cc5b50c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4314ce44-3514-41e6-bd97-f85ce0fe6ca8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 910a94bb-f046-4a18-bd27-3d2948d17df9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf45706c-c18b-4968-8fcb-599f34c14f14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 392876ff-db5a-4607-8853-97ea74bd47dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8ded725-b407-46a6-bdda-545c6a5acb43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94faee36-259d-45eb-90f0-d1fd51d3d9d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d951d4d-7318-488f-b94a-5a482f676f40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3802af6b-eb6c-481c-afc8-ae3f8d7fa516
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41fc5fd4-652a-4ec3-88dd-b537e9cb5033
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9a2b0e8-ac71-4a38-865c-86fb4f0e394e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f0269cd-a58f-497f-b597-97cc5c6ed6c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28a0f9b4-eab9-4b27-a32c-4579a6ff6244
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message afd85f9d-f9b3-403b-9615-0675e8f2a75f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb4c87e7-851b-4e96-b000-fae09e06f5a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9d4ca41-6bc4-41ac-a755-5bad07610a2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6af5d9d-8236-401a-ba70-26d7b3fc5412
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 585b6930-1cfb-4993-97b5-4838d79d6a7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9876b886-bb87-406b-924c-35735626eb47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12d663e6-9931-415e-95b7-4a6cbaefc16e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7eb6ab1-b670-4cdc-8aee-5bd1f1efe983
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 626a71f7-1125-41e8-896d-1b8607bf8f16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f2789d5-4bc5-4ee2-8fe7-2f7c91629293
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a389da54-8b85-4d2f-afd1-8447eaa40981
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c1f1754-7f86-46c9-a090-d2072b9b47b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b58d488-9e20-4efa-a317-b1a9889e64c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 287c4aea-3143-4b14-830d-419f88388c59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b13139f-4754-44e6-9826-8708c5e9b048
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0da6a13e-378e-4856-bcec-727620eb80ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3796937f-a09c-472b-9403-3a66a218a2e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0f59893-d4ca-4af5-ade2-bbc99f487cc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b74ecd9-a868-4b0f-b4d4-14aa9b063b79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06f88f8d-1b25-40a9-bfd6-5286d612d9ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a4f5f2b-5ba0-4f17-a56f-8e27d4db1d47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7240a886-9cd0-424b-b791-b90f7df312c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a4d4ab8-9495-4b32-a3c0-73382538640a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d79f62e-bf01-4924-9e57-2b57c57b2849
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message baf6ff2b-ee5a-4231-ab69-5d0d1b52d263
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c8c3060-22a1-4d66-9985-0ec659b1dbcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e0e7fb9-5555-4517-9d1f-5a0ddab87165
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32174b46-53c3-47b0-8df3-095a6cdaf6b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11cb40b8-ed88-4d96-b000-f430e0921a0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 465ce189-5c8c-4b95-88fd-72c0a9ac7e22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89b1d346-e414-4799-8ad2-9fead37704ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37eaef08-829b-4d53-b9f0-d8817fc8aa79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d43620f-d924-4d51-ac51-24324c64661e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6cb3ebef-ad5b-416a-8fa2-3510db9eec9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 318f4202-08b3-4ba1-b3ed-e983523e85cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4f86895-be9e-44f5-8bf0-fce75f613c78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1125d1e4-12a5-4ce4-b470-ad6c10ee2a21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d406aded-d7ed-421e-a1c1-0595ddbc97ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dce6e971-4aee-4590-8411-5a8422013bb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8b9885d-816a-4f90-bd1d-5e18d084e0f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 024bf092-9338-4454-9eea-3d2d70169b30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c521168c-11d7-492f-98dc-c51148d8cbd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1eaf21f2-e682-41a7-8bfa-55d299a6ca93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12dbfce9-a16a-43d3-a477-b33c9327e257
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c17cf3a9-118e-4ce8-8f87-19de64dd8a6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6975b392-4775-4747-bd97-b8a61d64b5d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3b6c876-bc65-4136-a943-16777e6c6961
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9319e34a-fb68-4b63-b05b-33dd6c7ef141
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0188d74-8a13-4823-900a-f26b3dbc11aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b9bfe14-ea71-405d-a6eb-356c8e12e96b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b57d429c-4833-405e-9d48-b809b5edaac7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1746e7b-18bb-44b0-8e09-597b8527d101
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14055e58-3080-4aea-a914-2a21df4b5020
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61e49cff-ea29-4a07-b486-6d0550dc6621
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84545e2e-7a10-4318-8ec8-cf79545ee180
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3cee732-9b4b-4bca-9bec-1b42d4afe4cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c1b5d8a-6616-46fc-a042-2ffefaabe814
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df17d34c-a15a-4a75-ad19-1ba93f918b18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13773b69-0e25-432b-ba65-4cf929c3841a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6e274f4-08c3-4853-b9df-59a326e24227
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5fb57194-55e4-4848-86cf-72af3e5275fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0482a34-1784-4a99-b049-007b16c48495
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9a8df11-1ba8-4fd4-b22b-5db82f151f26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86d6b193-be60-492d-a240-8cb6353edb0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19316645-a9ef-49f8-b32c-bf5e282ab6fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e101db49-509a-420f-9b1a-dfc22c68caac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 857b99f5-98c7-4cc7-b3a3-60adebedfb9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4edd60b2-4736-4aaf-9059-f37bda04362d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e6cb4ef-e03f-4a7a-baea-5675b79db9a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9662a07d-b996-4415-a38c-9092359b0487
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1fc3ad62-2723-4df8-ba65-25bc2e65e5be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5212ce2b-47c8-44da-b965-ddff2aeae2d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8644445f-dd2c-4483-9c3f-8fb82d76e94a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc6ac678-315c-4f19-9d51-148472cf5054
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 193bb886-b20d-49d4-b0cb-80218c15cd41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 234b9240-596b-445b-9d49-82b1839dfb4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62a457db-86d8-4378-8e72-10935f97b246
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ed18124-d5fd-4005-9394-735bd4761698
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29b8d9ee-e9eb-4c8d-8801-c62bd7a23021
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0403c36-8d31-4843-85df-b54cf765117d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e477185-0507-4de0-8720-c466a74f1580
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b837206-7067-4da0-a839-203b58d31a7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42948f89-c55d-4f0a-81a9-a54b018205fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ddf96ca-bc59-4857-9a51-6d881f4febcd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35617910-6754-429d-8ef9-4127e7bde8e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1fba15ab-31c3-4d6b-a2aa-6b36d965b22a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26b3f25a-aaf4-48d3-8bce-c2ca051c55b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad9f0697-34c4-44af-8c92-def141fc0821
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec84ffb8-dfbd-4314-8de5-6c672eac61ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c900a706-fde6-4737-91dc-e04da839203e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b230c31-ee9b-4f5f-9dc5-b73b73a76950
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message edbf5343-87c9-470b-ae1d-188112bbcbec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ff56b91-c425-4aad-ab52-5d661203deb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5a2b711-e1b1-4301-a0ef-03e97ec3d0d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75631dd7-6033-4bba-ac41-ce195960bd19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 427ad57d-60d4-4f8d-9216-2a8dcd9cdccc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 742910c9-1d56-42db-9a0a-a48047a956e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22b67e8e-584b-4bed-92cd-13fe3929985e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41835c97-177e-4a24-8dc4-c43f31d50775
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 542ba4bc-3fa6-4223-bddf-01a55aa91362
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53cdf42c-cfcf-4c33-977d-556214c8d0d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2a3c3a6-b652-4fd3-b2d4-c0948739106b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e4b8e76-5e40-4b02-968a-d554794b601c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2baccedf-02f4-4228-9973-64a1a0161951
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0b79dc8-6c62-4ba3-8281-87dbf31248d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a4b1720-9b98-4d37-a95c-ec3f5052f67b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42b94996-6414-4239-9b36-30a43411a8cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5cfbe7b-001b-4c06-a631-5d92ba69d0c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f91386bd-a54e-40eb-abaf-10502a389517
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64658d22-7984-43c5-acab-71a9fe6938fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c860dd3-9259-43a3-9c27-88835821a724
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61d05710-4559-40c2-a953-473ec4084408
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf7b719a-5112-4708-8d7d-fdd8cd88fcdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09752d9a-0d0f-454e-a51b-a65d51577fe4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d45e6c1-1274-4f3b-bab6-ccb1a8b293b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd224ad8-112c-4305-b53d-c9fbabd6ef3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e1809d2-4770-4224-945a-4bc3bc762046
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0252b744-1a50-4976-9e82-0a07df564165
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 301d5bd0-6199-4663-92db-8e5be6ab3bf6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa97562e-59cd-4fcb-80cd-2d00f6339c4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2da7f0b-1cf6-442a-b25d-8658e3696443
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d89c7de-ea04-44b4-81f9-4cf2e65f5b44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70c5d114-86b2-4a7c-942f-18fd44eda87f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67a0d0ec-ff2d-46a1-966a-51382baffde6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1cc36008-f9f1-4d2b-b2cb-04cbd49e9580
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 034e3cab-74c7-4524-8975-237445e9a85c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b1a6b74-a28d-486c-b2dc-ed8a2548df9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f59c3988-3228-42bd-9ce6-18f618e921c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7762166-9baa-4d09-901f-c79cb68b3d25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6dcce38c-c898-4303-b841-25c06445fd0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0fca6eeb-9097-41c9-9ce7-e0d274793ed8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6352d760-4e20-46dd-b09e-64ac8f0fcd5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d5237d9-40cc-47ce-b48a-e04b50f741be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d593a79-4bdc-4f61-ace8-767bfbecc20d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33dd8bd6-bb26-45f4-b928-d84096de1209
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02835557-9fd5-4fb9-ba24-fb03d8569ba8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6c66894-010a-49af-bda3-1d67d8488937
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1775355-918c-45cf-874a-687799ba15d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dfc1100a-5dae-4ca6-9fb7-04ea285c88e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab5504ce-245c-48d7-a7a6-34ce78ec0abb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3526fde7-82de-4909-8dc1-5d1bc3d0cd2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1dd36f4d-a81a-4c95-9df0-867ada193b41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 141aec06-7ac5-40fe-8853-9953118a122b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3549e61f-1e4e-4700-93df-ed78dbf43504
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af9603c3-d976-48d2-ab7c-ecd1b2e10219
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36c5a591-06ac-4b65-8089-b9968c09fa98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2eb7f00-c7b9-40de-8154-8eda41424f46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8dc8450d-0f95-4170-bb0a-15a914565547
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84d60bab-8e0d-45bf-a823-d50b363075f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd123e65-379f-4080-91e8-78cde934d6e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 704eb02c-874c-4ac4-bfe8-09f39be3a9d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 316c880f-3a20-4f3d-82b6-74e13cef301f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message afc05435-2644-4c69-9078-c8dbbe6ce205
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 646bbe1e-ed1f-4f32-af51-f331cbcee209
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 857f079d-f6c8-4721-b6da-6045465cb32b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8fc904f3-3a0a-4336-bb13-20a8dbc5e984
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de4baeb8-e22d-492e-b64f-c9000523ec36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad9d0ad0-69b1-4969-a338-37bf2b8ee860
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc0ee901-e9e7-4e0c-8904-90ccd4114572
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6220103d-c236-4510-a301-ad96762d8cb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd09781f-b8b0-491d-a221-4701d56ea76e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6e4fc41-87ba-4a9b-ba2b-8539b86ccc80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 744166a2-93e3-4f55-9ce9-2b3d2bc3fd62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d57c006a-3fa1-46eb-bb95-6998fcb887b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76ee858d-0bfb-4c34-9b2e-2cc76eb19ddc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83e33c37-b293-4516-ba5a-e453c52cf187
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f892df1-b88a-425b-b447-a1cc9664b4cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 662ffd18-f3b9-4d57-bf3d-27c7d9144725
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 025df2c2-6811-40da-a7f2-aa951d9ef2c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3cd5fb1-0573-43f5-a484-40d2b624abba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc7c8d95-b86d-4ffe-9653-b73381ef9cca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17677f96-d327-458e-be39-0d4d168469ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bca7d23e-ab2a-468e-9b51-baa93e7d2ff5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27e917d4-b772-427a-9399-100d0665963e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a4548fd-2ae3-4f7c-8e79-a8e39f6aa251
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b73d4fa6-8b76-46c7-ba79-edcc2abdd275
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c7f5c12-950f-4dd5-b984-85ef22e94d7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 566e08ef-b9fc-472d-8df7-79583090ac43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc8b4f50-0630-44c5-86a2-7247ca37dc62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95433274-0b37-472f-9c75-895bb249236a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2306718a-9a8d-468b-af5b-f65ffe8c2acb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae74849a-83ad-46da-b03d-6db76059de9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5a6e288-6e34-47cb-9e82-6d9fc5a975cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89c0ad86-326c-4f6a-8572-d48da61eaa8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45f7e928-c3e5-46c2-8a1b-a2b00295442e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17ba6e0a-e623-4983-82ea-9ffe9660dcbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c743f47c-0852-4911-9f45-cc4850055a85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11d591c2-f994-46e2-81b0-1497640d7ffe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a375f525-06e6-4e7c-989e-dbbd8d8d6e8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 447f6927-5000-4cc5-9e11-00cab1d8c93d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8f23ee9-71bc-4dfa-8849-0bd4bc004762
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3100710-dc24-4599-91d5-f0180225aaeb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8bf64a2-5421-4045-b1b1-cce5d0a99c28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35637506-2e0e-4c86-bc17-f4aac8c5f6c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 206c88d8-aae8-43ea-ad32-d207271aad9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cbd4974e-c15f-4d5d-b4dd-924d885f68f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2927d83e-07f4-43c5-8208-17f2f4e5a2d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b599851d-1f85-4914-8f88-52f1e71ce3cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4ee5e26-c347-4b17-9223-8fb449be5243
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 365ea898-1521-4c08-aa67-d606bc082a04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 625bc801-07f2-4a75-b07a-8bb524f77c92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2362ec84-b14b-457f-9fbe-e7007885344c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 685727f3-3791-4356-9358-d3a76befd9db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6592935-ffa1-4de7-a320-60f268e8ef96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4fbf2790-23b5-4bcf-8422-947c0bb35ec8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f85932aa-2560-442e-917a-4082bc52d994
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11e3bf4a-7288-48b3-b002-563ca310555c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f49269c-2118-42ad-86b6-a59bd5d58635
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4314129a-8f83-4935-b01a-52e97ebacabc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 040ad96b-2182-4e62-8fc9-2e308b099c47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5aff3577-51d1-4eeb-9663-1f5618151a22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a048adad-3e63-418d-bf52-3a9858974b91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78bcbbd3-bd04-47ca-a35c-116a0577edb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d6d9ece-b2c5-49c8-a59d-a2953ddd5c36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 279a1560-5143-4559-bd32-eebfe56b6390
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d8d2967-48ee-4730-a2d0-1fac57957fd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 366b13ba-0776-4269-a1c6-9f5faa309876
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de26a3f0-97d9-4036-b94f-e2d2febb60f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5851650b-46da-4ede-a739-215c45d49b97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5f342d0-6b0f-4d7d-b165-2d5b393b6aff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b87dc217-e6ea-43fc-9d73-07a452bff5d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c6cbbb0-b925-48e6-8a6f-aeadcf66b36c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7c85dc3-1a60-4d56-8342-861987316e0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0803fa14-96d1-4df6-b668-b2622f1d3106
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 254a5455-15f8-4091-8dbf-8efdeadcb077
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a6a5db6-3717-40e2-b0e9-8b6139e2584d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7530c5c9-ec6a-45f0-9c68-967d68bbb67e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f5ec536-ee5f-497f-a73c-63b14dfcc914
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3b1731c-0931-4a24-8a17-fdec7f16fbb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a66e2973-8cf9-42e8-aa9c-b457f601910b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39826675-498a-449d-8444-6dad8b3418ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28c4126f-916d-4b3a-9782-8b9053f40670
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0d51cdb-1343-49fb-a99f-61a02128fc49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bcb0bbd9-0bb2-4aa3-9558-da63ace7915c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d4f48c0-8fa8-4704-a556-f6ae247a3a14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a392e3d-b03f-4562-b353-4a8bffff7978
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9efc679-b715-48f0-8afc-e421d3029553
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 441963d0-031f-4d76-9f57-b56c6d11e3df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c83dc80-998c-4422-9512-0241954ef71a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3bf2e8d4-aeb4-4a2f-9c24-e1901eb9f4e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fdeeae40-a65f-4489-98ab-d34e5504b15e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ecd7903-c607-4ec2-9fc8-a79136fad260
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1fdbafeb-eb00-4a57-af7a-33443606e59b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c7274cf-2897-421c-bedb-73276ee77e30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4395d977-9a90-4a01-b3f1-1c403216fbed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 706f42b5-d0a2-4197-9fb2-61201ef86a68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04bd00da-8c57-4f27-b6c5-a8d1d3271aa1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1cf28104-ea47-4f76-afc0-409d354bc800
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5fc3d7db-d792-4565-aebd-114e9385a96b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 233ebb21-f3d5-4621-bc00-1624cb727baf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e3333a9-e2dc-4ff9-bd44-2f5cedc58fb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16ab0c40-fc21-4df8-9f1e-c66c1e14db6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e88445a-901a-4ceb-8bf6-c4d32c4dd63a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94147202-91c2-40ed-a31e-e3381c4f6674
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3cc1506-181c-4526-ba34-a80962b861ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3486cc5f-8adc-44b5-9a4a-76268277725d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31158f80-2364-416f-b592-51b420e9cdc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8f4218e-516b-4063-849e-167049662192
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37ecf086-8d38-44ed-a8dd-01d879ad1d09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b546b7b-268a-451b-a7b4-94d6f6871e53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9375c2ce-e1ee-46e9-8552-ee3e3b211829
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message edceccf1-b603-4007-812f-1093b8931a5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 144fdc13-31e2-4b2c-9df0-358a59e537cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae5dfbff-1ed3-4045-be70-d9d25e0403ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53f3cff4-de69-485b-9605-7beff67c4260
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d0fe2aa-6fda-4f72-98a7-3c793dfd5345
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47f687a2-8648-4a52-81fe-c453f375b941
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3df40db-f27e-4650-90be-0bb5165b6604
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b3bded3-8409-4788-9c6c-c3e36738777d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 966c8d67-9bac-4a3a-bd4a-73ede08843f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c7629cf-8aa5-4a8a-9bc3-5e45baf5db5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a364854d-8eff-4952-9d1e-cac8f9745d61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24706256-70da-4448-905d-6cb0f23234a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47cddf94-c61f-43d3-b8b5-bb21591775d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f67b9832-1531-49d0-859b-4593bf54e93b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6eac8eb4-9cbf-4117-a2fd-1f669dffa099
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9bd73671-61af-4981-bad0-002b06ce4f3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0fee8e5-6f11-4a85-8e55-ba8889631579
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44e93fd8-1c18-4c5a-a56d-9c22af24a1d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 184a696d-2c59-4aae-93be-bd05abdd5d0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6328f09a-4ca0-41da-8ba0-ff16e4375331
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f3aec4d-2ae5-419c-9363-6eb03cb18252
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f448787-7131-4f14-90dc-de89d138e93b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 590171a9-f03b-40ad-8e49-3c77c069b911
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1aee4dcf-9d98-466b-a6b7-48e194f7e024
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 154a1a02-4a4f-4e5c-98d0-12c57e4da509
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91326103-f0ad-4c49-8698-e92bd4ac437d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 016790ab-df5e-49e0-952d-3ca8e0bc3c01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db1e3276-904c-49f4-a65e-ea68974d2b3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2b57af0-e7e5-4821-8523-541e7eec3f86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7190ac38-3e34-4868-a9d7-bf7d6debf4dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95cc34d1-f0b1-48fe-931d-4fc1ad6d6b66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a8e99e8-8b68-4676-a456-9fd160f144b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b235af7a-d603-4780-b8ad-9ba087d2ffb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f511151-1d84-49d8-ad05-21c661f75d58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2786709e-8dba-46ae-b067-79bfaea473c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7718d7b2-e616-4e6b-b57b-cb76683aa239
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e939e86-c6dc-4c6d-a400-fc90f82fe9ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6693564b-a0f2-443b-93ed-b797b92d03f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5234e52a-13b1-4bbc-9c83-b1158aed31a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e133ae3a-c8f6-443e-83a1-5f5569e373ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message faa9fb48-784e-48e0-9923-77c697ba5589
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d33c3ab4-37b2-4d40-835d-c39c83fd932b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb84312b-d5b8-4358-956c-087973544045
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9010b45a-e856-40c0-b578-5364c4de6867
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5cd7f3a-fe3a-49cc-8baf-1e80521997fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0197d561-30ac-4a3a-b301-809f6c9e680e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19ebf54d-713a-4165-a74b-880230ca3399
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee9299ae-3462-4f25-b8bf-248b24b731b4
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8690 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_20
Server: localhost:8690
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_20
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_20/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_20/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_20/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_20/test_labels.txt

📊 Raw data loaded:
   Train: X=(6680, 24), y=(6680,)
   Test:  X=(1670, 24), y=(1670,)

⚠️  Limiting training data: 6680 → 800 samples
⚠️  Limiting test data: 1670 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_20 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 1 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.3217, val=0.1311 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.1005, val=0.0927 (↓), lr=0.001000
   • Epoch   3/100: train=0.0862, val=0.0925, patience=1/15, lr=0.001000
   ✓ Epoch   4/100: train=0.0877, val=0.0919 (↓), lr=0.001000
   • Epoch   5/100: train=0.0878, val=0.0915, patience=1/15, lr=0.001000
   • Epoch  11/100: train=0.0868, val=0.0914, patience=7/15, lr=0.001000
   • Epoch  21/100: train=0.0858, val=0.0911, patience=8/15, lr=0.001000

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 1 Summary - Client client_20
   Epochs: 28/100 (early stopped)
   LR: 0.001000 → 0.001000 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0070
   Val:   Loss=0.0913, RMSE=0.3022, R²=-0.0012
============================================================


============================================================
🔄 Round 3 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0899 (↓), lr=0.001000
   • Epoch   2/100: train=0.0869, val=0.0896, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0867, val=0.0895, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0864, val=0.0895, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0863, val=0.0896, patience=4/15, lr=0.001000
   📉 Epoch 9: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0852, val=0.0898, patience=10/15, lr=0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 3 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0112
   Val:   Loss=0.0899, RMSE=0.2998, R²=-0.0072
============================================================


📊 Round 3 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2490, R²: -0.0024

📊 Round 3 Test Metrics:
   Loss: 0.0823, RMSE: 0.2870, MAE: 0.2488, R²: 0.0001

============================================================
🔄 Round 6 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000500 → 0.000250
   ✓ Epoch   1/100: train=0.0846, val=0.0965 (↓), lr=0.000250
   • Epoch   2/100: train=0.0844, val=0.0961, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0843, val=0.0962, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0842, val=0.0961, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0842, val=0.0961, patience=4/15, lr=0.000250
   📉 Epoch 9: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0839, val=0.0961, patience=10/15, lr=0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0965)

============================================================
📊 Round 6 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000500 → 0.000125 (2 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=0.0021
   Val:   Loss=0.0965, RMSE=0.3107, R²=-0.0097
============================================================


📊 Round 6 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2488, R²: 0.0004

============================================================
🔄 Round 11 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0870 (↓), lr=0.000125
   • Epoch   2/100: train=0.0863, val=0.0871, patience=1/15, lr=0.000125
   • Epoch   3/100: train=0.0862, val=0.0873, patience=2/15, lr=0.000125
   • Epoch   4/100: train=0.0861, val=0.0874, patience=3/15, lr=0.000125
   • Epoch   5/100: train=0.0860, val=0.0875, patience=4/15, lr=0.000125
   📉 Epoch 7: LR reduced 0.000125 → 0.000063
   • Epoch  11/100: train=0.0858, val=0.0879, patience=10/15, lr=0.000063
   📉 Epoch 15: LR reduced 0.000063 → 0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 11 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000125 → 0.000031 (2 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=0.0032
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0045
============================================================


============================================================
🔄 Round 13 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0877 (↓), lr=0.000031
   • Epoch   2/100: train=0.0862, val=0.0880, patience=1/15, lr=0.000031
   • Epoch   3/100: train=0.0861, val=0.0883, patience=2/15, lr=0.000031
   • Epoch   4/100: train=0.0860, val=0.0885, patience=3/15, lr=0.000031
   • Epoch   5/100: train=0.0860, val=0.0886, patience=4/15, lr=0.000031
   📉 Epoch 7: LR reduced 0.000031 → 0.000016
   • Epoch  11/100: train=0.0858, val=0.0889, patience=10/15, lr=0.000016
   📉 Epoch 15: LR reduced 0.000016 → 0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 13 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000031 → 0.000008 (2 reductions)
   Train: Loss=0.0862, RMSE=0.2935, R²=0.0004
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0056
============================================================


============================================================
🔄 Round 16 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0898, val=0.0736 (↓), lr=0.000008
   • Epoch   2/100: train=0.0898, val=0.0736, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0898, val=0.0736, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0898, val=0.0736, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0897, val=0.0736, patience=4/15, lr=0.000008
   • Epoch  11/100: train=0.0897, val=0.0736, patience=10/15, lr=0.000008
   📉 Epoch 12: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 16 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000004 (1 reductions)
   Train: Loss=0.0897, RMSE=0.2995, R²=0.0022
   Val:   Loss=0.0736, RMSE=0.2714, R²=-0.0005
============================================================


============================================================
🔄 Round 17 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0872 (↓), lr=0.000004
   • Epoch   2/100: train=0.0862, val=0.0872, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0862, val=0.0872, patience=2/15, lr=0.000004
   📉 Epoch 4: LR reduced 0.000004 → 0.000002
   • Epoch   4/100: train=0.0862, val=0.0872, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0862, val=0.0872, patience=4/15, lr=0.000002
   • Epoch  11/100: train=0.0862, val=0.0872, patience=10/15, lr=0.000002
   📉 Epoch 12: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 17 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=0.0036
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0053
============================================================


============================================================
🔄 Round 18 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 18 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2959, R²=0.0008
   Val:   Loss=0.0822, RMSE=0.2868, R²=0.0015
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0003

============================================================
🔄 Round 20 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 20 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=0.0014
   Val:   Loss=0.0840, RMSE=0.2899, R²=-0.0342
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0003

📊 Round 20 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0003

============================================================
🔄 Round 24 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 24 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2967, R²=0.0028
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0083
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0003

============================================================
🔄 Round 26 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 26 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=0.0032
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0099
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0003

📊 Round 26 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0003

📊 Round 26 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

📊 Round 26 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 33 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 33 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2967, R²=0.0005
   Val:   Loss=0.0804, RMSE=0.2835, R²=0.0074
============================================================


============================================================
🔄 Round 34 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 34 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=0.0044
   Val:   Loss=0.0869, RMSE=0.2948, R²=-0.0206
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

📊 Round 34 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

📊 Round 34 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

📊 Round 34 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 43 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0892, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0891, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0891, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 43 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0893, RMSE=0.2988, R²=-0.0013
   Val:   Loss=0.0753, RMSE=0.2744, R²=0.0118
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 47 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 47 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0015
   Val:   Loss=0.0891, RMSE=0.2986, R²=0.0029
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

📊 Round 47 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 51 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 51 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=0.0006
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0034
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 52 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 52 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2971, R²=0.0021
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0020
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0003

============================================================
🔄 Round 53 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 53 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0000
   Val:   Loss=0.0875, RMSE=0.2959, R²=0.0041
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

📊 Round 53 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0003

============================================================
🔄 Round 55 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 55 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2937, R²=0.0006
   Val:   Loss=0.0874, RMSE=0.2957, R²=0.0023
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 59 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 59 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=0.0025
   Val:   Loss=0.0907, RMSE=0.3012, R²=-0.0122
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 60 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 60 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=0.0008
   Val:   Loss=0.0840, RMSE=0.2899, R²=-0.0009
============================================================


============================================================
🔄 Round 61 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 61 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0029
   Val:   Loss=0.0884, RMSE=0.2972, R²=-0.0160
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 64 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 64 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0002
   Val:   Loss=0.0860, RMSE=0.2933, R²=0.0012
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

📊 Round 64 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 69 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 69 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=0.0024
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0045
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 70 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 70 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=0.0027
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0140
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 73 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 73 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=0.0004
   Val:   Loss=0.0871, RMSE=0.2951, R²=0.0060
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

📊 Round 73 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 76 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 76 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=0.0019
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0074
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 78 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 78 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=0.0022
   Val:   Loss=0.0885, RMSE=0.2976, R²=-0.0396
============================================================


============================================================
🔄 Round 79 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 79 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=0.0008
   Val:   Loss=0.0897, RMSE=0.2995, R²=0.0044
============================================================


============================================================
🔄 Round 82 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 82 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2978, R²=0.0037
   Val:   Loss=0.0777, RMSE=0.2787, R²=-0.0120
============================================================


============================================================
🔄 Round 85 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 85 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=0.0023
   Val:   Loss=0.0913, RMSE=0.3022, R²=-0.0094
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 89 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 89 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=0.0021
   Val:   Loss=0.0874, RMSE=0.2956, R²=0.0005
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 90 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 90 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2979, R²=0.0006
   Val:   Loss=0.0774, RMSE=0.2782, R²=0.0002
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 93 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 93 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2947, R²=0.0008
   Val:   Loss=0.0850, RMSE=0.2915, R²=0.0058
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

📊 Round 93 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

📊 Round 93 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 98 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.1001 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.1001, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.1001, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.1002, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.1002, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.1002, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1001)

============================================================
📊 Round 98 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0011
   Val:   Loss=0.1001, RMSE=0.3165, R²=0.0019
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 101 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 101 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=0.0020
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0009
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 106 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 106 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=0.0020
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0118
============================================================


============================================================
🔄 Round 108 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 108 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=0.0030
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0037
============================================================


============================================================
🔄 Round 109 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0957 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0957, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0957, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0957, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0957, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0957, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0957)

============================================================
📊 Round 109 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0022
   Val:   Loss=0.0957, RMSE=0.3094, R²=-0.0055
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

📊 Round 109 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 113 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 113 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=0.0032
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0045
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 114 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 114 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0004
   Val:   Loss=0.0879, RMSE=0.2965, R²=0.0038
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 115 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 115 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2952, R²=0.0032
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0048
============================================================


============================================================
🔄 Round 118 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 118 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2952, R²=0.0010
   Val:   Loss=0.0838, RMSE=0.2895, R²=0.0005
============================================================


============================================================
🔄 Round 119 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 119 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=0.0042
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0226
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 121 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0999 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0999, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0999, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0999, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0999, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0999, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0999)

============================================================
📊 Round 121 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0020
   Val:   Loss=0.0999, RMSE=0.3160, R²=-0.0047
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 124 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 124 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2971, R²=0.0023
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0007
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 125 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 125 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2954, R²=0.0026
   Val:   Loss=0.0834, RMSE=0.2887, R²=-0.0016
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

📊 Round 125 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 128 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 128 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2968, R²=0.0012
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0037
============================================================


============================================================
🔄 Round 129 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 129 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2964, R²=-0.0001
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0090
============================================================


============================================================
🔄 Round 130 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 130 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=0.0033
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0052
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 132 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 132 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0031
   Val:   Loss=0.0880, RMSE=0.2967, R²=-0.0182
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 135 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 135 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=0.0027
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0042
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 136 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0991 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0991, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0991, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0991, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0991, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0991, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0991)

============================================================
📊 Round 136 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0027
   Val:   Loss=0.0991, RMSE=0.3149, R²=-0.0092
============================================================


============================================================
🔄 Round 137 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 137 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0024
   Val:   Loss=0.0926, RMSE=0.3042, R²=-0.0047
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 140 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0954 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0954, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0954, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0954, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0954, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0954, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0954)

============================================================
📊 Round 140 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0022
   Val:   Loss=0.0954, RMSE=0.3089, R²=0.0004
============================================================


============================================================
🔄 Round 141 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 141 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0002
   Val:   Loss=0.0907, RMSE=0.3012, R²=0.0061
============================================================


============================================================
🔄 Round 142 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 142 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=-0.0000
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0096
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 144 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 144 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2979, R²=0.0015
   Val:   Loss=0.0775, RMSE=0.2784, R²=0.0034
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 147 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 147 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=0.0016
   Val:   Loss=0.0847, RMSE=0.2911, R²=-0.0016
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 148 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 148 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2975, R²=0.0012
   Val:   Loss=0.0784, RMSE=0.2801, R²=-0.0018
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

📊 Round 148 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 153 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 153 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2944, R²=0.0030
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0042
============================================================


============================================================
🔄 Round 155 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 155 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=0.0018
   Val:   Loss=0.0861, RMSE=0.2934, R²=0.0018
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 156 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0975 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0975, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0975, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0975, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0975, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0976, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0975)

============================================================
📊 Round 156 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=0.0016
   Val:   Loss=0.0975, RMSE=0.3122, R²=-0.0100
============================================================


============================================================
🔄 Round 157 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 157 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=0.0013
   Val:   Loss=0.0913, RMSE=0.3022, R²=0.0027
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 159 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 159 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2975, R²=0.0020
   Val:   Loss=0.0783, RMSE=0.2799, R²=-0.0001
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 162 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 162 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=0.0013
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0014
============================================================


============================================================
🔄 Round 163 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 163 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=0.0022
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0011
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

📊 Round 163 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 166 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0891, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0891, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0891, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0891, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0890, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 166 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2987, R²=0.0008
   Val:   Loss=0.0756, RMSE=0.2749, R²=-0.0061
============================================================


============================================================
🔄 Round 167 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0891, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0891, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0891, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0891, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 167 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2981, R²=0.0013
   Val:   Loss=0.0769, RMSE=0.2774, R²=0.0013
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

============================================================
🔄 Round 171 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0922 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0922, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0922, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0922, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0922, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0922, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0922)

============================================================
📊 Round 171 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0033
   Val:   Loss=0.0922, RMSE=0.3037, R²=-0.0054
============================================================


============================================================
🔄 Round 174 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 174 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=0.0017
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0053
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

============================================================
🔄 Round 175 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 175 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=0.0025
   Val:   Loss=0.0844, RMSE=0.2906, R²=-0.0024
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

============================================================
🔄 Round 177 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 177 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=0.0020
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0005
============================================================


============================================================
🔄 Round 179 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 179 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=0.0015
   Val:   Loss=0.0877, RMSE=0.2962, R²=-0.0247
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 183 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 183 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2947, R²=0.0004
   Val:   Loss=0.0850, RMSE=0.2915, R²=0.0055
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 185 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 185 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=0.0021
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0005
============================================================


============================================================
🔄 Round 186 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 186 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=0.0038
   Val:   Loss=0.0890, RMSE=0.2983, R²=-0.0063
============================================================


============================================================
🔄 Round 187 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 187 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0006
   Val:   Loss=0.0879, RMSE=0.2965, R²=0.0004
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

📊 Round 187 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

📊 Round 187 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 192 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 192 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=0.0021
   Val:   Loss=0.0867, RMSE=0.2945, R²=-0.0005
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 193 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 193 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=0.0022
   Val:   Loss=0.0848, RMSE=0.2913, R²=-0.0025
============================================================


📊 Round 193 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

📊 Round 193 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 197 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 197 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=0.0011
   Val:   Loss=0.0897, RMSE=0.2995, R²=0.0015
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

📊 Round 197 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

📊 Round 197 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 202 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0950 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0950, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0950, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0950, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0950, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0950, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0950)

============================================================
📊 Round 202 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0002
   Val:   Loss=0.0950, RMSE=0.3081, R²=0.0081
============================================================


============================================================
🔄 Round 204 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 204 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2952, R²=0.0035
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0073
============================================================


📊 Round 204 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 210 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 210 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=0.0002
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0016
============================================================


============================================================
🔄 Round 212 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 212 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=0.0035
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0102
============================================================


📊 Round 212 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 216 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 216 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=0.0008
   Val:   Loss=0.0865, RMSE=0.2940, R²=0.0056
============================================================


📊 Round 216 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 217 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 217 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0012
   Val:   Loss=0.0903, RMSE=0.3005, R²=-0.0150
============================================================


📊 Round 217 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

📊 Round 217 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 219 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 219 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2957, R²=0.0020
   Val:   Loss=0.0825, RMSE=0.2873, R²=0.0002
============================================================


============================================================
🔄 Round 220 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 220 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=0.0035
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0071
============================================================


📊 Round 220 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 222 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 222 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2957, R²=0.0017
   Val:   Loss=0.0825, RMSE=0.2873, R²=0.0025
============================================================


📊 Round 222 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 223 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 223 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=-0.0001
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0084
============================================================


📊 Round 223 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 224 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 224 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=0.0009
   Val:   Loss=0.0852, RMSE=0.2919, R²=0.0006
============================================================


📊 Round 224 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 226 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0927 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0927, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0927, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0927, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0928, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0927)

============================================================
📊 Round 226 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0008
   Val:   Loss=0.0927, RMSE=0.3044, R²=-0.0091
============================================================


============================================================
🔄 Round 228 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0943 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0943, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0943, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0943, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0943, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0943, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0943)

============================================================
📊 Round 228 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0010
   Val:   Loss=0.0943, RMSE=0.3071, R²=0.0046
============================================================


============================================================
🔄 Round 235 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 235 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2959, R²=0.0014
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0035
============================================================


📊 Round 235 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

📊 Round 235 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

📊 Round 235 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 238 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 238 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=0.0018
   Val:   Loss=0.0835, RMSE=0.2890, R²=0.0004
============================================================


📊 Round 238 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 241 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 241 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=-0.0001
   Val:   Loss=0.0845, RMSE=0.2906, R²=-0.0622
============================================================


============================================================
🔄 Round 242 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0894, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0894, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0894, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0894, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0894, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0894, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 242 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0893, RMSE=0.2989, R²=0.0023
   Val:   Loss=0.0751, RMSE=0.2740, R²=-0.0201
============================================================


📊 Round 242 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 245 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0939 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0939, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0939, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0939, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0939, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0939, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0939)

============================================================
📊 Round 245 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0017
   Val:   Loss=0.0939, RMSE=0.3064, R²=0.0010
============================================================


📊 Round 245 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 246 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 246 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=0.0016
   Val:   Loss=0.0846, RMSE=0.2908, R²=-0.0010
============================================================


============================================================
🔄 Round 247 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 247 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2976, R²=0.0024
   Val:   Loss=0.0781, RMSE=0.2795, R²=-0.0033
============================================================


📊 Round 247 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 250 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 250 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0006
   Val:   Loss=0.0887, RMSE=0.2979, R²=0.0077
============================================================


📊 Round 250 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 251 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 251 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=0.0009
   Val:   Loss=0.0837, RMSE=0.2892, R²=0.0000
============================================================


============================================================
🔄 Round 252 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 252 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0013
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0056
============================================================


📊 Round 252 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 253 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 253 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=0.0018
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0094
============================================================


📊 Round 253 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 256 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 256 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2971, R²=0.0016
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.0024
============================================================


📊 Round 256 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 257 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 257 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=0.0039
   Val:   Loss=0.0867, RMSE=0.2945, R²=-0.0344
============================================================


============================================================
🔄 Round 258 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 258 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=0.0017
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0014
============================================================


============================================================
🔄 Round 259 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0936 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0936, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0936, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0936, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0936, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0936, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0936)

============================================================
📊 Round 259 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0030
   Val:   Loss=0.0936, RMSE=0.3060, R²=-0.0068
============================================================


============================================================
🔄 Round 260 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 260 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=0.0011
   Val:   Loss=0.0828, RMSE=0.2878, R²=0.0051
============================================================


📊 Round 260 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 263 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0947 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0947, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0947, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0947, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0947, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0947, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0947)

============================================================
📊 Round 263 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=0.0034
   Val:   Loss=0.0947, RMSE=0.3077, R²=-0.0066
============================================================


📊 Round 263 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 264 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 264 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=0.0017
   Val:   Loss=0.0869, RMSE=0.2948, R²=0.0005
============================================================


============================================================
🔄 Round 265 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0955 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0955, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0955, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0955, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0955, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0955, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0955)

============================================================
📊 Round 265 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0014
   Val:   Loss=0.0955, RMSE=0.3091, R²=0.0008
============================================================


📊 Round 265 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

📊 Round 265 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 267 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0979 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0979, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0980, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0980, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0980, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0981, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0979)

============================================================
📊 Round 267 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0033
   Val:   Loss=0.0979, RMSE=0.3129, R²=-0.0032
============================================================


📊 Round 267 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

📊 Round 267 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 272 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 272 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2959, R²=0.0005
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0035
============================================================


📊 Round 272 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

📊 Round 272 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

📊 Round 272 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

📊 Round 272 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

📊 Round 272 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 279 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 279 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2952, R²=0.0028
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0039
============================================================


📊 Round 279 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 281 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 281 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0022
   Val:   Loss=0.0883, RMSE=0.2971, R²=-0.0197
============================================================


📊 Round 281 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

📊 Round 281 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 285 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 285 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=0.0029
   Val:   Loss=0.0902, RMSE=0.3003, R²=-0.0024
============================================================


📊 Round 285 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 287 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 287 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2962, R²=0.0031
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0034
============================================================


============================================================
🔄 Round 289 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0939 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0939, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0939, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0939, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0939, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0939, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0939)

============================================================
📊 Round 289 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0024
   Val:   Loss=0.0939, RMSE=0.3065, R²=-0.0018
============================================================


📊 Round 289 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 290 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 290 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=0.0023
   Val:   Loss=0.0854, RMSE=0.2923, R²=-0.0001
============================================================


📊 Round 290 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

📊 Round 290 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

📊 Round 290 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 294 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 294 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=0.0018
   Val:   Loss=0.0819, RMSE=0.2862, R²=0.0021
============================================================


📊 Round 294 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 295 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 295 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=0.0019
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0000
============================================================


📊 Round 295 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 297 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 297 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2935, R²=-0.0004
   Val:   Loss=0.0877, RMSE=0.2962, R²=0.0043
============================================================


📊 Round 297 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

📊 Round 297 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 301 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 301 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=0.0010
   Val:   Loss=0.0895, RMSE=0.2992, R²=-0.0029
============================================================


📊 Round 301 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 302 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 302 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=0.0025
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0031
============================================================


📊 Round 302 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

📊 Round 302 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 304 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 304 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2962, R²=0.0035
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0066
============================================================


📊 Round 304 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

📊 Round 304 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 306 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0939 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0939, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0939, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0939, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0939, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0939, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0939)

============================================================
📊 Round 306 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0023
   Val:   Loss=0.0939, RMSE=0.3065, R²=-0.0013
============================================================


📊 Round 306 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 309 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 309 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2962, R²=0.0016
   Val:   Loss=0.0813, RMSE=0.2852, R²=0.0019
============================================================


📊 Round 309 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

📊 Round 309 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 313 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 313 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2957, R²=0.0034
   Val:   Loss=0.0825, RMSE=0.2873, R²=-0.0097
============================================================


📊 Round 313 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 315 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 315 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=0.0015
   Val:   Loss=0.0863, RMSE=0.2937, R²=-0.0004
============================================================


📊 Round 315 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 316 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 316 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=-0.0018
   Val:   Loss=0.0918, RMSE=0.3029, R²=-0.0074
============================================================


📊 Round 316 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 318 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0892, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 318 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0893, RMSE=0.2988, R²=0.0027
   Val:   Loss=0.0753, RMSE=0.2743, R²=-0.0099
============================================================


📊 Round 318 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 321 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 321 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=0.0013
   Val:   Loss=0.0917, RMSE=0.3029, R²=-0.0075
============================================================


📊 Round 321 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 323 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0950 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0950, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0950, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0950, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0950, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0950, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0950)

============================================================
📊 Round 323 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0037
   Val:   Loss=0.0950, RMSE=0.3083, R²=-0.0100
============================================================


============================================================
🔄 Round 324 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 324 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=0.0014
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0009
============================================================


📊 Round 324 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 328 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 328 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=-0.0008
   Val:   Loss=0.0828, RMSE=0.2877, R²=0.0063
============================================================


============================================================
🔄 Round 329 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 329 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0004
   Val:   Loss=0.0839, RMSE=0.2897, R²=0.0085
============================================================


============================================================
🔄 Round 330 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0951 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0951, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0951, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0951, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0951, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0951, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0951)

============================================================
📊 Round 330 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0011
   Val:   Loss=0.0951, RMSE=0.3084, R²=0.0039
============================================================


📊 Round 330 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 331 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 331 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0026
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0009
============================================================


📊 Round 331 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 333 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 333 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=0.0001
   Val:   Loss=0.0856, RMSE=0.2926, R²=0.0091
============================================================


============================================================
🔄 Round 334 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0948 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0948, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0948, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0948, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0948, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0949, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0948)

============================================================
📊 Round 334 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0027
   Val:   Loss=0.0948, RMSE=0.3079, R²=-0.0310
============================================================


📊 Round 334 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 335 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 335 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2932, R²=0.0021
   Val:   Loss=0.0886, RMSE=0.2977, R²=-0.0066
============================================================


📊 Round 335 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

📊 Round 335 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 339 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 339 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=0.0009
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0044
============================================================


📊 Round 339 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 344 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 344 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0012
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0025
============================================================


📊 Round 344 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 351 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 351 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2937, R²=0.0024
   Val:   Loss=0.0874, RMSE=0.2957, R²=-0.0012
============================================================


============================================================
🔄 Round 354 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 354 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=0.0002
   Val:   Loss=0.0812, RMSE=0.2849, R²=0.0090
============================================================


📊 Round 354 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

📊 Round 354 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

📊 Round 354 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

📊 Round 354 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

📊 Round 354 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

📊 Round 354 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 365 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 365 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=0.0003
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0469
============================================================


📊 Round 365 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 366 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0953 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0953, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0953, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0953, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0953, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0953, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0953)

============================================================
📊 Round 366 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0025
   Val:   Loss=0.0953, RMSE=0.3088, R²=-0.0091
============================================================


============================================================
🔄 Round 367 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0980 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0980, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0980, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0980, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0980, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0980, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0980)

============================================================
📊 Round 367 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0008
   Val:   Loss=0.0980, RMSE=0.3131, R²=0.0043
============================================================


📊 Round 367 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

📊 Round 367 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

============================================================
🔄 Round 370 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 370 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=0.0031
   Val:   Loss=0.0891, RMSE=0.2985, R²=-0.0039
============================================================


============================================================
🔄 Round 373 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 373 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=0.0009
   Val:   Loss=0.0899, RMSE=0.2998, R²=0.0006
============================================================


📊 Round 373 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

📊 Round 373 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

📊 Round 373 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

📊 Round 373 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

📊 Round 373 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

📊 Round 373 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

📊 Round 373 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 383 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 383 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=0.0045
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0192
============================================================


📊 Round 383 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 386 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 386 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=0.0011
   Val:   Loss=0.0914, RMSE=0.3023, R²=0.0016
============================================================


📊 Round 386 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

📊 Round 386 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 390 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0938 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0938, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0938, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0938, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0938, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0939, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0938)

============================================================
📊 Round 390 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0032
   Val:   Loss=0.0938, RMSE=0.3063, R²=-0.0224
============================================================


============================================================
🔄 Round 391 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 391 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=0.0017
   Val:   Loss=0.0895, RMSE=0.2992, R²=0.0007
============================================================


📊 Round 391 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

============================================================
🔄 Round 392 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 392 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0017
   Val:   Loss=0.0892, RMSE=0.2986, R²=-0.0044
============================================================


📊 Round 392 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

============================================================
🔄 Round 393 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0993 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0993, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0993, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0993, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0993, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0993, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0993)

============================================================
📊 Round 393 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0018
   Val:   Loss=0.0993, RMSE=0.3151, R²=-0.0036
============================================================


============================================================
🔄 Round 394 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 394 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2974, R²=0.0025
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.0135
============================================================


📊 Round 394 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

📊 Round 394 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

============================================================
🔄 Round 397 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 397 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=-0.0000
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0100
============================================================


📊 Round 397 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

============================================================
🔄 Round 398 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 398 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=0.0024
   Val:   Loss=0.0917, RMSE=0.3029, R²=-0.0007
============================================================


============================================================
🔄 Round 399 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 399 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=0.0026
   Val:   Loss=0.0889, RMSE=0.2982, R²=-0.0015
============================================================


============================================================
🔄 Round 400 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 400 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0016
   Val:   Loss=0.0903, RMSE=0.3006, R²=-0.0091
============================================================


============================================================
🔄 Round 401 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 401 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2954, R²=0.0026
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0095
============================================================


📊 Round 401 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

📊 Round 401 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 404 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 404 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=0.0020
   Val:   Loss=0.0891, RMSE=0.2985, R²=-0.0007
============================================================


📊 Round 404 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 407 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 407 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0035
   Val:   Loss=0.0905, RMSE=0.3008, R²=-0.0052
============================================================


📊 Round 407 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 409 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 409 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=0.0015
   Val:   Loss=0.0866, RMSE=0.2943, R²=0.0027
============================================================


============================================================
🔄 Round 410 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 410 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=0.0021
   Val:   Loss=0.0844, RMSE=0.2906, R²=0.0001
============================================================


📊 Round 410 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 412 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 412 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=0.0007
   Val:   Loss=0.0848, RMSE=0.2911, R²=-0.0059
============================================================


============================================================
🔄 Round 414 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 414 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=0.0016
   Val:   Loss=0.0831, RMSE=0.2883, R²=0.0026
============================================================


============================================================
🔄 Round 415 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 415 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0002
   Val:   Loss=0.0866, RMSE=0.2943, R²=0.0048
============================================================


============================================================
🔄 Round 416 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 416 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=0.0017
   Val:   Loss=0.0872, RMSE=0.2953, R²=0.0022
============================================================


📊 Round 416 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 419 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 419 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2937, R²=0.0010
   Val:   Loss=0.0874, RMSE=0.2957, R²=0.0002
============================================================


📊 Round 419 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

📊 Round 419 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

📊 Round 419 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 423 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 423 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=0.0047
   Val:   Loss=0.0895, RMSE=0.2992, R²=-0.0093
============================================================


📊 Round 423 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

📊 Round 423 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 427 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 427 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=0.0029
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0024
============================================================


============================================================
🔄 Round 429 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0928 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0928, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0928, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0928, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0928, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0928, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 429 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0010
   Val:   Loss=0.0928, RMSE=0.3046, R²=0.0052
============================================================


============================================================
🔄 Round 431 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 431 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2932, R²=0.0000
   Val:   Loss=0.0886, RMSE=0.2977, R²=-0.0031
============================================================


📊 Round 431 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 432 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 432 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=0.0038
   Val:   Loss=0.0899, RMSE=0.2998, R²=-0.0109
============================================================


============================================================
🔄 Round 433 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0939 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0939, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0939, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0939, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0939, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0940, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0939)

============================================================
📊 Round 433 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0006
   Val:   Loss=0.0939, RMSE=0.3064, R²=0.0007
============================================================


📊 Round 433 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

📊 Round 433 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 435 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0924 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 435 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0020
   Val:   Loss=0.0924, RMSE=0.3040, R²=0.0014
============================================================


📊 Round 435 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 439 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0932 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0932, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0932, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0931, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0931, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0931, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0932)

============================================================
📊 Round 439 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0038
   Val:   Loss=0.0932, RMSE=0.3052, R²=-0.0101
============================================================


============================================================
🔄 Round 440 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0935 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0935, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0935, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0935, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0935, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0935, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0935)

============================================================
📊 Round 440 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0020
   Val:   Loss=0.0935, RMSE=0.3058, R²=0.0015
============================================================


📊 Round 440 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

📊 Round 440 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

📊 Round 440 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

📊 Round 440 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

📊 Round 440 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

📊 Round 440 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 447 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 447 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=0.0011
   Val:   Loss=0.0855, RMSE=0.2923, R²=0.0014
============================================================


📊 Round 447 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

📊 Round 447 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 451 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 451 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2964, R²=0.0013
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0010
============================================================


📊 Round 451 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

📊 Round 451 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

📊 Round 451 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

📊 Round 451 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 457 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 457 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=0.0005
   Val:   Loss=0.0860, RMSE=0.2933, R²=0.0024
============================================================


============================================================
🔄 Round 459 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 459 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=0.0024
   Val:   Loss=0.0852, RMSE=0.2918, R²=-0.0017
============================================================


============================================================
🔄 Round 464 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 464 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=0.0001
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0025
============================================================


============================================================
🔄 Round 466 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 466 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=0.0005
   Val:   Loss=0.0843, RMSE=0.2903, R²=0.0071
============================================================


============================================================
🔄 Round 467 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 467 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0016
   Val:   Loss=0.0882, RMSE=0.2969, R²=0.0024
============================================================


📊 Round 467 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

📊 Round 467 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 469 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0948 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0948, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0948, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0949, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0949, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0949, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0948)

============================================================
📊 Round 469 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0007
   Val:   Loss=0.0948, RMSE=0.3080, R²=0.0000
============================================================


📊 Round 469 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

📊 Round 469 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

============================================================
🔄 Round 473 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 473 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2959, R²=0.0020
   Val:   Loss=0.0821, RMSE=0.2866, R²=0.0000
============================================================


📊 Round 473 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

📊 Round 473 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

============================================================
🔄 Round 478 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 478 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=0.0030
   Val:   Loss=0.0898, RMSE=0.2997, R²=-0.0042
============================================================


============================================================
🔄 Round 480 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 480 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2952, R²=0.0006
   Val:   Loss=0.0839, RMSE=0.2897, R²=0.0015
============================================================


📊 Round 480 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

📊 Round 480 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 483 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0952 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0952, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0952, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0952, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0952, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0952, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0952)

============================================================
📊 Round 483 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0015
   Val:   Loss=0.0952, RMSE=0.3085, R²=0.0033
============================================================


============================================================
🔄 Round 484 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 484 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2967, R²=0.0005
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0080
============================================================


📊 Round 484 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 490 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 490 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=0.0008
   Val:   Loss=0.0890, RMSE=0.2983, R²=-0.0116
============================================================


📊 Round 490 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 492 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 492 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=0.0001
   Val:   Loss=0.0914, RMSE=0.3023, R²=0.0077
============================================================


📊 Round 492 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

📊 Round 492 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

============================================================
🔄 Round 495 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0928, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 495 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0017
   Val:   Loss=0.0925, RMSE=0.3042, R²=-0.0189
============================================================


📊 Round 495 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

📊 Round 495 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 497 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 497 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=0.0024
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0009
============================================================


📊 Round 497 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 498 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 498 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2954, R²=0.0019
   Val:   Loss=0.0834, RMSE=0.2888, R²=0.0018
============================================================


📊 Round 498 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

📊 Round 498 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 500 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 500 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=0.0004
   Val:   Loss=0.0884, RMSE=0.2974, R²=-0.0012
============================================================


============================================================
🔄 Round 501 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 501 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2962, R²=0.0000
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0124
============================================================


📊 Round 501 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

📊 Round 501 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

📊 Round 501 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 505 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 505 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2981, R²=0.0019
   Val:   Loss=0.0768, RMSE=0.2771, R²=-0.0032
============================================================


============================================================
🔄 Round 506 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 506 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=0.0018
   Val:   Loss=0.0917, RMSE=0.3028, R²=0.0022
============================================================


📊 Round 506 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

📊 Round 506 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 512 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 512 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=0.0013
   Val:   Loss=0.0917, RMSE=0.3029, R²=-0.0353
============================================================


============================================================
🔄 Round 515 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 515 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=0.0021
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0008
============================================================


============================================================
🔄 Round 517 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0924 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 517 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0014
   Val:   Loss=0.0924, RMSE=0.3040, R²=0.0028
============================================================


============================================================
🔄 Round 519 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 519 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=0.0032
   Val:   Loss=0.0856, RMSE=0.2925, R²=-0.0060
============================================================


============================================================
🔄 Round 520 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 520 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=0.0017
   Val:   Loss=0.0876, RMSE=0.2959, R²=-0.0015
============================================================


📊 Round 520 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

📊 Round 520 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

📊 Round 520 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

📊 Round 520 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 530 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0943 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0943, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0943, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0943, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0943, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0944, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0943)

============================================================
📊 Round 530 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0009
   Val:   Loss=0.0943, RMSE=0.3070, R²=-0.0033
============================================================


📊 Round 530 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 531 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0937 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0937, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0937, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0937, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0937, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0937, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0937)

============================================================
📊 Round 531 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0022
   Val:   Loss=0.0937, RMSE=0.3061, R²=0.0005
============================================================


📊 Round 531 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 533 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 533 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=0.0010
   Val:   Loss=0.0851, RMSE=0.2918, R²=0.0019
============================================================


📊 Round 533 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 534 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 534 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=0.0030
   Val:   Loss=0.0873, RMSE=0.2954, R²=-0.0027
============================================================


📊 Round 534 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

📊 Round 534 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

============================================================
🔄 Round 545 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0967 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0967, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0967, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0967, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0967, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0967, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0967)

============================================================
📊 Round 545 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0011
   Val:   Loss=0.0967, RMSE=0.3110, R²=-0.0097
============================================================


============================================================
🔄 Round 546 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 546 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0029
   Val:   Loss=0.0908, RMSE=0.3013, R²=-0.0032
============================================================


📊 Round 546 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

============================================================
🔄 Round 547 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 547 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=0.0010
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0055
============================================================


============================================================
🔄 Round 550 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 550 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=0.0036
   Val:   Loss=0.0895, RMSE=0.2991, R²=-0.0059
============================================================


============================================================
🔄 Round 551 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 551 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2957, R²=0.0014
   Val:   Loss=0.0827, RMSE=0.2875, R²=0.0031
============================================================


============================================================
🔄 Round 553 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 553 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=0.0030
   Val:   Loss=0.0889, RMSE=0.2982, R²=-0.0059
============================================================


📊 Round 553 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 554 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 554 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2980, R²=0.0013
   Val:   Loss=0.0771, RMSE=0.2776, R²=0.0044
============================================================


📊 Round 554 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

📊 Round 554 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

📊 Round 554 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 557 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 557 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0012
   Val:   Loss=0.0911, RMSE=0.3018, R²=0.0040
============================================================


============================================================
🔄 Round 560 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 560 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=0.0025
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0011
============================================================


============================================================
🔄 Round 562 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 562 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0005
   Val:   Loss=0.0883, RMSE=0.2971, R²=0.0044
============================================================


============================================================
🔄 Round 563 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 563 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=0.0010
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0068
============================================================


============================================================
🔄 Round 564 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0891, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0891, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0891, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0891, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 564 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2979, R²=0.0011
   Val:   Loss=0.0773, RMSE=0.2780, R²=0.0055
============================================================


📊 Round 564 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 566 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 566 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2977, R²=0.0012
   Val:   Loss=0.0779, RMSE=0.2791, R²=0.0005
============================================================


============================================================
🔄 Round 568 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0947 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0947, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0947, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0947, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0948, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0948, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0947)

============================================================
📊 Round 568 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0007
   Val:   Loss=0.0947, RMSE=0.3078, R²=0.0008
============================================================


============================================================
🔄 Round 571 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0930 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0930, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0930, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0930, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0930, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0930, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0930)

============================================================
📊 Round 571 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=0.0031
   Val:   Loss=0.0930, RMSE=0.3050, R²=-0.0029
============================================================


============================================================
🔄 Round 574 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 574 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=0.0034
   Val:   Loss=0.0901, RMSE=0.3001, R²=-0.0092
============================================================


============================================================
🔄 Round 575 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 575 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0033
   Val:   Loss=0.0915, RMSE=0.3025, R²=-0.0032
============================================================


📊 Round 575 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

============================================================
🔄 Round 577 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 577 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=0.0029
   Val:   Loss=0.0887, RMSE=0.2978, R²=-0.0037
============================================================


📊 Round 577 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

============================================================
🔄 Round 578 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 578 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=0.0016
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0001
============================================================


📊 Round 578 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

============================================================
🔄 Round 580 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 580 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2928, R²=-0.0009
   Val:   Loss=0.0893, RMSE=0.2989, R²=-0.0114
============================================================


📊 Round 580 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 581 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0964 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0964, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0964, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0964, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0964, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0964, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0964)

============================================================
📊 Round 581 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0020
   Val:   Loss=0.0964, RMSE=0.3105, R²=-0.0022
============================================================


📊 Round 581 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

📊 Round 581 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

📊 Round 581 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

📊 Round 581 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 587 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 587 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=0.0017
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0047
============================================================


📊 Round 587 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

============================================================
🔄 Round 589 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0895, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0895, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0895, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0895, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0895, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0895, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 589 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0893, RMSE=0.2989, R²=-0.0002
   Val:   Loss=0.0751, RMSE=0.2740, R²=0.0056
============================================================


============================================================
🔄 Round 591 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 591 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=0.0001
   Val:   Loss=0.0872, RMSE=0.2953, R²=0.0077
============================================================


============================================================
🔄 Round 593 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 593 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=0.0026
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0023
============================================================


============================================================
🔄 Round 594 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 594 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=0.0015
   Val:   Loss=0.0918, RMSE=0.3029, R²=0.0002
============================================================


📊 Round 594 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0002

============================================================
🔄 Round 595 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 595 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=0.0018
   Val:   Loss=0.0873, RMSE=0.2954, R²=0.0011
============================================================


📊 Round 595 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

============================================================
🔄 Round 598 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 598 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=0.0020
   Val:   Loss=0.0862, RMSE=0.2937, R²=0.0002
============================================================


📊 Round 598 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

📊 Round 598 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

============================================================
🔄 Round 600 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 600 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=0.0016
   Val:   Loss=0.0907, RMSE=0.3012, R²=0.0018
============================================================


============================================================
🔄 Round 601 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 601 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0036
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0056
============================================================


============================================================
🔄 Round 602 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 602 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0005
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0006
============================================================


============================================================
🔄 Round 603 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0937 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0937, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0937, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0937, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0937, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0937, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0937)

============================================================
📊 Round 603 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0022
   Val:   Loss=0.0937, RMSE=0.3062, R²=-0.0019
============================================================


📊 Round 603 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

📊 Round 603 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

============================================================
🔄 Round 610 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0962 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0962, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0962, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0962, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0962, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0962, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0962)

============================================================
📊 Round 610 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=0.0015
   Val:   Loss=0.0962, RMSE=0.3101, R²=0.0026
============================================================


📊 Round 610 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

📊 Round 610 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

============================================================
🔄 Round 613 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0927 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0927, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0927, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0927, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0927, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0927)

============================================================
📊 Round 613 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0015
   Val:   Loss=0.0927, RMSE=0.3044, R²=0.0030
============================================================


📊 Round 613 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

============================================================
🔄 Round 615 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0927 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0927, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0927, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0927, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0927, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0927)

============================================================
📊 Round 615 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0029
   Val:   Loss=0.0927, RMSE=0.3045, R²=-0.0021
============================================================


📊 Round 615 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

📊 Round 615 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

============================================================
🔄 Round 617 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 617 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=0.0020
   Val:   Loss=0.0875, RMSE=0.2958, R²=0.0009
============================================================


📊 Round 617 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

📊 Round 617 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

📊 Round 617 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

📊 Round 617 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

📊 Round 617 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

============================================================
🔄 Round 623 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 623 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=0.0025
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0250
============================================================


📊 Round 623 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

📊 Round 623 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

============================================================
🔄 Round 625 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 625 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0015
   Val:   Loss=0.0881, RMSE=0.2968, R²=0.0013
============================================================


📊 Round 625 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

📊 Round 625 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

📊 Round 625 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

📊 Round 625 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

============================================================
🔄 Round 629 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 629 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2968, R²=0.0017
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0023
============================================================


📊 Round 629 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

============================================================
🔄 Round 632 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 632 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0016
   Val:   Loss=0.0905, RMSE=0.3008, R²=-0.0010
============================================================


📊 Round 632 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

📊 Round 632 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

============================================================
🔄 Round 634 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0969 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0969, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0969, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0969, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0969, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0969, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0969)

============================================================
📊 Round 634 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0015
   Val:   Loss=0.0969, RMSE=0.3113, R²=0.0024
============================================================


============================================================
🔄 Round 635 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0936 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0936, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0936, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0936, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0936, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0935, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0936)

============================================================
📊 Round 635 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0030
   Val:   Loss=0.0936, RMSE=0.3059, R²=-0.0092
============================================================


📊 Round 635 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

============================================================
🔄 Round 637 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 637 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2957, R²=0.0042
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0084
============================================================


📊 Round 637 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

📊 Round 637 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

============================================================
🔄 Round 642 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0978 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0978, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0978, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0977, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0977, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0977, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0978)

============================================================
📊 Round 642 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2892, R²=0.0023
   Val:   Loss=0.0978, RMSE=0.3127, R²=-0.0133
============================================================


📊 Round 642 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

📊 Round 642 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

============================================================
🔄 Round 645 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 645 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0016
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0010
============================================================


📊 Round 645 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0000

============================================================
🔄 Round 648 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 648 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=-0.0006
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0022
============================================================


============================================================
🔄 Round 649 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 649 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=0.0026
   Val:   Loss=0.0894, RMSE=0.2990, R²=-0.0011
============================================================


============================================================
🔄 Round 650 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 650 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=0.0036
   Val:   Loss=0.0854, RMSE=0.2923, R²=-0.0156
============================================================


============================================================
🔄 Round 652 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 652 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2923, R²=0.0001
   Val:   Loss=0.0906, RMSE=0.3009, R²=0.0059
============================================================


============================================================
🔄 Round 653 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 653 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=0.0021
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0101
============================================================


📊 Round 653 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

============================================================
🔄 Round 655 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 655 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=0.0007
   Val:   Loss=0.0862, RMSE=0.2936, R²=0.0038
============================================================


📊 Round 655 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

============================================================
🔄 Round 656 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 656 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0023
   Val:   Loss=0.0904, RMSE=0.3006, R²=-0.0014
============================================================


============================================================
🔄 Round 657 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 657 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2957, R²=0.0017
   Val:   Loss=0.0827, RMSE=0.2875, R²=0.0024
============================================================


📊 Round 657 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

============================================================
🔄 Round 659 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 659 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=0.0034
   Val:   Loss=0.0862, RMSE=0.2935, R²=-0.0059
============================================================


📊 Round 659 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2489, R²: -0.0001

============================================================
🔄 Round 660 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 660 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=0.0007
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0047
============================================================


❌ Client client_20 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8690 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8690 {grpc_message:"Socket closed", grpc_status:14}"
>
