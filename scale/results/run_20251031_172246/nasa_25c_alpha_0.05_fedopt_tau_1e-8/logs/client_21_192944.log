[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0493d62-1c11-45de-86aa-b79f08d3de19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fab2bd04-ad7d-4aa6-9c68-ffb4cdd4c83f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ef9d4fa-3345-47d7-a358-3e7fd89938e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f79e7207-739d-442d-b349-1b557e568357
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67081d38-170a-49f2-b5e6-37f7d628f6b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ccc08820-6a4d-4165-89bd-c4f8f727aff7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fff6f353-94fd-49c2-81f1-8cf55ec42165
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7566f28f-0757-4a08-9128-210cadf98ffd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe9cec41-4302-49b5-8d91-63841f66b9fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c41a872d-020c-45eb-abdf-733f11448b5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2f18844-a928-43f5-9221-283ba2bc7889
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 155f5023-7a18-4299-925e-0db7d65d1e9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 777a1c38-ddd9-44b5-95b7-e4abfaf42af8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d6d8a83-cf45-4fda-94cc-8629928463dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6118b693-5bc0-4180-ba29-6ebbaa337f58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4949ab2-b2dd-4380-89be-9d48f8443b33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca73fc19-234d-4423-9d90-4d84bd1a78c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ab9d0ad-4075-451f-b1d1-5b5a0c9f7a7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d923f8c-a2fb-4a97-827e-9fab46e8cf98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76b9d19b-6a74-4287-be6d-500735f59570
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 548d6ace-ad6e-4604-a575-27a85a62f36a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f58c469-4ff7-4ee2-b53a-3cacb65165d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6afe4d96-e8b1-4a9b-a5ac-21da1ead90f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4568331d-717d-42d5-8d98-79d4ca94bd84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d668ba4-643a-4801-8b14-18eef5eee6bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eefd0258-d3f7-4c2c-93da-aef1396b728a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message edbfeca4-3548-46b5-ba9e-4bb8599abb0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a2974d3-63bb-4c11-a687-a132a6e638fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60cd019e-a066-4104-bbcc-96c99129a78a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22b7281f-e4d5-4501-a3b9-07d93d544599
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2731177b-6c28-44f4-91a9-d185369cc678
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1bd83478-91b9-479e-b78c-18b91358cfda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00ca6a9e-200b-4bcc-b452-dfd01bf34d78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6172aa98-041c-47e7-9b3d-af9f55d575d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73c323ce-8903-4131-802d-39ba57526e47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30c5f774-156a-47a8-bae3-e35509c45ab3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d9226a7-4d3f-475d-97c5-bcbabf9a84db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08a9384b-b416-4d85-9635-7045c121cf1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc6cdfaa-7c38-45e0-917c-250e08623821
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af182ac0-d03d-4218-b1fb-d06a7611aa4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c15f3e96-1c37-4f3b-81ad-5ed8043e2fc1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5cc073d-2b14-42dd-8f0b-2922caa45b0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 204e5480-85fd-446a-999c-8d00808092b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3af2a6c5-a5a0-495a-bd0c-7bad5949fd19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3fecd86-c85e-406f-a730-c5f3208b966f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2103a180-1b25-419e-aba2-ae4c567c4ded
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f39b2385-c487-4551-99cb-49a5e2013166
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63694d29-7d9e-42f2-946f-045ad222a1c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a44de27-f887-45b1-95d9-f0497fd80d91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20614964-4a84-402a-811c-671a6a4ea71e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 222bd254-c211-4359-9719-39032b03f148
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e4b3ec1-195b-4ef1-aea7-410ed76e3f56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30391749-528b-4d27-afd4-c0a39a12497b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a35d599-4c8d-4fa4-a6f9-d02db6cc125a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04c0b4a7-aeab-4419-b053-9fa3fa498bff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ed35190-513e-443e-915e-14526db53c2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2755936-e179-4fdc-a33a-523c5aeca97c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7ba45aa-066f-4803-815d-d74dcc64a2f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 662b9c74-8c8f-4293-a5fa-a3a47eec2a79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66d7bad7-5cd4-4a1a-909d-f56badb967bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a526c80-f3f4-474a-927f-855310919569
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 248a91ba-8b0d-4bba-b7e8-80f6314b71fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02f4d79b-f06d-4ee4-8c64-940a56034e8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d804fef9-faee-4d1d-a05e-0dabc6644961
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a80f279-ada5-4a10-aef2-1df0d5b0e816
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2a59583-cffb-4991-83f0-dcef00040443
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3adc123-294e-4b24-92ef-88b820e242b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da7a47e7-9dae-4f31-9fe6-05ce14ba22c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7d3912a-b1cf-4dc1-bde5-ab8b5c3c9d9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12e2b953-771a-4800-99b8-a711dc37e012
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6aab32f2-dd1f-4cc8-ab42-f2f573493820
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23871832-81f3-4e6a-9912-9d7f17bbb7c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6289c1fd-67bf-43c4-aa3b-4660882b7349
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0bba58ac-91ee-44d2-875c-7cabc148ae08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ceaafac9-aebe-429f-8ae3-35fa0774070e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f6d664e-f380-43b3-bc01-25caa415c16c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86e2176a-0b79-4bfa-b8ec-0cd1267e8ecf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99e8e4f0-d0b5-4c1a-aa62-c237f1282b3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd4b7a76-f701-4125-a187-6f811284f3cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c234e416-775e-41e3-953a-45b2da94acb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d98ffa44-5d1d-4200-bcfb-5a3f97c6f2cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8dba75f9-5262-49e4-bb23-7ac83437b399
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ecbdf92-90d5-4594-909b-259767d4660f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24df1108-48cc-4f1f-ac6a-dafefa3fbcb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 514ca8bc-9dee-4329-92e8-61297be32de8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1205fc9b-f476-4f64-a464-b5dd4f040fce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2137b971-fdd1-4c26-ad2d-135de394fe94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message def5d573-b817-41f8-8757-42a5daa13382
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d44f164e-1853-44a5-96a1-ad8bf6178fe2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 891a47fc-1fd6-4686-bcc0-9e9b48cb771b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 048379c5-49e4-4d8a-887b-8872b44d23db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1d9facd-aa5b-44bd-b8ad-6a3b16621396
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e350d82-8121-4bf1-8b87-447d1f1417c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fead2ab5-5783-44fa-8956-8f1efcee603d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f0b9524-60ae-439d-8faa-48d454816e35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a403e8f-882d-4040-b04f-23e108780ae4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3b0e2b0-9ab3-4ad1-b78f-0e89db63d633
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3bf986f-73ae-4c75-9641-1892289668c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6cfbc33-da8f-4ca5-9b3e-63d0204416f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87728601-638c-417d-8c8b-5e3e8ea10794
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 201ade4b-fb03-47d7-a4ea-ef7129e2369a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4a26a78-b630-4109-818e-7b7258e4864a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dba21b42-f2ac-4a13-9109-650085677cbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba327a42-09ea-4822-b81a-a07dd2d58ea8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d40b96a-53fc-4dd7-84db-e9d299d463f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f05416ae-577d-4728-a152-75ac366c29fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e420e4b-354f-4963-a94c-844e417fe1aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 978f6a4b-14c0-4150-bd11-fa860b4a5785
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0052a29d-cee7-44ac-9f38-156c8b31dcc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff79c535-1de3-48b9-b820-9c622d567cae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93f0af1e-f613-49e0-b0ac-da562a2b386a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b27cb448-fa5e-47eb-a2fc-7dfe6656b652
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f0e9e34-4d57-48e4-b1d5-a8f7fc064e8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2bd779dc-efc2-4d56-a0e6-95daa171a592
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c41e825-d087-4da0-a996-5d2343e21230
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 149dcfc5-56eb-472a-84ce-53735e872f64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3554decb-e433-45f6-948e-f65e4fb3933d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dbf5e396-457f-428b-8405-a2f3ca42b244
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53248feb-80d1-48b0-839a-425e4c2e4106
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 326c9bc4-012f-4ac9-9332-9acd9419a258
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb2ac477-98ca-4ffc-9433-f19b593d2d41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e28b611-3052-45a6-b3b3-efafd005928d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e8e7b75-4d3c-466a-9b82-f523b1f54a28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a55f1b5c-65ad-454d-b31c-3527413ec489
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a790bfaa-a22a-4ecd-9da7-5eedae767563
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 666812dd-e3ff-41b7-825e-d47fe99e7167
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6ed4fff-efa8-4413-a6f0-68e0112767fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 758dc769-ad02-43c0-87c2-30058fafe0ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9246f066-d92a-49b7-85d6-376e1c7976b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 743a07ea-c23d-49b0-91dc-f69ae22d9f56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12775883-7256-488c-92b7-3c4fc2af27a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd0dffe5-bec0-4cc6-a600-d7fc49b0de85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b89e6d95-9287-4338-8d3c-7b5cb78bc7e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49eb0dfe-dcac-4780-9983-f4fe1a7cd6ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3cdee2f-7684-46fa-8e83-af89ea07ab60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6b24018-acf4-446c-b4a0-0b113275668d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f381b160-c579-4d5c-826a-b22683004487
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3925db49-231b-46b6-bcbf-91651f62c346
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f28a1dc-a67c-43d5-8311-c161d5918731
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1edeb488-826b-4250-8d14-024bd8ca6f22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 919a002a-d891-48a0-9107-ae7d0bd06201
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 970bdc4a-033a-4f96-be38-393f3243e342
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1d90405-8b7d-4c99-af1d-bef4ab2198a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83a924b1-6df2-4f3f-bd62-4b129460421f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 681857aa-c85a-4c51-a4ca-1a28d5631b03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1826a8a6-4b7d-4fe1-a4c9-b02e3f903b91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f90402e-d471-4cfd-8a78-b31373940936
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77351bba-cd3f-4579-8857-2b8a76d1521b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 023f599d-bb9c-427f-8c5a-26ff20f6f9c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f933bf32-6c11-42e7-b09e-59506a55478c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ff4e06a-7bc9-40e6-9b67-c446518de16f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e66aee1-8bfb-418a-b98f-d242ab55ff03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80cea9df-c9a0-4f73-96c0-55241d869fdd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ead5b307-e543-42d9-bfad-d20ba8b2accd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 814ae403-9d70-48a4-87d3-38832514f54f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0151fb74-4d38-4a9e-8286-f3b2a7d97d95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41400a28-1510-42c1-8a96-4d629371aeee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 064bda5c-f6e9-407d-9cb4-2298768ea4ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 703bceb4-cbda-4212-be31-5a63552841c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b556f1bd-af38-42ac-8f9d-e1fc985cef18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a17c4f8-fc88-478f-9124-1f900fa4d5f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec320e4a-fb5e-42b9-884d-1a960b1b2a1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e3724a8-a12f-402c-9bbf-1cb5a6a47420
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 975e86c4-9237-40ec-bb47-412718fea68b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 268a8eb9-4e4e-406a-891b-f22c31aeda52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c79a1e3-8e1d-458f-b79f-79f243561e07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46946da4-3241-4b99-9d10-9b03b4a07ef5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 650b7c7e-8e4e-41c5-84d8-204131e77182
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f119755-52b0-4246-9c2e-bac3b8858a23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb1b12bb-10ed-4f2d-80f2-7df0504c1588
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5f361b1-9136-44c0-b293-7a2b00a4a9ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bffb92c7-f340-4e9c-84a0-b3dd2dff1fe9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae665b35-296b-4d3e-9723-a61fdc799ada
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 496b2fcc-a677-498b-acb8-62226aeb6e62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b6e0d7e-3e6c-4b80-bc7e-fad84042ab67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64b31948-290c-42d6-bd50-5c1ab1a8df2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ed5e02f-3165-4b43-956c-b3b955727a11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2b254e5-3b40-4d09-9054-ac550d985cf4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5731823-9b88-4d10-be11-b2a6c99e4a67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a4d1e69-130f-4d0e-88c4-492dad29798b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1730787-ea35-4bdc-95fe-ea49ae1b6146
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e6103c7-d71d-4b6a-af0b-29b526ed4094
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22070c47-0eb8-46ac-9a90-8b43ff8b3327
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95908788-9ee7-420c-9ea2-067b9b5f870e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 685d24db-2b5b-48fd-bb96-ef88da5d0dca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de0b6572-fc71-47b6-984d-5b4b36d97b23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a7989ef-5602-4ed0-a634-1546754de3d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f55c53d8-802d-40e4-b8f4-232a4050d0e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9316407-2c36-4e6c-b842-b6e778d22b1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eeda319c-5521-4058-8c5d-3fd4be9c3d0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49864980-5995-4450-94bf-de9a994b7f8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf48a605-4a54-4769-8559-f8800a9cfadc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a50059ab-7b99-49be-be94-d09bc7a8fa1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4a1800e-b0e7-4140-967b-b0fb57087c17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb5de696-88b0-453e-9478-e0df49be5ad4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb8b7bbb-a2d4-46cf-b8d3-8feb2660d4e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0770d1f2-1ea9-4d75-abb2-0d62964cc41f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 807a31de-dcf5-42eb-b2d0-f0c062b07db6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 073d5449-3ece-4848-be8e-2660c3ca778b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd8633b4-5957-49d9-a8b7-220c3b914017
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87974eff-886e-4fa8-b152-1b679bc23b3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89a1bb30-9950-4d84-8c3a-475f5ae46d16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5daf8c8f-8749-4dea-9a63-06955ae60d06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e00f404-65bd-4640-b0ed-0418264c3d74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca07a056-490e-4f0a-adc4-7f99d9bb9567
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bba14b3a-6f03-472f-9e85-c422d4a29f25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c0f588c-a734-4140-aaa5-998a43f09e43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4790d73-7f2a-45e1-b42b-a5eb29fc50a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9fd3bd7-4e2f-4155-987a-bda3c2a78a23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e119de86-6ea4-4dee-ab9b-740ca0ebdf7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60e4a619-f345-4761-a021-76bef2e207f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1911dce-e34f-42ee-b301-ecd5b97f3a0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84a56f9a-5642-4a4a-ad6b-78c58babb536
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29abceae-29e9-4cf2-b246-77530bdd3e9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4bfd8a2d-758f-4a2d-b5bc-2f28604f6bbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d684ebba-5961-415e-b657-712a5447072d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f621f09-a3d4-455a-b857-e8de4cdaccdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 189b26dd-4215-47a4-b10a-dedb3afe6b50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f17bbbc-1bb8-4679-87ed-1bd5d8778a44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6e5094c-c971-4527-8003-a6b5ece45fd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a83db38-6490-4c01-bf00-326fba042b4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f8c6624-4ddc-4161-a711-1226ba7dfeaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7fb09b2d-c054-456e-8b70-031d6f85ef72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15e21965-83f2-4c57-a10d-183ce5c055b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8939869-8cf1-46ec-837f-2da7f0886e49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5027d8a-0ed5-4413-af1a-08e8f0c3237b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f746a479-f0f6-4cef-96a8-5290eb57ee40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58f39d5a-e4a3-4078-ac18-eb05b8d30163
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfe4ca7f-8af7-40f5-98d0-ef477aaa8335
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f2200ec-c67a-4e0f-b1f4-6ca7f64eb32f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6330c43b-90a6-41a9-9760-ce014d6df0fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e60d6b1-eff5-4489-ae67-91a1410e5e11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 393b7186-c406-4ba1-a81f-9394d6a08c38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 047992e3-1000-4b91-b068-e176bb783d7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b5e3305-d3a8-4786-b90f-8e43663a2e1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9fd2972-3ea6-455b-bda2-0c7c4b85b07c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6dfa2720-0bee-4722-a610-1bfe119fe9e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c3b7dd0-29fc-45cf-882b-b12728fc688a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c578c61-846b-46d8-a7ba-92ec7526bcc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2560987b-ab0d-415e-9904-6d1aa6008a30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c9b4a53-b0d0-44f0-b7fc-c9bb7c064617
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e33aed7-1d0f-4347-8bae-e0b5e988d7c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca7d5386-2bbb-4c2e-9bf9-cb913bd5eb4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55be5805-4474-48ce-9500-c7b54b058c42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1a7bd19-c490-469c-963b-5bc5662b4754
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7ce21b1-dc23-4902-a77c-4d7c48a04641
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f94326b-862b-490a-94ea-667a59e575ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a72feae-f2d2-4ca7-83af-e6e2e5d8a858
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c99ab9c-ee31-476e-beab-6c97962ad79b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aef034a2-ddcf-48ca-8173-0d77c279c79e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0db1f1a2-3faa-497e-8fe8-8a35e10b0ae1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0840ef09-97f2-439f-8c63-26cafc448124
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 329e0681-b6c9-4419-984f-0e2879c9dc7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66df4aa4-b368-4665-b6f2-0935d30f0908
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53ab0fc0-41c4-4dc0-b9fc-f79588a130bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5197204e-5744-4412-860f-77ef2aad37f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb4fd159-f4d9-4cd2-934f-f52a295707b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 921b7299-5aa0-4581-bb32-e2e83f1ea39e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3da24837-6a50-45f6-bfa1-8f09c106d031
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a9d0832-5a63-4180-b2af-85a76140d4a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8203586-054f-4f0a-9459-070e619899b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17e5c3a5-1ab5-4df6-b782-440bdaf16f3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b5adb98-99d1-4340-b99c-b732c3c5ba1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7de12304-3765-4545-b247-d805811a470c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cea1af33-3055-4e18-93db-deb9ea2798a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ead9c18b-4561-40df-8183-7307bfa5dbfd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86f18d54-d004-401e-9e45-cefb0e0800c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3ac4739-4e5a-4364-8558-eeb7ae34775e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b2700aa-4300-4955-9a61-28a8485a22a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ce84749-9953-442a-9628-4c6f61c62b0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 532a5434-3e99-4251-abba-e2725ce38739
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f2011e7-516b-419a-949a-9d9b0cb1735d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63568a74-b07a-4500-86e1-be09a7e72be7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c176635-55dc-49b8-917d-34ecd4061241
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6dad711c-5827-426e-ad90-ab9165a91635
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c70885df-55f7-47c3-b28d-969523992bfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40b8bc14-d4f4-496e-8fc3-0bc6dd04264b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1cef295c-3fb1-4515-b91c-f51eccbab4fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72968992-ca93-4c49-9836-0c2b0087c4d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37111bf3-fa80-462d-8250-07fff017df96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01fccb39-079d-4e11-89dd-6f8abe5936df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 022d9ff5-cd6e-4c9d-b88f-112a6d89cdcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b672cd0c-5807-413c-9d3f-103cac1c4505
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2cb7cd0a-270d-448c-9d83-59bb6542e10c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16635ce1-b54c-4e03-97e4-e0a558e43779
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02f63675-a61d-4dd5-9d2a-bc1f9a2c45c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20bc3db8-a994-4e28-9cad-da3cbc8abe53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba5e2f0a-f12a-4738-90ce-480a36cab10f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb7b0ab2-00b1-4496-8a02-29bff03ee03b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00405192-2f78-4e7c-bcf8-765f1f0cfc92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 405e144e-5985-4bef-9ad2-9f1d8a1cd44a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f19c534-8e4e-444a-9c75-2e07eab11a00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44fc88b0-18b1-4cd5-9e6a-88b30bef60ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2757e2a9-20e2-4b7d-8e16-5e9388014a8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43362c63-a255-48b5-9eda-ecbd244e63ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4aff0fbb-afba-4902-82ac-78c11a8c19e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9f58458-0140-46d1-a796-2e03fea2e7fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30c8b7d3-b3d1-47bb-a53e-2bda63084878
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c4a2418-61e5-4753-9433-129eaba212f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2cdb8d6a-e12e-4fa1-a8f7-915cfcd70607
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb7335a2-1772-4dfa-a048-613d09df10e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ec197ae-e1ad-433b-aea2-39f301411861
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b57ad01-232c-469a-aa78-fd82caa02985
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b56dd0c-79bc-4546-9f3e-7f1d7c505921
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26491148-9752-463b-8cda-dfd4cbb5720e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37bcdcc9-3abc-4852-9add-26b48be95cbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f03b238-55e0-44c8-a37b-22eb32d099c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85a6229e-2226-4673-80bb-1bc0c7f84f12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80c43f93-9a2a-4309-bf33-4291ca7e2c91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 826ed901-7340-4921-9669-8fa2096d5056
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 283ba1c5-c088-49b6-a580-743c9c643f73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c1c1dd2-b328-4279-a361-aecd872f4ebe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9084fbb6-0bc4-4b16-9fd3-728d497d7630
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23ec55f7-b887-4a8d-a146-f4aebedeef5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a634b46-7a0b-44c7-8f0c-1bcae88effba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 423c62ff-7b10-481e-ac03-fd78c4b6e1a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 618716ba-01e7-4eb1-974b-0a2edb2257e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01a275a3-6956-429f-b457-fbcc1dba3a59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b995b60-10a2-4977-a177-9bb65f29363d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8d0cbd1-f404-44b8-bc92-8347b3874a48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92e2bbfa-6e7d-4a4a-8994-5a2358a0886c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21d17baa-3839-4a16-93c9-c406107b6fb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1dc9c87-26af-41c1-a3d8-98ef8a024a6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bcc7600a-1d63-4605-8d04-efd851ed5191
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd9d649a-84c8-4c66-a17f-738ad0496e5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5c7cb05-0df4-4af4-9206-eac0b1ae107e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5c96e5f-1ac9-468f-aac8-a4cfc064147d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfa41a92-7e20-4d92-9f7e-d7d3d58d325a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa237b6a-6906-4aa5-b222-d346c4dbf93a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 056ec9a8-91fe-47e1-b0cb-573c84050394
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c406fce-8623-4e76-9ac0-ba72ed54a9d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11680525-593a-421c-9af7-515f14d9f99e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 686ab1cb-4d3a-4449-99cb-2163fc47a3d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 300c1658-c0d8-4760-a52d-97dcde79d503
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a575a53-d30a-474f-a80c-bf250ef85258
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd248eb5-23e7-4774-b7ed-7c8df7f0de92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a8ee15c-dec0-4e8a-8d1f-5b8f862ee931
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b79b0d5a-12a8-4f11-bfb0-e035cb53e167
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02e7def2-0ec2-4bf4-86de-b31e2d7c8d41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc825a0e-9485-4550-86f3-f8c26cb3f041
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3d5f05a-375d-4350-9fb4-0f5b8ee864c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 096b5ad9-988f-4379-aea9-4d092555782f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb624dff-b0e5-476d-97f1-dcdad3dbbbc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9504f6f-a664-46e9-b5a9-26417bb914ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6bd826cb-d16b-4bdb-a9af-30a44c7cfa6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2eb9e715-8ff2-4189-95a9-191a19b9c513
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5b5c23b-6970-4451-bf69-25340c6ebe62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e8779cf-2516-4f7b-a7c7-d10d961499d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5184e914-f210-44d6-8301-d28da8fd0d69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22b019a8-da52-45e7-a013-aa662a8309af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 684e2fdb-6c34-4513-9cfe-de08ea38a863
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1528666f-4dd4-4b04-9aa4-33523b5f6f3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 485bdeb8-648f-48b8-a637-63f155320f67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4decb20-c42b-4c80-96c2-f378c657a0ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dea89e13-2574-4ffa-a408-0af3d40f361b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37b70ab6-aafe-4b40-998d-6fa633521aba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73e03c95-8ef8-489b-a9fa-96d6467e54c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5c89251-5393-4467-aa9c-df3b66325d86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2439c7be-a0d9-4f4d-9843-41b5986dd351
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a1b1c23-c93a-4523-a46a-21520422f364
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7cd7b66d-9e6f-4a54-90f5-9f5b116676f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6fb6758-2aa6-45ff-9705-e1d0a7248b1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49136872-3356-45b2-9394-0f335abfd7c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ff3cada-acda-4900-9dff-ce3e1ae44ea7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63796d19-4df8-4b43-9fc6-5383deb83739
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35949977-e426-4903-8a47-edccc01ece8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 879d7fbb-c2a5-423e-bc90-ae1ba1891424
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9b1ee4f-af51-4888-8090-671899294864
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message afd2f046-93c0-4e92-be1f-34e58794998e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d62a0433-0ab5-429d-ad99-0ea0e9ee85f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80d7dc6d-9c86-4d15-ba6b-05a9014ac67a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 334aad24-6df1-4a02-90d8-0bcc30047516
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c826b679-c740-4e13-aa1b-8ec0c68485e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2df641ed-87c3-4207-9dc7-e1011b5dce47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2db593cd-0ff8-41ee-b266-a37907845d50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51bf5885-c76b-4620-ae36-43371f66402a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c42d0dd0-040a-459c-a17c-199f671ac966
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9c56a5b-eb17-4a27-9aeb-1dbeff375ed6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 507f4bb5-133a-43f7-b738-62cb7e00fdfa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ea1fd98-56b4-46bd-9483-98d9816fbe24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea8dc9a1-1149-48a2-965a-7473b3561f2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0842053-1166-470a-a7c8-ec9be09be365
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d93fb5c-2b43-4a3c-b28b-5fa2ad8664e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55135d6a-8d76-4ef7-8d3f-68545891553f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97029f6d-baa9-4d86-9f0b-ce38b41f3176
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6520900b-a978-4504-8e00-6119f4681f5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f07e8678-af80-45e7-8852-1a64000393db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a00a6ce4-8d68-4765-bee0-e8c26627516f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f7dc381-3ecb-4332-b935-225311437b4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0180dbc8-8288-47c3-84f0-7e3802b80693
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f90b2323-9c52-42bd-b57e-55cc7898aa14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b124f81-b0b3-4e3f-9965-219c13941b55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1131001-29af-4236-aa4c-9d4921fa68fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4408930-291c-453d-9de9-0bf69140148e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2cf12e8a-ab57-4dde-9a2c-90e0b61a25a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78981fb5-833e-43d3-bd47-da178f5f5230
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f6af3f3-3e86-4381-aa3b-ea4c2b11c278
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5bbf314d-9e75-41ef-b958-ee42aa6b5a3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9959b75-b642-4341-9560-27614e038e69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28b9247e-202a-4ae5-9c63-f7a4a11be8a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8aeaf1a-e0c5-47b6-ab36-9eeb8d1d1dbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb619796-b19b-41ec-9ae1-cab68d251b16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8606cba2-9df5-43f0-8908-aea6a636fdfd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8462f57d-7a18-4caa-9f48-ac117acb8513
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7cc2d73-a6af-452a-9605-28b965e1416d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af6b315b-7898-4179-8a5b-c69e20bef40a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23ad8044-4983-4af9-aa39-fbfce7da6d77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68f4e9f6-f61b-49da-9601-e4cf061cfd42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ca2a3c1-b89c-48c7-a75b-a5f7c9bc5a0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b16f81e6-dffd-4e08-8f83-8333116a1e83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4628635a-dd76-4132-9666-49096a14f4a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 978c39a0-ca11-4abb-b5c5-750c6af09a7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 938152e9-7aef-4f08-a5df-f486d39801a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5f046a1-49a6-4ba9-a8dc-b93f35f1f5f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e52e07f-5031-4d1c-89d9-e1cd8e90da95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea429467-3ca4-4199-a41f-279ca0b1ea8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8199f8ff-6628-4d88-b6ef-d7017d0539c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd859edc-a31d-4f12-91fc-f88f50229740
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8678a4b8-da73-43a1-8613-a7f622d579e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52bd67f4-f8ec-4be4-9799-a5057d40c299
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8803e626-0872-4a04-869c-95c684ac76fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 136ade44-86bb-49f1-8a6e-a2492671b1a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 368d0642-f5ae-4d14-95cc-d6e8e53301b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53e97e31-c5b4-44fd-bb10-0f6f881f6372
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8dcaf0c-9880-4f1e-8856-221b6544c9ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb16e776-c80e-46c8-8fa6-bbcfb94faf29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01d3fa95-e552-4f48-b384-9b78f3f63bbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb415f8d-620c-4ccd-b90b-51c9e6f666ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea55d252-2191-4370-9d27-baf00a318f58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30986f10-49b4-4bd2-a70d-2f2bfc6f46f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1dc4cd9-dc2c-4ceb-8a43-164ba1bdea2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4de657b-486c-4db5-b1d3-43924914a208
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0aa35f78-556c-4ed5-a942-c9912f8994ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7569317d-2828-4bf1-9b33-6848fa021e03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e666e8d-5969-4d78-9eb5-b20ca609443d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14af0c1e-5a2e-4314-ba1b-58861faf1ac0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be81ded6-df12-4183-8b10-281e1c6a12c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 582ca03c-c83e-4499-859c-c19bdf5dfa89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7b41653-146d-45a7-b087-3b8c25461452
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bfb3b18c-6739-4cbc-9fee-383e5cc851a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db9597b2-1b0d-4746-9eac-aa353b5abbf9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86474429-27b7-4cfd-9463-5f9140e20ecf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 154fbfeb-e1e5-40af-a4f6-56ddc060ea64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9db708e7-9cd2-408e-a195-715d5ddcb9d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6bb96541-4a0a-4841-92f6-77ea25e78721
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fcfddf57-b537-4481-8bfe-7fb4a3f39bc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4a6da3b-a41e-42f7-b3b1-07802f2da499
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c670252f-c558-4f8a-95ec-fec3a5c9416f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a816b66b-f0b2-4b2c-9db5-3b1224abbfbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e714fcab-7a67-4eb5-b297-d92b318099f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfb8900b-cfd1-4973-b989-c3f488935776
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5335a93d-925c-4db2-a721-7fbd1d3469de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4aedfea9-c65c-4cb5-a49a-d6b6d15d315d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c9bc33d-f2f3-42ca-a072-56899c408a54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71dd925f-f768-4b07-9981-94e607baa4f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ad25efb-6f58-4e3b-b39d-bd451a21f3d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59f8cfec-de0f-4545-a739-1533590db6ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f721a5e-e87b-4572-a9b1-af843f4d252c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 668d3d96-eb43-42a4-9896-2282f2a0566a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49df2dc4-9e30-4c29-b637-520d88f5d61b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2fe4e2ba-5395-4750-8cc1-2eb5166296f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4799527-076c-4c19-acfa-8334e0145186
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce25ea08-9d63-430c-bd50-611ee4db30be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45e4c4af-3609-4868-b26d-7cac6ba00abe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0843ecff-8c87-4e8b-b8b2-feab73951cdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87638c01-8ed7-4989-89ac-6fb88d899fa8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60bdbc5d-05c4-4343-9646-b59dadcb3557
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8e45b8c-4fd9-4d52-be07-96def7b413a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52ec1531-1c50-4d57-8293-dfde59833a2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06300b80-99f8-49e7-9728-a52d2f2a61f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef57eab2-62b4-4c30-95cd-e893db4d1bb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8621f274-df29-4c2c-961f-39e1790e0909
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a744bdaa-c259-46b3-9631-d796711b7af5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dac53436-eb08-47be-a210-85f87762659c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c6e8b3a-124e-4e5c-9456-625f19c7c204
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5be27edc-b8ff-4d47-8a1f-f02e74f18d83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90b79048-fa30-4eac-997f-9e77ce318018
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a6eac85-e71b-4b3c-a682-7a4d0cd82ac5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db32fa59-68fd-4bce-ab4f-bbdcb455cba0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce9c9937-d64e-4845-88be-49fbd4ef518e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c830689-8519-4acc-8d65-569b2d32c96f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec71323b-787c-4500-8b8f-ebb51de8e512
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9c379e2-ef2b-4a5d-bab0-2d618c0249ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d82ad78-52c5-4ab7-8402-228726db50d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c1ee4c7-d4f9-4a11-bfff-e8f1eb1d942c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b05254df-c14b-4541-bcb3-9d81e2f66f52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb743adc-aa0f-40e0-a63d-ec358febe19e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ddccd8e6-0e9b-4b1f-ae8b-eb872ae2ee27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b738c46-c9f6-4354-b44a-439a624f31b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55f78ac2-1387-44ac-a6bb-c8d88f7528e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b0d3011-aa48-41bf-9408-7610c2d30996
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 818afe14-7973-4170-92c9-500f16c180c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 276f4848-65ed-4275-a9d0-38dac7664157
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58280ecb-d368-4868-a3f9-e29000ca5ee6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5a67e62-9ec2-4610-b772-d661f7c72dff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1bc1760d-29d3-4b0b-aa3f-45cd0777881a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da26a5b5-9291-4f66-a27e-c254c8e1747f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2bcf2646-c5ad-414c-b199-6a357ed50869
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5191db44-adf2-48bd-b865-53ee1fc20afc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f374698-bc95-4dad-8f0d-36025ad2153c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10263235-2c1b-4647-96f4-b5bcb70f7403
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6b50dbf-4d17-4c33-aa6d-0764fcca56e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 855279ff-9f71-4074-bf02-82a97206e16a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e91b535-7231-4921-aab1-6c1c39962986
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1546fe4e-fd1a-435c-88cf-465c3d614d5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15cd4afd-b957-4b8a-8410-312b37481780
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1fd0013a-5bea-4a00-bf51-a233c859263e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1943b1bd-47f2-46a1-a271-ca0d40757073
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a38c89bd-3a4c-4f11-acd1-cd8e347503e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 736d09a0-6fa4-4808-bf0d-c914d7fbae4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ce4c27b-5384-4084-aa98-17c28b42c17b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ccd82d1-1c83-458b-805d-cf87be853bd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 035ac8cb-2933-41c5-bcc2-d75b1aa482d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f62c122-f606-4bb2-b959-3e2196ae83fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e07b4a38-44b4-4797-93f3-ed273c444736
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 288d6d80-f251-4d70-930b-a388a66738f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 285d4efe-0e2b-48b7-b845-52c06e8b69f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5a3a490-db12-45ca-8b8f-e355be6cd60f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea7459c4-5d06-4baa-9922-70788da25870
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 885d710c-30f7-4423-bfc2-8e072b284e92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 454f5cf6-c1e5-4890-8a7e-3e03d61be0a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c2be637-34f5-4765-8532-bb51921af761
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b6b1346-78b8-447f-9e7f-7204cec0184a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 539c2b5f-2c12-4575-b72c-5319fa184a7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3fad4bbb-dcbe-4ebb-990d-ae0110eab9c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5041eec5-9fd9-4e7f-bdef-a75ee1f49502
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c528214b-7fa1-482a-98c8-b22e21238eef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8500a2f0-e817-43a5-88b4-7501ebe3e30a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3080df88-7c3f-4f48-a912-cc2d9ff7f831
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c49bd19-ae12-4219-bbfc-21f8d154074b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70b452cc-6cb8-47ea-bea5-af945e0639e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45f11ce3-749a-404f-baeb-a1888b77ed3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c1c4837-c18b-4128-95e6-f5eb16b753c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd3042eb-2d4d-4bd1-9d89-d025e4e526dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1efcd7e7-bcc5-486f-b10f-8be76a492297
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73a3fcea-53b8-4a14-9498-fab2877ec743
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a74e85ec-f48c-4fdf-9000-8de618dd31ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1fa45f49-6538-4f3c-bfd6-81a0331f8015
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22a9eeef-9025-496f-8a05-4842410fddd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e411fca-9692-4a75-869c-7e07b7cf3102
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05b48102-c4f3-4b54-8267-a2a004477457
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42dd976c-572f-4884-9a0a-1359cfe6e752
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b49062c-b153-4af8-910c-0e4eab0e66ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a532d086-cb19-48c5-aa8e-e01478babd52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c61f779-2241-4ac4-993f-266643832040
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9239db0-84f9-49f9-9153-d53940303c0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6eef34c-b185-4c9b-9f92-ffac3be5e965
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3673b9c4-fb67-48e9-9fb5-fce0b2a2ccf5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2be394f8-f5b8-45f5-a11c-2418316b1875
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 754ce13f-d927-4405-8eb1-2130410218e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 618d4102-907d-4716-80b8-78a5cf99867b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfe216a3-8d36-4d7c-91a3-4531ddff0f61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86000b57-f3f5-4a52-98bb-ed8a30eac73d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 051cc218-88e3-4534-a4c9-8545364c78ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c84cf12-cbf7-4ced-86b2-878f91fd3be3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa53aed6-51b5-4377-83f7-ad8eb6002d83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9122714-6cf8-444b-b92c-c0a2f8667334
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39234545-bc25-4ba1-84cc-c76f88d0edcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8dad635c-cd5b-4d71-aae1-03adc2824110
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60827de2-c586-4254-835b-2df73e1c4319
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 867c7061-3e48-46a1-a337-06541f31e0a8
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8690 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_21
Server: localhost:8690
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_21
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_21/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_21/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_21/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_21/test_labels.txt

📊 Raw data loaded:
   Train: X=(4800, 24), y=(4800,)
   Test:  X=(1200, 24), y=(1200,)

⚠️  Limiting training data: 4800 → 800 samples
⚠️  Limiting test data: 1200 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_21 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2421, R²: -0.0010

============================================================
🔄 Round 3 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0842 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0782, val=0.0835 (↓), lr=0.001000
   ✓ Epoch   3/100: train=0.0779, val=0.0816 (↓), lr=0.001000
   • Epoch   4/100: train=0.0764, val=0.0817, patience=1/15, lr=0.001000
   • Epoch   5/100: train=0.0760, val=0.0820, patience=2/15, lr=0.001000
   📉 Epoch 9: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0723, val=0.0841, patience=8/15, lr=0.000500
   📉 Epoch 17: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 3 Summary - Client client_21
   Epochs: 18/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0756, RMSE=0.2750, R²=0.0003
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0025
============================================================


📊 Round 3 Test Metrics:
   Loss: 0.0794, RMSE: 0.2819, MAE: 0.2425, R²: -0.0063

============================================================
🔄 Round 5 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0752 (↓), lr=0.000250
   • Epoch   2/100: train=0.0773, val=0.0753, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0773, val=0.0750, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0771, val=0.0752, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0770, val=0.0752, patience=4/15, lr=0.000250
   📉 Epoch 9: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0765, val=0.0751, patience=10/15, lr=0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 5 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000125 (1 reductions)
   Train: Loss=0.0770, RMSE=0.2776, R²=0.0035
   Val:   Loss=0.0752, RMSE=0.2741, R²=-0.0201
============================================================


============================================================
🔄 Round 6 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000125 → 0.000063
   ✓ Epoch   1/100: train=0.0756, val=0.0799 (↓), lr=0.000063
   • Epoch   2/100: train=0.0755, val=0.0799, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0755, val=0.0799, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0755, val=0.0799, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0755, val=0.0799, patience=4/15, lr=0.000063
   📉 Epoch 9: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0754, val=0.0798, patience=10/15, lr=0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 6 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000125 → 0.000031 (2 reductions)
   Train: Loss=0.0757, RMSE=0.2751, R²=0.0036
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0023
============================================================


============================================================
🔄 Round 7 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000031 → 0.000016
   ✓ Epoch   1/100: train=0.0738, val=0.0876 (↓), lr=0.000016
   • Epoch   2/100: train=0.0738, val=0.0877, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0737, val=0.0877, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0737, val=0.0877, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0737, val=0.0877, patience=4/15, lr=0.000016
   📉 Epoch 9: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0736, val=0.0878, patience=10/15, lr=0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 7 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000031 → 0.000008 (2 reductions)
   Train: Loss=0.0738, RMSE=0.2717, R²=0.0032
   Val:   Loss=0.0876, RMSE=0.2960, R²=0.0003
============================================================


📊 Round 7 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2421, R²: -0.0018

============================================================
🔄 Round 8 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000008 → 0.000004
   ✓ Epoch   1/100: train=0.0756, val=0.0809 (↓), lr=0.000004
   • Epoch   2/100: train=0.0756, val=0.0809, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0755, val=0.0809, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0755, val=0.0809, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0755, val=0.0808, patience=4/15, lr=0.000004
   📉 Epoch 9: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0755, val=0.0808, patience=10/15, lr=0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 8 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0755, RMSE=0.2748, R²=0.0017
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0056
============================================================


============================================================
🔄 Round 9 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000002 → 0.000001
   ✓ Epoch   1/100: train=0.0752, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0752, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0752, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0752, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0752, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0752, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 9 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0751, RMSE=0.2741, R²=0.0034
   Val:   Loss=0.0823, RMSE=0.2870, R²=-0.0008
============================================================


📊 Round 9 Test Metrics:
   Loss: 0.0790, RMSE: 0.2810, MAE: 0.2420, R²: -0.0005

📊 Round 9 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2419, R²: 0.0002

============================================================
🔄 Round 12 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0750, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0750, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0750, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0750, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0750, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0750, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 12 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0751, RMSE=0.2741, R²=0.0028
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0024
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2419, R²: 0.0006

============================================================
🔄 Round 14 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 14 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=0.0029
   Val:   Loss=0.0735, RMSE=0.2711, R²=0.0091
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2418, R²: 0.0008

============================================================
🔄 Round 16 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0745, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0745, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0745, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0745, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0745, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0745, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 16 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0744, RMSE=0.2727, R²=0.0057
   Val:   Loss=0.0847, RMSE=0.2911, R²=-0.0051
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2418, R²: 0.0009

📊 Round 16 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2418, R²: 0.0009

============================================================
🔄 Round 20 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 20 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2755, R²=0.0047
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.0031
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2418, R²: 0.0009

============================================================
🔄 Round 22 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 22 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=0.0060
   Val:   Loss=0.0747, RMSE=0.2734, R²=-0.0030
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0010

============================================================
🔄 Round 27 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 27 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2767, R²=0.0030
   Val:   Loss=0.0760, RMSE=0.2756, R²=0.0057
============================================================


============================================================
🔄 Round 29 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 29 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2766, R²=0.0043
   Val:   Loss=0.0763, RMSE=0.2761, R²=0.0057
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0010

============================================================
🔄 Round 37 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 37 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2754, R²=0.0020
   Val:   Loss=0.0789, RMSE=0.2809, R²=-0.0027
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

============================================================
🔄 Round 44 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 44 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2757, R²=0.0032
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0058
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

============================================================
🔄 Round 45 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 45 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2751, R²=0.0037
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0070
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0010

============================================================
🔄 Round 48 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0754, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0754, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0754, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 48 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0754, RMSE=0.2745, R²=0.0029
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0022
============================================================


============================================================
🔄 Round 49 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0692 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0692, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0692, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0692, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0692, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0692, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0692)

============================================================
📊 Round 49 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2797, R²=0.0046
   Val:   Loss=0.0692, RMSE=0.2630, R²=0.0002
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0010

============================================================
🔄 Round 53 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 53 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0058
   Val:   Loss=0.0730, RMSE=0.2702, R²=-0.0056
============================================================


============================================================
🔄 Round 54 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0722 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 54 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0041
   Val:   Loss=0.0722, RMSE=0.2687, R²=-0.0028
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0010

📊 Round 54 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0010

============================================================
🔄 Round 58 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 58 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2781, R²=0.0036
   Val:   Loss=0.0728, RMSE=0.2699, R²=0.0084
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

============================================================
🔄 Round 63 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 63 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2749, R²=0.0033
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0020
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

============================================================
🔄 Round 64 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0754, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0754, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0754, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 64 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0754, RMSE=0.2745, R²=0.0014
   Val:   Loss=0.0808, RMSE=0.2842, R²=0.0082
============================================================


============================================================
🔄 Round 65 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 65 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0038
   Val:   Loss=0.0726, RMSE=0.2694, R²=-0.0005
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

============================================================
🔄 Round 68 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0755, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0755, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0755, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0755, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0755, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0755, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 68 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2753, R²=0.0037
   Val:   Loss=0.0791, RMSE=0.2812, R²=0.0039
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

📊 Round 68 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

============================================================
🔄 Round 71 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 71 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2781, R²=0.0047
   Val:   Loss=0.0728, RMSE=0.2699, R²=0.0010
============================================================


============================================================
🔄 Round 72 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0710 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0710, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0710, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0710, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0710, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0710, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0710)

============================================================
📊 Round 72 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0050
   Val:   Loss=0.0710, RMSE=0.2664, R²=0.0029
============================================================


============================================================
🔄 Round 73 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0747, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0747, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0747, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0747, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0747, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0746, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 73 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0745, RMSE=0.2730, R²=0.0059
   Val:   Loss=0.0840, RMSE=0.2899, R²=-0.0162
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

============================================================
🔄 Round 74 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 74 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2751, R²=0.0040
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0022
============================================================


============================================================
🔄 Round 76 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 76 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=0.0024
   Val:   Loss=0.0755, RMSE=0.2747, R²=-0.0030
============================================================


============================================================
🔄 Round 77 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0675 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0675, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0675, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0675, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0676, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0676, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0675)

============================================================
📊 Round 77 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0040
   Val:   Loss=0.0675, RMSE=0.2599, R²=0.0050
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

============================================================
🔄 Round 78 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 78 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2753, R²=0.0023
   Val:   Loss=0.0791, RMSE=0.2812, R²=-0.0188
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

============================================================
🔄 Round 80 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0754, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0754, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0754, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 80 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0755, RMSE=0.2748, R²=0.0039
   Val:   Loss=0.0802, RMSE=0.2831, R²=-0.0151
============================================================


============================================================
🔄 Round 81 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0751, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0751, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0751, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0750, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0750, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0750, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 81 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0749, RMSE=0.2737, R²=0.0026
   Val:   Loss=0.0825, RMSE=0.2873, R²=0.0114
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0010

============================================================
🔄 Round 83 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0742, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0742, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0742, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0742, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0742, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0742, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 83 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0740, RMSE=0.2720, R²=0.0035
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0045
============================================================


============================================================
🔄 Round 84 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0755, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0755, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0755, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0755, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0755, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0755, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 84 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2749, R²=0.0044
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0049
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0010

📊 Round 84 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0010

============================================================
🔄 Round 86 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 86 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2755, R²=0.0049
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0026
============================================================


============================================================
🔄 Round 87 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 87 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0048
   Val:   Loss=0.0737, RMSE=0.2714, R²=0.0008
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

============================================================
🔄 Round 89 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 89 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2770, R²=0.0044
   Val:   Loss=0.0754, RMSE=0.2745, R²=0.0030
============================================================


============================================================
🔄 Round 90 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 90 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2770, R²=0.0058
   Val:   Loss=0.0752, RMSE=0.2742, R²=-0.0007
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

============================================================
🔄 Round 92 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 92 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0754, RMSE=0.2746, R²=0.0046
   Val:   Loss=0.0805, RMSE=0.2838, R²=0.0005
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

============================================================
🔄 Round 95 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0689 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0689, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0689, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0689, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0689, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0689, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0689)

============================================================
📊 Round 95 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0050
   Val:   Loss=0.0689, RMSE=0.2626, R²=0.0015
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

📊 Round 95 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

============================================================
🔄 Round 98 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 98 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=0.0062
   Val:   Loss=0.0755, RMSE=0.2748, R²=-0.0018
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0010

============================================================
🔄 Round 99 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0743, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0743, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0743, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0743, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0743, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0743, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 99 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0744, RMSE=0.2727, R²=0.0042
   Val:   Loss=0.0848, RMSE=0.2911, R²=-0.0013
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

📊 Round 99 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

============================================================
🔄 Round 103 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0752, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0752, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0752, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0752, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0752, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0751, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 103 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0753, RMSE=0.2744, R²=0.0067
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0039
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

📊 Round 103 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

📊 Round 103 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

📊 Round 103 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

============================================================
🔄 Round 109 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0743, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0743, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0743, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0743, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0743, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0742, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 109 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0742, RMSE=0.2725, R²=0.0050
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0064
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

📊 Round 109 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

============================================================
🔄 Round 112 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0729, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0729, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0729, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0729, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0729, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0728, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 112 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0728, RMSE=0.2699, R²=0.0041
   Val:   Loss=0.0909, RMSE=0.3015, R²=-0.0042
============================================================


============================================================
🔄 Round 114 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 114 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2785, R²=0.0041
   Val:   Loss=0.0720, RMSE=0.2684, R²=0.0055
============================================================


============================================================
🔄 Round 116 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 116 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2762, R²=0.0047
   Val:   Loss=0.0770, RMSE=0.2775, R²=0.0047
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0012

============================================================
🔄 Round 117 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 117 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2764, R²=0.0026
   Val:   Loss=0.0766, RMSE=0.2767, R²=-0.0548
============================================================


============================================================
🔄 Round 118 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 118 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0755, RMSE=0.2747, R²=0.0030
   Val:   Loss=0.0804, RMSE=0.2835, R²=0.0101
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

============================================================
🔄 Round 120 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0747, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0747, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0747, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0747, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0747, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0747, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 120 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0749, RMSE=0.2737, R²=0.0039
   Val:   Loss=0.0827, RMSE=0.2875, R²=0.0073
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

============================================================
🔄 Round 123 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 123 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2774, R²=0.0039
   Val:   Loss=0.0745, RMSE=0.2729, R²=0.0047
============================================================


============================================================
🔄 Round 125 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0722 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 125 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0041
   Val:   Loss=0.0722, RMSE=0.2686, R²=0.0044
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

============================================================
🔄 Round 126 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0699 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0699, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0699, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0699, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0699, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0699, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0699)

============================================================
📊 Round 126 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=0.0042
   Val:   Loss=0.0699, RMSE=0.2644, R²=0.0019
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

📊 Round 126 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

============================================================
🔄 Round 131 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0741, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0741, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0741, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0741, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0741, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0741, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 131 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0740, RMSE=0.2721, R²=0.0041
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0079
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

============================================================
🔄 Round 132 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0753, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0753, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0753, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0753, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0753, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0753, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 132 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0755, RMSE=0.2748, R²=0.0034
   Val:   Loss=0.0801, RMSE=0.2831, R²=0.0078
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

============================================================
🔄 Round 134 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 134 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=0.0052
   Val:   Loss=0.0735, RMSE=0.2712, R²=-0.0150
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

============================================================
🔄 Round 135 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0706 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0706, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0706, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0706, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0706, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0707, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0706)

============================================================
📊 Round 135 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0045
   Val:   Loss=0.0706, RMSE=0.2657, R²=-0.0069
============================================================


============================================================
🔄 Round 136 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0739, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0739, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0739, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0738, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0738, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0738, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 136 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0742, RMSE=0.2723, R²=0.0058
   Val:   Loss=0.0856, RMSE=0.2926, R²=0.0007
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0010

============================================================
🔄 Round 138 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0751, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0751, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0751, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0751, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0751, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0751, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 138 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0749, RMSE=0.2737, R²=0.0055
   Val:   Loss=0.0825, RMSE=0.2873, R²=0.0006
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0010

============================================================
🔄 Round 140 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 140 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2757, R²=0.0061
   Val:   Loss=0.0781, RMSE=0.2794, R²=-0.0018
============================================================


============================================================
🔄 Round 141 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 141 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2756, R²=0.0048
   Val:   Loss=0.0783, RMSE=0.2798, R²=0.0038
============================================================


============================================================
🔄 Round 143 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 143 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=0.0023
   Val:   Loss=0.0746, RMSE=0.2732, R²=-0.0099
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0010

============================================================
🔄 Round 144 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0736, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0736, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0736, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0736, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0736, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0736, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 144 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0736, RMSE=0.2714, R²=0.0044
   Val:   Loss=0.0877, RMSE=0.2961, R²=0.0056
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

📊 Round 144 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

📊 Round 144 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

============================================================
🔄 Round 147 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 147 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2749, R²=0.0053
   Val:   Loss=0.0798, RMSE=0.2826, R²=-0.0051
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

📊 Round 147 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

📊 Round 147 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

============================================================
🔄 Round 153 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0738, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0738, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0737, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0737, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0737, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0737, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 153 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0736, RMSE=0.2713, R²=0.0057
   Val:   Loss=0.0879, RMSE=0.2964, R²=0.0007
============================================================


============================================================
🔄 Round 154 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 154 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2750, R²=0.0030
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0066
============================================================


============================================================
🔄 Round 157 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0746, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0746, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0746, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0746, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0746, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0746, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 157 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0746, RMSE=0.2731, R²=0.0041
   Val:   Loss=0.0838, RMSE=0.2894, R²=0.0068
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

============================================================
🔄 Round 159 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0744, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0744, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0744, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0744, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0744, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0743, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 159 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0746, RMSE=0.2731, R²=0.0036
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0253
============================================================


============================================================
🔄 Round 160 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0696 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0696, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0697, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0697, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0697, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0697, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0696)

============================================================
📊 Round 160 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0032
   Val:   Loss=0.0696, RMSE=0.2639, R²=-0.0157
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

============================================================
🔄 Round 161 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 161 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=0.0040
   Val:   Loss=0.0754, RMSE=0.2747, R²=-0.0078
============================================================


============================================================
🔄 Round 162 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 162 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2766, R²=0.0043
   Val:   Loss=0.0762, RMSE=0.2760, R²=0.0010
============================================================


============================================================
🔄 Round 163 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0746, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0746, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0746, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0746, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0746, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0746, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 163 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0749, RMSE=0.2737, R²=0.0036
   Val:   Loss=0.0825, RMSE=0.2873, R²=0.0085
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

============================================================
🔄 Round 167 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0755, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0755, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0755, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0755, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0755, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0755, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 167 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0753, RMSE=0.2744, R²=0.0039
   Val:   Loss=0.0810, RMSE=0.2847, R²=0.0032
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

============================================================
🔄 Round 169 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 169 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2752, R²=0.0029
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0009
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0012

============================================================
🔄 Round 170 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 170 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2785, R²=0.0030
   Val:   Loss=0.0720, RMSE=0.2683, R²=0.0082
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0012

📊 Round 170 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0012

📊 Round 170 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2417, R²: 0.0012

============================================================
🔄 Round 175 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0686 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0686, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0686, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0686, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0686, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0686, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0686)

============================================================
📊 Round 175 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0046
   Val:   Loss=0.0686, RMSE=0.2620, R²=-0.0014
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2417, R²: 0.0012

============================================================
🔄 Round 176 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0746, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0746, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0746, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0746, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0746, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0746, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 176 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0748, RMSE=0.2736, R²=0.0036
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0034
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0012

============================================================
🔄 Round 178 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0746, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0746, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0746, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0746, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0746, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0746, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 178 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0746, RMSE=0.2731, R²=0.0054
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0187
============================================================


============================================================
🔄 Round 181 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 181 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2756, R²=0.0031
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0052
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

📊 Round 181 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

============================================================
🔄 Round 183 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0735, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0735, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0735, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0735, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0735, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0735, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 183 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0736, RMSE=0.2714, R²=0.0049
   Val:   Loss=0.0876, RMSE=0.2960, R²=0.0034
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

============================================================
🔄 Round 185 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0699 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0699, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0699, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0699, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0699, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0699, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0699)

============================================================
📊 Round 185 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=0.0045
   Val:   Loss=0.0699, RMSE=0.2643, R²=0.0051
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

📊 Round 185 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

📊 Round 185 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

============================================================
🔄 Round 189 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 189 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=0.0035
   Val:   Loss=0.0756, RMSE=0.2750, R²=-0.0289
============================================================


============================================================
🔄 Round 191 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 191 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2755, R²=0.0044
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0058
============================================================


============================================================
🔄 Round 193 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0702 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0702, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0702, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0702, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0702, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0702, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0702)

============================================================
📊 Round 193 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0049
   Val:   Loss=0.0702, RMSE=0.2649, R²=0.0028
============================================================


============================================================
🔄 Round 195 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0733, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0733, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0733, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0733, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0733, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0733, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 195 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0734, RMSE=0.2710, R²=0.0060
   Val:   Loss=0.0885, RMSE=0.2974, R²=-0.0020
============================================================


📊 Round 195 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

📊 Round 195 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

============================================================
🔄 Round 199 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 199 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2785, R²=0.0046
   Val:   Loss=0.0720, RMSE=0.2683, R²=0.0008
============================================================


============================================================
🔄 Round 203 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0690 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0690, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0690, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0690, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0690, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0690, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0690)

============================================================
📊 Round 203 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0026
   Val:   Loss=0.0690, RMSE=0.2626, R²=0.0123
============================================================


============================================================
🔄 Round 205 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0748, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0748, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0748, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0748, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0748, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0748, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 205 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0749, RMSE=0.2737, R²=0.0044
   Val:   Loss=0.0825, RMSE=0.2871, R²=0.0046
============================================================


📊 Round 205 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0010

============================================================
🔄 Round 207 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 207 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=0.0054
   Val:   Loss=0.0746, RMSE=0.2731, R²=-0.0092
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

============================================================
🔄 Round 209 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0744, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0744, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0744, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0744, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0744, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0743, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 209 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0746, RMSE=0.2731, R²=0.0048
   Val:   Loss=0.0840, RMSE=0.2897, R²=-0.0047
============================================================


============================================================
🔄 Round 210 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0709 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0709, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0709, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0709, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0709, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0709, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0709)

============================================================
📊 Round 210 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2790, R²=0.0055
   Val:   Loss=0.0709, RMSE=0.2662, R²=0.0011
============================================================


============================================================
🔄 Round 211 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 211 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2761, R²=0.0056
   Val:   Loss=0.0773, RMSE=0.2779, R²=-0.0013
============================================================


📊 Round 211 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

📊 Round 211 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

📊 Round 211 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

============================================================
🔄 Round 215 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0750, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0750, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0750, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0750, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0750, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0750, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 215 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0752, RMSE=0.2743, R²=0.0050
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0121
============================================================


📊 Round 215 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

============================================================
🔄 Round 217 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0680 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0680, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0680, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0680, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0680, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0680, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0680)

============================================================
📊 Round 217 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0062
   Val:   Loss=0.0680, RMSE=0.2608, R²=-0.0023
============================================================


📊 Round 217 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

============================================================
🔄 Round 218 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 218 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2755, R²=0.0045
   Val:   Loss=0.0786, RMSE=0.2803, R²=0.0054
============================================================


============================================================
🔄 Round 220 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 220 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2776, R²=0.0038
   Val:   Loss=0.0739, RMSE=0.2718, R²=0.0033
============================================================


📊 Round 220 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

📊 Round 220 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

📊 Round 220 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

📊 Round 220 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

============================================================
🔄 Round 225 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 225 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2765, R²=0.0056
   Val:   Loss=0.0763, RMSE=0.2762, R²=-0.0003
============================================================


============================================================
🔄 Round 226 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 226 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2765, R²=0.0038
   Val:   Loss=0.0764, RMSE=0.2764, R²=0.0083
============================================================


============================================================
🔄 Round 227 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0745, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0745, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0745, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0745, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0745, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0745, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 227 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0745, RMSE=0.2730, R²=0.0064
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0062
============================================================


============================================================
🔄 Round 229 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 229 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=0.0049
   Val:   Loss=0.0758, RMSE=0.2753, R²=0.0038
============================================================


============================================================
🔄 Round 230 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 230 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=0.0043
   Val:   Loss=0.0756, RMSE=0.2750, R²=0.0034
============================================================


📊 Round 230 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

============================================================
🔄 Round 231 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 231 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2772, R²=0.0042
   Val:   Loss=0.0749, RMSE=0.2737, R²=0.0044
============================================================


============================================================
🔄 Round 234 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 234 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2783, R²=0.0040
   Val:   Loss=0.0723, RMSE=0.2689, R²=0.0039
============================================================


📊 Round 234 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

============================================================
🔄 Round 235 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 235 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2753, R²=0.0046
   Val:   Loss=0.0790, RMSE=0.2811, R²=0.0046
============================================================


📊 Round 235 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

📊 Round 235 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0010

============================================================
🔄 Round 239 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0696 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0696, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0696, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0696, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0696, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0696, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0696)

============================================================
📊 Round 239 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0058
   Val:   Loss=0.0696, RMSE=0.2637, R²=-0.0025
============================================================


📊 Round 239 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0010

📊 Round 239 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0010

📊 Round 239 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0010

📊 Round 239 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0010

📊 Round 239 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0010

📊 Round 239 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

============================================================
🔄 Round 249 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0712 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0712, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0712, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0712, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0713, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0713, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0712)

============================================================
📊 Round 249 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0033
   Val:   Loss=0.0712, RMSE=0.2669, R²=0.0101
============================================================


============================================================
🔄 Round 250 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0684 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0684, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0684, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0684, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0684, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0684, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0684)

============================================================
📊 Round 250 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=0.0036
   Val:   Loss=0.0684, RMSE=0.2614, R²=0.0090
============================================================


============================================================
🔄 Round 252 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 252 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2774, R²=0.0048
   Val:   Loss=0.0743, RMSE=0.2725, R²=0.0029
============================================================


📊 Round 252 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0010

📊 Round 252 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0010

============================================================
🔄 Round 258 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 258 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2772, R²=0.0070
   Val:   Loss=0.0748, RMSE=0.2736, R²=-0.0181
============================================================


============================================================
🔄 Round 259 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 259 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2754, R²=0.0027
   Val:   Loss=0.0788, RMSE=0.2807, R²=0.0024
============================================================


============================================================
🔄 Round 260 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0703 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0703, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0703, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0703, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0703, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0703, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0703)

============================================================
📊 Round 260 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2792, R²=0.0040
   Val:   Loss=0.0703, RMSE=0.2651, R²=0.0064
============================================================


📊 Round 260 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

============================================================
🔄 Round 262 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 262 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2756, R²=0.0025
   Val:   Loss=0.0784, RMSE=0.2801, R²=-0.0084
============================================================


============================================================
🔄 Round 263 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0671 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0671, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0671, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0671, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0671, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0671, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0671)

============================================================
📊 Round 263 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0051
   Val:   Loss=0.0671, RMSE=0.2590, R²=0.0018
============================================================


📊 Round 263 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

📊 Round 263 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

📊 Round 263 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

============================================================
🔄 Round 266 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 266 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2763, R²=0.0036
   Val:   Loss=0.0768, RMSE=0.2772, R²=0.0065
============================================================


📊 Round 266 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

📊 Round 266 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

📊 Round 266 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

📊 Round 266 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0010

============================================================
🔄 Round 273 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 273 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2781, R²=-0.0001
   Val:   Loss=0.0727, RMSE=0.2697, R²=-0.0130
============================================================


============================================================
🔄 Round 275 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0747, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0747, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0747, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0747, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0747, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0747, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 275 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0747, RMSE=0.2734, R²=0.0043
   Val:   Loss=0.0833, RMSE=0.2885, R²=-0.0232
============================================================


============================================================
🔄 Round 276 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0751, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0751, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0751, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0751, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0751, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0751, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 276 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0750, RMSE=0.2738, R²=0.0065
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0081
============================================================


📊 Round 276 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0010

============================================================
🔄 Round 278 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0753, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0753, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0753, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0753, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0753, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0753, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 278 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0752, RMSE=0.2743, R²=0.0048
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0014
============================================================


📊 Round 278 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0010

📊 Round 278 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

📊 Round 278 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0010

📊 Round 278 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0010

============================================================
🔄 Round 282 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0755, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0755, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0755, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0755, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0755, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0755, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 282 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2752, R²=0.0049
   Val:   Loss=0.0791, RMSE=0.2813, R²=0.0036
============================================================


📊 Round 282 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

📊 Round 282 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0010

============================================================
🔄 Round 285 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 285 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2762, R²=0.0039
   Val:   Loss=0.0771, RMSE=0.2777, R²=0.0076
============================================================


📊 Round 285 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

============================================================
🔄 Round 286 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 286 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2751, R²=0.0050
   Val:   Loss=0.0794, RMSE=0.2818, R²=0.0035
============================================================


📊 Round 286 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

📊 Round 286 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0010

📊 Round 286 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0010

============================================================
🔄 Round 289 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 289 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2763, R²=-0.0003
   Val:   Loss=0.0768, RMSE=0.2772, R²=-0.0194
============================================================


📊 Round 289 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

============================================================
🔄 Round 290 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 290 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2763, R²=0.0045
   Val:   Loss=0.0768, RMSE=0.2771, R²=0.0046
============================================================


📊 Round 290 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

============================================================
🔄 Round 291 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 291 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=0.0037
   Val:   Loss=0.0746, RMSE=0.2731, R²=-0.0123
============================================================


============================================================
🔄 Round 292 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 292 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2761, R²=0.0028
   Val:   Loss=0.0773, RMSE=0.2780, R²=0.0083
============================================================


📊 Round 292 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0010

📊 Round 292 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0010

📊 Round 292 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

📊 Round 292 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

📊 Round 292 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

📊 Round 292 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

============================================================
🔄 Round 302 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 302 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2757, R²=0.0055
   Val:   Loss=0.0781, RMSE=0.2795, R²=-0.0012
============================================================


============================================================
🔄 Round 303 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0746, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0746, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0746, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0746, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0746, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0746, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 303 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0749, RMSE=0.2737, R²=0.0037
   Val:   Loss=0.0826, RMSE=0.2873, R²=0.0080
============================================================


📊 Round 303 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0010

============================================================
🔄 Round 304 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 304 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2781, R²=0.0040
   Val:   Loss=0.0728, RMSE=0.2698, R²=-0.0156
============================================================


============================================================
🔄 Round 305 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 305 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2753, R²=0.0045
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0255
============================================================


============================================================
🔄 Round 307 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0690 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0690, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0690, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0690, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0690, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0690, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0690)

============================================================
📊 Round 307 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0055
   Val:   Loss=0.0690, RMSE=0.2627, R²=-0.0002
============================================================


📊 Round 307 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

============================================================
🔄 Round 308 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 308 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=0.0022
   Val:   Loss=0.0757, RMSE=0.2751, R²=0.0041
============================================================


============================================================
🔄 Round 309 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0748, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0748, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0748, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0748, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0748, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0748, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 309 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0747, RMSE=0.2734, R²=0.0046
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0005
============================================================


============================================================
🔄 Round 310 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0708 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0708, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0708, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0708, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0708, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0708, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0708)

============================================================
📊 Round 310 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2790, R²=0.0056
   Val:   Loss=0.0708, RMSE=0.2662, R²=-0.0024
============================================================


📊 Round 310 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

============================================================
🔄 Round 312 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0662 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0662, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0662, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0662, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0662, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0662, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0662)

============================================================
📊 Round 312 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0044
   Val:   Loss=0.0662, RMSE=0.2573, R²=-0.0020
============================================================


============================================================
🔄 Round 313 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 313 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0025
   Val:   Loss=0.0750, RMSE=0.2739, R²=0.0017
============================================================


📊 Round 313 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

============================================================
🔄 Round 314 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0739, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0739, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0739, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0739, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0738, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0738, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 314 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0740, RMSE=0.2721, R²=0.0058
   Val:   Loss=0.0861, RMSE=0.2935, R²=-0.0092
============================================================


📊 Round 314 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

============================================================
🔄 Round 316 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 316 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0046
   Val:   Loss=0.0750, RMSE=0.2738, R²=-0.0122
============================================================


📊 Round 316 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

============================================================
🔄 Round 317 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 317 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2756, R²=0.0031
   Val:   Loss=0.0784, RMSE=0.2801, R²=0.0067
============================================================


📊 Round 317 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

📊 Round 317 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

📊 Round 317 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

📊 Round 317 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0010

============================================================
🔄 Round 322 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 322 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2775, R²=0.0040
   Val:   Loss=0.0741, RMSE=0.2723, R²=0.0053
============================================================


============================================================
🔄 Round 323 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0755, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0755, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0755, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0755, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0755, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0755, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 323 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0754, RMSE=0.2746, R²=0.0024
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0193
============================================================


📊 Round 323 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0010

============================================================
🔄 Round 325 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0683 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0684, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0684, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0684, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0684, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0684, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0683)

============================================================
📊 Round 325 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=0.0018
   Val:   Loss=0.0683, RMSE=0.2614, R²=0.0059
============================================================


📊 Round 325 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0010

============================================================
🔄 Round 327 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0740, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0740, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0740, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0740, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0740, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0740, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 327 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0739, RMSE=0.2718, R²=0.0025
   Val:   Loss=0.0866, RMSE=0.2943, R²=0.0037
============================================================


📊 Round 327 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

============================================================
🔄 Round 330 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 330 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2757, R²=0.0056
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0046
============================================================


============================================================
🔄 Round 331 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0716 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0716, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0716, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0716, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0716, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0716, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0716)

============================================================
📊 Round 331 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0055
   Val:   Loss=0.0716, RMSE=0.2676, R²=-0.0077
============================================================


📊 Round 331 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0010

============================================================
🔄 Round 332 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0748, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0747, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0747, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0747, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0747, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0747, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 332 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0748, RMSE=0.2734, R²=0.0019
   Val:   Loss=0.0831, RMSE=0.2882, R²=0.0084
============================================================


📊 Round 332 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

============================================================
🔄 Round 334 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0751, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0751, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0751, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0751, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0751, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0751, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 334 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0754, RMSE=0.2746, R²=0.0025
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0095
============================================================


📊 Round 334 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

============================================================
🔄 Round 336 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 336 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2775, R²=0.0068
   Val:   Loss=0.0740, RMSE=0.2721, R²=-0.0044
============================================================


============================================================
🔄 Round 337 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0715 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0715, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0715, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0715, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0715, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0715, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0715)

============================================================
📊 Round 337 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0051
   Val:   Loss=0.0715, RMSE=0.2674, R²=0.0022
============================================================


============================================================
🔄 Round 339 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0744, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0744, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0744, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0744, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0744, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0744, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 339 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0741, RMSE=0.2722, R²=0.0050
   Val:   Loss=0.0857, RMSE=0.2928, R²=0.0016
============================================================


============================================================
🔄 Round 340 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0684 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0684, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0684, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0684, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0684, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0685, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0684)

============================================================
📊 Round 340 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2801, R²=0.0041
   Val:   Loss=0.0684, RMSE=0.2615, R²=-0.0117
============================================================


📊 Round 340 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

📊 Round 340 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

============================================================
🔄 Round 343 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0710 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0710, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0710, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0710, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0710, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0711, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0710)

============================================================
📊 Round 343 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0069
   Val:   Loss=0.0710, RMSE=0.2665, R²=-0.0215
============================================================


📊 Round 343 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

============================================================
🔄 Round 344 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 344 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2756, R²=0.0041
   Val:   Loss=0.0783, RMSE=0.2799, R²=0.0060
============================================================


📊 Round 344 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

============================================================
🔄 Round 345 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 345 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2774, R²=0.0047
   Val:   Loss=0.0743, RMSE=0.2725, R²=-0.0044
============================================================


📊 Round 345 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

📊 Round 345 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

============================================================
🔄 Round 348 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 348 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2759, R²=0.0057
   Val:   Loss=0.0778, RMSE=0.2789, R²=-0.0153
============================================================


============================================================
🔄 Round 350 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 350 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2783, R²=0.0036
   Val:   Loss=0.0723, RMSE=0.2688, R²=0.0093
============================================================


📊 Round 350 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

============================================================
🔄 Round 352 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 352 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2755, R²=0.0062
   Val:   Loss=0.0785, RMSE=0.2801, R²=-0.0010
============================================================


📊 Round 352 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

============================================================
🔄 Round 353 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0755, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0755, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0755, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0755, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0755, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 353 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2749, R²=0.0063
   Val:   Loss=0.0799, RMSE=0.2826, R²=-0.0029
============================================================


📊 Round 353 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

📊 Round 353 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

📊 Round 353 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

============================================================
🔄 Round 364 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 364 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2764, R²=0.0042
   Val:   Loss=0.0765, RMSE=0.2765, R²=0.0069
============================================================


📊 Round 364 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0012

============================================================
🔄 Round 365 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0754, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0754, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0754, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 365 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0753, RMSE=0.2744, R²=0.0036
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0121
============================================================


📊 Round 365 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0012

============================================================
🔄 Round 366 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0706 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0706, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0706, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0706, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0706, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0707, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0706)

============================================================
📊 Round 366 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0026
   Val:   Loss=0.0706, RMSE=0.2657, R²=0.0043
============================================================


============================================================
🔄 Round 369 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 369 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2778, R²=0.0031
   Val:   Loss=0.0736, RMSE=0.2712, R²=0.0107
============================================================


📊 Round 369 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0012

📊 Round 369 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0012

📊 Round 369 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2417, R²: 0.0012

============================================================
🔄 Round 374 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 374 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2756, R²=0.0051
   Val:   Loss=0.0784, RMSE=0.2799, R²=0.0026
============================================================


📊 Round 374 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2417, R²: 0.0012

============================================================
🔄 Round 377 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0737, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0737, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0737, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0737, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0737, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0737, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 377 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0738, RMSE=0.2717, R²=0.0027
   Val:   Loss=0.0869, RMSE=0.2948, R²=0.0048
============================================================


============================================================
🔄 Round 378 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 378 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2770, R²=0.0045
   Val:   Loss=0.0753, RMSE=0.2743, R²=0.0007
============================================================


📊 Round 378 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

============================================================
🔄 Round 382 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0718, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 382 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0036
   Val:   Loss=0.0718, RMSE=0.2679, R²=0.0095
============================================================


============================================================
🔄 Round 384 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0740, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0740, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0740, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0739, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0739, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0739, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 384 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0740, RMSE=0.2720, R²=0.0048
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0022
============================================================


📊 Round 384 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0012

============================================================
🔄 Round 385 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 385 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2776, R²=0.0040
   Val:   Loss=0.0738, RMSE=0.2718, R²=0.0016
============================================================


📊 Round 385 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0012

============================================================
🔄 Round 389 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 389 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2760, R²=0.0040
   Val:   Loss=0.0773, RMSE=0.2781, R²=-0.0080
============================================================


📊 Round 389 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0012

📊 Round 389 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2417, R²: 0.0012

📊 Round 389 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0012

📊 Round 389 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0012

============================================================
🔄 Round 396 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0747, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0747, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0747, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0747, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0747, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0747, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 396 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0747, RMSE=0.2733, R²=0.0023
   Val:   Loss=0.0835, RMSE=0.2889, R²=0.0096
============================================================


📊 Round 396 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

📊 Round 396 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

📊 Round 396 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

📊 Round 396 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

============================================================
🔄 Round 404 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0730, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0730, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0730, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0730, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0730, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0730, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 404 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0729, RMSE=0.2700, R²=0.0049
   Val:   Loss=0.0906, RMSE=0.3009, R²=-0.0083
============================================================


📊 Round 404 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

============================================================
🔄 Round 409 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 409 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=0.0057
   Val:   Loss=0.0756, RMSE=0.2750, R²=-0.0042
============================================================


============================================================
🔄 Round 410 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 410 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2764, R²=0.0039
   Val:   Loss=0.0766, RMSE=0.2768, R²=0.0077
============================================================


📊 Round 410 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

============================================================
🔄 Round 411 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 411 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0055
   Val:   Loss=0.0738, RMSE=0.2716, R²=0.0015
============================================================


📊 Round 411 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

============================================================
🔄 Round 413 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0675 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0675, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0675, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0675, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0675, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0675, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0675)

============================================================
📊 Round 413 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0066
   Val:   Loss=0.0675, RMSE=0.2598, R²=-0.0102
============================================================


📊 Round 413 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

📊 Round 413 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

📊 Round 413 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

============================================================
🔄 Round 417 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0751, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0751, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0751, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0751, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0751, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0751, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 417 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0751, RMSE=0.2741, R²=0.0048
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0041
============================================================


📊 Round 417 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

============================================================
🔄 Round 419 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0750, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0750, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0750, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0750, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0750, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0750, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 419 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0751, RMSE=0.2741, R²=0.0034
   Val:   Loss=0.0817, RMSE=0.2859, R²=0.0029
============================================================


📊 Round 419 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0010

📊 Round 419 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

============================================================
🔄 Round 424 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0753, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0753, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0753, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0753, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0753, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0753, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 424 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0752, RMSE=0.2742, R²=0.0048
   Val:   Loss=0.0813, RMSE=0.2852, R²=-0.0032
============================================================


📊 Round 424 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

============================================================
🔄 Round 426 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0712 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0712, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0712, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0712, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0712, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0713, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0712)

============================================================
📊 Round 426 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0028
   Val:   Loss=0.0712, RMSE=0.2669, R²=-0.0084
============================================================


============================================================
🔄 Round 428 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0719 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0719, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0719, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0719)

============================================================
📊 Round 428 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2785, R²=0.0016
   Val:   Loss=0.0719, RMSE=0.2681, R²=-0.0059
============================================================


📊 Round 428 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

============================================================
🔄 Round 429 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0754, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0754, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0754, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 429 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0755, RMSE=0.2747, R²=0.0053
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0028
============================================================


📊 Round 429 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

📊 Round 429 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0010

============================================================
🔄 Round 432 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 432 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2772, R²=0.0047
   Val:   Loss=0.0748, RMSE=0.2736, R²=0.0034
============================================================


============================================================
🔄 Round 433 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 433 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2772, R²=0.0030
   Val:   Loss=0.0748, RMSE=0.2736, R²=-0.0055
============================================================


============================================================
🔄 Round 434 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 434 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2757, R²=0.0058
   Val:   Loss=0.0782, RMSE=0.2797, R²=-0.0080
============================================================


📊 Round 434 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0010

============================================================
🔄 Round 437 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 437 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2763, R²=0.0025
   Val:   Loss=0.0769, RMSE=0.2773, R²=0.0109
============================================================


📊 Round 437 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0010

============================================================
🔄 Round 441 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0688 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0688, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0688, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0688, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0688, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0688, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0688)

============================================================
📊 Round 441 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=0.0049
   Val:   Loss=0.0688, RMSE=0.2624, R²=0.0040
============================================================


📊 Round 441 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

============================================================
🔄 Round 443 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0751, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0751, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0751, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0751, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0751, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0751, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 443 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0752, RMSE=0.2742, R²=0.0035
   Val:   Loss=0.0814, RMSE=0.2852, R²=0.0005
============================================================


============================================================
🔄 Round 444 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0745, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0745, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0745, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0745, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0745, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0745, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 444 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0743, RMSE=0.2726, R²=0.0039
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0061
============================================================


============================================================
🔄 Round 446 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0755, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0755, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0755, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0755, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0755, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0755, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 446 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2751, R²=0.0058
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0007
============================================================


📊 Round 446 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

📊 Round 446 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

============================================================
🔄 Round 451 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 451 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2766, R²=0.0054
   Val:   Loss=0.0760, RMSE=0.2758, R²=0.0011
============================================================


📊 Round 451 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

============================================================
🔄 Round 455 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 455 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2785, R²=0.0037
   Val:   Loss=0.0720, RMSE=0.2683, R²=0.0037
============================================================


📊 Round 455 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

============================================================
🔄 Round 456 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0751, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0751, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0751, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0751, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0751, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0751, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 456 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0754, RMSE=0.2745, R²=0.0039
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0034
============================================================


📊 Round 456 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

📊 Round 456 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

============================================================
🔄 Round 459 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 459 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0047
   Val:   Loss=0.0750, RMSE=0.2738, R²=-0.0002
============================================================


📊 Round 459 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

============================================================
🔄 Round 460 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0746, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0746, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0746, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0746, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0746, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0746, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 460 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0747, RMSE=0.2733, R²=0.0049
   Val:   Loss=0.0834, RMSE=0.2889, R²=-0.0016
============================================================


============================================================
🔄 Round 461 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 461 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=0.0046
   Val:   Loss=0.0732, RMSE=0.2706, R²=0.0053
============================================================


============================================================
🔄 Round 462 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 462 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2774, R²=0.0057
   Val:   Loss=0.0743, RMSE=0.2725, R²=0.0003
============================================================


============================================================
🔄 Round 463 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 463 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2763, R²=0.0029
   Val:   Loss=0.0769, RMSE=0.2773, R²=0.0092
============================================================


============================================================
🔄 Round 464 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 464 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2755, R²=0.0058
   Val:   Loss=0.0786, RMSE=0.2803, R²=-0.0066
============================================================


📊 Round 464 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

============================================================
🔄 Round 468 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0749, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0749, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0749, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0749, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0749, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0749, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 468 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0751, RMSE=0.2740, R²=0.0049
   Val:   Loss=0.0819, RMSE=0.2861, R²=0.0041
============================================================


📊 Round 468 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0012

📊 Round 468 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0012

📊 Round 468 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0012

📊 Round 468 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0012

============================================================
🔄 Round 473 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 473 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2772, R²=0.0029
   Val:   Loss=0.0747, RMSE=0.2733, R²=0.0005
============================================================


============================================================
🔄 Round 474 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 474 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=0.0057
   Val:   Loss=0.0745, RMSE=0.2730, R²=0.0006
============================================================


📊 Round 474 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0012

📊 Round 474 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2417, R²: 0.0012

============================================================
🔄 Round 477 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0685 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0685, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0685, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0685, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0685, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0685, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0685)

============================================================
📊 Round 477 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0045
   Val:   Loss=0.0685, RMSE=0.2618, R²=0.0057
============================================================


📊 Round 477 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2417, R²: 0.0012

============================================================
🔄 Round 478 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 478 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2765, R²=0.0035
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.0090
============================================================


📊 Round 478 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2417, R²: 0.0012

============================================================
🔄 Round 479 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0753, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0753, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0753, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0753, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0753, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0753, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 479 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0751, RMSE=0.2741, R²=0.0045
   Val:   Loss=0.0817, RMSE=0.2859, R²=0.0043
============================================================


📊 Round 479 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0012

============================================================
🔄 Round 481 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0718, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 481 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2785, R²=0.0048
   Val:   Loss=0.0718, RMSE=0.2680, R²=0.0043
============================================================


📊 Round 481 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0012

📊 Round 481 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2417, R²: 0.0012

📊 Round 481 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

============================================================
🔄 Round 491 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 491 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2765, R²=0.0049
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.0042
============================================================


============================================================
🔄 Round 493 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 493 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2765, R²=0.0046
   Val:   Loss=0.0764, RMSE=0.2764, R²=0.0052
============================================================


📊 Round 493 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2417, R²: 0.0012

📊 Round 493 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0012

============================================================
🔄 Round 497 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 497 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2764, R²=0.0028
   Val:   Loss=0.0766, RMSE=0.2768, R²=0.0098
============================================================


📊 Round 497 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0012

============================================================
🔄 Round 498 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0750, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0750, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0750, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0750, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0750, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0750, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 498 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0750, RMSE=0.2739, R²=0.0046
   Val:   Loss=0.0820, RMSE=0.2863, R²=0.0017
============================================================


============================================================
🔄 Round 499 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 499 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0059
   Val:   Loss=0.0736, RMSE=0.2713, R²=-0.0074
============================================================


📊 Round 499 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

📊 Round 499 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0012

============================================================
🔄 Round 501 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0752, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0752, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0752, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0752, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0752, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0752, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 501 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0752, RMSE=0.2742, R²=0.0035
   Val:   Loss=0.0815, RMSE=0.2854, R²=0.0095
============================================================


============================================================
🔄 Round 502 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0748, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0748, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0748, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0748, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0748, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0748, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 502 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0749, RMSE=0.2737, R²=0.0067
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0135
============================================================


📊 Round 502 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0012

📊 Round 502 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0012

============================================================
🔄 Round 505 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 505 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2755, R²=0.0070
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.0053
============================================================


📊 Round 505 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

============================================================
🔄 Round 506 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 506 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2763, R²=0.0036
   Val:   Loss=0.0769, RMSE=0.2772, R²=-0.0133
============================================================


📊 Round 506 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

📊 Round 506 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

📊 Round 506 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

============================================================
🔄 Round 510 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0687 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0687, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0687, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0687, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0687, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0687, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0687)

============================================================
📊 Round 510 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2799, R²=0.0053
   Val:   Loss=0.0687, RMSE=0.2621, R²=0.0000
============================================================


📊 Round 510 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

============================================================
🔄 Round 511 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 511 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0051
   Val:   Loss=0.0731, RMSE=0.2704, R²=0.0022
============================================================


============================================================
🔄 Round 512 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0649 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0650, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0650, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0650, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0650, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0650, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0649)

============================================================
📊 Round 512 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0023
   Val:   Loss=0.0649, RMSE=0.2548, R²=0.0089
============================================================


📊 Round 512 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

📊 Round 512 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

============================================================
🔄 Round 519 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0699 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0699, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0699, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0699, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0699, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0699, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0699)

============================================================
📊 Round 519 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=0.0042
   Val:   Loss=0.0699, RMSE=0.2643, R²=0.0067
============================================================


📊 Round 519 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

============================================================
🔄 Round 521 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 521 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2752, R²=0.0039
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.0083
============================================================


📊 Round 521 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0012

============================================================
🔄 Round 523 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 523 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2758, R²=0.0049
   Val:   Loss=0.0779, RMSE=0.2791, R²=0.0035
============================================================


📊 Round 523 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

============================================================
🔄 Round 524 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0698 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0698, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0698, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0698, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0698, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0698, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0698)

============================================================
📊 Round 524 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=0.0037
   Val:   Loss=0.0698, RMSE=0.2642, R²=0.0013
============================================================


📊 Round 524 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0012

📊 Round 524 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0012

============================================================
🔄 Round 526 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0735, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0735, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0735, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0735, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0735, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0735, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 526 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0734, RMSE=0.2709, R²=0.0037
   Val:   Loss=0.0886, RMSE=0.2977, R²=-0.0037
============================================================


📊 Round 526 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0012

============================================================
🔄 Round 527 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 527 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0059
   Val:   Loss=0.0730, RMSE=0.2702, R²=-0.0021
============================================================


📊 Round 527 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0012

============================================================
🔄 Round 530 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 530 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2750, R²=0.0054
   Val:   Loss=0.0796, RMSE=0.2822, R²=-0.0029
============================================================


📊 Round 530 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

============================================================
🔄 Round 531 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 531 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2757, R²=0.0037
   Val:   Loss=0.0782, RMSE=0.2796, R²=0.0044
============================================================


============================================================
🔄 Round 535 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 535 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2776, R²=0.0038
   Val:   Loss=0.0740, RMSE=0.2720, R²=0.0005
============================================================


📊 Round 535 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0012

📊 Round 535 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0012

============================================================
🔄 Round 537 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 537 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2767, R²=0.0047
   Val:   Loss=0.0758, RMSE=0.2754, R²=0.0024
============================================================


📊 Round 537 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

============================================================
🔄 Round 538 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0742, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0742, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0742, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0742, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0742, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0742, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 538 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0742, RMSE=0.2723, R²=0.0044
   Val:   Loss=0.0855, RMSE=0.2924, R²=0.0041
============================================================


📊 Round 538 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

📊 Round 538 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

============================================================
🔄 Round 541 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0661 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0661, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0661, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0662, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0662, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0662, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0661)

============================================================
📊 Round 541 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0045
   Val:   Loss=0.0661, RMSE=0.2572, R²=0.0036
============================================================


📊 Round 541 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0012

============================================================
🔄 Round 542 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 542 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0056
   Val:   Loss=0.0736, RMSE=0.2714, R²=-0.0051
============================================================


📊 Round 542 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2417, R²: 0.0012

📊 Round 542 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2417, R²: 0.0012

============================================================
🔄 Round 546 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0725, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 546 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0046
   Val:   Loss=0.0725, RMSE=0.2692, R²=-0.0057
============================================================


📊 Round 546 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2417, R²: 0.0012

============================================================
🔄 Round 552 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 552 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2752, R²=0.0036
   Val:   Loss=0.0791, RMSE=0.2813, R²=0.0090
============================================================


📊 Round 552 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0012

============================================================
🔄 Round 553 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 553 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2767, R²=0.0048
   Val:   Loss=0.0760, RMSE=0.2756, R²=0.0041
============================================================


📊 Round 553 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0012

============================================================
🔄 Round 556 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 556 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2776, R²=0.0063
   Val:   Loss=0.0739, RMSE=0.2718, R²=-0.0097
============================================================


============================================================
🔄 Round 557 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 557 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=0.0043
   Val:   Loss=0.0756, RMSE=0.2750, R²=-0.0013
============================================================


============================================================
🔄 Round 558 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 558 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2753, R²=0.0048
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0013
============================================================


📊 Round 558 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2417, R²: 0.0012

📊 Round 558 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2417, R²: 0.0012

📊 Round 558 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0012

📊 Round 558 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2417, R²: 0.0012

============================================================
🔄 Round 566 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 566 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=0.0042
   Val:   Loss=0.0746, RMSE=0.2731, R²=0.0051
============================================================


📊 Round 566 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2417, R²: 0.0012

============================================================
🔄 Round 567 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0748, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0748, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0747, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0747, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0747, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0747, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 567 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0750, RMSE=0.2739, R²=0.0044
   Val:   Loss=0.0822, RMSE=0.2866, R²=0.0057
============================================================


📊 Round 567 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0012

============================================================
🔄 Round 568 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0749, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0749, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0749, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0749, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0749, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0749, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 568 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0749, RMSE=0.2736, R²=0.0040
   Val:   Loss=0.0827, RMSE=0.2875, R²=-0.0006
============================================================


📊 Round 568 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0011

============================================================
🔄 Round 572 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 572 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2753, R²=0.0042
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0000
============================================================


📊 Round 572 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2417, R²: 0.0012

============================================================
🔄 Round 574 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0617 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0617, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0617, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0617, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0617, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0618, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0617)

============================================================
📊 Round 574 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0029
   Val:   Loss=0.0617, RMSE=0.2484, R²=-0.0012
============================================================


📊 Round 574 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2417, R²: 0.0012

============================================================
🔄 Round 575 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0748, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0748, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0748, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0748, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0748, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0748, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 575 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0748, RMSE=0.2735, R²=0.0027
   Val:   Loss=0.0829, RMSE=0.2880, R²=0.0122
============================================================


📊 Round 575 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2417, R²: 0.0012

============================================================
🔄 Round 576 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 576 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2760, R²=0.0048
   Val:   Loss=0.0775, RMSE=0.2783, R²=0.0046
============================================================


📊 Round 576 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0012

📊 Round 576 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2417, R²: 0.0012

============================================================
🔄 Round 587 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 587 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0032
   Val:   Loss=0.0749, RMSE=0.2737, R²=0.0064
============================================================


📊 Round 587 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2417, R²: 0.0012

📊 Round 587 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2417, R²: 0.0012

📊 Round 587 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2417, R²: 0.0012

📊 Round 587 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2417, R²: 0.0012

============================================================
🔄 Round 593 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 593 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0057
   Val:   Loss=0.0730, RMSE=0.2703, R²=-0.0008
============================================================


📊 Round 593 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2417, R²: 0.0012

📊 Round 593 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2417, R²: 0.0012

============================================================
🔄 Round 596 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 596 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2754, R²=0.0047
   Val:   Loss=0.0789, RMSE=0.2808, R²=0.0019
============================================================


============================================================
🔄 Round 597 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0754, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0754, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0754, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 597 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0755, RMSE=0.2747, R²=0.0051
   Val:   Loss=0.0803, RMSE=0.2833, R²=0.0000
============================================================


📊 Round 597 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2417, R²: 0.0012

============================================================
🔄 Round 599 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 599 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0033
   Val:   Loss=0.0731, RMSE=0.2704, R²=-0.0053
============================================================


============================================================
🔄 Round 600 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 600 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0034
   Val:   Loss=0.0720, RMSE=0.2684, R²=0.0102
============================================================


📊 Round 600 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2417, R²: 0.0012

📊 Round 600 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2417, R²: 0.0012

============================================================
🔄 Round 605 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 605 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0755, RMSE=0.2748, R²=0.0048
   Val:   Loss=0.0802, RMSE=0.2831, R²=0.0044
============================================================


============================================================
🔄 Round 606 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 606 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2750, R²=0.0053
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0077
============================================================


📊 Round 606 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2417, R²: 0.0013

============================================================
🔄 Round 608 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0703 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0703, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0703, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0703, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0703, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0704, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0703)

============================================================
📊 Round 608 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2792, R²=0.0047
   Val:   Loss=0.0703, RMSE=0.2652, R²=-0.0077
============================================================


📊 Round 608 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2417, R²: 0.0013

📊 Round 608 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2417, R²: 0.0013

📊 Round 608 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2417, R²: 0.0013

============================================================
🔄 Round 613 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 613 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2765, R²=0.0026
   Val:   Loss=0.0762, RMSE=0.2761, R²=0.0104
============================================================


📊 Round 613 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2417, R²: 0.0013

============================================================
🔄 Round 615 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 615 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2762, R²=0.0049
   Val:   Loss=0.0771, RMSE=0.2776, R²=0.0007
============================================================


============================================================
🔄 Round 616 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 616 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2753, R²=0.0024
   Val:   Loss=0.0789, RMSE=0.2809, R²=-0.0010
============================================================


📊 Round 616 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2417, R²: 0.0013

📊 Round 616 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2417, R²: 0.0013

📊 Round 616 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2417, R²: 0.0013

============================================================
🔄 Round 624 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0752, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0752, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0752, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0752, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0752, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0752, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 624 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0752, RMSE=0.2743, R²=0.0057
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0015
============================================================


📊 Round 624 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2417, R²: 0.0014

============================================================
🔄 Round 627 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0748, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0747, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0747, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0747, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0747, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0747, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 627 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0748, RMSE=0.2735, R²=0.0029
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0052
============================================================


📊 Round 627 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2417, R²: 0.0014

📊 Round 627 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2417, R²: 0.0014

📊 Round 627 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2417, R²: 0.0014

📊 Round 627 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2417, R²: 0.0014

📊 Round 627 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2417, R²: 0.0014

📊 Round 627 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2417, R²: 0.0013

============================================================
🔄 Round 636 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0712 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0712, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0712, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0712, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0712, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0712, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0712)

============================================================
📊 Round 636 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0038
   Val:   Loss=0.0712, RMSE=0.2669, R²=0.0090
============================================================


📊 Round 636 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2417, R²: 0.0013

📊 Round 636 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2417, R²: 0.0013

============================================================
🔄 Round 638 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 638 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0050
   Val:   Loss=0.0721, RMSE=0.2686, R²=0.0041
============================================================


📊 Round 638 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2417, R²: 0.0013

============================================================
🔄 Round 640 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 640 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2770, R²=0.0028
   Val:   Loss=0.0751, RMSE=0.2741, R²=0.0090
============================================================


📊 Round 640 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2417, R²: 0.0013

📊 Round 640 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2417, R²: 0.0013

📊 Round 640 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2417, R²: 0.0013

============================================================
🔄 Round 648 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 648 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2752, R²=0.0045
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.0010
============================================================


============================================================
🔄 Round 650 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 650 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2761, R²=0.0046
   Val:   Loss=0.0772, RMSE=0.2779, R²=-0.0097
============================================================


📊 Round 650 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2417, R²: 0.0013

📊 Round 650 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2417, R²: 0.0013

============================================================
🔄 Round 653 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 653 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2764, R²=0.0062
   Val:   Loss=0.0765, RMSE=0.2766, R²=-0.0033
============================================================


📊 Round 653 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2417, R²: 0.0013

============================================================
🔄 Round 654 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 654 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0044
   Val:   Loss=0.0750, RMSE=0.2739, R²=0.0010
============================================================


============================================================
🔄 Round 656 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 656 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2762, R²=0.0067
   Val:   Loss=0.0770, RMSE=0.2774, R²=-0.0050
============================================================


📊 Round 656 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2417, R²: 0.0013

📊 Round 656 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2417, R²: 0.0013

============================================================
🔄 Round 658 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0751, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0751, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0751, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0751, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0751, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0751, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 658 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0752, RMSE=0.2741, R²=0.0060
   Val:   Loss=0.0815, RMSE=0.2856, R²=0.0003
============================================================


============================================================
🔄 Round 659 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0755, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0755, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0755, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0755, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0755, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0755, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 659 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0755, RMSE=0.2748, R²=0.0039
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0068
============================================================


============================================================
🔄 Round 660 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 660 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=0.0046
   Val:   Loss=0.0745, RMSE=0.2729, R²=0.0040
============================================================


============================================================
🔄 Round 661 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0754, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0754, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0754, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 661 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0754, RMSE=0.2746, R²=0.0031
   Val:   Loss=0.0805, RMSE=0.2838, R²=-0.0005
============================================================


📊 Round 661 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2417, R²: 0.0013

📊 Round 661 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2417, R²: 0.0013

❌ Client client_21 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8690 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8690 {grpc_status:14, grpc_message:"Socket closed"}"
>
