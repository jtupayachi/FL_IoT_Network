[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b5eab98-8e70-43ce-9f04-2d06b19f217f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2bb6d3ba-7810-4009-bbe6-b066c66d164e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7976c422-5b55-40ec-9ec0-e0f55a5288c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2b8fb3f-f124-4842-a835-9e38f3079527
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47503130-88ee-4b3a-a28f-8a9001242186
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b571abbd-a263-47b8-ab83-d556883d0eb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eaa1446c-cf6a-486b-8f0f-1397d7e7b492
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b444c86-ed1a-4acb-9239-5d5b9eaeb3aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a758748c-d99b-4263-b68e-84d058b6ebe5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9303973-7106-4d23-873e-171ce9571962
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3bc81911-aac7-477d-ae4b-4903e90d8925
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba0e4e90-b927-4c44-9415-bc9f02bef76e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b98c7c7b-2ef7-4ed1-b125-7ce2c918dc96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd86d5c4-c050-43fa-a863-6491a5efd7a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5100d3be-1c7a-4085-ba63-acdf50727275
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 098d09ea-f3f3-463b-931d-fa5f9bab0ce1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63470a7c-1cc3-419f-80db-79cb78aed5a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca228e27-8e40-410a-aa48-5becf86888c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a4eb921-89f8-4b41-a962-0abb99de14aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3135bcf1-9f65-4fa5-8510-1bd2d47725d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4910f050-ff4c-4990-ba6f-92d4ca37abdb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a366466c-cca1-444e-9576-4166353b7977
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3ae0b04-30a2-470e-b947-e06e7bd4c9a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6d5b168-e173-4aa0-ac58-85e1363b19d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 669c1c65-be2f-4832-837d-3b031cde0f3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a67c40b-b65d-48cb-93d5-4040d98ee6e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a47d406-9e6a-4268-bff9-660d73c6eea7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf60b92d-a910-4f27-9f17-a8051925306f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d6e4deb-3b85-4ef1-a6b1-1ecfbfd1fb96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38ba6fb5-b7e9-485f-ac2c-632cbad4e287
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 507dd8ab-7e57-432c-9994-d47156977af9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72051862-9a34-433a-ab31-ecdceb4e2ab8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4018189-2846-4f38-ba04-ae26c9873b76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0851b2f5-ba66-4a2a-b05e-8aefda6d4814
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 990a4664-9e77-498d-9cb5-ea33aaae35f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07e5cbec-2299-4a83-8918-120901fae75e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 754e2e0a-a9fe-4a2a-9b80-d5a41c8f09e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d101ec5-0f21-4271-a5c0-2218b4a119fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78b43161-d1c3-4ec5-9ee0-b3d73595a9d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1e907ce-0de6-4425-bc3f-3c55bbf0e991
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7da82e53-b870-44b7-84e3-fb200b905296
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69cdd19e-34a5-471c-9e2b-ba11bc92496b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be04392e-8ed6-4f72-8152-dce1fee75076
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9d10c54-7e7d-4581-bfbe-97f57254e19e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74aaecbf-fabc-4cb6-b1a3-2757ba955b39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 981d9040-c533-404d-a313-9fcc21a3da0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0da809ac-cc3c-4a70-9b93-26077948ce97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 129044d3-ebac-478c-95ec-301b8ad2c60d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc22eae5-edc2-4b09-ba0f-f0a7f26864f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f9dabef-a9a7-4617-991a-587f2124768e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ebbf8389-b744-4a09-a633-7b610aca95ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c97d653d-9cb4-4a88-ac71-838f2230ae62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 711df357-a2d5-46e9-8ed2-cbc7514cf101
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b239bed-ca79-4120-b494-820a7df834b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f49ca4b9-df48-440a-8ee5-8ba593cdb33d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6704eec-a2fc-4462-8c9c-8e4072748ad9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44b1a3ac-b9af-4ca5-810b-fdc03f9ffe5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20e9df88-71bc-4dd4-9fc1-de8d908aadb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7958d8b1-9ba9-4eaa-85dc-9e9d1f16238f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 586bb1ee-fb30-4f43-9c6a-f8cf670958bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3fb46caf-2ad4-429b-901d-f2a69c1c5a9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54bf5528-11b3-49d9-b993-50981abb8537
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06e3bb14-8b0f-4332-84d1-13a9754cb112
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6468e661-ad14-463d-af5a-36ca9e75f2b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ad3dd4e-df1b-44e3-987b-092cc10f7789
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1fa0002c-f3f0-4623-abe6-e7635825842d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d15bdc20-3e96-46ed-9b99-d51201007f5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 750f3fce-9639-458b-9dc3-abb577383cd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8cd6ace0-83cc-4809-9f29-10b23a849df7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message acb15fb8-3804-4704-bf3f-743eae73646f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7b34990-62a6-4675-9535-74fd4c284d95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7142ce65-9b94-4e63-9f5e-fb10446c6e6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0491e107-a491-427e-9257-bc011e65876d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e50516ce-dc3d-441a-8a86-ff92b845f74a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 325e7e51-be14-4bc5-84bb-95ba569f2cb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13c23e90-008e-4d3d-8f6d-b41611a45814
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ccb68dd-ae7e-4b70-b5ec-f27e8317bb9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6ce22ff-fe49-47b0-a919-5c70d10da6ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f75557ac-4bfa-4296-82d5-7452b24ab757
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06b2280e-89e4-42f6-8852-0453cd9f90f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 354fa639-b6ec-4afe-b56b-e2fe8c561eb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 006b1b51-29c2-4736-913e-2fadf014ff2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 239e9f93-2697-401e-94a8-ad4e469cd4fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ceb344a6-9745-49e3-b9fc-a7ac6ce067dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9858b140-de10-48cb-9a99-9f81761d1d07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8928c264-ec7f-44f2-b9e5-f44719f77149
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 681e6ad6-0a97-43df-a672-dc5474dea045
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eda2b60d-d344-49ec-96a8-c4c50f387261
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c38d485-59dd-4614-9a00-0092934dffea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e81c219-7d31-4e02-b8d2-509c1fa66c4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09150a2b-ae48-447c-b7f9-02b806b9fd58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42593505-062a-4010-b8fc-6fec3da4bc78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4e899b1-f929-4aa7-9c5e-1004f4d3d629
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83296e28-cc44-4ed6-9f89-61fb8b43501d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e5b6823-ccdc-4600-965d-325baf5198ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8177f9bd-76a5-4d45-a494-3af02ef4d31d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f9bf87c-830d-4196-bbb2-5463ac8be770
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e591a02-b870-4522-a5b0-a414eb7d48ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3c8116d-9ce2-46c6-973a-a278f7bec640
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 669ed24f-f95f-4786-ac56-4ef98b31468e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80b89aeb-55ab-4cd2-87c0-d73de607e75f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7808d03c-5c89-4038-a541-62ca456714a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee2b29f0-aad8-495a-81bc-892ee42f2a39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 349c59cb-79c5-4c3d-b67d-e8b67d752b48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3de89168-7c53-4a73-a82b-b5f2ea8f1c44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa95b378-0ec4-4c16-9fa5-a614b02ff7e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4c1693f-63ae-4f47-910c-eb072499388e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49e9d0cc-89cc-42e5-baab-41031480f911
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed5e6519-5846-4e69-8f0e-237c7194fa44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0902c9ab-3a7a-487f-9e4f-8834e4117952
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a19a6b4b-c28f-4730-bfa1-9376e603b630
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f0a9e27-721b-471d-8b86-cc547a9c724c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 464e3c48-d45d-42cd-88ed-6f5971c988a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8b94d5e-7ee7-4458-b5b7-41a1fe4ed4c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message feed4d75-ff6b-4ed1-9b47-76ac389b57a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b7791f4-130d-4909-92d8-b4e5c9d07884
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aaaf34d8-e5a2-4089-9cc8-2a73e296ceb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d0f2020-1331-4758-b3be-3f71f5737d64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9e0f6a3-db3d-4381-8feb-744f440dd7b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67edb60d-2ecc-428a-84f1-3480467cb041
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ab6dc01-be6c-4f39-8737-7b7ac4d96fad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6ae26c9-30d0-4316-885b-93e1e2ff440c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50283a2b-d9f6-4a5c-b054-6aa04f4be80d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5aee5cfd-b98b-4af9-832b-b38f5a35b38c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97132392-67fc-42f6-b24d-b28b86f4d2d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca3f6e11-49b8-416a-a804-1f16ce0cc6d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd199395-120f-4fd6-a08d-90c119c79f50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96c81794-3752-4ac7-b533-407703912c50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c48c8c75-ddd7-4dd1-a882-811ed80a04f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ebe5672-efb6-4554-aff6-940217054a4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20944287-1082-4380-898e-09f3649b2875
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51d2ec9b-1267-45b1-94c4-9faed6089895
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62d5cbc4-20a1-461a-8bbd-773843f16a8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d35cf87d-94b8-4caf-9128-c49ece0defe7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26a51dc3-8422-41e7-af47-996d91766820
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee9ea099-cb53-4d01-867e-c53fb3b71f24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91441edd-2863-48f4-a67f-c5e0afcd80da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29e86ce2-f2c3-4e60-95e2-d2f554cd4543
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 927689cc-36eb-4a78-bb53-9ad1e105b55d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a9c4afb-9f15-479c-bbfa-d5519777ea7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d10a1f18-8b02-41be-aec2-ed04f5b85c28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad573999-256f-4b09-8121-7815b3ec250f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66f0b3a8-ca2e-418a-b24a-d38808064689
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 022ff160-5877-4dd3-b564-7711caf77826
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65e3e68b-5d7e-4161-b572-dd4e4b548c83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c60b1e0-c5bc-4122-955c-4a408ace0771
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53450f36-461d-4be9-90b4-7a48a7feffbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd02241b-998a-4de6-91bb-d09a0e852fb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55c68cef-5a3d-43bd-8676-c2e239cc0828
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b6a0cf7-f28b-4ccf-916f-a560a3c8f116
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f047c3e1-51f5-4239-a9d7-95b0b9e69847
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 215c7a0d-89c3-45cc-a76c-ee82789fb4bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9bb59201-5784-40cb-96fb-bec74a317c80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb0d4267-3585-4893-b8ca-7f0e98201bc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3ac7699-e557-403c-87ca-e14d3fc5b7e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message faad63ba-8c0a-470c-a1e2-66d9728518a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0481856-459a-4ee3-9d25-8d5c0179fa3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df8d1a71-6989-4310-81a2-accdde60177e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9fba4499-51e3-41b8-beab-fa13e3a7f4d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f32cec3-91ca-4270-b143-6258e980f8c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87ae4e50-d14b-4c28-9cd6-d8b4d18a6dbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c2dafde-b47e-4f9e-8f4f-e76a64cb4778
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b5a4bf8-ae51-4334-a3bf-89214246b9d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9c92d19-e84b-4a39-887e-594658d475f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc3fcc1a-e6a5-444b-8c95-00c9b2954ad4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c47ce41-fc54-40f5-9e0c-6653671a2d89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f11fc5d-3140-4e87-9650-0aaf4bca8c73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8fa99093-1aa8-4651-8620-90a2baa688fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e25a6f3-62fa-4ac9-89c1-66677d653c9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc92a980-a02c-47ac-b306-18298339d649
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a206d070-069b-4a79-8975-33768ef1e685
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05ed7ab9-94b6-4387-b113-6c1925b96983
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0577e672-f18b-4f1c-91b3-62c9c34bcf24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73d1cce8-f3d5-44c7-be79-84b3af93595b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 480e91f2-663f-4199-8413-40dcd4eeb8e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 962e4f91-b220-4261-84d1-da2cb005ed62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b5cc20c-807f-41c5-9308-eb5b1c1a9dac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0bf0e2bc-10e7-483c-baf7-113f6cd97e84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca466b81-ad42-4962-8006-c3785646d54f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd347882-c540-4f23-80a9-3b4d15902430
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 111df8cc-e1b5-4ef0-af28-d38c36e57565
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e8636d2-0339-499a-8b2b-fbe024610392
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d35d2a6b-e556-4cf2-8574-1938a0ebc8cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46b518a7-7a0e-4de2-babb-cbda0c68445d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1145cb22-7eac-4084-b7a9-0c8524508458
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2a4e98b-17c1-4dad-bb23-d3ce8e19b40f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3752dbcf-b424-4be9-bcbe-222854f49338
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61c71ae4-5019-42d6-ab0d-af43eb264e2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dbabcc52-9d71-4096-9cfb-1b678afa8fde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ecd41fbe-8e67-4786-b99d-a41495972fa3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message abdd91d7-70ea-4344-a303-3407de83c5c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96be786c-15ec-446c-8443-95836e31775a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c4b0bef-243f-493c-93ff-f2ce77a5d494
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 693a47cf-3748-4aec-8f6c-94b7cf38fcbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 805623b1-bfab-4381-b0fd-176597e94ef9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 152a34f3-7918-4a59-9b40-f9fdec26b4b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29e734d2-842a-4416-81a8-add8630e227d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6dc3b057-3988-4a2a-9bcb-d29d5d16a083
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c6e83eb-9821-4d32-88e2-187467c00b87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e4e4e72-6b82-43d6-9c80-4704bfe29d07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70e25c7a-2cc7-4275-82c3-98f4b9fe802e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c367072-659c-4f42-bd1c-da8a48e6208b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62a8c9d1-c15d-428b-9a55-ac2d0bd0c16d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3af43e9e-1149-458d-b0b8-f8f0cb4827d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12700e35-2643-41ee-98a1-51d79d9687df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1669a640-8595-4947-a94d-c9c44f04ad6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3bb522a0-da1e-4d0a-8580-690ea933841f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16c0be8f-6117-4a82-a12a-446313bb6106
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36cb8d28-5f36-4cd9-b992-72d348450e0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1d9c3ab-5822-431d-a9d1-b6023e5ad6af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c099af44-ab63-4c95-a6e9-c87a69ca785c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2aabae05-0001-4660-8a8e-53066e049f7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d4ff45a-7cec-424f-a016-710f536811ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bbd461d9-2f78-49fa-a0a0-e624b2f1080d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 871b18d2-9855-4258-a465-3788cf845ac1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c50fb51-ff29-408e-86e7-cc6040212d0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83820bed-4baf-4664-8cf1-fdf9ebed5cef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b686434-73bc-4b47-9b4c-2380298b4e4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa791d79-9c48-4ea7-ad78-4abab0a4b952
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a22c899b-e21b-4b4b-b758-947853cd2de3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26452fbd-4f76-452a-8f44-e516ce2aa78b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25bdd60f-7c39-47c1-b13f-c8be6e0de59b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0d6eb37-b203-41a6-a226-676f04600a2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message afa11a2f-d0b3-4748-85b0-e163653d9628
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cde161bb-5047-4b76-b05f-f416a01b3c28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90c9d58c-c94c-4690-af8a-a790bfeb4ae1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 939b6634-7644-4c9b-a38a-cd9b9d9b383b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61ec4330-cd26-4bb7-8416-673e0bcdc931
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ec626c1-0510-42a1-b2a7-e612b017d8a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b54bfcaa-3b9b-4602-bd37-48d6c4680d44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb58a793-096c-4e68-90d7-bfdc72f052eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea54a073-aa1f-49ef-a629-b966509b1a59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e294f71-d2bf-4b89-8122-d665aa1e4e09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8cf5b2e0-17f5-49eb-899c-94073a096dd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17b3b4fb-97bb-4bf2-a851-f4bd009435e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9b130e5-049c-4076-9bf7-0b06e5b99087
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4fed869b-c7a4-41c7-b4a8-a18042d4e26f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b9d732f-6c14-4d15-bcbd-562c3c396654
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75dbafab-53b1-406e-ad47-85ace8775b7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 882544d1-a96b-4db8-a499-7245630a4bed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52db972d-2860-44a8-b70b-effd1ecc8ea1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c21e229-f168-4edc-bd35-c39316fb74da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dabe906d-1421-43d8-9c2c-baa8a750e9ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71fceb6b-a3c7-4a5b-ac44-b1a6ffdd8792
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 619bf85d-6c75-4640-adeb-a035d03e7768
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a55b959-3ecd-4f01-a1d3-03fc47382dd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 231da1ab-02df-44f8-989d-71d0116ab1aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27ce5ef6-228c-4009-80e0-5bb018ff0e96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 655226d4-57b7-492d-909b-6fe072191757
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 954cc0c6-6957-48c9-8f35-5d94b3aaada6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 154af9be-1886-4c25-9a83-616a2feb9885
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e157bac-a150-4df0-bfbe-e74bc4754253
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eebb30c9-6f44-48da-8d76-4d21556f8225
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2bb03bd6-4115-43f3-802a-2c3b263102a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3faecb4-8a4c-4fda-b1df-644d8d5c27bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 581264a1-1985-412e-bd22-63c27279b968
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 115f1936-a8cf-4752-8cc4-481f06e0fb3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a02275f-9779-49cf-852e-5079c2737114
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56550f0e-8cb9-4dfd-9d30-862bcd4414d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a378f9c4-41b5-4456-8701-26d9693fac0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b430c3b4-4505-42fb-8df3-61426e7a785e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06598be7-c466-46f3-aad3-9b720529cdd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 944167ad-ea7e-4dbd-ae8e-55ec05168430
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d29269cf-d44a-4c9a-8834-c04c978e7643
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6902f09-63c8-41dd-9063-a76296b845bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ab7d05d-3513-4715-87d6-230d3080bb0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64fb9c66-8ddf-481e-a07c-6c8747a20c2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35a8140d-8540-4e05-a6f8-92521297b379
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 613cf795-3578-4d1b-ae4e-b4f55c571433
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39f9dbbd-7f98-40bf-853d-3c6a3101c835
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 135ab268-fc29-4f1b-a58d-c56efd503ec2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18e40ffb-3b60-489e-910d-c8406c46b3d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2efc99b-b790-4497-be05-df2849aa4af4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a75eda4-cf34-4a38-a71e-c0aa966f3dd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5efa2ad-8ea6-48d4-9745-f4a74794ffce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aec7fe62-b872-4834-9341-926514f36e08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0a3d343-295c-473d-a5d0-804c9aeedb8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59e5a691-5be8-4328-b8a2-ae6ba24d2334
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3275176-149e-41b5-a80f-c39a5de4b998
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c90462e4-ca57-403f-9852-374079993bb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2bfeab69-5dec-415b-a79c-8e0c3ed3f5d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5fde276-452a-4dc3-bd0c-8ba9c4fbca9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c763cd0c-062e-4bff-9324-5f9d81ff541a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e87a33d-59c9-4b7f-9e7e-c2a44eafc73a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f244861-2f1b-4f24-8678-d8c1dc69f8bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fbac6773-d587-4a94-8315-dd77806b3f57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ad8e8dc-ac33-4c9d-840a-9a2d670c1046
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd61055b-213f-4a78-bea4-ba106b175dca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c15a6491-534b-4ecd-8243-491edc0cf6e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 328df730-b0fd-44dd-9b17-2fcb4d542f65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50f6e03c-fcd1-4150-8f25-5e50a29effa4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2aa7867c-7f8e-4c02-8456-638ec12f0a6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10bea345-dd97-415b-aa79-ee10bccb235f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af55ae7b-352e-42ea-86a5-d7181f49af61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22a0a1c8-ba05-421a-b6ec-2678236624f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5ef679e-d3df-4b36-8ff6-e27716f89c69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0774f6d-b692-4d45-870c-3168004513d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7360b7ca-c1b6-4a07-8f7b-ec35f85dae32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3859e11c-b013-474d-ae5d-ff1ce6a72c33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e468c2a6-2b00-402e-b2ef-cb27d41dec06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49ef30d4-dd46-411e-88ac-a1442a7f7549
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad9a17b1-a2b7-4f29-9c01-80209e47ba9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0062d5f2-fa2a-4e71-80ca-f79385521ef5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb121766-e9f8-43b9-a9a9-c4f9e85d42b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5eb47f4-d427-4998-85da-5c835bf31031
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7b2b15e-a532-40ff-8ccd-b0da94469fd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message efa98e3f-37c7-48ab-b027-5e5ce0aff487
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9214aa7-1e10-4cb2-9f08-316b6e84ab6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e80a42e2-dcb8-403c-a4b1-a9506a9f3982
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ca0bd71-6d35-4ac3-8c2a-e6cc64a7bcd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83d72234-47ab-4964-a617-27db9e7f7e1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25a239e6-effd-46dc-af70-bb622875070b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a70108a-2681-4347-9745-48acc743982c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef5ce979-69b3-43af-b945-5e6142778022
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2c162f4-8810-4e10-bbf5-c2b9b3d8bdff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b75bcb9-a4ae-44b0-958e-35657ebc2f4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e957a189-08b1-4df4-9c44-ca04c6e572a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e13c980d-61ce-452b-838c-b96898d5e0dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6fbe6c35-397b-46df-9dd0-798284576a8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20b282fd-318d-443c-b250-d917c3a7ef9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 757c86d0-e036-4edf-928a-5a5ff676a377
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac1bb925-0bc4-4e7d-b113-91f769383004
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ccc16e18-ef13-4ce6-8a87-f29d31e31541
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c848a7b-475d-4fea-8239-a9b448f7e689
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4cd3cffd-d833-4bd8-bd09-57b4c2753d83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 249426d1-30f7-4266-a40a-352c4cc687ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05c23710-4dbf-4a36-a389-71261a000bef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d3be711-a1cb-4faf-9e84-ce7a033bc332
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66d05e54-c96a-4b6b-ad50-dfe162c8bbdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 236924b6-2f60-43d0-a4bc-69abef4ea64c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 172c7c04-c461-45e1-ad3a-4fec3ea0ec8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17c38678-a81a-4df0-9885-6e991fa83a02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e058bc73-aa53-4719-a893-1a3ce4684df4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba9f4e56-c268-4e52-9f8e-a6946f2c1314
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message efe94cea-4569-4459-9787-b6d30c24f0bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aba7b5b9-9207-4c49-aaec-057bfbc484d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af86a926-df35-483e-97fb-1b24ad0c7906
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e77dd281-4356-4c38-be2e-532931fd4620
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91684b83-55f8-422d-84c3-a5366de0ddbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6dee16a1-53ef-452a-9229-42ff7d7f7355
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message acc8a83d-4d3c-4b22-a3a5-44df874b7dc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1dadba1-db0c-4d80-9fc8-8ff7c279fa73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8214f521-17f1-48e5-b9a3-d3846ea421b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 529128b0-3634-4a17-9a67-cbe9bf46bc2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f51072f0-cf06-4a85-81fd-ae0adb5f0886
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d29f536c-b57c-4501-9b9b-b34d07bdec7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6d33ffa-3971-490b-b2fa-bb91e58b4c09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 515f0eb2-31f1-4a98-9d38-98ce5b2ac33c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56b9960d-e050-4f70-95bb-683763b0bac7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c46c65a-ce98-48ab-879e-2109fed4a299
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f3a769a-c856-4c2d-8811-288028b219fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f68a06a3-bcab-401c-8e9c-f340890afa09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa2aac94-bd86-4f6c-8102-f73b75afbb98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a96d6d4-af37-48b7-beb1-8d66e499afcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90ba33ec-89f9-48a7-a789-065c5339ba75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e356e590-df3a-4902-86f1-35af245285f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28f53fca-72dc-4fdb-b8e0-22f402bc8d0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 834cd0fd-1eec-4fcb-adfd-29434ca8afa1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78400adc-8330-4898-8639-c963af7b6711
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a42a6dc-dd9f-4650-8a4e-ba7e06b3bae8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48f19ec4-7d36-4a14-b072-3bf7f74f4760
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24f97f57-f962-4b89-a8a3-dcb954b20bb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e86db1d-25c5-4e81-9bde-a89a5e752a51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d91478d-5ee6-4079-a9e9-2f38536ad4bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7236175-3faf-46fb-b226-328fde8af1b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ab16f5e-08e9-48f6-96ef-a7f1799ee633
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4e25d12-18f5-40e6-b64e-531d567b3a5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a34cdca3-684f-49cf-81af-eb540e603006
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 598047c6-bff8-4ff6-a692-354ebdf7becb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8567a0ed-bb62-4476-a9e1-82f9a24a4d00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74d362d0-a1f9-4f57-a6b4-f2684e725c6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a230b55b-2582-4e1d-91aa-b2fb4d0c92cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aaa3db0d-85c6-4ffb-85b3-3ffd19cd3ad3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 987b9424-1ec4-452e-9f08-3539e687d4a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13ca1c5e-0aeb-41da-b0c0-ce90ef73b51e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4bf053c2-9f2b-481c-959d-ba96d99744e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1930e96-d6f4-4f7c-a1eb-f30524bab6ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d19910d1-5957-45ff-bbc7-e4f06301fbbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8da09b60-f213-4db3-a48f-7bbaab271998
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2dfad028-b8a3-493b-8cd8-31df3542ff4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf201bae-af7f-4f2f-b1c9-2443ba3c25db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a478a7a-36a9-4efd-bfd8-098a273ae802
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d19d5ca9-cabf-45f8-b54b-8e9f591d2b83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b6ded44-f058-4436-8b35-c39f8e269ae2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 565e7258-3b51-43de-8cd8-446dee9ccf56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2848ce3-9e98-4077-b1a8-d7e06c871f15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d58eea38-c0fc-469c-a401-6f5b4b20adf1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dfb15b1f-68c9-4b6a-8f0b-2c305c3904f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88bc8364-bad7-4d0b-8ae5-64efb2163f9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28974c04-0420-4f08-abc1-29637228d04b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f248cf3-95af-48c6-8a0e-3878c437d35a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3431b0af-692d-4e44-b11c-a69310b5fd00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6970c250-aeba-4645-a667-60490655da80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99216275-7f66-4e27-b90c-8a05e07045fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be0056fd-dc47-4d21-9650-b5dbe5e07a8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10853b65-3149-40f6-8315-3aa3526ce9fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e266f4ad-c8e5-4e16-a005-3220a529d454
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ec36bf3-5519-43fb-ae61-a28bf0170cec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 682934c0-d465-4147-8173-aa93198c23f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7120fa6d-ecf1-4402-a303-9e81f470c522
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47972cc5-150c-45be-a76a-1c6fc7374d1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b80328b0-8aee-4f04-a255-021870c12457
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1202d268-b74c-4c0b-85cf-b0fed4e23342
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0da53f65-abef-403a-a8ac-ffa2f1f4a526
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40370652-ea44-4e6a-8a48-c30ce4c73916
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6cd31470-5179-4287-8335-69c94eead305
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81a462c5-16ab-47df-84e0-0ab7ab0161a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 625a732c-3b1c-49de-b6ca-88945733abd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94f41616-b009-4709-8c56-8b160fc1a3a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a517fd0-870a-41c9-b8ee-4fe38bcb93e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b14cca10-8068-41ca-8e6a-818716e4696c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c89df862-af0c-484f-9702-1af004c9bfd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5b135a2-30de-4165-9b14-a6ca9835e9aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83619cc2-2ad3-4a7d-9cba-b90218d476bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6fad1384-5716-44ec-9d46-12a967e8035f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7160c8b6-ffcc-40d2-83f8-95a51167aaf7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74aabc90-e371-4a3f-90f8-e07d5a2fbb5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9077cca8-7710-419d-b153-2eac93f5414f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11b16c48-17d9-4ca4-b40e-402ccd1066fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05e01542-24d4-496b-b44d-2c3d46646536
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ba0b2cb-3130-4cef-b9b0-bf39019b1b2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a00389c9-4963-49ff-910e-766145f5df01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 824948a0-0ecc-4958-a79a-adf50270547c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f85f761-65aa-4b95-a657-abf932b24067
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a588b1b6-65af-4958-a69b-d2c7eeb1104f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac9c1588-0ca9-4860-ba53-2b6ce8694ad6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9afaec64-0f84-4d6b-b0da-954518e0d8e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8c87c29-be10-442c-a155-d0c8d3e32542
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4738dd5-1ad2-42de-bd10-994f59cf2ae6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d695da5-96d8-4929-8dec-1d160d4dbfa3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21af28ae-f975-4a20-8631-181d32b20bea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 844a4bb1-f9b8-4fe3-9ef7-993a16dae378
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca2d6e8c-3e03-4f88-a6c5-ac38a00c07c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb093b6a-0828-49b9-85d8-d5818f91f9eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0655572-b479-42a0-8ee4-00159f0bdbed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7ead9e9-e90b-4713-8a89-6aaf748ff2c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5238f54f-0be8-4ea4-a0a5-107fc122a4dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32c1f68c-6666-41f0-b40b-80cf532fbb0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa072269-df7f-4287-92cf-c50a029ca084
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b93f18a-cc56-43ea-9330-a8f0f8568976
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0549c487-94b6-4544-8c96-b0b1e7be31d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4863013a-923a-41cd-8523-8af0bc0cb304
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fbfa7953-147c-44ed-80bb-fafca5faf6a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dabe4429-a55f-4f70-8022-d3324494a8d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e02dcd40-1dbc-4c22-8c4f-73451fd1bbea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c6e3809-15fb-405b-9dc1-489a7e149c1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2d7a555-a83e-4f4a-b08d-0cd1ebbfec58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ace6ba98-faa6-4e80-b06a-d52dc6fd64cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c8eb7d7-8d34-4b0f-9f73-e0f028c36018
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97b53733-f361-4ae0-af34-caa0e9359d37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6ef3315-dd13-439b-97f2-2c9a9983b404
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22c32dbf-7b97-4c8b-8bd5-b5fbb2ef122c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71815939-325d-4eea-9324-8096d4732457
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 668f06a9-80af-48bc-9e06-833d37d37584
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d384437-6c2f-4595-8c19-f5c4648426ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0fe437e-a8f3-441d-89e0-e7ef2bf64d16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e19c53b6-0c8a-4e63-bc5e-36a0770d1d89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3979480-72bd-47a8-80fa-9db49c954562
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f1c7c4a-0256-43d8-a86b-69faec4c6219
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 043ae5a7-cc85-4fab-a732-56165ce51dec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2afd7ef0-c784-42b7-9f82-8011c73ecb7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a125c09b-17b0-4fe3-889b-d2e04ae0bbbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5884dc5b-d143-4d89-9efc-473c357cd15f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef77092a-5e24-4df3-859b-40a22c790074
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ea9e0ad-b34b-4128-b4b4-da18954046f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3e15924-3862-4ca5-b0e6-dc49e3a8d2fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3bd6d2d-e1e8-4c5e-afe0-cea4841f406a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb12aac4-fc73-49b2-ab8c-8e463a4fe5ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 160012d1-4496-4974-8881-b9c76c619528
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 857a42d9-aad9-4031-baf7-77b554a8bc65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2beb3e6e-6419-4461-9944-20ed483eeef4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a5f6a36-0759-4fa7-a0bc-bae40e26f963
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1230cdf-c1aa-4729-8ce9-17c13d67d9e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d665dd7c-a4ee-4449-923d-56b51954dbca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2c22ee4-20df-4e91-bc5e-6bf3d0a4300a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e77f599-637a-40d2-9f90-c85332416afd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62cb922c-9657-4f8d-b6e4-5f0d9ace642a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72c89d42-0a92-42bf-9dbd-91ac08e437b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8575bd0-3648-4d66-805b-74f5def0c863
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ca14f3a-9c69-47ca-8e1c-a45901053474
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d46503b-105a-406d-9784-5e94e4cdeb5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6496fa26-b1b0-4465-836e-ec6197da16f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79e5b14e-a84f-4f20-95c2-32bfd1ae5d00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7634952f-57dd-4718-baab-0d16e28309bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c53adfe0-e5dd-4eaa-aad0-49e9d038a13e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2877cdf-ceca-426a-bc27-8047e8d1e1fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32860138-7ff1-4104-90b8-9e09457b41a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33c614f8-c463-4ecd-b7ac-1eb6e0f56fb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa1ff5e0-600e-4f02-be46-daff726b206f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8eae7928-309b-4b50-9c9b-3e779bc4da03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 712a0ff6-a19b-429a-b44e-0b1afac34e5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9b58038-b9c1-40e9-8378-7dbfb9ff5de4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b9b1efa-f361-46e3-a279-4931983cc693
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22f2807e-574b-4e5e-8b30-36052aad7f1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 124cdf24-0321-4e97-bf21-b679380897d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9135125-e4b0-401c-bcde-becc3cd95b31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 309e75c1-357f-4e71-8c5e-f758f985b08c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f492de3a-02aa-430b-ae33-a4a1fb0b9da0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2588d391-461d-4c74-9dcb-341cd57aaef4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4e8f611-c21f-431b-b8ce-4d3f448bf99f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7d3ce78-71b3-4b3b-b1b2-aad9c381ec20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d8729a9-ce24-4eca-9970-990e84c5a8d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 817e4590-3df1-4839-8bb8-1a51c4394374
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72f28de3-3b7e-40e4-9260-22d2ba22be0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2cee041c-ea03-4883-9100-bfa1460f498c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e02d0ec-b00c-41de-a73a-ea1544ea56eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98afb207-510d-4eea-b01a-43f2050e5db1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d87ee30-cefb-4f15-b236-818b69db69f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9811c7fc-513a-4161-871e-4df58b06d7ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a244a65-15a2-476e-a227-4f7842db560f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc1b6026-3798-4b8f-8db8-f48b44f207b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c462519-5eb8-48de-a817-45daabd0e45f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e317b10-c6fc-4889-a4db-994e37615602
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d59f27ea-006f-4baa-ae3c-4b99b55ba6d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47510d19-8f0f-4cf2-b4e1-0f3adab20a6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e0648f0-26ef-455c-8da7-739f98a58ef7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9ed712b-0674-431a-9b45-874de226a10b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2aef7bb3-d0b3-479b-971f-99e52fae7135
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e3e7ee3-0315-4872-8687-048230ae8894
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4bcdbaa1-bd02-4362-b976-ac67b4fd21ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ada7b08-3301-4399-8cf9-2a3b439669a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d9cc64b-be0a-4631-bf20-78e73ff0eb3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a6601f1-e724-4959-a534-814d593f18e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 377f862c-0c88-404d-8d36-b622850ee8dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88fa5a54-e51a-4926-b3ea-d207e5cbfb89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 335d3cba-3b5a-467a-8ffa-12519bcfe7a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3134f6f3-49f9-4e1e-8bbf-aed932922ac7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a188f2f7-1b2d-4ad3-bd26-2d6788911d0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d6ceb38-6214-413d-84db-de87821377c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb0bfea2-10ae-4f37-99d7-f91d1531a947
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 561f4029-93ba-4d10-8764-541a6cb86335
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4bd8b573-aa79-4697-bda7-4bca8f0a0b3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f057d6b-59ae-4f94-801c-c6cb274ed2b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10d92ee0-b6f5-4b1d-9911-502d3d2f9ce3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81354430-4ae5-4a92-86f5-f7aaa48be882
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab0accca-a246-4ba1-a74b-1d062499db87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0536966a-8f27-4b54-bd8e-32894e2cd5f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2785d845-5ddd-4669-8a19-3b78d31a7581
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 759fb3ec-8eee-4109-a0e9-3ac20aef75ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11a7e023-8616-4a5e-aea5-bfef7a2ba5e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83a8b595-fc93-438c-88f5-529b074e2ac5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8cb05ea-c718-4884-ac79-bb06575a829b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c400f3de-0ddc-402f-918c-bdeae443e8c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5a1afb6-df22-407e-87c3-9d91721b8c88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de8c0880-481f-4d4b-894e-3b90de83e10f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1437b705-d7b8-4c31-b396-7339f8613651
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 408ac0f7-bdfc-4bb7-9d21-44b1e64c408f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ddebfd90-289e-4d88-8630-2ae236bc3d98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ea1eec2-c360-4927-9de4-92c5fa9c438b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ffabb908-e937-48ed-8b0e-24dd7514e0ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed1a88e7-b084-46c9-baf5-99dfcbe6a4a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ca4d2d7-fdf6-476d-8ee1-878742ec5921
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 352c68d9-c542-4852-9811-b478b01937be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ece39212-dab5-4f65-9b40-7dd3860f1d7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc528ed6-6baf-4e17-a4b5-cd366bfdf13c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 112871b4-aaf6-4753-9a94-87b2bf00ac0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7e1b7bd-b4a3-49dc-b2e5-50d08a6caba1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24a2ee8d-10dc-43c1-a777-2afd64dfb952
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e1566cf-bb21-47d8-aac6-e080b318d688
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26b4dfab-0101-4e37-8d15-b92d91579d01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60d9eebf-be2d-47d6-a944-71113741fdca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2764ade-8118-4c63-b80a-54933d169c07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18ec3a87-b7d6-41ba-a3e0-ec0ce3a8d18f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8e1ab9b-2ed4-4b7b-9c9a-62b483b63813
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d905f8d2-abf8-414f-8512-f2142dea7c1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 366a467e-53c9-4e05-bfeb-871886f8c62f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 338f5900-f48f-42ab-b79b-44f70936c460
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74ffdf99-a168-4917-9bbe-3b6aa6b96dcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03e3a728-1b25-4bf4-9c5b-e2afd0c06c3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15851cb6-17bc-496c-b41d-506181c3e4f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1d58453-a4bf-4403-9d5d-1ac78c1fbbe6
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8690 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_22
Server: localhost:8690
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_22
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_22/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_22/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_22/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_22/test_labels.txt

📊 Raw data loaded:
   Train: X=(3694, 24), y=(3694,)
   Test:  X=(924, 24), y=(924,)

⚠️  Limiting training data: 3694 → 800 samples
⚠️  Limiting test data: 924 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_22 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 1 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.2990, val=0.1300 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0872, val=0.0824 (↓), lr=0.001000
   ✓ Epoch   3/100: train=0.0830, val=0.0768 (↓), lr=0.001000
   • Epoch   4/100: train=0.0855, val=0.0764, patience=1/15, lr=0.001000
   ✓ Epoch   5/100: train=0.0854, val=0.0762 (↓), lr=0.001000
   • Epoch  11/100: train=0.0830, val=0.0761, patience=6/15, lr=0.001000
   📉 Epoch 16: LR reduced 0.001000 → 0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 1 Summary - Client client_22
   Epochs: 20/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=-0.0265
   Val:   Loss=0.0762, RMSE=0.2761, R²=-0.0016
============================================================


============================================================
🔄 Round 2 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0861 (↓), lr=0.000500
   ✓ Epoch   2/100: train=0.0806, val=0.0856 (↓), lr=0.000500
   • Epoch   3/100: train=0.0804, val=0.0856, patience=1/15, lr=0.000500
   📉 Epoch 4: LR reduced 0.000500 → 0.000250
   • Epoch   4/100: train=0.0802, val=0.0856, patience=2/15, lr=0.000250
   • Epoch   5/100: train=0.0798, val=0.0863, patience=3/15, lr=0.000250
   • Epoch  11/100: train=0.0793, val=0.0865, patience=9/15, lr=0.000250
   📉 Epoch 12: LR reduced 0.000250 → 0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 2 Summary - Client client_22
   Epochs: 17/100 (early stopped)
   LR: 0.000500 → 0.000125 (2 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0002
   Val:   Loss=0.0856, RMSE=0.2925, R²=-0.0211
============================================================


📊 Round 2 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2427, R²: -0.0048

📊 Round 2 Test Metrics:
   Loss: 0.0801, RMSE: 0.2829, MAE: 0.2422, R²: 0.0003

============================================================
🔄 Round 5 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0719 (↓), lr=0.000125
   • Epoch   2/100: train=0.0840, val=0.0723, patience=1/15, lr=0.000125
   • Epoch   3/100: train=0.0839, val=0.0720, patience=2/15, lr=0.000125
   • Epoch   4/100: train=0.0839, val=0.0719, patience=3/15, lr=0.000125
   • Epoch   5/100: train=0.0838, val=0.0719, patience=4/15, lr=0.000125
   • Epoch  11/100: train=0.0836, val=0.0717, patience=10/15, lr=0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0719)

============================================================
📊 Round 5 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000125 → 0.000125 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0034
   Val:   Loss=0.0719, RMSE=0.2682, R²=-0.0507
============================================================


📊 Round 5 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2423, R²: -0.0016

============================================================
🔄 Round 11 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0737 (↓), lr=0.000125
   • Epoch   2/100: train=0.0835, val=0.0736, patience=1/15, lr=0.000125
   • Epoch   3/100: train=0.0835, val=0.0736, patience=2/15, lr=0.000125
   • Epoch   4/100: train=0.0834, val=0.0737, patience=3/15, lr=0.000125
   • Epoch   5/100: train=0.0834, val=0.0738, patience=4/15, lr=0.000125
   📉 Epoch 6: LR reduced 0.000125 → 0.000063
   • Epoch  11/100: train=0.0831, val=0.0740, patience=10/15, lr=0.000063
   📉 Epoch 14: LR reduced 0.000063 → 0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 11 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000125 → 0.000031 (2 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0032
   Val:   Loss=0.0737, RMSE=0.2715, R²=-0.0112
============================================================


============================================================
🔄 Round 12 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0871 (↓), lr=0.000031
   • Epoch   2/100: train=0.0801, val=0.0875, patience=1/15, lr=0.000031
   • Epoch   3/100: train=0.0800, val=0.0878, patience=2/15, lr=0.000031
   • Epoch   4/100: train=0.0800, val=0.0880, patience=3/15, lr=0.000031
   • Epoch   5/100: train=0.0800, val=0.0881, patience=4/15, lr=0.000031
   📉 Epoch 6: LR reduced 0.000031 → 0.000016
   • Epoch  11/100: train=0.0799, val=0.0882, patience=10/15, lr=0.000016
   📉 Epoch 14: LR reduced 0.000016 → 0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 12 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000031 → 0.000008 (2 reductions)
   Train: Loss=0.0801, RMSE=0.2829, R²=-0.0050
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0306
============================================================


============================================================
🔄 Round 14 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0800 (↓), lr=0.000008
   • Epoch   2/100: train=0.0818, val=0.0800, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0818, val=0.0800, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0817, val=0.0800, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0817, val=0.0800, patience=4/15, lr=0.000008
   📉 Epoch 6: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0817, val=0.0801, patience=10/15, lr=0.000004
   📉 Epoch 14: LR reduced 0.000004 → 0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 14 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0042
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0296
============================================================


============================================================
🔄 Round 15 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0849 (↓), lr=0.000002
   • Epoch   2/100: train=0.0808, val=0.0849, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0808, val=0.0849, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0808, val=0.0849, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0808, val=0.0849, patience=4/15, lr=0.000002
   📉 Epoch 6: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0808, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 15 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0056
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0083
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2422, R²: -0.0004

============================================================
🔄 Round 19 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 19 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0048
   Val:   Loss=0.0766, RMSE=0.2768, R²=-0.0112
============================================================


============================================================
🔄 Round 20 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 20 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0063
   Val:   Loss=0.0762, RMSE=0.2760, R²=0.0013
============================================================


============================================================
🔄 Round 22 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0718, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 22 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0036
   Val:   Loss=0.0718, RMSE=0.2680, R²=-0.0110
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0006

============================================================
🔄 Round 23 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 23 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0042
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0055
============================================================


============================================================
🔄 Round 25 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 25 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=-0.0065
   Val:   Loss=0.0836, RMSE=0.2892, R²=-0.0108
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0006

============================================================
🔄 Round 26 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 26 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2835, R²=-0.0031
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0150
============================================================


============================================================
🔄 Round 27 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 27 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0051
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0033
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0006

============================================================
🔄 Round 28 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 28 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=-0.0058
   Val:   Loss=0.0788, RMSE=0.2808, R²=0.0011
============================================================


============================================================
🔄 Round 29 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 29 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=-0.0053
   Val:   Loss=0.0907, RMSE=0.3012, R²=-0.0038
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0006

📊 Round 29 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0007

============================================================
🔄 Round 32 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 32 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0058
   Val:   Loss=0.0853, RMSE=0.2921, R²=0.0007
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0007

============================================================
🔄 Round 35 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 35 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0059
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0049
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0007

📊 Round 35 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0007

============================================================
🔄 Round 37 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 37 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0069
   Val:   Loss=0.0757, RMSE=0.2751, R²=0.0057
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0007

============================================================
🔄 Round 38 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 38 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0042
   Val:   Loss=0.0727, RMSE=0.2696, R²=-0.0113
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0007

============================================================
🔄 Round 39 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 39 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0056
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0186
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0007

============================================================
🔄 Round 41 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 41 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0028
   Val:   Loss=0.0839, RMSE=0.2896, R²=-0.0191
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0007

📊 Round 41 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0006

============================================================
🔄 Round 50 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 50 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0053
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0097
============================================================


============================================================
🔄 Round 52 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 52 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0053
   Val:   Loss=0.0834, RMSE=0.2889, R²=-0.0009
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0006

============================================================
🔄 Round 56 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 56 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=-0.0063
   Val:   Loss=0.0918, RMSE=0.3029, R²=-0.0049
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0006

============================================================
🔄 Round 58 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 58 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0025
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0118
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0007

============================================================
🔄 Round 59 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0961 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0961, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0961, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0961, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0961, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0962, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0961)

============================================================
📊 Round 59 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2790, R²=-0.0048
   Val:   Loss=0.0961, RMSE=0.3100, R²=-0.0277
============================================================


============================================================
🔄 Round 61 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 61 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0041
   Val:   Loss=0.0729, RMSE=0.2700, R²=-0.0082
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0007

============================================================
🔄 Round 63 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 63 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=-0.0049
   Val:   Loss=0.0853, RMSE=0.2920, R²=-0.0031
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0007

============================================================
🔄 Round 65 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 65 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0045
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0039
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0007

============================================================
🔄 Round 66 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 66 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=-0.0053
   Val:   Loss=0.0901, RMSE=0.3002, R²=-0.0010
============================================================


============================================================
🔄 Round 67 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 67 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0075
   Val:   Loss=0.0831, RMSE=0.2882, R²=0.0037
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0007

============================================================
🔄 Round 68 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 68 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0061
   Val:   Loss=0.0867, RMSE=0.2945, R²=0.0002
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0007

📊 Round 68 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0007

============================================================
🔄 Round 71 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 71 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0065
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0025
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0007

📊 Round 71 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0007

📊 Round 71 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0007

============================================================
🔄 Round 74 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 74 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=-0.0034
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0117
============================================================


============================================================
🔄 Round 75 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 75 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0032
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0087
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0007

📊 Round 75 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0007

============================================================
🔄 Round 81 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 81 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0054
   Val:   Loss=0.0793, RMSE=0.2817, R²=-0.0046
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0007

============================================================
🔄 Round 84 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 84 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0081
   Val:   Loss=0.0858, RMSE=0.2930, R²=-0.0122
============================================================


============================================================
🔄 Round 86 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 86 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0022
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0227
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0007

============================================================
🔄 Round 89 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 89 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=-0.0031
   Val:   Loss=0.0910, RMSE=0.3016, R²=-0.0100
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0007

============================================================
🔄 Round 93 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 93 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0064
   Val:   Loss=0.0802, RMSE=0.2831, R²=-0.0208
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0006

📊 Round 93 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0006

============================================================
🔄 Round 95 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 95 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=-0.0063
   Val:   Loss=0.0911, RMSE=0.3019, R²=-0.0079
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0007

============================================================
🔄 Round 96 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 96 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0057
   Val:   Loss=0.0799, RMSE=0.2826, R²=-0.0014
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0007

📊 Round 96 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0007

============================================================
🔄 Round 100 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 100 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0035
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0081
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0006

============================================================
🔄 Round 101 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 101 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0057
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0140
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0007

============================================================
🔄 Round 103 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 103 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0068
   Val:   Loss=0.0873, RMSE=0.2955, R²=0.0043
============================================================


============================================================
🔄 Round 105 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 105 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=-0.0032
   Val:   Loss=0.0885, RMSE=0.2974, R²=-0.0204
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0007

============================================================
🔄 Round 107 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 107 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=-0.0064
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0001
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0007

============================================================
🔄 Round 111 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 111 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0068
   Val:   Loss=0.0802, RMSE=0.2833, R²=-0.0028
============================================================


============================================================
🔄 Round 112 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 112 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=-0.0039
   Val:   Loss=0.0869, RMSE=0.2947, R²=-0.0068
============================================================


============================================================
🔄 Round 114 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 114 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0053
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0133
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0007

============================================================
🔄 Round 115 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 115 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0048
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0033
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0008

📊 Round 115 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0007

============================================================
🔄 Round 123 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 123 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0034
   Val:   Loss=0.0857, RMSE=0.2928, R²=-0.0105
============================================================


============================================================
🔄 Round 124 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 124 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=-0.0041
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0071
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0007

============================================================
🔄 Round 126 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 126 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0044
   Val:   Loss=0.0759, RMSE=0.2755, R²=-0.0056
============================================================


============================================================
🔄 Round 127 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 127 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=-0.0035
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0076
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0007

============================================================
🔄 Round 128 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 128 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0034
   Val:   Loss=0.0765, RMSE=0.2767, R²=-0.0176
============================================================


============================================================
🔄 Round 129 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 129 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0054
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0032
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0007

============================================================
🔄 Round 130 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 130 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0056
   Val:   Loss=0.0778, RMSE=0.2789, R²=-0.0104
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0007

============================================================
🔄 Round 132 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 132 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0043
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0172
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0006

📊 Round 132 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0006

📊 Round 132 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0006

============================================================
🔄 Round 136 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 136 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0081
   Val:   Loss=0.0755, RMSE=0.2748, R²=-0.0022
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0006

============================================================
🔄 Round 138 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 138 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0048
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0268
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0006

============================================================
🔄 Round 139 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 139 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0037
   Val:   Loss=0.0762, RMSE=0.2760, R²=-0.0191
============================================================


============================================================
🔄 Round 141 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 141 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0048
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0026
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0006

📊 Round 141 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0006

📊 Round 141 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0006

============================================================
🔄 Round 144 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 144 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0036
   Val:   Loss=0.0776, RMSE=0.2786, R²=-0.0093
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0006

============================================================
🔄 Round 145 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 145 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0051
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0135
============================================================


============================================================
🔄 Round 146 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 146 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0035
   Val:   Loss=0.0792, RMSE=0.2815, R²=-0.0252
============================================================


============================================================
🔄 Round 147 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 147 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0045
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0035
============================================================


============================================================
🔄 Round 148 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 148 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0053
   Val:   Loss=0.0777, RMSE=0.2787, R²=-0.0055
============================================================


============================================================
🔄 Round 152 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 152 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0033
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0088
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0007

============================================================
🔄 Round 154 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 154 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0052
   Val:   Loss=0.0748, RMSE=0.2734, R²=-0.0069
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0007

============================================================
🔄 Round 157 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 157 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0074
   Val:   Loss=0.0739, RMSE=0.2718, R²=-0.0127
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0007

============================================================
🔄 Round 158 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0699 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0699, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0699, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0699, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0699, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0699, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0699)

============================================================
📊 Round 158 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0048
   Val:   Loss=0.0699, RMSE=0.2643, R²=-0.0295
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0007

============================================================
🔄 Round 162 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 162 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0069
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0019
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0007

============================================================
🔄 Round 164 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 164 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0059
   Val:   Loss=0.0781, RMSE=0.2795, R²=-0.0037
============================================================


============================================================
🔄 Round 165 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0709 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0709, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0709, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0709, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0709, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0709, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0709)

============================================================
📊 Round 165 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0045
   Val:   Loss=0.0709, RMSE=0.2663, R²=-0.0067
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0007

📊 Round 165 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0007

============================================================
🔄 Round 167 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 167 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0027
   Val:   Loss=0.0855, RMSE=0.2925, R²=-0.0104
============================================================


============================================================
🔄 Round 168 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 168 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0041
   Val:   Loss=0.0805, RMSE=0.2838, R²=-0.0115
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0007

============================================================
🔄 Round 169 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 169 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=-0.0050
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0016
============================================================


============================================================
🔄 Round 170 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 170 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0038
   Val:   Loss=0.0766, RMSE=0.2768, R²=-0.0068
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0007

============================================================
🔄 Round 171 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 171 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0041
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0113
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0008

📊 Round 171 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0008

============================================================
🔄 Round 174 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 174 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=-0.0038
   Val:   Loss=0.0903, RMSE=0.3004, R²=-0.0062
============================================================


============================================================
🔄 Round 175 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 175 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0044
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0104
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0008

============================================================
🔄 Round 176 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 176 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0058
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0012
============================================================


============================================================
🔄 Round 177 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 177 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0035
   Val:   Loss=0.0822, RMSE=0.2868, R²=-0.0072
============================================================


============================================================
🔄 Round 178 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0688 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0688, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0688, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0688, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0688, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0688, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0688)

============================================================
📊 Round 178 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0052
   Val:   Loss=0.0688, RMSE=0.2623, R²=0.0002
============================================================


============================================================
🔄 Round 179 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 179 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0057
   Val:   Loss=0.0841, RMSE=0.2899, R²=-0.0039
============================================================


============================================================
🔄 Round 180 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 180 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0062
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0023
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0007

📊 Round 180 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0007

============================================================
🔄 Round 184 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 184 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0055
   Val:   Loss=0.0729, RMSE=0.2700, R²=-0.0007
============================================================


============================================================
🔄 Round 186 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 186 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0032
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0124
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0007

============================================================
🔄 Round 188 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0927 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0927, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0927, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0927, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0927, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0927)

============================================================
📊 Round 188 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=-0.0038
   Val:   Loss=0.0927, RMSE=0.3045, R²=-0.0079
============================================================


============================================================
🔄 Round 191 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 191 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=-0.0041
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0060
============================================================


📊 Round 191 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0006

📊 Round 191 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0006

============================================================
🔄 Round 195 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 195 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0045
   Val:   Loss=0.0784, RMSE=0.2800, R²=-0.0141
============================================================


============================================================
🔄 Round 196 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 196 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=-0.0032
   Val:   Loss=0.0816, RMSE=0.2856, R²=-0.0150
============================================================


============================================================
🔄 Round 197 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 197 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=-0.0049
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0018
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0006

📊 Round 197 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0006

============================================================
🔄 Round 200 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 200 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0045
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0033
============================================================


📊 Round 200 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0006

📊 Round 200 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0006

============================================================
🔄 Round 206 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 206 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0029
   Val:   Loss=0.0791, RMSE=0.2812, R²=-0.0268
============================================================


📊 Round 206 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0006

============================================================
🔄 Round 209 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 209 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0027
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0244
============================================================


📊 Round 209 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0006

============================================================
🔄 Round 210 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 210 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0055
   Val:   Loss=0.0775, RMSE=0.2784, R²=-0.0012
============================================================


============================================================
🔄 Round 211 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 211 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0053
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0042
============================================================


📊 Round 211 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0006

📊 Round 211 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0006

============================================================
🔄 Round 213 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 213 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0045
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0035
============================================================


============================================================
🔄 Round 214 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 214 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0051
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0015
============================================================


============================================================
🔄 Round 216 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 216 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=-0.0091
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0119
============================================================


📊 Round 216 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0006

============================================================
🔄 Round 218 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 218 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0051
   Val:   Loss=0.0864, RMSE=0.2940, R²=-0.0043
============================================================


📊 Round 218 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0006

============================================================
🔄 Round 219 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 219 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0060
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0002
============================================================


============================================================
🔄 Round 220 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 220 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0042
   Val:   Loss=0.0782, RMSE=0.2796, R²=-0.0174
============================================================


============================================================
🔄 Round 222 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0719 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0719, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0719, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0719, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0719)

============================================================
📊 Round 222 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0031
   Val:   Loss=0.0719, RMSE=0.2681, R²=-0.0100
============================================================


📊 Round 222 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0006

📊 Round 222 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0006

📊 Round 222 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0006

📊 Round 222 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0006

============================================================
🔄 Round 227 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 227 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0056
   Val:   Loss=0.0748, RMSE=0.2734, R²=0.0013
============================================================


📊 Round 227 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0006

============================================================
🔄 Round 228 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 228 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=-0.0055
   Val:   Loss=0.0879, RMSE=0.2965, R²=-0.0020
============================================================


📊 Round 228 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0006

📊 Round 228 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0006

📊 Round 228 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0006

============================================================
🔄 Round 235 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 235 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0030
   Val:   Loss=0.0771, RMSE=0.2776, R²=-0.0114
============================================================


📊 Round 235 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0006

============================================================
🔄 Round 236 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 236 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=-0.0046
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0143
============================================================


📊 Round 236 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0006

📊 Round 236 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0006

============================================================
🔄 Round 241 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 241 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0037
   Val:   Loss=0.0876, RMSE=0.2959, R²=-0.0110
============================================================


📊 Round 241 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0005

📊 Round 241 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2422, R²: -0.0005

============================================================
🔄 Round 244 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 244 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0022
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0141
============================================================


============================================================
🔄 Round 245 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 245 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0042
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0158
============================================================


📊 Round 245 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0005

📊 Round 245 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0005

============================================================
🔄 Round 247 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 247 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0032
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0129
============================================================


============================================================
🔄 Round 248 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 248 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0039
   Val:   Loss=0.0783, RMSE=0.2799, R²=-0.0157
============================================================


============================================================
🔄 Round 250 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 250 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0046
   Val:   Loss=0.0775, RMSE=0.2785, R²=-0.0040
============================================================


============================================================
🔄 Round 251 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 251 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=-0.0044
   Val:   Loss=0.0753, RMSE=0.2744, R²=-0.0079
============================================================


📊 Round 251 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0005

============================================================
🔄 Round 253 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 253 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0066
   Val:   Loss=0.0813, RMSE=0.2852, R²=-0.0292
============================================================


============================================================
🔄 Round 254 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 254 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0061
   Val:   Loss=0.0813, RMSE=0.2852, R²=0.0012
============================================================


============================================================
🔄 Round 255 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 255 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=-0.0045
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0034
============================================================


📊 Round 255 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2422, R²: -0.0005

============================================================
🔄 Round 259 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 259 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2849, R²=-0.0090
   Val:   Loss=0.0829, RMSE=0.2878, R²=-0.0104
============================================================


📊 Round 259 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0006

============================================================
🔄 Round 260 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 260 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0054
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0004
============================================================


============================================================
🔄 Round 261 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 261 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0045
   Val:   Loss=0.0791, RMSE=0.2813, R²=-0.0044
============================================================


📊 Round 261 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0006

============================================================
🔄 Round 268 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 268 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0060
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0014
============================================================


📊 Round 268 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0006

============================================================
🔄 Round 270 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 270 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=-0.0026
   Val:   Loss=0.0772, RMSE=0.2779, R²=-0.0127
============================================================


============================================================
🔄 Round 271 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 271 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0039
   Val:   Loss=0.0778, RMSE=0.2789, R²=-0.0059
============================================================


============================================================
🔄 Round 273 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 273 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0030
   Val:   Loss=0.0842, RMSE=0.2901, R²=-0.0097
============================================================


============================================================
🔄 Round 276 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 276 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=-0.0034
   Val:   Loss=0.0768, RMSE=0.2772, R²=-0.0090
============================================================


📊 Round 276 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2422, R²: -0.0005

============================================================
🔄 Round 278 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 278 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0047
   Val:   Loss=0.0735, RMSE=0.2711, R²=-0.0031
============================================================


============================================================
🔄 Round 279 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 279 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0077
   Val:   Loss=0.0742, RMSE=0.2724, R²=-0.0199
============================================================


📊 Round 279 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0005

📊 Round 279 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0005

============================================================
🔄 Round 282 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0725, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 282 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=-0.0036
   Val:   Loss=0.0725, RMSE=0.2693, R²=-0.0084
============================================================


📊 Round 282 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0005

📊 Round 282 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2422, R²: -0.0005

============================================================
🔄 Round 285 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 285 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0053
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0016
============================================================


📊 Round 285 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0005

============================================================
🔄 Round 286 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 286 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0033
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0152
============================================================


📊 Round 286 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0006

============================================================
🔄 Round 287 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0666 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0666, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0666, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0666, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0666, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0666, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0666)

============================================================
📊 Round 287 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0041
   Val:   Loss=0.0666, RMSE=0.2581, R²=-0.0108
============================================================


============================================================
🔄 Round 288 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 288 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=-0.0050
   Val:   Loss=0.0849, RMSE=0.2913, R²=-0.0019
============================================================


📊 Round 288 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0005

============================================================
🔄 Round 289 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 289 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=-0.0040
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0228
============================================================


📊 Round 289 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0005

============================================================
🔄 Round 292 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 292 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0054
   Val:   Loss=0.0846, RMSE=0.2908, R²=-0.0083
============================================================


📊 Round 292 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2422, R²: -0.0005

============================================================
🔄 Round 293 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 293 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0045
   Val:   Loss=0.0814, RMSE=0.2854, R²=-0.0074
============================================================


📊 Round 293 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2422, R²: -0.0005

============================================================
🔄 Round 294 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 294 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0019
   Val:   Loss=0.0724, RMSE=0.2690, R²=-0.0153
============================================================


📊 Round 294 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2422, R²: -0.0005

============================================================
🔄 Round 296 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0722 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 296 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0042
   Val:   Loss=0.0722, RMSE=0.2686, R²=-0.0120
============================================================


📊 Round 296 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0005

============================================================
🔄 Round 297 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 297 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0033
   Val:   Loss=0.0774, RMSE=0.2782, R²=-0.0392
============================================================


============================================================
🔄 Round 299 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 299 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=-0.0053
   Val:   Loss=0.0898, RMSE=0.2996, R²=-0.0018
============================================================


📊 Round 299 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0005

📊 Round 299 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0005

📊 Round 299 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0005

============================================================
🔄 Round 302 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0711 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0711, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0711, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0711, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0711, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0712, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0711)

============================================================
📊 Round 302 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0057
   Val:   Loss=0.0711, RMSE=0.2666, R²=-0.0203
============================================================


============================================================
🔄 Round 304 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 304 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=-0.0049
   Val:   Loss=0.0772, RMSE=0.2779, R²=-0.0097
============================================================


============================================================
🔄 Round 305 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 305 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0038
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0063
============================================================


📊 Round 305 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2422, R²: -0.0005

============================================================
🔄 Round 308 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 308 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0046
   Val:   Loss=0.0734, RMSE=0.2709, R²=-0.0029
============================================================


📊 Round 308 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0005

📊 Round 308 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0006

============================================================
🔄 Round 315 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 315 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0046
   Val:   Loss=0.0829, RMSE=0.2878, R²=-0.0112
============================================================


📊 Round 315 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0005

============================================================
🔄 Round 316 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 316 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0039
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0081
============================================================


============================================================
🔄 Round 319 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 319 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0029
   Val:   Loss=0.0779, RMSE=0.2791, R²=-0.0139
============================================================


📊 Round 319 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0005

📊 Round 319 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2422, R²: -0.0005

============================================================
🔄 Round 321 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 321 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0045
   Val:   Loss=0.0882, RMSE=0.2969, R²=-0.0192
============================================================


📊 Round 321 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2422, R²: -0.0005

============================================================
🔄 Round 325 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 325 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0050
   Val:   Loss=0.0746, RMSE=0.2731, R²=-0.0038
============================================================


============================================================
🔄 Round 326 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 326 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=-0.0021
   Val:   Loss=0.0896, RMSE=0.2993, R²=-0.0122
============================================================


============================================================
🔄 Round 327 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 327 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0036
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0179
============================================================


============================================================
🔄 Round 328 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 328 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0061
   Val:   Loss=0.0770, RMSE=0.2775, R²=-0.0060
============================================================


📊 Round 328 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2422, R²: -0.0005

📊 Round 328 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2422, R²: -0.0005

============================================================
🔄 Round 332 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 332 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0024
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0166
============================================================


============================================================
🔄 Round 333 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 333 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0051
   Val:   Loss=0.0813, RMSE=0.2852, R²=-0.0156
============================================================


============================================================
🔄 Round 334 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 334 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0017
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0151
============================================================


📊 Round 334 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2422, R²: -0.0005

============================================================
🔄 Round 337 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 337 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0033
   Val:   Loss=0.0750, RMSE=0.2739, R²=-0.0148
============================================================


============================================================
🔄 Round 338 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0698 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0698, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0698, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0698, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0698, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0698, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0698)

============================================================
📊 Round 338 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0045
   Val:   Loss=0.0698, RMSE=0.2643, R²=-0.0034
============================================================


📊 Round 338 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0005

============================================================
🔄 Round 340 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 340 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2864, R²=-0.0052
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0026
============================================================


📊 Round 340 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0005

============================================================
🔄 Round 341 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 341 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0031
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0146
============================================================


📊 Round 341 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0005

📊 Round 341 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0005

============================================================
🔄 Round 343 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 343 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=-0.0054
   Val:   Loss=0.0889, RMSE=0.2981, R²=0.0001
============================================================


📊 Round 343 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0005

📊 Round 343 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0005

📊 Round 343 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0006

============================================================
🔄 Round 347 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 347 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0047
   Val:   Loss=0.0813, RMSE=0.2852, R²=-0.0083
============================================================


📊 Round 347 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0006

============================================================
🔄 Round 349 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 349 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=-0.0041
   Val:   Loss=0.0736, RMSE=0.2713, R²=-0.0086
============================================================


============================================================
🔄 Round 352 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 352 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0036
   Val:   Loss=0.0847, RMSE=0.2911, R²=-0.0116
============================================================


📊 Round 352 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0006

============================================================
🔄 Round 353 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 353 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=-0.0032
   Val:   Loss=0.0768, RMSE=0.2772, R²=-0.0119
============================================================


📊 Round 353 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0006

============================================================
🔄 Round 354 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 354 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0058
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0214
============================================================


📊 Round 354 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0006

📊 Round 354 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0006

📊 Round 354 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0006

============================================================
🔄 Round 359 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 359 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0053
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0014
============================================================


📊 Round 359 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0006

============================================================
🔄 Round 360 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0663 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0663, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0663, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0663, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0663, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0663, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0663)

============================================================
📊 Round 360 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0068
   Val:   Loss=0.0663, RMSE=0.2575, R²=0.0090
============================================================


📊 Round 360 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0006

============================================================
🔄 Round 362 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 362 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0045
   Val:   Loss=0.0777, RMSE=0.2788, R²=-0.0100
============================================================


📊 Round 362 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0006

============================================================
🔄 Round 364 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 364 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0041
   Val:   Loss=0.0797, RMSE=0.2824, R²=-0.0054
============================================================


📊 Round 364 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0006

============================================================
🔄 Round 365 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 365 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=-0.0062
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0401
============================================================


📊 Round 365 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0006

📊 Round 365 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0006

============================================================
🔄 Round 375 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 375 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0048
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0054
============================================================


============================================================
🔄 Round 376 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 376 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0048
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0027
============================================================


📊 Round 376 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0006

============================================================
🔄 Round 378 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 378 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0039
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0062
============================================================


📊 Round 378 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0006

📊 Round 378 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0006

📊 Round 378 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0006

============================================================
🔄 Round 385 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 385 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0030
   Val:   Loss=0.0857, RMSE=0.2928, R²=-0.0112
============================================================


============================================================
🔄 Round 386 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 386 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0049
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0015
============================================================


============================================================
🔄 Round 387 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 387 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0049
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0066
============================================================


📊 Round 387 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0006

============================================================
🔄 Round 388 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 388 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0035
   Val:   Loss=0.0764, RMSE=0.2764, R²=-0.0167
============================================================


📊 Round 388 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0006

📊 Round 388 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0006

============================================================
🔄 Round 390 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 390 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0039
   Val:   Loss=0.0806, RMSE=0.2838, R²=-0.0054
============================================================


============================================================
🔄 Round 392 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 392 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0031
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0230
============================================================


============================================================
🔄 Round 394 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 394 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0033
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0297
============================================================


============================================================
🔄 Round 398 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 398 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=-0.0034
   Val:   Loss=0.0849, RMSE=0.2913, R²=-0.0090
============================================================


============================================================
🔄 Round 399 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 399 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0049
   Val:   Loss=0.0777, RMSE=0.2788, R²=-0.0037
============================================================


📊 Round 399 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0005

============================================================
🔄 Round 402 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 402 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0056
   Val:   Loss=0.0770, RMSE=0.2774, R²=0.0019
============================================================


📊 Round 402 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0005

============================================================
🔄 Round 409 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 409 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0043
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0036
============================================================


============================================================
🔄 Round 410 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 410 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0042
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0060
============================================================


============================================================
🔄 Round 411 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 411 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0054
   Val:   Loss=0.0777, RMSE=0.2787, R²=-0.0025
============================================================


============================================================
🔄 Round 412 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 412 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0060
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0000
============================================================


📊 Round 412 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0005

============================================================
🔄 Round 413 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 413 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0050
   Val:   Loss=0.0743, RMSE=0.2725, R²=-0.0186
============================================================


============================================================
🔄 Round 414 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 414 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0029
   Val:   Loss=0.0887, RMSE=0.2978, R²=-0.0152
============================================================


📊 Round 414 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2421, R²: -0.0005

📊 Round 414 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2421, R²: -0.0005

📊 Round 414 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2421, R²: -0.0005

📊 Round 414 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2421, R²: -0.0005

📊 Round 414 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2421, R²: -0.0004

📊 Round 414 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2421, R²: -0.0004

============================================================
🔄 Round 421 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 421 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0053
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0001
============================================================


============================================================
🔄 Round 422 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 422 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0048
   Val:   Loss=0.0793, RMSE=0.2817, R²=-0.0119
============================================================


============================================================
🔄 Round 424 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 424 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0063
   Val:   Loss=0.0858, RMSE=0.2928, R²=-0.0107
============================================================


📊 Round 424 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2421, R²: -0.0005

============================================================
🔄 Round 431 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 431 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0057
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0202
============================================================


📊 Round 431 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2421, R²: -0.0004

📊 Round 431 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2421, R²: -0.0004

============================================================
🔄 Round 438 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 438 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0043
   Val:   Loss=0.0887, RMSE=0.2979, R²=-0.0042
============================================================


📊 Round 438 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2421, R²: -0.0004

📊 Round 438 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2421, R²: -0.0004

============================================================
🔄 Round 441 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 441 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0047
   Val:   Loss=0.0754, RMSE=0.2746, R²=-0.0231
============================================================


============================================================
🔄 Round 442 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 442 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0066
   Val:   Loss=0.0741, RMSE=0.2723, R²=0.0043
============================================================


============================================================
🔄 Round 444 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 444 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0061
   Val:   Loss=0.0733, RMSE=0.2707, R²=-0.0060
============================================================


============================================================
🔄 Round 446 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 446 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=-0.0024
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0160
============================================================


📊 Round 446 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2421, R²: -0.0005

============================================================
🔄 Round 448 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 448 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2870, R²=-0.0027
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0105
============================================================


📊 Round 448 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2421, R²: -0.0005

============================================================
🔄 Round 449 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 449 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=-0.0024
   Val:   Loss=0.0768, RMSE=0.2771, R²=-0.0547
============================================================


📊 Round 449 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2421, R²: -0.0005

============================================================
🔄 Round 450 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 450 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0047
   Val:   Loss=0.0852, RMSE=0.2920, R²=-0.0020
============================================================


📊 Round 450 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2421, R²: -0.0005

📊 Round 450 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2421, R²: -0.0005

📊 Round 450 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2421, R²: -0.0005

============================================================
🔄 Round 453 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 453 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0021
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.0148
============================================================


📊 Round 453 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2421, R²: -0.0005

============================================================
🔄 Round 454 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 454 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0039
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0073
============================================================


📊 Round 454 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2421, R²: -0.0005

============================================================
🔄 Round 457 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 457 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=-0.0057
   Val:   Loss=0.0800, RMSE=0.2829, R²=0.0000
============================================================


📊 Round 457 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2421, R²: -0.0005

============================================================
🔄 Round 458 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 458 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0051
   Val:   Loss=0.0781, RMSE=0.2794, R²=-0.0010
============================================================


📊 Round 458 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2421, R²: -0.0005

============================================================
🔄 Round 461 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 461 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0045
   Val:   Loss=0.0854, RMSE=0.2923, R²=-0.0108
============================================================


📊 Round 461 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2421, R²: -0.0005

============================================================
🔄 Round 462 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 462 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0073
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0222
============================================================


📊 Round 462 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2421, R²: -0.0005

============================================================
🔄 Round 464 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 464 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=-0.0043
   Val:   Loss=0.0816, RMSE=0.2856, R²=-0.0111
============================================================


📊 Round 464 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2421, R²: -0.0005

📊 Round 464 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2421, R²: -0.0005

============================================================
🔄 Round 467 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 467 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=-0.0018
   Val:   Loss=0.0925, RMSE=0.3041, R²=-0.0132
============================================================


============================================================
🔄 Round 470 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 470 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0031
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0089
============================================================


📊 Round 470 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0006

============================================================
🔄 Round 471 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 471 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=-0.0072
   Val:   Loss=0.0890, RMSE=0.2983, R²=-0.0181
============================================================


============================================================
🔄 Round 475 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 475 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=-0.0070
   Val:   Loss=0.0889, RMSE=0.2982, R²=-0.0206
============================================================


📊 Round 475 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0006

============================================================
🔄 Round 477 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 477 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0036
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0081
============================================================


📊 Round 477 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0006

📊 Round 477 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0006

📊 Round 477 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0006

============================================================
🔄 Round 483 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0725, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 483 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0048
   Val:   Loss=0.0725, RMSE=0.2692, R²=-0.0018
============================================================


📊 Round 483 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0005

============================================================
🔄 Round 484 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 484 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0038
   Val:   Loss=0.0755, RMSE=0.2747, R²=-0.0057
============================================================


============================================================
🔄 Round 486 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 486 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0059
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0074
============================================================


📊 Round 486 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0006

============================================================
🔄 Round 490 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 490 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0067
   Val:   Loss=0.0881, RMSE=0.2969, R²=-0.0166
============================================================


📊 Round 490 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0005

============================================================
🔄 Round 493 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 493 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0029
   Val:   Loss=0.0837, RMSE=0.2894, R²=-0.0100
============================================================


📊 Round 493 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0006

============================================================
🔄 Round 495 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 495 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=-0.0042
   Val:   Loss=0.0911, RMSE=0.3019, R²=-0.0037
============================================================


📊 Round 495 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0006

============================================================
🔄 Round 496 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 496 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0067
   Val:   Loss=0.0768, RMSE=0.2772, R²=-0.0045
============================================================


============================================================
🔄 Round 499 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 499 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0042
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0057
============================================================


============================================================
🔄 Round 500 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 500 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2892, R²=-0.0042
   Val:   Loss=0.0727, RMSE=0.2696, R²=-0.0037
============================================================


📊 Round 500 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0006

============================================================
🔄 Round 503 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 503 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0033
   Val:   Loss=0.0785, RMSE=0.2801, R²=-0.0091
============================================================


============================================================
🔄 Round 504 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0927 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0927, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0927, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0927, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0928, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0927)

============================================================
📊 Round 504 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=-0.0062
   Val:   Loss=0.0927, RMSE=0.3045, R²=-0.0076
============================================================


============================================================
🔄 Round 506 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 506 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=-0.0056
   Val:   Loss=0.0913, RMSE=0.3021, R²=-0.0007
============================================================


============================================================
🔄 Round 507 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 507 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0053
   Val:   Loss=0.0877, RMSE=0.2961, R²=0.0002
============================================================


📊 Round 507 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2421, R²: -0.0005

📊 Round 507 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2421, R²: -0.0005

📊 Round 507 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2421, R²: -0.0005

============================================================
🔄 Round 511 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 511 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0042
   Val:   Loss=0.0785, RMSE=0.2801, R²=-0.0110
============================================================


📊 Round 511 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2421, R²: -0.0005

============================================================
🔄 Round 512 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 512 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=-0.0034
   Val:   Loss=0.0816, RMSE=0.2856, R²=-0.0131
============================================================


📊 Round 512 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2421, R²: -0.0005

📊 Round 512 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2421, R²: -0.0005

============================================================
🔄 Round 516 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 516 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2871, R²=-0.0042
   Val:   Loss=0.0775, RMSE=0.2785, R²=-0.0057
============================================================


📊 Round 516 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2421, R²: -0.0005

============================================================
🔄 Round 518 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0692 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0692, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0692, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0692, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0692, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0692, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0692)

============================================================
📊 Round 518 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=-0.0035
   Val:   Loss=0.0692, RMSE=0.2630, R²=-0.0139
============================================================


📊 Round 518 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2421, R²: -0.0005

============================================================
🔄 Round 519 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 519 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0043
   Val:   Loss=0.0807, RMSE=0.2840, R²=-0.0139
============================================================


============================================================
🔄 Round 521 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 521 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0022
   Val:   Loss=0.0757, RMSE=0.2751, R²=-0.0146
============================================================


📊 Round 521 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2421, R²: -0.0005

============================================================
🔄 Round 524 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 524 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0039
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0065
============================================================


📊 Round 524 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0005

============================================================
🔄 Round 526 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 526 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0037
   Val:   Loss=0.0777, RMSE=0.2787, R²=-0.0233
============================================================


📊 Round 526 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2421, R²: -0.0005

📊 Round 526 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2421, R²: -0.0005

============================================================
🔄 Round 528 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 528 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0053
   Val:   Loss=0.0866, RMSE=0.2943, R²=-0.0171
============================================================


📊 Round 528 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2421, R²: -0.0005

============================================================
🔄 Round 531 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 531 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0025
   Val:   Loss=0.0742, RMSE=0.2724, R²=-0.0117
============================================================


📊 Round 531 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2421, R²: -0.0005

📊 Round 531 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2421, R²: -0.0005

============================================================
🔄 Round 536 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 536 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2878, R²=-0.0047
   Val:   Loss=0.0759, RMSE=0.2755, R²=-0.0013
============================================================


============================================================
🔄 Round 539 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 539 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0026
   Val:   Loss=0.0866, RMSE=0.2942, R²=-0.0101
============================================================


📊 Round 539 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2421, R²: -0.0005

📊 Round 539 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2421, R²: -0.0005

============================================================
🔄 Round 541 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 541 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0059
   Val:   Loss=0.0852, RMSE=0.2920, R²=0.0013
============================================================


============================================================
🔄 Round 542 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 542 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0066
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0137
============================================================


📊 Round 542 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0005

============================================================
🔄 Round 544 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 544 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0038
   Val:   Loss=0.0752, RMSE=0.2743, R²=-0.0114
============================================================


📊 Round 544 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0006

============================================================
🔄 Round 546 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 546 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0053
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0010
============================================================


============================================================
🔄 Round 547 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 547 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0050
   Val:   Loss=0.0779, RMSE=0.2791, R²=-0.0078
============================================================


============================================================
🔄 Round 549 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 549 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0025
   Val:   Loss=0.0732, RMSE=0.2705, R²=-0.0115
============================================================


============================================================
🔄 Round 550 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 550 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0047
   Val:   Loss=0.0782, RMSE=0.2796, R²=-0.0015
============================================================


📊 Round 550 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0005

============================================================
🔄 Round 554 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 554 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0066
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0034
============================================================


============================================================
🔄 Round 555 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 555 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0080
   Val:   Loss=0.0779, RMSE=0.2791, R²=-0.0125
============================================================


============================================================
🔄 Round 556 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 556 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0051
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0003
============================================================


============================================================
🔄 Round 557 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 557 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0035
   Val:   Loss=0.0772, RMSE=0.2778, R²=-0.0076
============================================================


📊 Round 557 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2421, R²: -0.0005

📊 Round 557 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2421, R²: -0.0005

============================================================
🔄 Round 560 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 560 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=-0.0045
   Val:   Loss=0.0784, RMSE=0.2800, R²=-0.0069
============================================================


============================================================
🔄 Round 563 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 563 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0058
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0041
============================================================


📊 Round 563 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2421, R²: -0.0005

============================================================
🔄 Round 566 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 566 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0038
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0059
============================================================


============================================================
🔄 Round 567 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0628 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0628, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0628, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0628, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0628, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0628, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0628)

============================================================
📊 Round 567 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0049
   Val:   Loss=0.0628, RMSE=0.2507, R²=0.0000
============================================================


📊 Round 567 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2421, R²: -0.0005

============================================================
🔄 Round 570 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 570 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=-0.0033
   Val:   Loss=0.0891, RMSE=0.2985, R²=-0.0311
============================================================


📊 Round 570 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2421, R²: -0.0005

============================================================
🔄 Round 572 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 572 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=-0.0022
   Val:   Loss=0.0917, RMSE=0.3028, R²=-0.0194
============================================================


📊 Round 572 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0005

============================================================
🔄 Round 573 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 573 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0039
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0054
============================================================


📊 Round 573 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0006

============================================================
🔄 Round 574 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 574 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0024
   Val:   Loss=0.0744, RMSE=0.2727, R²=-0.0158
============================================================


============================================================
🔄 Round 575 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 575 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0036
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0074
============================================================


============================================================
🔄 Round 576 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 576 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0055
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0001
============================================================


📊 Round 576 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2421, R²: -0.0005

============================================================
🔄 Round 578 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 578 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0049
   Val:   Loss=0.0740, RMSE=0.2720, R²=-0.0060
============================================================


📊 Round 578 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2421, R²: -0.0005

============================================================
🔄 Round 584 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 584 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0007
   Val:   Loss=0.0777, RMSE=0.2788, R²=-0.0221
============================================================


============================================================
🔄 Round 585 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 585 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0037
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0159
============================================================


📊 Round 585 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2421, R²: -0.0005

📊 Round 585 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2421, R²: -0.0005

📊 Round 585 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2421, R²: -0.0005

============================================================
🔄 Round 590 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 590 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0037
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0053
============================================================


📊 Round 590 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2421, R²: -0.0005

============================================================
🔄 Round 591 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 591 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0034
   Val:   Loss=0.0809, RMSE=0.2845, R²=-0.0069
============================================================


📊 Round 591 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2421, R²: -0.0005

============================================================
🔄 Round 592 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 592 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0039
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0163
============================================================


📊 Round 592 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2421, R²: -0.0005

============================================================
🔄 Round 595 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 595 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0031
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0092
============================================================


📊 Round 595 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2421, R²: -0.0005

============================================================
🔄 Round 596 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 596 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0051
   Val:   Loss=0.0861, RMSE=0.2935, R²=-0.0089
============================================================


📊 Round 596 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2421, R²: -0.0005

📊 Round 596 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0006

============================================================
🔄 Round 598 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0697 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0697, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0697, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0697, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0697, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0697, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0697)

============================================================
📊 Round 598 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0040
   Val:   Loss=0.0697, RMSE=0.2640, R²=-0.0044
============================================================


============================================================
🔄 Round 599 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 599 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0053
   Val:   Loss=0.0840, RMSE=0.2899, R²=-0.0008
============================================================


============================================================
🔄 Round 600 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 600 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0054
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.0017
============================================================


📊 Round 600 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0006

============================================================
🔄 Round 601 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 601 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0053
   Val:   Loss=0.0742, RMSE=0.2723, R²=0.0004
============================================================


📊 Round 601 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0005

============================================================
🔄 Round 603 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 603 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=-0.0032
   Val:   Loss=0.0903, RMSE=0.3006, R²=-0.0179
============================================================


📊 Round 603 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0006

============================================================
🔄 Round 604 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0708 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0708, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0708, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0708, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0708, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0708, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0708)

============================================================
📊 Round 604 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=-0.0041
   Val:   Loss=0.0708, RMSE=0.2660, R²=-0.0087
============================================================


📊 Round 604 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0006

============================================================
🔄 Round 606 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 606 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0057
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0073
============================================================


============================================================
🔄 Round 607 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 607 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0018
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0128
============================================================


============================================================
🔄 Round 608 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 608 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=-0.0037
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0093
============================================================


📊 Round 608 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0006

📊 Round 608 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0006

============================================================
🔄 Round 611 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 611 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0051
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0130
============================================================


============================================================
🔄 Round 613 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 613 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0068
   Val:   Loss=0.0739, RMSE=0.2719, R²=-0.0072
============================================================


📊 Round 613 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0006

============================================================
🔄 Round 615 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 615 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0040
   Val:   Loss=0.0760, RMSE=0.2758, R²=-0.0131
============================================================


📊 Round 615 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0007

============================================================
🔄 Round 619 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 619 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=-0.0018
   Val:   Loss=0.0751, RMSE=0.2741, R²=-0.0153
============================================================


📊 Round 619 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0007

============================================================
🔄 Round 622 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 622 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0036
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0094
============================================================


📊 Round 622 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0008

============================================================
🔄 Round 624 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 624 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0044
   Val:   Loss=0.0737, RMSE=0.2714, R²=-0.0072
============================================================


============================================================
🔄 Round 625 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 625 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0045
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0043
============================================================


============================================================
🔄 Round 626 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 626 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2878, R²=-0.0053
   Val:   Loss=0.0759, RMSE=0.2755, R²=-0.0017
============================================================


📊 Round 626 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0007

============================================================
🔄 Round 628 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 628 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0036
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0085
============================================================


============================================================
🔄 Round 631 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 631 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0031
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0077
============================================================


============================================================
🔄 Round 632 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 632 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0052
   Val:   Loss=0.0852, RMSE=0.2918, R²=-0.0078
============================================================


📊 Round 632 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0007

============================================================
🔄 Round 633 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 633 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=-0.0021
   Val:   Loss=0.0889, RMSE=0.2981, R²=-0.0113
============================================================


📊 Round 633 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0007

📊 Round 633 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0007

============================================================
🔄 Round 636 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 636 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0028
   Val:   Loss=0.0801, RMSE=0.2829, R²=-0.0086
============================================================


============================================================
🔄 Round 639 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 639 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0051
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0115
============================================================


============================================================
🔄 Round 640 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 640 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0046
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0112
============================================================


============================================================
🔄 Round 641 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 641 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=-0.0063
   Val:   Loss=0.0893, RMSE=0.2989, R²=-0.0197
============================================================


============================================================
🔄 Round 642 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 642 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0048
   Val:   Loss=0.0745, RMSE=0.2729, R²=-0.0016
============================================================


📊 Round 642 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0007

============================================================
🔄 Round 643 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 643 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=-0.0035
   Val:   Loss=0.0783, RMSE=0.2799, R²=-0.0063
============================================================


============================================================
🔄 Round 646 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 646 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0031
   Val:   Loss=0.0837, RMSE=0.2894, R²=-0.0113
============================================================


📊 Round 646 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0007

============================================================
🔄 Round 647 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 647 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0020
   Val:   Loss=0.0776, RMSE=0.2786, R²=-0.0132
============================================================


📊 Round 647 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0007

============================================================
🔄 Round 650 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 650 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0044
   Val:   Loss=0.0801, RMSE=0.2831, R²=-0.0059
============================================================


📊 Round 650 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0007

============================================================
🔄 Round 651 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0964 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0964, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0964, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0964, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0964, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0965, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0964)

============================================================
📊 Round 651 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=-0.0072
   Val:   Loss=0.0964, RMSE=0.3105, R²=-0.0029
============================================================


📊 Round 651 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0007

============================================================
🔄 Round 652 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 652 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=-0.0027
   Val:   Loss=0.0900, RMSE=0.3000, R²=-0.0090
============================================================


📊 Round 652 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0007

📊 Round 652 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0007

📊 Round 652 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0007

============================================================
🔄 Round 656 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0965 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0965, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0965, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0965, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0965, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0966, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0965)

============================================================
📊 Round 656 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=-0.0038
   Val:   Loss=0.0965, RMSE=0.3106, R²=-0.0212
============================================================


📊 Round 656 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0007

📊 Round 656 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0007

============================================================
🔄 Round 658 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 658 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0035
   Val:   Loss=0.0752, RMSE=0.2743, R²=-0.0117
============================================================


📊 Round 658 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0007

============================================================
🔄 Round 659 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 659 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0045
   Val:   Loss=0.0772, RMSE=0.2778, R²=-0.0162
============================================================


📊 Round 659 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0006

📊 Round 659 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0006

============================================================
🔄 Round 661 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 661 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0032
   Val:   Loss=0.0818, RMSE=0.2859, R²=-0.0082
============================================================


📊 Round 661 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2422, R²: -0.0006

============================================================
🔄 Round 662 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 662 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=-0.0081
   Val:   Loss=0.0905, RMSE=0.3008, R²=-0.0524
============================================================


============================================================
🔄 Round 663 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 663 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0043
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0129
============================================================


❌ Client client_22 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8690 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8690 {grpc_status:14, grpc_message:"Socket closed"}"
>
