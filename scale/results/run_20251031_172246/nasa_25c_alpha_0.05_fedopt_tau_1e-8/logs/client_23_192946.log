[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ef4fce8-58ce-4c47-bc9e-6f22b060dbf0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d097f19d-bbdb-4f7d-8ee5-688523de1878
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd3f478f-07ca-4757-91c6-2221b8418dc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de720485-c5ae-4915-a906-5715132a4464
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5549269d-ceb5-453c-b1e7-d7c959e47cd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf7367f6-6cfc-4491-aac5-248943ca94f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f228a86e-23d8-4602-a2af-069cd6082f95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4cf4a519-98a3-4597-8a27-aa286fabfd7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3ed7e41-ec55-4515-afca-a05ce54390b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d33198b-e472-472f-9bcd-5809421495b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 086f0287-1746-4898-8d24-1b09c1f90835
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0cf97502-03d5-4e41-8e72-17fddce5f176
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d820d8b-88e0-44e3-ac9b-a8c8c4ddeefc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfc18768-e14d-4a6c-8ec7-c32ea730e88a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9a60ea7-b38b-471d-9f76-5b13a6250f2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b7015cc-7417-43b5-ba4e-ae3af061bd5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7eb51d4-8217-4ede-942b-881ea386d3df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1fd84a0c-b5a4-4d9c-ada4-3aec70570d6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7fa10dd4-0dbb-4a2d-bee7-1e0cc972f7c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f30184f0-c4a3-4458-8ca5-0ac2b8fb6046
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc8b8cb9-5265-4dd7-819d-452a3fc71382
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2f1bd2f-f382-4c8c-a5ad-a4e8b748b31e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0e5cfbd-d2be-4a97-9fc8-6e18a1539acd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44344cd6-4e35-4eda-95c1-e3c639777aa8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5e02291-2145-4f79-885d-4e7cc076e688
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70d5ac5b-69a5-45d3-b3f4-807d12ba8043
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a081a275-bbb7-4a39-830c-f7dc0830d11e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a95bee31-33a6-434b-9343-67ee352fbe1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05b50b80-6653-40a0-bbb0-dbc4f8758943
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01a950b4-310c-4a08-a6c3-eb4c6e69594d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8be0a3c-a7a1-427b-933f-f384c4f2dbdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ffdbf8e-8270-44fa-83a4-0c2a198cb902
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12d72a39-4ccd-496e-8111-ccf7a02c6752
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1719d76d-b1d3-4887-b3e5-bd295963c3dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 473cbe72-ac6c-404c-97b8-ae72fbf173cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9fb60abc-2ea0-429b-ae8d-b3539fbdce8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ce9a36b-6692-47c6-ba41-b5e2358877e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f334501-8b0b-429e-bf8b-79ad3e377701
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a1c8c14-5808-4d3a-902a-791b11231d4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 193dcdbf-bafa-4637-9385-1a59b30aa110
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message edb40b48-9e9f-4209-8fdd-c82029412916
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c719458-466e-4303-8e58-64e34facccd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 822bf4bd-0f8b-472b-9dcb-0638a7e464a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea45dbce-a83f-439e-8efd-a451edad485e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2eb0aed-cc69-496f-bccf-8ba610d46f66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3645a7fa-1f2d-4411-b8c4-379bf9ad6044
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b34ab718-21a6-4021-a532-ae1cbaf76868
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a0d8018-f9cd-488e-8553-91ece048f4a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01cef8a5-d570-459d-9a42-70c8b1d0b246
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b222a36d-1d5e-466d-92ae-9f902bd6e04c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aff1301b-4326-4b15-94f1-41c132cdf281
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b4e4ff1-5535-4ec2-a66f-f7b6b4bcf74d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a88179b-1b02-403d-bc19-8d8caa8182e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e3d810e-2112-4678-88ff-0f450237aea4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a8e3f68-ce51-4642-82f6-a6ecb0deb67c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 516b18cc-8817-4c2b-80fc-4f324895b99c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c40ad7c-d5b4-43a3-822d-e8d4aefd87e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f3c48d5-8d40-4a70-9611-6d98956a3130
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc2aef5c-3f1f-420d-84ae-125ce2ffddc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ba7b6f2-3c03-4d27-bdd3-993a711d652d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d845e9f6-c09b-428a-82f2-a33e967f57f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b566c537-5709-4ae8-92cd-22b17b5c18d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f59985df-704c-4552-b17f-72fa447aa938
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0a4fec3-588c-4df9-bf52-29dabc7f9410
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7a978b6-f274-4fb2-9dfe-5d4ef5e41b0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9fb40ddc-75ed-4aff-b312-42510acc461e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4cda7403-3f6f-4914-8139-ee55a5450681
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ec3cdae-727a-4fe1-82bb-c1817fe23d39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75a5dca8-670d-4635-8622-83b843652628
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 937f2b66-cb3b-4e52-b472-649005525ce2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9692487-a420-4f2c-a0dc-47030f7591f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62353f6f-a90b-4798-879d-dc80db90ddbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a3d2f94-c04e-4ed5-a54b-6ae2d0b01c76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13b42bea-5abf-4cd9-9e13-935da0cecc32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c18fc1d5-1b03-43fd-80bc-ae0a71dae7e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 885c3596-7092-4071-bb71-e46f7fa8091c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c98358d3-6985-42f0-912c-6c922e9a4c29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 535c99c4-3452-461b-ac5c-52c75bd1ed0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3605dbed-cae1-47e2-9ceb-dd9f43add650
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e03b7339-04e5-4dce-94ab-79b066d17458
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2616a489-581f-4547-b865-350afa368c10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 470bd983-6b71-487a-8cfa-6906fba0e7aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34e49c6c-824d-4bbe-8728-96b5ba863fe2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 235c1372-b4f0-4117-8301-1b13b0079c18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 676f43e2-76de-42f6-a5d2-e74313751d39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd2e13ab-7f60-47c2-b259-1c25390327ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e07ce05-f499-4cca-a2b8-0aa75f8bfb96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab5b2ec4-7946-49a7-a5d9-62dd2ef9b76c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 082e24d8-8c96-4439-8250-eb84f3fc668a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b50a1c03-1491-4cb3-94d7-261f644046bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02fdf433-4086-4238-aa91-1afebdff26b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 503f704e-b248-40a1-8cb4-5c78a1af3c62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2bb78ce7-ad5d-4757-8f52-0c97de8da69f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f000a84c-e615-4d8f-9c0f-755c25f51ae3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 695012a9-ae53-4d6c-9a33-0fd24fa2566b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97f56080-7600-4a38-a753-950f1ee7ac1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1dba57f-26c6-4971-b2e1-0855746d1ae4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c8f6573-4342-4589-ba15-2086efb6aaad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8fa46c77-0ac8-44fb-a9a1-011ae6de2925
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 462c0bdc-7270-49df-93ec-fe465fd9025c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90641ab5-ada2-4010-9c79-4c6fe440477e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84d5dda5-4995-4b27-9ed8-ba9e698eb324
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18c0daf1-e683-477b-aeb2-46675ba0e465
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0a50624-9f71-430c-a022-e252e268ef00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6603068-8d3b-4149-8f74-9630b10a27d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cde6da40-332b-4408-85d0-3060aef14572
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 267ce88d-0122-42b6-bb16-07945b030692
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f263499-581f-44b9-9668-4ed9167f0b3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a70b1ac-a9e7-47da-8b75-b55206eae735
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4bcc663b-73c5-4b47-b39e-deddf2aeaa1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 561082c2-d2b9-448d-aa3d-7ac43ca77dcd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63d9c21d-7b23-491e-97da-e1bb1f71310c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4f20d36-daba-4703-816e-b811eca73d91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d6379b3-a959-4fa8-b03f-0e9d36b5013f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 552de6d9-af05-4857-8a3d-1e7f5afcba2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58f1783d-300f-45ed-8435-d393f8506d3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 088f6ad4-cea2-477a-b8bc-6585a174af0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34f23374-44e0-4cbe-ac46-e0be82abfab0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01ee6105-dcb6-4b62-ab7a-9c692f4e2c0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bbbe6dc6-75ee-451f-bc8b-92cf85be9fe5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1617365-23a4-4d4d-aa3e-d29b640280e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 250c1d4f-2d1b-44a1-a3c3-d2467d3e83db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3fa0819-9f9d-443d-a031-1adb62b3015b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9824721-2441-4dd8-a594-338fe21adddc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b10b41d-83dd-4baa-86df-f5e9e33b09fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 435a58ed-15c6-4d15-9661-2735d7bbd2a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20c1ee68-3d3f-4459-b13a-f5c060722930
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 553722be-898a-4235-b7f9-8071232a1b44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec71248e-1441-469e-a12e-9ee27822a947
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 486fdc4d-fc74-4c3e-bd25-ed7179ec576a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5eb74d2d-3cf4-4e0a-81a7-10c99174c2d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64d803f7-65ad-4a05-a2ec-9a0d38940a81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae75861f-7fd2-4054-816c-1c484f50386a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e89f6fa-1645-4d70-8346-92d788140a8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e54b46b0-a46f-4732-a705-f299ce6d4222
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38dbc020-a0f2-4545-8f8a-0a43f0705167
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8378c14e-5fe2-41d3-ac7a-5b7da6f76e10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 121cb758-f360-4e01-9c24-ee32cd9a1e04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eeb45500-1123-46ff-be34-49434f01df6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 466bc3b8-f874-47a2-b203-5bacc6135f7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09aa5c54-cc78-4672-b018-98f2d1b26f0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1666a38-9331-434a-9eeb-c5135690ce29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c845b9d-53e8-434b-8b06-3499433be9c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4868080f-a92c-4c01-b8f2-ce9b0c3aee06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a8b59b6-c651-460d-9e46-76b031916a65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57a9fef9-68d3-497a-90b1-c57fd3e1b315
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33eb1ac5-d325-4a15-9f25-28c852eb5eec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06dff7c9-2832-4958-8f85-c0c166e08891
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6c97184-2fa9-4142-a844-73df65880f76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6865553-bc5d-4687-816f-518844e8e3b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd511957-d348-4672-a72a-5e611f4307f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73f3967b-fc6e-4ab5-b452-295427d4d06d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4bb80525-55e2-47ed-8cc6-a794a3cb144b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70e2d744-d4c1-4390-b222-4a732ba31ae5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 619a3591-1ed3-44d2-a44b-cf170841f1b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94f50683-ba44-47a9-8451-b0425cafd591
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 934b1da5-3802-4efa-9fee-4fe74f2c39e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 572e1fe8-4a30-492d-971d-99cd40024ec1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14615aad-b4ae-4c6d-99fb-cfd70318b84d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97d981a6-66d7-4568-a848-c66ac84186aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd0bfdb3-c0a8-498f-8188-0886f854e8d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4a16730-b24e-40b9-8176-e63d279dbd7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10dcf444-d9c2-4e3a-a246-f9f1ec97a98a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40b4e1c9-0a29-4aa4-952e-9359195cc943
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c944e786-0746-4306-b8ac-097d177181d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 063de13d-0165-43d3-9364-caf183894046
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b029a80d-2a92-4e81-a62d-fbbfe61133fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3f1b345-59b2-47b4-a8bb-d526087ee823
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af7894ce-24f0-48ce-9403-5c9515cc386f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7a7585a-5497-47fe-86ec-95b6bba659cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60201e52-903d-426d-8cbf-2f3eeebcd440
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ca2512c-43a6-44af-8e7d-7a0ae519d35f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 416b3a32-5439-47cb-a5cb-70c191d7ade1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b77c602-5f90-452f-a827-fe5194f7748f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef071126-fd46-471b-939a-21385b1e3b4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89ca86ec-47c0-4d0e-a648-73f07befbafb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7334eac-1aa4-414e-8855-da584e72b807
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6dbcc41-d6c0-4241-9387-39f98ce3a544
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac5941fd-4929-40a4-9c54-2f547d5dec9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0775898b-49d0-4922-9932-4e2cf322c44b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf95b029-e1cc-44d7-8aa2-9c513536f9ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2bbccf94-e9d7-4692-87fa-13b75ace5f91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61b6ba93-b9e1-4a55-add5-573fb8651150
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35ed97ab-dedb-48f5-99fb-1ed0b791ba90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7749a674-87b8-44cd-9e71-782cebfcd124
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eef46dc9-6802-480e-9b90-d33b802d08d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 214750c2-3dcd-4c4d-945f-d16e446e028d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba01ebc7-32fa-4589-a756-d42508048b8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c775be6b-0a14-4c67-a38b-178f371b5e6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6108a7c0-7939-40b4-afbf-78a81e047672
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af41f2ef-55cf-45da-b14c-efe14bf13454
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76c773fb-dc74-42ed-af2f-c87e996f8187
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2e686af-de47-4bd6-b992-0158c8757f87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c78dd3ea-e4ef-4a77-a192-f9ac99275cc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bbb81201-af54-456f-95ae-3c0f8bcd377a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e25a102-8d23-4248-987c-b9b3a7e42a9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b519d46f-3e21-4c91-9914-24fc942d4fe9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ddff9bfb-ba46-47c6-b9ea-0959dda0ed25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26f1861e-c110-4ec8-b5c7-9eef7d29d0ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2948bc57-9204-4487-93ee-f15d3f6416d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22f31685-3d9c-42be-b1ad-1027fcd42735
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ffb1989b-46da-4f24-a22b-fa4c02be140e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 020af864-c1ae-41f4-948a-f6e3a5094050
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32a988ba-9c9b-4070-85fd-ff691e57293d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5fb56c2d-a099-4e23-8ac3-166866a22ad2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e72ba5b0-e34c-44f6-a0ad-8e2c94bb71aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5848c002-8fa2-47b9-bbbe-f5cb3eb00b2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4cc3894c-7f0a-4d2e-aef2-a66563a01c64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0573e5ab-08df-4b71-b840-d519a5174ed7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5185464-97a2-4ce8-bc63-14a1d8d04bba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48f23a92-b6e7-4d5e-910e-3efed48bb227
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64a9437f-fbd2-4791-af04-6920124bf840
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5aadee8b-c38b-42c9-8583-7afaa105422d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c547fa53-7ae1-4377-b548-db4937071b6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de2d7677-76cf-426a-b4d0-81ae354a6f3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f47ca2f-d7be-4524-bf30-200983ad79e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a286c25-6e8e-4831-bcec-a173d528dc05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a273bc1e-4609-47ce-9cb6-6e0eff8e58b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d77b130-72df-4b28-a9c0-e38676b842b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c11b79ee-71dc-47e2-be4f-36f1c8ccb30e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 528b791f-b45b-43d4-85dd-debafb8fdfa2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8a7602e-8aec-4514-97ce-033fa734fa0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb324954-f745-4f71-947b-633c9a49cca8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5b6d67a-2cc5-4f56-92be-76332898c056
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message acc7f357-06ce-4a77-b1d5-3b07602916b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65baf3f2-e532-42a1-961f-469a27ba96ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8fe994fa-657c-4b1b-8457-bb34fbe12119
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b726a159-560e-49ed-8056-bcabae85b335
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cca74120-8861-4bdf-8dda-fe0ffee123d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55129fcc-ef82-4c2f-aade-c56948302357
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 919f2069-30ef-4b34-b0b2-802c19ad46a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95f4e841-ee06-419b-bf79-8d1031b15076
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10d9061b-10e7-434b-931a-6b4935065ed5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4fcbb43-46c0-49bd-9563-0cd50ee8e552
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5451c4a5-8927-4435-9558-28bf0e652c21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ebf3b216-b0ee-4492-b5d6-320264412b21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 432d0bf0-ed13-402c-9f30-ca263b59d7e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de8edc14-3cc6-4624-bceb-8976c64cc463
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37e539bd-710f-415b-b6d1-0eac6744c2fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5e5b449-40b0-4927-843a-601a66c3ec41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a361f8c-b8c4-490c-8686-a11db9e1ffb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f51d0ab4-129d-4768-a100-39b607e0c477
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 506b1479-5cb5-4705-b91e-add13fa0045c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af3f1a51-11e5-4f8c-b593-b44ce25273c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66c0184d-a859-4cfd-94cd-60efe14e4097
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54a2f20d-a8dd-4529-bd10-63ea2b9c5111
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7c8aa4e-4ad7-4a20-aa93-9889cf37b27a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 987be0b3-2dba-4673-ad4e-c82a79233e53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b59bf7c6-c6a2-4ed9-a925-21d6dcbc2310
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 713e916e-defc-40fa-a790-eee7ba58b6a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 741f2af3-9379-4a85-9298-b2efbd935f5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf92205c-cdc6-4a52-a587-85d3210f9fbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a51ae39-5179-4c8f-879b-ec0952fb1590
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46dc60b7-53dc-463a-a10f-d22d8e0550ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 283ac077-33c4-4dbd-ac5e-0f72ba578007
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff162fdd-94b1-46c5-9403-61bb85a33fe7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8719db06-de45-46fb-bb61-12d8956af093
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a78ea0b-6db1-44d8-b423-742c410c076f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f38c9ab9-8afd-498a-9d53-e4738ae04219
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e24d437-03d9-418e-b7eb-0ada004b15a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99e17b9b-4d7c-477c-a046-fb33d5ad7bc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8fd52566-18d0-42ea-ae1d-bdd9e84b969c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4852dfd6-5f41-43c1-8a2d-e927fd7c6b8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8879de6-c75f-41e8-a461-ce541528154d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9e74db7-312f-45c3-8e0a-e375d93451ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb8d08e9-fc7f-4e8e-b6ba-a518163a32c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ba6320d-2ae5-4dc2-a3b0-7d177a9096fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e14ad64d-36e0-4d89-84ea-a55859c3efd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38f0de98-aad1-4c9c-8f70-a1d84223515b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f5b86d6-4c8e-49e7-96ed-e955288aad18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0fcf977c-c956-47e5-b216-6e33f9381b5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f4005a5-2a48-4d0a-a984-793101b77747
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ad97432-17cd-4256-afee-86052b5f0b7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 397d8e7c-e3d3-453f-af3e-df2dd3a57639
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d229ffc3-3614-4f1a-bc78-ebc435ce10bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f7861b0-9c0f-4d20-9c42-7b4be5e8fc96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a91f79d-7fa9-4185-8002-bb20820bd886
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f22279ae-67fe-403d-92c7-fdcaf0ded0d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8f7561c-428e-4471-abd5-607b14dcc4ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17eb51ac-aa6a-412a-8ed4-cbfbbce7efd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7493958d-b5c1-4cfb-946f-bcf0f3cb658a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc9ae664-fa0b-4a43-b11d-8baa96d0b391
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8472ffe-e2c7-48e0-8ee8-cbda8688bdb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ac2d095-c93c-4085-89f2-7eeb319ffd8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ddcc94a0-a8c9-40b9-b065-720629bc7517
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f43b8ac8-8218-478d-8fe4-451bb6faae39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db96f7cd-cc48-4cd3-8b64-e02174a135b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bbf4147d-3524-45ec-9d1b-c48d84e58241
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 475e6c1f-5fb3-442f-a8d0-14dd4fc16481
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aee49377-3169-415c-a360-486e5d6b1378
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e72cf2ce-fc50-42c5-be5a-7608dca609ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d555f47-94b1-4ea4-be4e-0fe49f2fa5f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35233a42-e844-417a-9b40-8fc52557e355
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 892b8372-d1cb-4250-8543-98481465eb6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8596a99-48ae-482f-b02a-268c894b9d83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7519cbe6-ba8a-4b2b-82a3-9782bbc67954
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ab8ef1b-1932-4810-aab3-0b2d107ae6d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12ca5392-903d-42b5-992b-df249c75ab1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ff982d0-ffb2-4873-9d0c-1f9d725740f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6fc25574-8b24-458c-9e63-150641b43926
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c23afad6-1220-4c12-8567-b9b31c655b84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 729168f4-0ca3-46c1-a238-36408d16260f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90bbeeae-6540-4c31-81e6-06e7714f3719
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11f92c89-d96d-4b22-897c-090b1cfacd3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a92e9c01-7c0d-4ba6-a774-f74889093c0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d54f2399-cce8-47f7-8730-162100f09e64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8b58bc1-04c5-4462-a3cd-04586ec140d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb1d4ea9-4d60-46b3-a985-b38ad45f4414
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25690b0c-0c8e-4625-ab94-52cf407992f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0cb8a7d7-4b31-41b2-8069-eb01b1664757
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2960166-794f-47d5-be7e-daec83db1b77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee9a6ab6-06a5-4698-8c4b-3f71ee9f8697
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99c53951-4293-4940-a584-e9288ec70005
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd582eed-7cbe-4a81-b904-0faeadb2dc5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a227c5e5-b6ed-4a48-beb4-1ddd008ad1fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7ddbe22-5bd7-4540-adea-580a24750153
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f60c61b8-e40a-4cf1-ae7a-89acf8a95004
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9960cfd3-e749-4962-aafc-d0d0b9c2957a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d93a2187-c495-4851-8a56-c49a2d003296
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message edb07025-9a68-417b-be5d-e8324e803751
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee86c893-2f57-45b3-91f6-6fe6e077471e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 760acca4-6199-4b52-b9e6-1f63dfacc16e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef552d3d-f474-40d2-a12d-e3e7c8f36273
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 766ac2dd-5468-43ea-a162-be9da0056f83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8128e7c-6d28-4c82-be46-733a9145ccdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d3f6317-6115-4004-8a3d-8f811c8f9a3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 320dec69-ec8e-45ed-a642-f128002c00b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b9e42ea-4f7c-4df8-a691-d07dc612ac18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c6c520c-3196-43a2-b21f-bb3e707d30c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 522190dc-547e-43e2-926c-845506c33c62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 130e8ac0-3e9e-4726-b501-1838961b5558
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61d60cbe-c86c-47a0-a97e-e80c69aeb237
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ffea2b8-813b-4f2e-8e08-0b806d2be675
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af8e7c03-d2eb-4996-890c-e1ea49eeae0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff893a41-d822-445a-97ac-3be8e79639ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90964a6f-682b-46e8-b8f4-3e8c47a3cf71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2c5f58d-e46e-4b49-82de-378f1795537a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51e5aba1-722c-4b9d-aba4-c5cbaa08b296
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa90cd5d-852e-48d8-afe5-fe99a22fe542
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b11986f-a4d5-4ed2-8322-538c47890360
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d02fb5cf-5c5e-46de-a484-bf92d13a232c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ff8bc19-1e75-4df3-838d-76dabd0ea943
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b4c6844-ed29-4610-a1df-1ae0f9b607fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e85ff57-c54b-483b-bc7e-4b8a6aed6226
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52b53e7a-18c8-4902-824c-b207e86472e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2355a4c6-608b-4eac-b214-ce0219021299
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c8ba609-3bc7-44a1-a342-38d810511236
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4fcd8229-c5d9-42f5-a531-b34fe4722c87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a09c57b-d085-4fee-ad36-9b507832d048
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ce1a45a-161a-4d11-bb9e-827cf1b42589
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51710b6b-1fdb-49c2-aebe-3a009a279f43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34a5d0f3-9509-4d3b-b5dc-f010fc6cb0f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e09613a-2f15-4498-8b01-6e431b8e6666
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6cfaaa93-0973-459c-a0d9-fec4b80cc6aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2718ac88-4aa3-4664-a247-2d2f2ccaa840
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ccd30507-879b-45ff-a081-8496709444b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 193d9657-9bb5-485f-a1a7-d9981b9b0cce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 931c4d44-f6b4-4019-a695-24fa06e930ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bebf9d2a-cedd-4124-a779-e0a0ff2e7610
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 234ef4ec-43f5-4b46-9845-37e08f22e2c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03fd3670-3fb0-4992-b6ab-248985416058
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92a1e395-5b18-458f-94a6-9ef9ced6f1c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a9ef456-9a7c-4032-ae08-1d7a36bc36d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f14a0933-ee97-4429-ad08-9f31d629918f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7714c3c-3ef0-4849-ae2c-92247ec93f0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f32c1e4-220b-4755-8994-625de843a142
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17248d7a-e024-4058-bede-075f48407e06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85d60323-8d42-44bf-9b8a-acaee15fd3e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05e9bb1a-f40f-4f64-953a-5d5558095329
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69e35771-f7be-4c36-8d8b-1db0f3e5b0e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6cc8dd26-1cf0-4cd1-9113-bc8428a782e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 436beee9-2c19-4bb1-97e2-3e65f2ac04ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 322dab54-25fe-425a-9ff9-d22cecf31e2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd6e1794-3bcd-43cc-8732-009e8cc447d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 171bb864-1fdf-4602-8192-013043176df4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e253e77-e238-4d98-9e90-887b91da58ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f35236b1-4106-4edd-93e2-06c6db1c0866
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47a7d52f-145e-4139-8a06-b40e5d902237
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8ea4d4b-d3b4-4a3b-b454-fb63fbf0da3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36f01418-5c1d-4fdf-845a-ed0c8e515e09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18bbbc36-ce25-44d9-bccd-a47241ae826f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d9b0165-cc83-4b48-bddb-6f0f9bee37fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4f573aa-dc88-4c9e-bfe8-1f2d6ce48951
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99b6bc7e-4d65-4369-ba84-011531ff4fe2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1409a66-f8d3-458d-9f9d-a50660afdaba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfa1994f-3f4d-43ab-ab08-b77caa64cb3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1a1c331-534a-4877-a6c0-5eca664ce5c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3ec5132-6628-4577-95ee-47a88c4da56e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46f99d9a-73bb-47f4-a0a1-771c22cb5a62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15e037e7-ff83-43e4-822f-843ceef6ff52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c59e5b9-4a12-4806-a9a4-e372cc649100
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8061dc40-fc68-4c19-88c0-7f206a5244cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e161141-4eb4-4dc4-985a-9d2e6bc4bdd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de6613bf-38a1-4245-9247-b77f8373ee20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a4c5385-c41c-4913-9905-418286b9394e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4bd731bf-bc50-47de-961b-82ee21bf2244
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31af3989-b161-48de-a8b9-bba2b19ed23f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 596510f9-e43b-4d28-b4b0-c346bf64c395
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 507cb9e2-44a1-43d2-9a5b-9f55c822ef4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfb935f2-ef8c-423f-bcb7-f59edf34667d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1beaa23d-cfb9-450f-a5f2-efb499762936
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1267120c-c423-45cd-94f6-a23530272a6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c35731b9-0694-4327-9ae2-fe20c5d13600
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27797bca-8975-4cd7-8185-b47d194d007d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d9ee36c-0d5b-4bc0-a1e8-ad1fc74d58e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ae6cf4a-206d-42c6-87df-cc56f788039e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da0412af-c187-4d1f-8a81-36931c08b76e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2dc0389c-28fd-4d46-b4b7-b923df080eb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f038a743-d2c2-4c21-aaae-3053d5154c24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95b96e5e-3b63-48d5-a0dd-46435878cb55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aed345c7-f95f-48be-9cd3-ef7518529a30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c36255b8-464a-4fce-abc7-5583994f481b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4abe2926-0dd7-4f22-90d3-98188210cabc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb9eb111-e995-4d55-9f45-d577b01d24b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac01a22c-7507-474c-87cb-d4b3ae909a21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b33b5c5-eff8-4fbf-8895-43d70fc28e33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b687de2d-0765-433b-881b-32b1379a5a9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55904f9b-87a1-47b2-9658-6916f0a3478f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2838f6d-5438-46ab-9bc2-ee903a668fbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b883c63f-e7a3-4b2c-9793-7d26799c5bbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e674d4d3-97a2-4b68-8829-1f2bcd412f43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 465d4a4a-da20-4e70-a0b4-ba77cdf385ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ab6ebe3-c66b-470d-a14f-117b2f8929dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1158e316-c64b-4a6a-a18c-86ef0a927941
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e84e04b8-a3d3-4a15-a225-a54908321ab9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2539a23d-aa53-4abe-9a4a-90e746ecb0e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51b2901b-4ac7-42e1-9dd9-2915f91c8a61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 622173f0-e444-47bc-9554-e716764426b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 372938e3-8440-4f05-9c19-44a246982bf6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00d19077-14bf-46e2-b506-511476ac6a72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b2a5b9d-4128-427a-a007-f3d0e3c82ac9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ffff449-9fc7-4f31-a774-eb5ff3f9d562
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 165fd393-bf80-46e4-9bce-41df22102c01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4b918e2-52f5-4ecf-8fb9-d818b4e26770
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed0ffd0f-0c8b-4da4-82a2-9a187b68a81d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c68c4143-ea5c-434c-803a-7ef191bb8af7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b4764d9-591c-48b6-9dd3-63e73e30a842
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bdf0489b-4750-4910-a08a-5f18dfdeeb86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22be2e7e-bc90-423b-8d22-3f6e39fb319d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0fb4e4ad-126b-42d6-ab12-74db0022bc00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a35f30ea-4900-4790-a617-b96ca5e92941
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72c645b4-5157-4099-b0a2-140305ae7a5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 619bb877-86a1-4328-bf95-da6fa2800adf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d169c1a-a52d-4a47-9a4e-cc15b0aa9bf7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cef6be2f-04b1-40e8-ac23-de7fc6bead71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 348e2615-4cc1-4aef-92f9-2c7bc6d97953
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5610989b-f77b-4539-97ea-f7759a05520f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ee3cfe9-1e02-44c8-9c79-35ecf2234327
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89312fea-04da-4055-a547-24f3a5fd297a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 714926bf-92ee-4be9-8396-a230203847b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f45b9b5-dbdf-4ea2-8b3f-e13a839f18a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ac202d1-5ec1-417e-a2a9-cd540c79b729
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a87dfe87-ae87-448f-aead-170c3c733ae4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c4c0074-a38c-475d-8076-f325f8b80d1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 223c979b-14e0-4c8c-acf2-7d54406d9f31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34daa908-25c0-41d8-9730-f798c51fd59b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bca1bad4-00ed-4f75-aebe-6600b140332d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7c2e925-b460-4be4-965c-ccd28470acb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4358b4a-1235-4ccb-8713-408c38eef79d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e9e6297-c3ed-4480-a2fc-49d60fbf46c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a45a7bd-dd29-43bd-9cd2-38dd1d63407f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1649b18b-531a-4df5-a53d-1464a8a867d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75816867-e05f-4430-a0f4-7e53137731bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e70d38c4-12ee-4621-ad02-a2d2da9e0333
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf4c0e21-a948-4b29-9f1a-07fc2b2ff298
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c4dc3b2-ff10-4cf5-96d5-6947f5721574
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 816d1b58-99e9-4a8c-96c3-928870226f5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3513084f-082e-4d98-b965-05f51e56758c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 273d3963-2761-4e8b-b894-090770cbc2f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4baf6b8f-fa7c-42c8-b77f-0a051d97bb3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab3c33f2-5995-4468-9d05-dcdfcdfb24aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29c0572e-125e-4928-b8e4-3ed71c97b701
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00352352-7ba3-4b79-9adb-f4155d42db28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4c9c30c-1e0f-43b7-a120-5ca94fd37dc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41a5b033-53bc-40ed-a219-720d597462f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d45a927e-5a92-4520-b047-c2bb549f6cc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d155e9e3-fc0c-4cce-8ebd-7e102317e182
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd429d96-2d21-4dec-8a50-41fdde823822
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6c62d92-37a7-4875-bdff-53190b1cf3de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 660962a8-6db0-41bc-ab5a-93087ca4a034
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01e932d5-592b-494a-beed-3bb60b04e01f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa35feaf-667b-4e86-8e25-71ddf2daad65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db3cbfa1-008e-4c22-a44e-f754ffa33581
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 337b9cf0-f079-4d6f-95f1-1fc052e66642
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03d64c8d-8f47-4380-ac4a-64a673193307
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d8018d4-ee90-4bea-89d0-0c39f9c9a6cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09b4210e-390b-4ab0-b088-7f6e2b96cae5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4b9c1d4-7604-4c33-a7e0-17c57e771f01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9333062-1f44-4d3a-8fd1-6a2365a72032
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f87fcc3d-687d-48bd-ad56-ecb067817f2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52911351-023d-4503-93db-7ac27aad4244
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9b80105-9473-4874-b77d-40fb868a1c86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2dab5eb5-e8b0-4fec-a2e4-1addec7055a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8e96117-18f4-4ccb-9a61-53a61f494651
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d4d69d6-77a9-41cf-b577-4abc3f9875aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ddbd32c-6da8-415f-abb3-ae0a3f87b24a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a041b9f9-92ef-4561-8851-53e60a337ed6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9efb9f75-b80f-4014-8382-8c17a0481892
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1cf17104-1441-473c-aac7-704e9ed21ebe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92b1eb05-9689-47a1-add2-6ccd901e3188
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a59d8a1-893a-4d4d-9974-05953fadec47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 356c9833-2e3d-46cb-bdbf-37b629ca79d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c2a61bf-76c9-4d48-94f7-a0d19059dff0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93c28f93-3360-4ebb-af50-25bf4b9930d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71cfa57b-4369-4051-86ed-3e44cc3e73fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2389c5a7-72aa-4b17-8108-38b60c8d1e95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f13a47e5-e249-4f5d-8a9f-c697fd1fbdd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8890b203-e9bc-4308-af1c-e4904d1200cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2697343-b1bd-47b1-995e-8abf6d247dcd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1570bc9a-c00b-480a-91cb-518fa5e318fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3bcbcdd7-bb99-4650-af50-53ee622858de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9fcf4e59-bbfe-4465-86e3-01046a61b34e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d507f58-97a3-4d57-b340-f0086402133e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73747ec6-d402-4392-8c67-001fd6814e00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a9c2459-91dc-4270-96d3-2ba7d5a168cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 613fb0c7-ad2a-4ca8-8409-b302c1b0c10a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5433202b-4f71-48dc-9122-cbc3dd6d1eb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ec85ba8-34b1-47d0-8891-19ad8504cb60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af0b2054-d122-4dff-bc56-e44b1516258d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39ba38a1-e9d0-45a9-a7c6-171c919390fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1527cad-8645-4bc3-ae94-3707b5558696
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d82930b-78cb-4169-b0ba-ffabec1b4f52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfdc76a2-6e20-46e0-a8d8-89e0ea754d72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c31bc8fd-340d-4bc2-8af4-2819168cd8b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34b9d118-9a05-494e-a4f6-e08ea90bed7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86166fe8-c51e-4ed5-a278-c83d88fb271c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 749b0aa0-974e-4879-92c3-66ca1f71911f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08b9a718-bcd8-42e3-9a7a-8627ac94d5a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e0a8bc9-b169-4712-b96d-b5d1308a36c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96a8af4b-bb42-4bd6-8ed4-0ccf10418aba
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8690 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_23
Server: localhost:8690
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_23
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_23/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_23/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_23/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_23/test_labels.txt

📊 Raw data loaded:
   Train: X=(7224, 24), y=(7224,)
   Test:  X=(1806, 24), y=(1806,)

⚠️  Limiting training data: 7224 → 800 samples
⚠️  Limiting test data: 1806 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_23 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 2 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0851 (↓), lr=0.001000
   • Epoch   2/100: train=0.0837, val=0.0852, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0834, val=0.0853, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0832, val=0.0855, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0831, val=0.0855, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0822, val=0.0855, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 2 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0006
   Val:   Loss=0.0851, RMSE=0.2918, R²=-0.0052
============================================================


📊 Round 2 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2435, R²: 0.0020

============================================================
🔄 Round 3 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0897 (↓), lr=0.000250
   • Epoch   2/100: train=0.0825, val=0.0896, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0824, val=0.0896, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0823, val=0.0896, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0823, val=0.0897, patience=4/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0818, val=0.0899, patience=10/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 3 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=0.0019
   Val:   Loss=0.0897, RMSE=0.2995, R²=-0.0082
============================================================


📊 Round 3 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2444, R²: 0.0015

============================================================
🔄 Round 4 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0880 (↓), lr=0.000063
   • Epoch   2/100: train=0.0827, val=0.0879, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0826, val=0.0879, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0826, val=0.0879, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0825, val=0.0879, patience=4/15, lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0823, val=0.0880, patience=10/15, lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 4 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0010
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0137
============================================================


📊 Round 4 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2438, R²: 0.0031

📊 Round 4 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2435, R²: 0.0039

============================================================
🔄 Round 6 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0776 (↓), lr=0.000016
   • Epoch   2/100: train=0.0852, val=0.0776, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0852, val=0.0776, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0852, val=0.0776, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0852, val=0.0776, patience=4/15, lr=0.000016
   📉 Epoch 7: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0851, val=0.0776, patience=10/15, lr=0.000008
   📉 Epoch 15: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 6 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0002
   Val:   Loss=0.0776, RMSE=0.2785, R²=-0.0006
============================================================


📊 Round 6 Test Metrics:
   Loss: 0.0814, RMSE: 0.2852, MAE: 0.2438, R²: 0.0034

📊 Round 6 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2437, R²: 0.0037

📊 Round 6 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2434, R²: 0.0041

============================================================
🔄 Round 9 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0860 (↓), lr=0.000004
   • Epoch   2/100: train=0.0830, val=0.0861, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0830, val=0.0861, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0830, val=0.0861, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0830, val=0.0862, patience=4/15, lr=0.000004
   📉 Epoch 7: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0830, val=0.0863, patience=10/15, lr=0.000002
   📉 Epoch 15: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 9 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0014
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0085
============================================================


📊 Round 9 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2435, R²: 0.0041

============================================================
🔄 Round 11 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 11 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=0.0005
   Val:   Loss=0.0914, RMSE=0.3024, R²=-0.0066
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2432, R²: 0.0045

============================================================
🔄 Round 12 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 12 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0003
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0365
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2435, R²: 0.0042

📊 Round 12 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2434, R²: 0.0044

============================================================
🔄 Round 17 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 17 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0001
   Val:   Loss=0.0918, RMSE=0.3031, R²=-0.0029
============================================================


============================================================
🔄 Round 18 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0701 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0701, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0701, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0701, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0701, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0701, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0701)

============================================================
📊 Round 18 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2952, R²=-0.0015
   Val:   Loss=0.0701, RMSE=0.2647, R²=0.0048
============================================================


============================================================
🔄 Round 20 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 20 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0002
   Val:   Loss=0.0772, RMSE=0.2778, R²=-0.0062
============================================================


============================================================
🔄 Round 21 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 21 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0012
   Val:   Loss=0.0853, RMSE=0.2920, R²=-0.0053
============================================================


============================================================
🔄 Round 22 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 22 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2896, R²=-0.0003
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0097
============================================================


============================================================
🔄 Round 23 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 23 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0008
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0244
============================================================


============================================================
🔄 Round 25 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 25 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=-0.0015
   Val:   Loss=0.0720, RMSE=0.2683, R²=0.0017
============================================================


============================================================
🔄 Round 26 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0952 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0952, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0952, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0952, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0952, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0952, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0952)

============================================================
📊 Round 26 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0000
   Val:   Loss=0.0952, RMSE=0.3085, R²=-0.0024
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 30 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 30 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0005
   Val:   Loss=0.0782, RMSE=0.2797, R²=-0.0073
============================================================


============================================================
🔄 Round 34 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 34 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2935, R²=-0.0015
   Val:   Loss=0.0740, RMSE=0.2720, R²=0.0040
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 36 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 36 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=-0.0016
   Val:   Loss=0.0780, RMSE=0.2793, R²=0.0044
============================================================


============================================================
🔄 Round 40 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 40 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0016
   Val:   Loss=0.0743, RMSE=0.2726, R²=0.0053
============================================================


============================================================
🔄 Round 41 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 41 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0029
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0034
============================================================


============================================================
🔄 Round 45 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 45 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0009
   Val:   Loss=0.0843, RMSE=0.2904, R²=0.0009
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 46 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 46 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0023
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0035
============================================================


============================================================
🔄 Round 47 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 47 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0010
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0018
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 49 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0999 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0999, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0999, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0999, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0999, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0999, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0999)

============================================================
📊 Round 49 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0004
   Val:   Loss=0.0999, RMSE=0.3161, R²=-0.0006
============================================================


============================================================
🔄 Round 50 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 50 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=-0.0018
   Val:   Loss=0.0747, RMSE=0.2734, R²=0.0037
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

📊 Round 50 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

📊 Round 50 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 55 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 55 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2885, R²=0.0008
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0130
============================================================


============================================================
🔄 Round 56 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 56 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0010
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0040
============================================================


============================================================
🔄 Round 58 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 58 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0020
   Val:   Loss=0.0859, RMSE=0.2930, R²=-0.0100
============================================================


============================================================
🔄 Round 60 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 60 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2877, R²=-0.0010
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0003
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

📊 Round 60 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 63 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 63 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0014
   Val:   Loss=0.0896, RMSE=0.2993, R²=-0.0183
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

📊 Round 63 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 72 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 72 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0002
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0023
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

📊 Round 72 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 77 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 77 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0017
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0095
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 78 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 78 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0010
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0060
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 81 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 81 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0002
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0032
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 82 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 82 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0006
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0078
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 83 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 83 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2885, R²=-0.0001
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0037
============================================================


============================================================
🔄 Round 84 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 84 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=-0.0014
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0160
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 86 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 86 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0014
   Val:   Loss=0.0844, RMSE=0.2904, R²=-0.0034
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 89 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 89 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0017
   Val:   Loss=0.0895, RMSE=0.2992, R²=0.0042
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 91 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 91 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0004
   Val:   Loss=0.0795, RMSE=0.2819, R²=-0.0084
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

📊 Round 91 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 95 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 95 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0002
   Val:   Loss=0.0853, RMSE=0.2920, R²=-0.0028
============================================================


============================================================
🔄 Round 96 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 96 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0031
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0023
============================================================


============================================================
🔄 Round 97 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 97 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0002
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0086
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 98 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 98 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0011
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0002
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 100 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 100 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0004
   Val:   Loss=0.0789, RMSE=0.2810, R²=-0.0013
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

📊 Round 100 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 102 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 102 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0004
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0036
============================================================


============================================================
🔄 Round 103 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 103 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0002
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0041
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 105 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 105 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0032
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0444
============================================================


============================================================
🔄 Round 106 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 106 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0022
   Val:   Loss=0.0850, RMSE=0.2915, R²=0.0039
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 108 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 108 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0002
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0011
============================================================


============================================================
🔄 Round 110 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0976 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0976, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0976, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0976, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0976, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0977, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0976)

============================================================
📊 Round 110 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0009
   Val:   Loss=0.0976, RMSE=0.3124, R²=-0.0070
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 112 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 112 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0008
   Val:   Loss=0.0822, RMSE=0.2867, R²=0.0004
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 113 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0944 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0944, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0944, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0944, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0944, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0944, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0944)

============================================================
📊 Round 113 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0009
   Val:   Loss=0.0944, RMSE=0.3072, R²=-0.0012
============================================================


============================================================
🔄 Round 114 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 114 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0009
   Val:   Loss=0.0750, RMSE=0.2738, R²=-0.0125
============================================================


============================================================
🔄 Round 115 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 115 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0007
   Val:   Loss=0.0774, RMSE=0.2782, R²=-0.0005
============================================================


============================================================
🔄 Round 116 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 116 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0036
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0106
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 117 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 117 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0003
   Val:   Loss=0.0826, RMSE=0.2875, R²=-0.0036
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 118 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 118 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=-0.0026
   Val:   Loss=0.0838, RMSE=0.2894, R²=0.0033
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

📊 Round 118 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 121 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 121 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0001
   Val:   Loss=0.0823, RMSE=0.2870, R²=-0.0023
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 123 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 123 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=0.0009
   Val:   Loss=0.0781, RMSE=0.2795, R²=-0.0095
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

📊 Round 123 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

📊 Round 123 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

📊 Round 123 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

📊 Round 123 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

📊 Round 123 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

📊 Round 123 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 132 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0716 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0716, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0716, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0716, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0716, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0716, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0716)

============================================================
📊 Round 132 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0027
   Val:   Loss=0.0716, RMSE=0.2675, R²=-0.0066
============================================================


============================================================
🔄 Round 133 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 133 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0001
   Val:   Loss=0.0830, RMSE=0.2880, R²=-0.0065
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

📊 Round 133 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

📊 Round 133 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

📊 Round 133 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 143 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0947 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0947, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0947, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0947, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0947, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0947, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0947)

============================================================
📊 Round 143 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0021
   Val:   Loss=0.0947, RMSE=0.3077, R²=0.0023
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

📊 Round 143 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 153 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 153 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0008
   Val:   Loss=0.0894, RMSE=0.2990, R²=-0.0020
============================================================


============================================================
🔄 Round 154 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 154 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0011
   Val:   Loss=0.0883, RMSE=0.2971, R²=-0.0062
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

📊 Round 154 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

📊 Round 154 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 159 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 159 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0024
   Val:   Loss=0.0858, RMSE=0.2929, R²=0.0045
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

📊 Round 159 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 167 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 167 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0006
   Val:   Loss=0.0877, RMSE=0.2962, R²=-0.0033
============================================================


============================================================
🔄 Round 168 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 168 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0005
   Val:   Loss=0.0842, RMSE=0.2901, R²=-0.0126
============================================================


============================================================
🔄 Round 169 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 169 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0005
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0065
============================================================


============================================================
🔄 Round 170 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 170 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2885, R²=-0.0002
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0017
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

📊 Round 170 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

📊 Round 170 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 173 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 173 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0005
   Val:   Loss=0.0845, RMSE=0.2906, R²=-0.0038
============================================================


============================================================
🔄 Round 178 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 178 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0006
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0049
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 179 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 179 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0007
   Val:   Loss=0.0812, RMSE=0.2849, R²=0.0010
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

📊 Round 179 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 182 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 182 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0020
   Val:   Loss=0.0862, RMSE=0.2937, R²=-0.0055
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 188 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 188 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0011
   Val:   Loss=0.0790, RMSE=0.2810, R²=-0.0012
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 189 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 189 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2896, R²=-0.0006
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0000
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

📊 Round 189 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 191 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 191 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=-0.0031
   Val:   Loss=0.0796, RMSE=0.2822, R²=0.0095
============================================================


📊 Round 191 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

📊 Round 191 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

📊 Round 191 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 199 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0968 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0968, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0968, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0968, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0968, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0968, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0968)

============================================================
📊 Round 199 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0000
   Val:   Loss=0.0968, RMSE=0.3111, R²=-0.0017
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

📊 Round 199 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 207 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 207 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0006
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0044
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 208 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 208 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0019
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0029
============================================================


📊 Round 208 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

📊 Round 208 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 213 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 213 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0018
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0005
============================================================


📊 Round 213 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

📊 Round 213 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 216 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0714 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0714, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0714, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0714, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0714, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0714, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0714)

============================================================
📊 Round 216 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0004
   Val:   Loss=0.0714, RMSE=0.2672, R²=-0.0067
============================================================


============================================================
🔄 Round 218 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 218 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0024
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0173
============================================================


============================================================
🔄 Round 220 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 220 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=-0.0008
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0003
============================================================


📊 Round 220 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 221 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 221 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0016
   Val:   Loss=0.0822, RMSE=0.2866, R²=0.0035
============================================================


📊 Round 221 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 222 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 222 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=-0.0007
   Val:   Loss=0.0797, RMSE=0.2822, R²=-0.0050
============================================================


📊 Round 222 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

📊 Round 222 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

📊 Round 222 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

📊 Round 222 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 227 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 227 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=0.0019
   Val:   Loss=0.0775, RMSE=0.2784, R²=-0.0122
============================================================


============================================================
🔄 Round 228 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 228 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=-0.0018
   Val:   Loss=0.0914, RMSE=0.3023, R²=-0.0062
============================================================


📊 Round 228 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 229 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 229 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0005
   Val:   Loss=0.0746, RMSE=0.2730, R²=-0.0099
============================================================


📊 Round 229 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 231 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 231 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0034
   Val:   Loss=0.0813, RMSE=0.2852, R²=0.0111
============================================================


📊 Round 231 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 232 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 232 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0012
   Val:   Loss=0.0731, RMSE=0.2703, R²=0.0031
============================================================


============================================================
🔄 Round 234 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 234 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=0.0000
   Val:   Loss=0.0780, RMSE=0.2792, R²=-0.0112
============================================================


📊 Round 234 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 236 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 236 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0035
   Val:   Loss=0.0848, RMSE=0.2913, R²=0.0049
============================================================


📊 Round 236 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

📊 Round 236 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

📊 Round 236 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 241 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 241 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0007
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0034
============================================================


============================================================
🔄 Round 242 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 242 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0018
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0023
============================================================


============================================================
🔄 Round 243 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 243 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0007
   Val:   Loss=0.0788, RMSE=0.2807, R²=0.0007
============================================================


============================================================
🔄 Round 244 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 244 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0000
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0137
============================================================


============================================================
🔄 Round 246 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 246 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0013
   Val:   Loss=0.0828, RMSE=0.2877, R²=0.0018
============================================================


📊 Round 246 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

📊 Round 246 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 252 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 252 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=-0.0005
   Val:   Loss=0.0898, RMSE=0.2996, R²=-0.0010
============================================================


============================================================
🔄 Round 253 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 253 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2892, R²=-0.0015
   Val:   Loss=0.0840, RMSE=0.2899, R²=0.0028
============================================================


📊 Round 253 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

📊 Round 253 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 256 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 256 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=-0.0015
   Val:   Loss=0.0752, RMSE=0.2742, R²=0.0003
============================================================


============================================================
🔄 Round 259 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 259 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0004
   Val:   Loss=0.0901, RMSE=0.3002, R²=-0.0049
============================================================


============================================================
🔄 Round 260 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 260 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0016
   Val:   Loss=0.0874, RMSE=0.2957, R²=0.0039
============================================================


============================================================
🔄 Round 262 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 262 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=-0.0018
   Val:   Loss=0.0901, RMSE=0.3001, R²=0.0008
============================================================


📊 Round 262 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 264 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0942 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0942, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0942, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0942, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0942, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0942, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0942)

============================================================
📊 Round 264 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0008
   Val:   Loss=0.0942, RMSE=0.3069, R²=-0.0049
============================================================


📊 Round 264 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 269 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 269 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0004
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0011
============================================================


============================================================
🔄 Round 270 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 270 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0001
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0037
============================================================


📊 Round 270 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 272 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 272 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=-0.0005
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0126
============================================================


============================================================
🔄 Round 274 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 274 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=0.0002
   Val:   Loss=0.0770, RMSE=0.2774, R²=-0.0046
============================================================


📊 Round 274 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 275 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 275 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0009
   Val:   Loss=0.0852, RMSE=0.2918, R²=-0.0135
============================================================


📊 Round 275 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 276 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 276 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0014
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0038
============================================================


============================================================
🔄 Round 277 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 277 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0007
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0002
============================================================


📊 Round 277 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 278 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 278 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0008
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0282
============================================================


📊 Round 278 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 282 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 282 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0007
   Val:   Loss=0.0807, RMSE=0.2840, R²=-0.0048
============================================================


📊 Round 282 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

📊 Round 282 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 284 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 284 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0016
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.0038
============================================================


============================================================
🔄 Round 285 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 285 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0011
   Val:   Loss=0.0863, RMSE=0.2937, R²=-0.0062
============================================================


📊 Round 285 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 287 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 287 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0004
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0007
============================================================


📊 Round 287 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 288 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 288 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0000
   Val:   Loss=0.0788, RMSE=0.2808, R²=-0.0097
============================================================


📊 Round 288 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 289 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 289 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0011
   Val:   Loss=0.0826, RMSE=0.2875, R²=-0.0286
============================================================


📊 Round 289 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 291 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 291 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0020
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0084
============================================================


📊 Round 291 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 295 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 295 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0025
   Val:   Loss=0.0804, RMSE=0.2835, R²=0.0083
============================================================


📊 Round 295 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 298 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 298 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=-0.0006
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0006
============================================================


============================================================
🔄 Round 299 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 299 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0031
   Val:   Loss=0.0885, RMSE=0.2975, R²=0.0005
============================================================


📊 Round 299 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 300 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 300 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0005
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0069
============================================================


📊 Round 300 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 302 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 302 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0012
   Val:   Loss=0.0860, RMSE=0.2932, R²=-0.0066
============================================================


============================================================
🔄 Round 303 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 303 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0005
   Val:   Loss=0.0807, RMSE=0.2840, R²=-0.0067
============================================================


📊 Round 303 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 305 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 305 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0009
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0128
============================================================


============================================================
🔄 Round 307 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 307 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0032
   Val:   Loss=0.0916, RMSE=0.3026, R²=-0.0049
============================================================


============================================================
🔄 Round 308 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 308 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0009
   Val:   Loss=0.0861, RMSE=0.2935, R²=-0.0198
============================================================


📊 Round 308 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 311 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 311 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0001
   Val:   Loss=0.0776, RMSE=0.2785, R²=-0.0263
============================================================


📊 Round 311 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 313 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 313 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0002
   Val:   Loss=0.0786, RMSE=0.2803, R²=-0.0113
============================================================


📊 Round 313 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

📊 Round 313 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 318 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 318 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0021
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0098
============================================================


============================================================
🔄 Round 319 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 319 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0007
   Val:   Loss=0.0916, RMSE=0.3026, R²=-0.0230
============================================================


📊 Round 319 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

📊 Round 319 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 325 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 325 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2856, R²=-0.0005
   Val:   Loss=0.0925, RMSE=0.3041, R²=-0.0071
============================================================


📊 Round 325 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

📊 Round 325 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 328 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 328 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0002
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0009
============================================================


📊 Round 328 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 330 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 330 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0007
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0001
============================================================


============================================================
🔄 Round 332 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 332 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0018
   Val:   Loss=0.0832, RMSE=0.2884, R²=0.0032
============================================================


📊 Round 332 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 336 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0950 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0950, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0950, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0950, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0950, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0950, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0950)

============================================================
📊 Round 336 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0002
   Val:   Loss=0.0950, RMSE=0.3082, R²=-0.0071
============================================================


============================================================
🔄 Round 337 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 337 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0016
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0017
============================================================


============================================================
🔄 Round 338 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 338 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0003
   Val:   Loss=0.0851, RMSE=0.2916, R²=-0.0016
============================================================


📊 Round 338 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 340 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 340 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0033
   Val:   Loss=0.0883, RMSE=0.2972, R²=-0.0089
============================================================


📊 Round 340 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 341 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0656 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0657, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0657, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0657, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0657, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0658, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0656)

============================================================
📊 Round 341 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2971, R²=-0.0022
   Val:   Loss=0.0656, RMSE=0.2562, R²=-0.0265
============================================================


============================================================
🔄 Round 342 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 342 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0001
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0059
============================================================


📊 Round 342 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

📊 Round 342 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

📊 Round 342 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 349 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 349 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0020
   Val:   Loss=0.0782, RMSE=0.2796, R²=-0.0111
============================================================


============================================================
🔄 Round 350 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 350 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0014
   Val:   Loss=0.0900, RMSE=0.3000, R²=-0.0014
============================================================


============================================================
🔄 Round 351 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 351 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0017
   Val:   Loss=0.0769, RMSE=0.2772, R²=0.0029
============================================================


============================================================
🔄 Round 352 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 352 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=-0.0009
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0002
============================================================


📊 Round 352 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

📊 Round 352 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 357 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0714 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0714, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0714, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0714, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0714, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0714, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0714)

============================================================
📊 Round 357 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0004
   Val:   Loss=0.0714, RMSE=0.2673, R²=-0.0002
============================================================


============================================================
🔄 Round 358 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 358 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=-0.0018
   Val:   Loss=0.0763, RMSE=0.2763, R²=-0.0042
============================================================


============================================================
🔄 Round 360 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 360 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0010
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0003
============================================================


📊 Round 360 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

📊 Round 360 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 365 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 365 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0018
   Val:   Loss=0.0798, RMSE=0.2825, R²=0.0057
============================================================


📊 Round 365 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

📊 Round 365 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 369 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 369 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0012
   Val:   Loss=0.0770, RMSE=0.2775, R²=-0.0071
============================================================


============================================================
🔄 Round 371 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 371 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0007
   Val:   Loss=0.0915, RMSE=0.3024, R²=-0.0120
============================================================


============================================================
🔄 Round 374 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 374 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=-0.0005
   Val:   Loss=0.0752, RMSE=0.2743, R²=0.0001
============================================================


============================================================
🔄 Round 375 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 375 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0003
   Val:   Loss=0.0757, RMSE=0.2751, R²=-0.0068
============================================================


📊 Round 375 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 378 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 378 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0011
   Val:   Loss=0.0751, RMSE=0.2740, R²=-0.0051
============================================================


📊 Round 378 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 383 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 383 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0013
   Val:   Loss=0.0854, RMSE=0.2923, R²=0.0020
============================================================


📊 Round 383 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 384 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 384 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0000
   Val:   Loss=0.0786, RMSE=0.2803, R²=-0.0018
============================================================


============================================================
🔄 Round 385 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 385 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0009
   Val:   Loss=0.0859, RMSE=0.2932, R²=0.0008
============================================================


📊 Round 385 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

📊 Round 385 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 391 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 391 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0002
   Val:   Loss=0.0891, RMSE=0.2986, R²=-0.0024
============================================================


📊 Round 391 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

📊 Round 391 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 396 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 396 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0021
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0060
============================================================


============================================================
🔄 Round 397 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 397 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0012
   Val:   Loss=0.0774, RMSE=0.2782, R²=0.0008
============================================================


============================================================
🔄 Round 398 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 398 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0026
   Val:   Loss=0.0807, RMSE=0.2840, R²=0.0012
============================================================


============================================================
🔄 Round 399 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0949 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0950, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0950, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0950, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0950, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0952, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0949)

============================================================
📊 Round 399 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0028
   Val:   Loss=0.0949, RMSE=0.3081, R²=-0.0281
============================================================


📊 Round 399 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

📊 Round 399 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

📊 Round 399 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 406 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 406 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=0.0007
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0045
============================================================


📊 Round 406 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 408 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 408 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0014
   Val:   Loss=0.0732, RMSE=0.2705, R²=0.0048
============================================================


📊 Round 408 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 409 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0707 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0707, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0708, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0708, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0708, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0709, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0707)

============================================================
📊 Round 409 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=-0.0015
   Val:   Loss=0.0707, RMSE=0.2660, R²=-0.0157
============================================================


============================================================
🔄 Round 411 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 411 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0026
   Val:   Loss=0.0797, RMSE=0.2824, R²=-0.0073
============================================================


📊 Round 411 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 414 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 414 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0023
   Val:   Loss=0.0896, RMSE=0.2994, R²=0.0068
============================================================


============================================================
🔄 Round 416 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 416 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0012
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0076
============================================================


📊 Round 416 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 417 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 417 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0006
   Val:   Loss=0.0819, RMSE=0.2863, R²=0.0010
============================================================


📊 Round 417 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 418 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 418 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0009
   Val:   Loss=0.0877, RMSE=0.2962, R²=-0.0033
============================================================


============================================================
🔄 Round 420 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 420 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2896, R²=0.0008
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0079
============================================================


📊 Round 420 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

📊 Round 420 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 423 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 423 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=-0.0003
   Val:   Loss=0.0898, RMSE=0.2996, R²=-0.0006
============================================================


============================================================
🔄 Round 425 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 425 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0011
   Val:   Loss=0.0861, RMSE=0.2935, R²=-0.0012
============================================================


============================================================
🔄 Round 426 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 426 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0015
   Val:   Loss=0.0829, RMSE=0.2878, R²=-0.0109
============================================================


📊 Round 426 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 427 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 427 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0011
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0188
============================================================


📊 Round 427 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

📊 Round 427 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 431 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 431 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=-0.0010
   Val:   Loss=0.0881, RMSE=0.2968, R²=0.0015
============================================================


============================================================
🔄 Round 434 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 434 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0009
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0184
============================================================


============================================================
🔄 Round 436 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 436 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0003
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0030
============================================================


📊 Round 436 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 440 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 440 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0011
   Val:   Loss=0.0838, RMSE=0.2894, R²=-0.0072
============================================================


📊 Round 440 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

📊 Round 440 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 443 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 443 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0011
   Val:   Loss=0.0808, RMSE=0.2842, R²=0.0028
============================================================


📊 Round 443 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 445 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0944 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0944, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0944, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0944, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0944, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0944, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0944)

============================================================
📊 Round 445 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=-0.0001
   Val:   Loss=0.0944, RMSE=0.3073, R²=-0.0041
============================================================


📊 Round 445 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

📊 Round 445 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 452 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 452 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0006
   Val:   Loss=0.0914, RMSE=0.3023, R²=0.0004
============================================================


📊 Round 452 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 454 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 454 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0023
   Val:   Loss=0.0823, RMSE=0.2868, R²=-0.0112
============================================================


============================================================
🔄 Round 455 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 455 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=0.0012
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0084
============================================================


============================================================
🔄 Round 456 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 456 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=0.0003
   Val:   Loss=0.0809, RMSE=0.2845, R²=-0.0125
============================================================


============================================================
🔄 Round 457 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 457 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0005
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0044
============================================================


📊 Round 457 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 458 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0710 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0710, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0710, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0710, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0710, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0710, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0710)

============================================================
📊 Round 458 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=0.0011
   Val:   Loss=0.0710, RMSE=0.2665, R²=-0.0084
============================================================


============================================================
🔄 Round 460 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 460 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0000
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0026
============================================================


📊 Round 460 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 461 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 461 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0007
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0131
============================================================


📊 Round 461 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 462 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 462 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0002
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0028
============================================================


📊 Round 462 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

📊 Round 462 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 466 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 466 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0009
   Val:   Loss=0.0880, RMSE=0.2967, R²=-0.0053
============================================================


📊 Round 466 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 467 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 467 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=0.0010
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0304
============================================================


📊 Round 467 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 468 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 468 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0012
   Val:   Loss=0.0805, RMSE=0.2838, R²=-0.0102
============================================================


📊 Round 468 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

📊 Round 468 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

📊 Round 468 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 475 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0943 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0943, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0943, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0943, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0943, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0943, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0943)

============================================================
📊 Round 475 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0003
   Val:   Loss=0.0943, RMSE=0.3070, R²=-0.0063
============================================================


============================================================
🔄 Round 476 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 476 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0012
   Val:   Loss=0.0730, RMSE=0.2701, R²=0.0037
============================================================


============================================================
🔄 Round 477 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 477 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=-0.0005
   Val:   Loss=0.0821, RMSE=0.2864, R²=-0.0010
============================================================


📊 Round 477 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

📊 Round 477 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 480 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 480 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2871, R²=0.0002
   Val:   Loss=0.0888, RMSE=0.2981, R²=-0.0021
============================================================


📊 Round 480 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 481 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 481 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0007
   Val:   Loss=0.0800, RMSE=0.2829, R²=-0.0031
============================================================


📊 Round 481 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

📊 Round 481 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 485 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 485 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=-0.0005
   Val:   Loss=0.0753, RMSE=0.2743, R²=-0.0001
============================================================


📊 Round 485 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 487 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 487 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0011
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0028
============================================================


============================================================
🔄 Round 488 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 488 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=-0.0005
   Val:   Loss=0.0720, RMSE=0.2683, R²=0.0004
============================================================


📊 Round 488 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

📊 Round 488 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 492 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 492 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0000
   Val:   Loss=0.0883, RMSE=0.2972, R²=-0.0052
============================================================


============================================================
🔄 Round 493 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 493 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0001
   Val:   Loss=0.0789, RMSE=0.2810, R²=-0.0021
============================================================


📊 Round 493 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 496 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 496 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0010
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0093
============================================================


📊 Round 496 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 497 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 497 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0001
   Val:   Loss=0.0859, RMSE=0.2930, R²=-0.0051
============================================================


📊 Round 497 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 499 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 499 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0004
   Val:   Loss=0.0778, RMSE=0.2790, R²=-0.0105
============================================================


============================================================
🔄 Round 500 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 500 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0014
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0027
============================================================


📊 Round 500 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 501 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 501 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0020
   Val:   Loss=0.0911, RMSE=0.3018, R²=0.0056
============================================================


============================================================
🔄 Round 503 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 503 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0008
   Val:   Loss=0.0774, RMSE=0.2783, R²=-0.0094
============================================================


============================================================
🔄 Round 505 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 505 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0021
   Val:   Loss=0.0917, RMSE=0.3029, R²=0.0018
============================================================


📊 Round 505 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

📊 Round 505 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 507 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 507 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=-0.0023
   Val:   Loss=0.0849, RMSE=0.2914, R²=0.0068
============================================================


📊 Round 507 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

📊 Round 507 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 511 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 511 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=0.0001
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0062
============================================================


============================================================
🔄 Round 512 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 512 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=-0.0018
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0022
============================================================


📊 Round 512 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

📊 Round 512 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 515 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 515 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0011
   Val:   Loss=0.0886, RMSE=0.2976, R²=-0.0006
============================================================


📊 Round 515 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 516 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 516 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0003
   Val:   Loss=0.0899, RMSE=0.2998, R²=-0.0033
============================================================


📊 Round 516 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0044

============================================================
🔄 Round 519 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 519 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0004
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0100
============================================================


============================================================
🔄 Round 520 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 520 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0004
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0087
============================================================


📊 Round 520 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 521 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 521 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0001
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0014
============================================================


============================================================
🔄 Round 522 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 522 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0013
   Val:   Loss=0.0845, RMSE=0.2908, R²=-0.0005
============================================================


📊 Round 522 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

📊 Round 522 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

📊 Round 522 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

📊 Round 522 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 527 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 527 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0001
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0061
============================================================


============================================================
🔄 Round 532 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 532 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0006
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0038
============================================================


📊 Round 532 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

📊 Round 532 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

📊 Round 532 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 537 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 537 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0002
   Val:   Loss=0.0895, RMSE=0.2992, R²=-0.0154
============================================================


============================================================
🔄 Round 538 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 538 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0019
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0102
============================================================


📊 Round 538 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

📊 Round 538 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

📊 Round 538 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

📊 Round 538 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 545 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 545 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0001
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0071
============================================================


📊 Round 545 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 548 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 548 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0013
   Val:   Loss=0.0855, RMSE=0.2924, R²=0.0036
============================================================


📊 Round 548 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 549 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 549 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0012
   Val:   Loss=0.0807, RMSE=0.2842, R²=-0.0231
============================================================


============================================================
🔄 Round 551 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 551 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0006
   Val:   Loss=0.0785, RMSE=0.2801, R²=-0.0079
============================================================


📊 Round 551 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 552 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 552 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0014
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0058
============================================================


============================================================
🔄 Round 553 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 553 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0019
   Val:   Loss=0.0759, RMSE=0.2754, R²=-0.0363
============================================================


📊 Round 553 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

📊 Round 553 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

📊 Round 553 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 556 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 556 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=0.0008
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0108
============================================================


============================================================
🔄 Round 558 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 558 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0007
   Val:   Loss=0.0830, RMSE=0.2880, R²=-0.0018
============================================================


📊 Round 558 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 561 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 561 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=-0.0013
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0162
============================================================


📊 Round 561 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

📊 Round 561 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

📊 Round 561 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

📊 Round 561 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

📊 Round 561 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0044

📊 Round 561 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 575 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 575 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0026
   Val:   Loss=0.0841, RMSE=0.2899, R²=0.0057
============================================================


============================================================
🔄 Round 576 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0945 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0945, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0945, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0945, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0945, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0945, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0945)

============================================================
📊 Round 576 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0006
   Val:   Loss=0.0945, RMSE=0.3074, R²=-0.0035
============================================================


📊 Round 576 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0044

📊 Round 576 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0044

============================================================
🔄 Round 584 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 584 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0012
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0102
============================================================


📊 Round 584 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0044

📊 Round 584 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

📊 Round 584 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

📊 Round 584 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 590 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 590 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0001
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0027
============================================================


📊 Round 590 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0044

📊 Round 590 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0044

============================================================
🔄 Round 593 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 593 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0008
   Val:   Loss=0.0893, RMSE=0.2989, R²=-0.0098
============================================================


📊 Round 593 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0044

============================================================
🔄 Round 594 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 594 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0020
   Val:   Loss=0.0866, RMSE=0.2942, R²=0.0050
============================================================


📊 Round 594 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0044

============================================================
🔄 Round 596 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 596 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0010
   Val:   Loss=0.0814, RMSE=0.2852, R²=-0.0046
============================================================


📊 Round 596 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 597 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 597 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0028
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0121
============================================================


============================================================
🔄 Round 599 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 599 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0001
   Val:   Loss=0.0829, RMSE=0.2880, R²=-0.0064
============================================================


============================================================
🔄 Round 602 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 602 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0015
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0050
============================================================


============================================================
🔄 Round 603 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 603 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=-0.0007
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0059
============================================================


📊 Round 603 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

📊 Round 603 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 606 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 606 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0001
   Val:   Loss=0.0778, RMSE=0.2790, R²=-0.0008
============================================================


📊 Round 606 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 609 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 609 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=0.0016
   Val:   Loss=0.0762, RMSE=0.2760, R²=-0.0126
============================================================


============================================================
🔄 Round 610 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 610 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0016
   Val:   Loss=0.0891, RMSE=0.2984, R²=-0.0041
============================================================


📊 Round 610 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 613 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 613 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2904, R²=-0.0003
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0015
============================================================


============================================================
🔄 Round 614 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 614 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0006
   Val:   Loss=0.0871, RMSE=0.2952, R²=-0.0092
============================================================


📊 Round 614 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 617 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 617 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0007
   Val:   Loss=0.0821, RMSE=0.2866, R²=-0.0020
============================================================


📊 Round 617 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2432, R²: 0.0045

============================================================
🔄 Round 620 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0988 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0989, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0989, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0989, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0989, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0989, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0988)

============================================================
📊 Round 620 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0004
   Val:   Loss=0.0988, RMSE=0.3144, R²=-0.0156
============================================================


============================================================
🔄 Round 623 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 623 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0022
   Val:   Loss=0.0868, RMSE=0.2947, R²=-0.0087
============================================================


📊 Round 623 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2432, R²: 0.0045

============================================================
🔄 Round 624 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 624 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0014
   Val:   Loss=0.0810, RMSE=0.2845, R²=-0.0016
============================================================


============================================================
🔄 Round 625 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 625 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0012
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0056
============================================================


📊 Round 625 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2432, R²: 0.0045

📊 Round 625 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2432, R²: 0.0045

📊 Round 625 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2432, R²: 0.0045

============================================================
🔄 Round 632 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 632 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=-0.0014
   Val:   Loss=0.0764, RMSE=0.2764, R²=-0.0012
============================================================


📊 Round 632 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2432, R²: 0.0045

📊 Round 632 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2432, R²: 0.0045

============================================================
🔄 Round 636 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 636 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0001
   Val:   Loss=0.0818, RMSE=0.2859, R²=-0.0030
============================================================


============================================================
🔄 Round 637 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 637 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0024
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0160
============================================================


📊 Round 637 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 638 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 638 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0004
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0006
============================================================


📊 Round 638 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 639 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 639 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=-0.0030
   Val:   Loss=0.0780, RMSE=0.2792, R²=-0.0091
============================================================


📊 Round 639 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 640 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 640 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0003
   Val:   Loss=0.0786, RMSE=0.2803, R²=-0.0006
============================================================


📊 Round 640 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 642 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 642 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=-0.0001
   Val:   Loss=0.0747, RMSE=0.2732, R²=-0.0011
============================================================


📊 Round 642 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

📊 Round 642 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 644 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 644 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0018
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0114
============================================================


📊 Round 644 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 645 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 645 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=0.0006
   Val:   Loss=0.0836, RMSE=0.2892, R²=-0.0036
============================================================


📊 Round 645 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

📊 Round 645 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 648 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 648 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0020
   Val:   Loss=0.0818, RMSE=0.2859, R²=0.0054
============================================================


📊 Round 648 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

📊 Round 648 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

📊 Round 648 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 652 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 652 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0022
   Val:   Loss=0.0843, RMSE=0.2904, R²=0.0064
============================================================


============================================================
🔄 Round 653 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 653 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0028
   Val:   Loss=0.0796, RMSE=0.2822, R²=-0.0217
============================================================


📊 Round 653 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

📊 Round 653 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2433, R²: 0.0045

============================================================
🔄 Round 658 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0944 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0944, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0944, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0945, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0945, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0946, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0944)

============================================================
📊 Round 658 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0005
   Val:   Loss=0.0944, RMSE=0.3072, R²=-0.0411
============================================================


============================================================
🔄 Round 659 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 659 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0022
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0070
============================================================


============================================================
🔄 Round 662 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 662 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0010
   Val:   Loss=0.0853, RMSE=0.2921, R²=0.0020
============================================================


============================================================
🔄 Round 663 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 663 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=0.0016
   Val:   Loss=0.0726, RMSE=0.2695, R²=-0.0249
============================================================


❌ Client client_23 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8690 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8690 {grpc_message:"Socket closed", grpc_status:14}"
>
