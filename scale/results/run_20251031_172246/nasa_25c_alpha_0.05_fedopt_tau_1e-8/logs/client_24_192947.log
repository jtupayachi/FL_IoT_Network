[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb47fb9d-a3e4-48cd-850e-3ab1ce6e764f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0dcad907-63e7-464b-8132-eaac387734bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 456e1b37-b497-4cd4-b30b-7798782d6be1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2ad72ff-fc78-41b2-b1b6-4b61fcf0a1c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c37242b-ba22-47b7-acee-c7885364a923
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1a6539b-c399-4996-b855-1d421c89e164
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2fb993c-7235-430f-9fb4-453b212f5674
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75e752aa-9258-49e9-92fc-fbc30d3a33bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a696588b-858d-4f69-88f5-f0785423303c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40f2a2fa-6769-456c-9e03-3e89b3a697e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf3d769a-d37b-4fad-b333-29d6ea12a68f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0a9d53a-8214-4915-991c-3baa49185fc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47fc6c04-2f6c-4923-b660-07aaab9ab5ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1bb70be3-b817-4f7b-94ca-2402cd0322c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05689e0d-6947-42f4-a40e-31b4c9c5426b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c204efd5-e119-46e1-817c-670dcd6735fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7a6b3cf-728e-4565-8832-b82d8e8ceeed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5986f006-9c5c-4199-a50a-4d7bdca8bc56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4aea83af-785b-49f0-9279-3ebdc328a2d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message feb306c0-5618-4880-b638-dee0048e56d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 564f7abb-f75e-4e1b-a257-20a5daaebb3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0775e77b-b7f0-4235-bca3-cf391d064111
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21a13be1-cba7-4a81-a461-041a253b114b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff8d65f1-6a05-47b6-948b-5a009c78d2e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18fce042-452f-4eb9-bf6c-628140c06010
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57645f6b-1c74-45e3-8e4e-81e0284ce5a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ca5d334-149b-4c36-81ae-31d60344e09e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb51d3a6-5d0e-43cb-aea8-599d03624472
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2857fa82-585b-4922-87de-6a0513b646a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message adb2cd3d-37d9-4840-8ce3-efeefef6e099
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8f7bd29-c4de-4918-9c28-a48d91229643
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a2fb0ce-7899-4937-bf81-eabdc24998de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d9a60e7-3ccc-401f-a2ad-a6247e961277
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f74ff01-ae43-4539-87e7-1d618c36a265
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd2f13bc-ab36-45c4-8b01-afe59b574b6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83fd8e50-a783-41ab-98cc-658f7263c4c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5045c7a4-279f-424d-9336-41f3f7b3dfc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22508631-a42a-4919-a751-15fe5e37e1ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f701afb-1142-44f3-96b5-6382bd428d06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0475e22-5cbd-4aa0-a007-3d922f01f71b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06af4a18-c7af-48f0-82d5-5d3236c014d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41e6ac0b-12d3-4312-a8c6-5ace1b65e5bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 906e7422-64c9-41ac-8930-86a884046baf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc04c05c-ecf7-49c3-89a5-9a866864f78e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4bd59ab-e70f-4212-b077-a29be5fdc407
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 570b32e2-e062-4418-85c7-5fcb393551ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d9a9c93-36f1-427d-b6af-af26484d19d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c86ac53-1f04-40db-9d4a-229ca984d4c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17b48829-528f-410a-b1c2-46bb92e0d003
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14f71cdd-b550-4605-a831-da1393278f8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e850e85-1e3d-424c-ac1f-e590bf5e05e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0de33678-362e-4a91-b05a-70d24d89abfc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a89bd9b-0f7f-44ef-8dd9-16c03037180f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0d23fe2-208a-477d-bb44-3c3ef06a3db2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f060c45c-4619-49b5-b85a-d3f5dbe2149a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98ff0263-3087-4b01-a101-5299996901ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1cbbdb42-d991-4437-a28d-d43ac41f6a9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c07450a-5a21-4c81-af82-6d613e106a76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d973bbd-ecc0-48ac-b203-5b9a7be8b73f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2b7beb3-6e01-4eb5-8c39-925a2b6a4745
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43049956-18e6-4e23-998f-30a9cf53540a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6fe387f0-0a16-44b3-8570-43ad09cefe22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65589fe0-ee30-437d-a537-dec28009c140
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98d929cf-f195-4a74-8701-b3d66f60753f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3678f21a-879c-45d1-9605-d6ffba10e49a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 044c68c6-1b81-47a3-8290-9ebfe4188fbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 147d3de4-0339-491c-a66b-e5235d88b739
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1402c7d0-b8d8-46bf-8092-7ea03b1d4793
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message effaf09a-76c4-46df-a45a-a2c9173cf460
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f205fa9-0097-4482-823d-d90d86cc2b6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3247671-1400-4ba1-889a-a2327e0b630c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 028003e3-20d9-4816-948c-2f72748cfad8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7bab29ab-46cd-4293-a6e6-254c6f370266
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fdf99578-ff6b-46ab-bcfe-bc225aa0315b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8efccda7-71a6-464a-a296-75fa06bfcd31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5544bf0a-6c28-47a7-8dd7-501b2ee6ed7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d3513b5-6dd8-4451-91b9-baa32d8c9ab3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f796b31-a964-49ff-8ab5-d02abf2e5e1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5403358-6d72-40d3-a170-88252a591e92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ef5a5e6-7ed3-4f13-81a1-a24a403fe7c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b8f5e45-7f9c-4b64-8e13-6055216cce98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed6c0e5d-5eaf-4de1-b5d2-214bce649f4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e046b4e-ee54-460d-849a-1002e588155c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b76c019-cc18-4e73-89f5-028658143d0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 961d337d-dee5-4c53-bc77-83214c432b35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c6b0c18-ca05-4664-bb28-bea6f9777af5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a241d937-b4bf-4235-a4f6-bc9a6a52897a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4de86ca3-d102-4ace-b551-a3ef1c9c785d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 236e5ca8-27b9-4e3c-bd0f-d27cb73d6fc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa624330-6aa6-4123-b617-1b2e81a7510a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c5a2100-d52b-40f8-992b-2a073f083565
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27723768-c3f3-459e-afa6-303ef13355b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec5244be-c576-4366-a052-6faf85e2cedd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 763fbce7-9477-47ff-bfc6-332c3b48e58c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c83cc44-e4e5-4e0e-8c6d-30ccfc7884d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53e87793-60f6-4ccf-b26f-4f8923be6a5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 470c6a05-77e3-4726-9395-b3c7537b4ad2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e7ec74c-fe7a-4ec5-82b0-e8e742fc9701
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72715bbf-5c66-4409-9df7-5fb4ef0a9d23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16eee101-9b93-4b68-bda2-6a5a5fd365d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bea517eb-427f-4df8-af2e-c67dbabc03a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4366bb60-36f6-437e-b66b-5c48ff3bae56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfcee99d-5269-48af-b5fc-641852f4dfdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35d2f0ba-0c89-477c-bd48-9951858b3ce6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b077013-2d6c-4358-90b9-997254e45003
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b7a6210-1e5f-4f1b-83de-9efb154e8318
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6291d3c3-a838-4feb-ac44-d5ba919176e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00a87de5-cef4-4d47-b0b9-eedeae8e4616
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53cfbf14-13ba-4a25-89ee-039f712cc13c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 209207e7-3c34-4b7f-a49a-368550dc282b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af7c3128-b666-4db0-87a0-f57b91d1e878
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a93edd70-08dc-439a-a9e6-22fcc774a9ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9938867d-ce1a-4484-81a3-95e4c003aa8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9adbaf74-a2be-4774-9bbc-d2057decb443
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95e62e4d-a164-4c46-b343-465f8a77e0f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9225be3-8fc8-4c64-a350-f082db07c47e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4633a7e1-4c98-4235-8b63-fde0743e6545
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0831253c-51ad-4d93-9d2f-c1f8d79b23bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 064a12f6-1332-4428-a157-09d8e2ff9ee9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03644188-01e7-4ab5-98e6-20c6e40c6f90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9763740f-7307-49b4-8bf7-a6aa50246b3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f38e702-c43e-46ec-95c7-7d9733bad3d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5620acc0-9161-4c27-9cdd-a0cc3dfe2937
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 486e3b14-5568-4900-b28e-bfe68d680e1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5874855a-9f0d-4741-9a5c-82e2f530ce07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30093784-f943-401d-9438-b8a724366cef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9de06ae6-af89-42c2-9a98-2255116246b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7e81d6c-3b34-4b83-870d-0a1c55e7feb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c81a9f09-e822-4ba6-8959-6abd8a4b4b14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ceb95998-be10-4fdf-9c9a-c50fb93daae5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f88cd16b-633d-48c1-a580-b815bbf1831d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0193db47-720c-44f9-b47a-799b7c137aa8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14cca585-287d-4e7b-903e-98a27be15ddf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c33c697-6ae4-420c-a851-133b714706df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1dd604fc-1ace-4c5a-b7c5-d2f85f389ab7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0677d2a-6ba7-4d6c-9285-d7e0325bc96a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d47c6377-98b8-4bc6-943f-78fe192d547e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8a05bac-0865-4960-b027-8bbfe8cb7ce2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1a16617-1273-435f-85b0-6077f1331e42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a61fd8a0-a629-4920-a6fc-a647539d6d8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46446abd-187f-4cdc-b078-24e59ec022f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eaa940c4-ac75-4112-89af-04b60acdbbed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9361601c-c7da-4f02-bfbf-51cd18ed6ea0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f3da2f0-630e-40ed-ae9a-d6b5a232e665
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64161cbe-751b-4175-a97f-855afdfc7ed2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d2349c9-2e1b-4d50-aef1-5fc263e620b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 688b63a2-4d9b-4dc4-87cd-c0e063ed6df0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5508eb9-9795-43d9-a122-883d177a732b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2dbfe5a6-2b3e-4dad-a892-bfb3b55769fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5d0ecb1-a11d-4474-96a2-670f5e5bd640
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b822c56-a983-4bbc-a9bb-651c32be7b51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bcec6a3e-2794-4b2f-86ae-3c818ea14060
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02857cde-1c44-4a44-9513-173b699bccc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 579f95c0-10a6-4fee-8b36-d0737b578fa5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ffd11a2e-1ba1-49f6-8652-5bdfd41ce0f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d70cd7b-d59e-4bd2-8f3f-d77ce353ac06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b278a221-1734-4840-b6f3-c278f25f2774
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a681afd-4fb9-4336-a507-2e335edf7b17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d251a17a-39fe-4058-92f7-cea4acc56123
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f890ac80-fb10-41b4-80e1-25ccb53258fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b4554f5-8b46-433a-8bee-94be5f76ed10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3253f46d-0bf2-44fd-8e3c-5a506d6ea812
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb28bfb7-1c8b-4202-b61b-30be33c85d98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2262efbf-63a2-495f-bb8a-1177f5dbe9c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5aec45db-9160-45bf-bdcc-aad6bfe44245
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7b11197-6bfe-4726-8ae6-32e99ef08bd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce50a512-5944-4f85-9961-4cb1bb67e5b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f8b1187-197e-4e90-87bb-7f6bd6d1aac0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f64b2d7d-6f93-475f-836b-ca4c1eb23c0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f04a7f0-5389-494f-8282-e65ae1855922
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a94cea1-b6ce-472b-a922-b477ed460fd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85d444ca-0e50-4af9-9c56-babf33a1e55a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78f641d3-94ee-4d94-8243-52f143211fe0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61027d79-c76c-46ae-9209-1b810e39746b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8fadbfd-1fe5-40fd-8482-fbb7eece3d19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03aa9efc-c368-4a38-89b4-1305c321d66c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fcb1b097-173f-4f32-8547-3c7f54aed8f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7bcd0ee7-475c-456d-978b-e143f63b24d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5db96b22-13df-481f-a77d-b8d21d09d3bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5944e5c3-0ed8-4cac-be90-95ade6f77142
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7507f7fb-8c03-4e31-b580-50bdd5c94fc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1998f6a5-72e9-425b-a07f-cf955fe236c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5e8fedd-16e5-48dc-99cb-09506c4a91ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e650aad8-5b26-4b05-a41d-10b2ca2b2e71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3093f662-41b8-4585-9d09-9aa9f633efed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6168d3a-492d-4b7b-83c8-fe580a41937b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3205d676-519d-4529-b28c-f2dd31c26791
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4dec7044-470f-47a2-8f98-025ec14b9c67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44b5fd73-ae79-468a-b0d7-dc2c8588dd63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 079b9081-220d-44e2-8156-a4aa78ea6f3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9545d20-2cce-40c3-8053-caf41e6ebd2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8596b853-db86-4c38-b171-638469680201
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45153d96-b809-461c-a7d9-753391c48e81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7f159b0-91c8-40e2-b86b-aac368f67635
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5fb3ea0-ab9a-45d4-b8de-b4563488c8cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3070d131-baa7-4c57-b184-ae9eb706acc1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee79bb4a-db43-44f9-a345-3ead3787f258
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17532c20-961f-46e0-8fd5-df567f9cc579
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7e80b87-199b-4ade-8495-eee2efeb9e46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5d4ede9-0453-4406-9e40-3bc185267062
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c3b6b08-85e2-4344-9919-5efef0297cef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ab71599-c6df-4f01-8d10-83aaa4b749a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cae0c506-b1c0-46c3-b833-10bfb25b49f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef116ee2-d5ed-4994-8b2d-0c6d696cfb58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58a5ca93-05d6-4f21-a1e8-43f03b26c14a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cbcdb9f8-b283-4b1d-a2f6-3c2df65a78ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7b5ba51-bfa9-471b-8928-30c5ca022849
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7769f627-cb5c-4be6-9268-8144a5d7038e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 946afbe8-dffb-4df2-8386-d4f36db2dc95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 520ac4d1-e0ad-4427-a838-59be7811abda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13a4a279-bb3d-47c8-a1bd-ece6efda144c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1255fdae-d9a0-4382-8f12-18edfc75d2ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6bc15020-41b3-49f8-ade0-80c75d92678e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19631f5f-cd30-4d6a-8b42-5eb7929a849b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95a8f4b7-925e-4747-81c1-54bfbff25b86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19070435-a274-4e10-a6e0-f6c86337c58c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 326d2eaa-499b-45c6-9a62-034b19485fcd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 203113b9-7ea9-4c5a-ae36-ca17dbce65f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c034abd6-12b7-4daf-b63a-e79e96a9b55b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e70c4754-80c5-4f0f-9ed7-4fefbfaf742b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc861bf4-2313-42a1-ae71-8ab554860ff2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d08d048-8a5d-4693-9922-f87c2f5eaf82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a34acb72-8f19-4cc2-b936-8faa8293172f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f6ae4da-757d-488f-86d3-9e243862ef0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f923f82-f562-4765-93ea-010b5caf67b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 347cd46b-b013-47d7-8741-1748defb4465
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb3715ee-bc83-4743-85a7-7aa2ce0bfcbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5da3d09-7884-40b1-8881-1d8f0c132f1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c75daff2-cd47-4ec1-862c-c24de8d9d201
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0112787a-59b0-4a9c-9dca-6258a3615b82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f50def87-8215-4bb1-a1fa-d87210b5fe18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9894b2f-d916-4c6d-ae0e-b647c42f98dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ecf1848-3602-4b47-982a-21b2efa5623b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d63450c4-1203-4b48-ac28-6afb9f9a5167
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f5cb30a-2237-4bb3-87ed-44ed26385deb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0603cc6d-367f-4f1e-a2aa-5f642e175787
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd7a44e5-2445-4863-b0a5-0202043ea8c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8b97dc9-40af-438b-a7e4-18e37d1a237c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67725330-21b1-4aa7-a3c4-699022f640c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21a769cb-cad9-4974-aebc-1d24875fe691
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a47aa3ac-d42a-4d45-81d2-3b45ca0532dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 613a982b-6347-4c7e-bef0-f3773b97db44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2b6b5e2-a5b1-4333-9e05-34b478a063c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ae8fbe0-7021-46bc-b5c5-c07c237b1c73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c721525-167f-4e03-b20c-6ceaa5e21276
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74cd72e8-4561-472f-bbcb-e66fa5bab21f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e56d09b5-c391-40d2-8a04-5f7cd48f3061
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c4f5dc4-ca42-46e8-ab0b-2c62fffab08a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5dd44a63-e362-4dd4-9f6f-754cce0e6eda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc96d600-5a92-4b8c-94dc-cc792a69d06a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36439794-cfbb-44a4-ba77-9484ed69d733
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba86f9d6-dd77-4936-bc01-e1c8b3318c1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1814789b-5d7e-422d-9ff7-d9234cd629ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2abc23ad-e320-482b-a27b-d39d1440a275
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a77ff3ec-88c9-4fd5-b2b8-b085db19281d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e02f776-c652-445c-8cc5-05a8fd45829d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1de63eec-54f6-48f5-b946-27c2c95d410c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af8d11c8-0843-4da3-b863-b764cee680c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0162613c-c4a7-4af0-aad6-0f4f77a2b1f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94236e09-0275-4e07-b91f-ab1a93190e93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79ecbd8a-64e4-44f8-a4ca-46f5d970b5cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ac25ef1-adae-4439-9cb9-dc8416553103
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe91aa21-1735-4fa3-b53d-95c53273eaf7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5421550-baf9-4147-8048-0ae02935df26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11a1ff6f-deae-4405-b722-da4a41933eff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb393b9b-5c6f-44d2-a7c0-e5fd253af971
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae9eafbb-5c32-48a0-9ea1-7c0eb3c58ea4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91e902e4-ca2a-4030-a761-0a05a7d92289
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70aafc08-a702-435a-a1d7-e142adb02e6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f525b6e2-abf3-444e-af38-afc950608b83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c74f21ff-46bc-4358-9ac9-5f4be7d7a47a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ffe2e407-bbf4-4801-a2ff-48713ddf479f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe5dc8b8-f069-4929-bc7e-e072f1e61b05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96e5bf97-ab4d-4418-944f-e2f61f3362bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0eaaef2d-9fa8-4a51-a978-acfd7d94378c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b45ecbf3-2239-4a02-9f74-8f0cd1c63e9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8164bfb4-93c4-4e45-81ce-03076b54b581
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9221cb23-8945-4d46-879f-82164f0b9f57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a48eae74-ca92-4df2-aadb-30b8e4410a03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0901249-1fd1-48a4-a7d3-fb3ed514aba9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f9dfad5-0b18-4824-8ebe-930901936478
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5f58a64-1a10-44ee-86fd-08d86d64a2ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c20507e-22cb-4472-bfd2-20f703a1dcef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a5e43bf-f046-4f32-9b29-6590834139c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38a1ce1c-a4b9-427c-85ab-d3e316ed4154
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a22fc82b-7184-4377-a3a0-4e270440fa32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d337a66c-13d0-4dd1-98cf-8b8ceb6bbbf4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60c04c0a-5e14-422a-88d8-d5efe9b46487
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 359fbaee-4465-468c-8184-3ea652b3d436
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b35d40a-584e-4b82-8fcd-ed2534fb3a98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d57454c-fd8f-401b-8916-dd809cf0679a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db549de3-62ee-48e0-ad32-fb12730753e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8e94c9b-a7cd-406b-b6fe-bc99df93e91a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 321e18d3-f895-4093-9ffc-366b6683d895
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82e1c4a0-5666-4405-984a-3b510b9687f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98bb58e4-54ea-400a-97d5-9c94d84263ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9ee1845-5647-4c87-8eaf-57ed7665af65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c9822d7-fd11-4d06-a2e8-dba621ec2521
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08d6b78c-a685-4e91-9498-38ec3f1d7566
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2809a7f-45b6-442c-81a4-ffe69f176f82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message faa27eff-75a8-426b-ae5a-b4ca2fd9d8fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 551a815f-9286-40cf-9e82-07211d04c52c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f746b765-ab47-4da4-b8b1-6d09a98bd6d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ec8d6e6-926b-4b60-8966-df3164e2a5eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13ff7073-04d9-469e-936d-b3010391feff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a50eaca9-13e9-475d-a4ad-3502c3b8c434
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68040d0c-cc45-439f-82a7-68eb0dcb83fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75d6e8fc-bd14-4ccb-9ca8-b4b7937dbac1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b41c638-3df0-4c36-ad5b-94e49cff75e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5fd5bac0-3380-4d1e-a162-1056b9482f13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6048261b-8325-4fde-a420-2f870f90a777
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0dc12aee-ade2-4d2b-a5db-e97f361dac84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aacd24e9-f9d4-409f-8663-4caeb0eed7eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe4ca5de-5fa4-4d16-bd61-e4528e8e9b52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b860f5a2-0ece-44be-9312-cbfec78428b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d542607d-529a-494b-8839-01aa7cc8f100
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8293709-7215-4529-88b8-2e5360405f74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f0253d3-7b2d-41b6-bad0-be44b4f1b689
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26deca5f-c72a-4426-90f1-0ebdde12316a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64d9a15e-2ef5-4b04-833b-77e1922a5afd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 939dad97-fa6d-4b18-aea1-7b2f017c7f58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a90127b6-c54c-4a16-ad12-b14f01dcdbc1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42a8614c-16f6-492e-9a98-c1e22b5c71eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad1885bf-39fb-439d-b448-aebcefe26e0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6538b45b-e430-43d4-adc8-e5415a7dd0d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70ab748a-bcb2-42c3-a844-7587664ae783
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f5f3bd8-989d-4268-b105-701385e03346
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c841dc1c-1d26-47d6-b0bc-b5932a002336
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07c0524b-66b8-4dbe-bdc4-fc5aff6c5cd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 468f7e6f-fd96-473b-a80e-71bd0dc93753
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36186c65-418a-4f07-a2c8-d447807aabc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b460b28b-2ce9-4b88-af65-82a1360a44e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9fcdd39-d3ce-45fb-83b8-dd3893f7e93f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6ee1e6a-e807-4635-aa69-81484a5459b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 631864f8-eff7-4a2c-9b1c-e2f6a890bebe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 062019df-26bc-4e09-9e76-76368f1251cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7fe648d-06e3-4301-aa54-b998c8715819
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d894d43-5aa9-451d-9a1f-02a8f4ab66a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1941808-4aae-4974-8f06-1307f3fe6ce2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1cc14d0-50c2-4a5b-b92d-c9451a21ceb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 224763a2-54da-45a1-81fe-bee31a98466d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c205cda4-07dd-4f6f-8f87-108d11ea110a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ba2833f-c9d4-4057-b0bd-0892b1df68c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ac5c7ad-e046-437d-8044-6fff6781bbb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36ab3ba0-eb92-478d-ae67-007e18f70095
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7e15565-f783-4646-b311-b408089ab7ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6480cf96-9518-4037-81b4-39b1154c53d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e591488-3e7a-4d8d-bc43-ec5bb62b4ec0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef620a91-55ff-4fef-bcd9-9f86d25b0c25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ccacca01-3d0c-4e66-9820-e955829b5215
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd5a8b3a-225c-488a-a9c8-97cd227fa959
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9b31fee-ce4f-4d56-9c8e-3d76d9342144
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8ba8a1f-6e04-4b2c-8420-2c8273d0ce34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6756a4e-33eb-4040-8655-797a19d21bc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39f841a7-1b79-44f1-9a64-990eeb42c036
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e66aff8b-40d9-4c7a-994d-d7152d623a85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5bef9033-c2f4-443a-8160-85b3ed80334b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1bb9d0bc-4d1c-4bcc-8a58-4c77b9a83f27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d8be8c9-bb92-4e03-92d2-7b8fbfd6f1fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75299193-25f5-4584-89ec-e3ffe3ab3b9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76f99b39-e8ef-4cc2-9d18-48afc804c5df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7fb10afc-a26d-4671-bffe-1f34458832b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8024d80-68e1-4b5c-97a3-51fc0af22ba5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03f419d8-984d-4fec-a594-ee7a6cbf6eb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eba2f61b-768c-46a4-b911-42809de75384
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a250f09-2e94-4f9d-be7c-1c6d827ea647
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10f36a55-3872-4367-9d70-62f705fc67f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c5f16e6-9aca-4397-8cb3-052196021ef0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4eb0ccbe-a492-4ee1-a5f6-e19350da055a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ff23b98-e512-4bbc-9ae6-7998c41ad9cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa4fe0ee-d323-43ab-9bfd-8b07b334b84a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d93fb9a-6f35-448a-bafd-1a0fef76bb85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36a67cc8-5fc6-4937-b1f8-d5625fd9ee6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25e3925f-660b-43ff-99ce-f35eb2774f1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ee696ec-3d89-47ff-9359-a239a7434934
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1eff9e77-e6d4-41a3-a5db-2e5ebed174b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4aab406-ca4b-4c2f-8a0a-6a6a3d69d015
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b556177-3fcc-4b26-a039-2cc0e5869198
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b6f6c56-5f54-4cb0-ae00-526e9934b31e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca73ace9-7960-4f8f-bf78-4a75a3644e81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 785a9aa1-fcce-41e0-a3c6-8232311b32a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4e90257-7221-4760-8984-1a2173a521e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e4f2976-dcbb-4184-8e21-938b0f5a181a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3dff0598-bb3b-4d3a-b603-66fbd7c57abc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf2687c8-1ed8-491f-a91d-85c7ba5c8b4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1aeeb88a-ff7a-4b6d-ae74-f42aa33c4549
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0bf32e9-6ffe-4e7a-a2dc-36d7d49c160b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad8731a3-6b5b-4205-a70a-39290800b9fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c04fb7e-8e86-463c-89b9-cfdcb45d23ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5122f48-49f1-4fb2-8e5e-fc3a8280f75d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9053334c-431c-4783-8059-7148b6c092d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1e2b503-769c-4b14-a27d-b6db4bf15715
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51d81642-a940-41a3-8d98-312483a2fa9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57dd9f92-b434-477c-9589-a9b69cafbdc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 773272a6-e943-4f96-b158-8daa941863e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb5405e6-b630-49c7-8d93-d358d40714c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2fa89bc-51f7-416d-8222-ca3d524282bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ef02bea-0339-4f00-8576-c4b9aa0f0721
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15523cc5-3f10-4db1-b369-5027d730f5a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c92e0e22-539a-4ead-87d8-70a896e1d56b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a254743-5a78-4da7-8fbf-e0575c0ad49b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6738ec1-a57b-4c5b-a811-2a7a7a443a04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c96fea0-207d-428d-8c3b-e73a5a201dc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19f8c05c-fbc6-4e5f-8d91-a79a71d42317
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 710586f2-6c80-4120-9448-20285f6f701e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d83c8d8a-6407-4dd9-a101-e951eb54d6c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e944eeb1-a5de-4721-b5ee-c2d078507e24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af6539b3-a142-4262-9d3e-792deec0f692
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0beebf2-433b-42ce-a54a-ae4be92fe8ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05dea474-1d1e-493e-b3b3-e27e6c57c3bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe250122-9cdb-474f-b4fe-690f516c8712
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da6ecd8e-cf25-401f-acc8-3f5a3661a3bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dad7f0fd-f82c-4615-9431-81486174527e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2970f71d-f999-4cf9-a06c-38ed1bb631c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1752e102-db97-4e26-b37a-1ff3d64634d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65be0753-419c-4324-8aa1-06c5c34f486d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e85bd68-7110-41df-b1f3-f08c642e0a19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1dba3256-94e4-49e7-bab7-20708c8e3aa1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 612a4bac-db88-42d3-8dda-d5efe531d9e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c148e09-1e24-4913-af91-4520f000b02d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47bb4bba-5e15-49e1-99ca-ae727f9f25e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e051dd2c-9539-44c3-9329-829f30707d77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15b9de2a-d4e6-4a81-ac77-61376dd6590b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9add5fe-4456-4577-8cf9-80d6652b7eda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cecc6547-68c0-421e-b9c0-bb98e9a836f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2fe207a-91dd-4c3d-b1dc-3556a5044c8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eeef0283-02cb-46ea-a3f9-19708dcdbb8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 879ea43e-9687-4982-a779-b3ea67ccb13e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 184022ef-e5c5-4d7b-a8d2-10db57f000f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e81c4221-ccf3-482e-b59b-7123c72380f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78dbd72f-6001-4233-a25d-0fc3a650ae6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9736dac8-286e-49cb-b7bd-10fa3eb9a86f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9189d24b-ee95-4d6b-abbb-93f1e7f3917e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc6eac21-c2ec-4b47-8a6a-f6f971871ef5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd4b79d8-1ec7-4448-953d-196274f9ae67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 351d19a8-4145-49ae-8224-ccb6a8feba39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76f9e453-4b44-4ab6-8c02-a17543673a12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 901021d6-2c49-43b1-b50c-25c4e21c4f8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7fedcec-5f95-4bf6-b6d6-16694068cfd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63a59f59-7835-439e-bd3e-d87e4f2da43b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f6c7cc3-f0cc-4ad8-9c0e-bcd2a27b837d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c5e9458-40e0-401a-842a-578fc261888f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7af9db57-8239-4fc3-8376-1adc886ca47c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65a056ab-ad5a-49c3-816e-8279ae31c92a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f9aa4f5-087c-4af5-8de7-6d96218e1d4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c19c0b3e-1d9e-4832-a7e6-faf466c69d49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3bb8a813-5c8c-4675-bd6d-264f0e81af1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9212b2b-ba3a-4273-bbca-e3a2be8a3bf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32a0ec79-953a-4e12-a254-277d6635b899
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7790dfc7-7de1-443e-bb0e-031504db9861
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b4cd08f-cd63-4b8d-a226-8785f8a6ec35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e28fc520-5051-46c8-9d59-4f4b028c02fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 962d2119-c185-4e28-a3df-5fe616b53478
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df4581a4-0cf3-4c72-a9c7-73962667fa12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19ae0648-78bb-4fcc-bee4-e6418af70618
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 797df242-8b67-440f-be84-b4f4fdc573e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e345f30-9314-4900-8ae1-23d5676f9de2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c5f06cb-7aa4-4877-bbce-f2157666daa7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 589fbd73-c852-4f61-8fba-b90bd1bc34fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bac4c8c9-6f04-45b0-a380-9d4d3c073a0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5658704a-965f-4214-8332-626bfecac30c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41141499-13ac-434c-89fe-6ac28adb5c8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d7996e6-90fc-4fa4-9260-80139d6bde38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e3cf959-564c-4b87-ae8d-2d55303ee264
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b367a48b-5e2d-4f59-a4c6-34b7fb075ec3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 631b0493-6f98-4908-aeab-bd03cd4add41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc35bb71-9972-4c93-a6db-b3d62ef2f9ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5107721c-856c-4c1f-8961-3ed96e186964
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7136b92a-6c8f-4c2c-8f32-e61f4abb5515
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55047565-e99d-4030-a368-e9f3eed08ddf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84497702-e2ff-4ac1-9fe0-a1ed64d5b3ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6f879d3-9fc3-49b5-96ea-31bb570e08f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f89b57fa-31a1-44af-b94b-e960359277af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e552bf7-d8a7-4292-98f1-fa13ca3e99db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a0f1dec-abb9-4a3c-a22b-41fb0aef61f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 073114ef-43fa-4181-85e0-f18a4c83fc33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 801d1e6c-ec0e-4ffe-b572-b91c81cae2df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85dbf7c9-fa3d-4941-b322-1a15c41bd0fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56cf495f-f980-4d78-a5d7-f80b39479f34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 110096e7-ca9e-4ea7-804a-217e70ec29ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a3d4d6e-d7c0-4bb4-b391-677c1dc90ee1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36c2ffe8-8845-49e5-8e11-1c7e52b94a83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d2cefde-7639-43f6-b64f-96aad788e013
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3065c1ee-6b07-4cdb-8306-01ac27f2451c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5fb0a555-e65f-487b-90e3-52faf1aa0f86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26861110-73f9-4b08-a1bc-1ed8f8301d10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2d75528-9128-49c3-b130-dfb70a09e2cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31ad46fb-e3f8-41c2-a286-5109406cfb63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a57958b8-a267-43ec-9ed9-570f7643af47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b55dfadd-dd37-4d20-9679-5d5992e39f56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76770609-1c02-4d8e-a812-7f6495d1ec9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de2f2b7f-796f-4a65-ba76-dd4fe8c71848
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9db6610-e2c2-48ac-83ab-fe3d02e45540
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee4197d0-3c3b-4100-bcf5-a672c5760cee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da4797cb-264e-43f9-a457-1811f0c71d83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b69f7b2-b3d0-4aa8-8170-89252d46d6ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7941cb61-ea4b-43b7-83de-c726e7572062
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f5d5e33-473b-47bc-ab3e-4a744d317536
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9a11e90-3fea-434a-8187-680c092f4370
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec1ede20-029f-42c9-bb03-78d2ec797bd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 509c0efd-cf0d-4cad-b89e-222e44117c35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0ea67a8-d2bf-4623-ab1d-e9e3c2c905be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7b23cf2-96fc-4063-a9f7-b9588d42aea6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b783419a-abe7-4f18-b24b-70e7f09b8eb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23751bdd-6776-4d19-a939-a4fd6483711c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35b9c8cc-18a2-49e8-ab23-a6190c7a3b53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 271131ea-74b5-44ff-806b-d963ecfe3907
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1c0f0c7-e800-43fe-b084-4f4d17ebc487
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d58e71c3-494c-4eca-a5a1-648284fb48ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84618694-f8ab-497b-b959-5e285dfbfcca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b06321a-7a72-43d8-aa7d-b1d5ec0c2cc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d5f5a29-3721-4ad7-b748-c4948f7e2763
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be128bbb-a807-4071-a9fd-670fb62e5ffe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26858653-d89e-45a6-95a7-3b9e224a8a39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e74bcb5-725c-44bc-93a5-4ab7db575cd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ba1422e-e799-4a58-81fa-23ec719f8b81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e41b2ef-c0ca-4fd6-a205-7bfef285c4f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d86875b-0fae-4e18-9d6d-0623607865b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1279d5b6-e542-4d56-91af-b20151d9a296
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02603baf-b018-477a-912d-04238d0da2ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d60780c-98b4-463f-b1fb-837fe531917c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bfc8bd11-e01c-46ec-a658-77659885928a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c450317-0be3-4f58-9e1f-8b74a9ea4e47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ad3a765-0be8-4006-b224-1cac806ad1f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee6fbb57-8f0b-4659-976f-a337b6fa5d99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f488c6d-02c3-491a-a483-289db90b395b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05e2c42b-4339-4724-982a-bef9edab4160
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42e63746-e6e9-4cdf-a233-9297f189f06f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89663921-880b-4127-b421-2ebb598b9f7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b23e091-7cd3-493c-9be6-651d2b2bca0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ef106c3-ec04-49eb-b476-71e9c414d1fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1e12dc0-0c1e-4101-a9a7-a5971515c74d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 106288ef-ba05-4a9f-8ebd-154e08db554a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1bf74989-0aff-4226-8e34-1667f3af75a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa71cbad-40c4-481e-827a-90f560dd34e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2596f31a-8067-408b-b6d5-566f2f3a9524
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4971b25-7949-430a-81fc-1d016c1db74c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a66a4720-f2a6-488e-a058-254421a7c42c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de1a1985-5fe3-4f64-baae-ad8a8dbcfefc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3cfbaf83-6832-4d4b-8dd6-9608569830c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0682b4c0-3e8e-46cf-b8be-75c438786405
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63da1408-7723-4366-a51b-1fe2b8fdb570
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 142e53fe-93bf-43ec-979a-1d3e0f48fa4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77d076d5-1bb8-4814-8876-b466fca76093
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8ece137-dc62-4bd1-b6b1-d40e79ade05a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee3f0e06-0cd5-443e-84c9-0fb9fb9d7676
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 863c6c15-5e86-45fc-aeda-a4e5bd5cdc9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bfa68e3c-60c9-4e1a-b45b-43cc68f2a87e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 750618cd-251c-443e-9645-b6c2f2c19c1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c070117-00d1-404e-a450-7ecc0182b582
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dec85a82-2a8d-4b80-8fa5-312e107faf53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77baebb1-40c2-498c-8878-69846a35e137
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c32f88c3-f296-4fe1-ba86-5206c6d2797f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe7feb73-aafe-40a5-9324-009f5ccfb5e8
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8690 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_24
Server: localhost:8690
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_24
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_24/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_24/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_24/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_24/test_labels.txt

📊 Raw data loaded:
   Train: X=(3897, 24), y=(3897,)
   Test:  X=(975, 24), y=(975,)

⚠️  Limiting training data: 3897 → 800 samples
⚠️  Limiting test data: 975 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_24 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2485, R²: -0.0013

============================================================
🔄 Round 3 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0958, val=0.0843 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0950, val=0.0829 (↓), lr=0.001000
   • Epoch   3/100: train=0.0922, val=0.0824, patience=1/15, lr=0.001000
   ✓ Epoch   4/100: train=0.0919, val=0.0823 (↓), lr=0.001000
   • Epoch   5/100: train=0.0920, val=0.0822, patience=1/15, lr=0.001000
   ✓ Epoch  11/100: train=0.0901, val=0.0816 (↓), lr=0.001000
   • Epoch  21/100: train=0.0831, val=0.0788, patience=2/15, lr=0.001000
   📉 Epoch 26: LR reduced 0.001000 → 0.000500
   • Epoch  31/100: train=0.0737, val=0.0807, patience=12/15, lr=0.000500
   📉 Epoch 34: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 3 Summary - Client client_24
   Epochs: 34/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.1012
   Val:   Loss=0.0790, RMSE=0.2811, R²=0.0451
============================================================


============================================================
🔄 Round 4 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0963 (↓), lr=0.000250
   • Epoch   2/100: train=0.0880, val=0.0967, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0879, val=0.0965, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0877, val=0.0966, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0876, val=0.0967, patience=4/15, lr=0.000250
   📉 Epoch 8: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0872, val=0.0968, patience=10/15, lr=0.000125
   📉 Epoch 16: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0963)

============================================================
📊 Round 4 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0877, RMSE=0.2962, R²=0.0074
   Val:   Loss=0.0963, RMSE=0.3104, R²=-0.0020
============================================================


📊 Round 4 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2485, R²: 0.0002

📊 Round 4 Test Metrics:
   Loss: 0.0818, RMSE: 0.2859, MAE: 0.2485, R²: -0.0004

============================================================
🔄 Round 9 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0907, val=0.0858 (↓), lr=0.000063
   • Epoch   2/100: train=0.0906, val=0.0858, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0905, val=0.0858, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0905, val=0.0858, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0905, val=0.0858, patience=4/15, lr=0.000063
   📉 Epoch 8: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0903, val=0.0858, patience=10/15, lr=0.000031
   📉 Epoch 16: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 9 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0904, RMSE=0.3007, R²=0.0081
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0015
============================================================


============================================================
🔄 Round 10 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0893, val=0.0913 (↓), lr=0.000016
   • Epoch   2/100: train=0.0893, val=0.0913, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0892, val=0.0914, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0892, val=0.0914, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0892, val=0.0914, patience=4/15, lr=0.000016
   📉 Epoch 8: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0891, val=0.0915, patience=10/15, lr=0.000008
   📉 Epoch 16: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 10 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0890, RMSE=0.2983, R²=0.0049
   Val:   Loss=0.0913, RMSE=0.3021, R²=0.0085
============================================================


============================================================
🔄 Round 11 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0896, val=0.0883 (↓), lr=0.000004
   • Epoch   2/100: train=0.0896, val=0.0883, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0896, val=0.0883, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0896, val=0.0883, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0896, val=0.0883, patience=4/15, lr=0.000004
   📉 Epoch 8: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0896, val=0.0883, patience=10/15, lr=0.000002
   📉 Epoch 16: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 11 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0898, RMSE=0.2997, R²=0.0063
   Val:   Loss=0.0883, RMSE=0.2972, R²=0.0036
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2483, R²: 0.0021

============================================================
🔄 Round 14 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0912, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0912, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0912, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0912, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0912, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0912, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 14 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0911, RMSE=0.3019, R²=0.0088
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0083
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2483, R²: 0.0019

📊 Round 14 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0016

📊 Round 14 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0018

============================================================
🔄 Round 17 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0924 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 17 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2974, R²=0.0078
   Val:   Loss=0.0924, RMSE=0.3040, R²=-0.0033
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0017

📊 Round 17 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0017

============================================================
🔄 Round 19 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 19 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2979, R²=0.0066
   Val:   Loss=0.0913, RMSE=0.3021, R²=0.0087
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0016

📊 Round 19 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2484, R²: 0.0016

📊 Round 19 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2484, R²: 0.0016

============================================================
🔄 Round 23 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0898, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0898, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0898, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0898, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0898, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0898, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 23 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0898, RMSE=0.2996, R²=0.0083
   Val:   Loss=0.0872, RMSE=0.2953, R²=0.0096
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2484, R²: 0.0016

============================================================
🔄 Round 28 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 28 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2980, R²=0.0040
   Val:   Loss=0.0910, RMSE=0.3017, R²=-0.0438
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2484, R²: 0.0015

============================================================
🔄 Round 31 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0895, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0895, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0895, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0895, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0895, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0894, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 31 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2987, R²=0.0075
   Val:   Loss=0.0893, RMSE=0.2988, R²=0.0135
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2484, R²: 0.0015

============================================================
🔄 Round 33 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0902, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0902, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0902, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0902, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0902, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0901, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 33 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0903, RMSE=0.3004, R²=0.0103
   Val:   Loss=0.0852, RMSE=0.2919, R²=0.0016
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2484, R²: 0.0015

============================================================
🔄 Round 34 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 34 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2976, R²=0.0106
   Val:   Loss=0.0920, RMSE=0.3032, R²=-0.0064
============================================================


============================================================
🔄 Round 35 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0935 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0935, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0935, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0935, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0935, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0935, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0935)

============================================================
📊 Round 35 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=0.0074
   Val:   Loss=0.0935, RMSE=0.3058, R²=0.0133
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2484, R²: 0.0015

============================================================
🔄 Round 37 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0917, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0917, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0916, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0916, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0916, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0916, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 37 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0916, RMSE=0.3027, R²=0.0087
   Val:   Loss=0.0798, RMSE=0.2824, R²=0.0023
============================================================


============================================================
🔄 Round 39 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0901, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0901, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0901, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0901, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0901, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0901, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 39 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0900, RMSE=0.3000, R²=0.0099
   Val:   Loss=0.0863, RMSE=0.2937, R²=0.0031
============================================================


============================================================
🔄 Round 41 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0897, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0897, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0897, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0897, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0896, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 41 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0897, RMSE=0.2995, R²=0.0087
   Val:   Loss=0.0875, RMSE=0.2957, R²=0.0082
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2484, R²: 0.0015

============================================================
🔄 Round 42 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0900, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0900, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0900, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0900, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0900, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0899, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 42 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0900, RMSE=0.3001, R²=0.0105
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0006
============================================================


============================================================
🔄 Round 43 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0893, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0893, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 43 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0893, RMSE=0.2989, R²=0.0083
   Val:   Loss=0.0889, RMSE=0.2982, R²=0.0103
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2484, R²: 0.0015

============================================================
🔄 Round 46 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0893, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0893, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0893, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0893, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 46 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2987, R²=0.0103
   Val:   Loss=0.0895, RMSE=0.2991, R²=0.0019
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2484, R²: 0.0015

============================================================
🔄 Round 48 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 48 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2977, R²=0.0064
   Val:   Loss=0.0918, RMSE=0.3029, R²=0.0050
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2484, R²: 0.0015

============================================================
🔄 Round 57 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0918, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0918, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0918, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0918, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0918, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0918, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 57 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0918, RMSE=0.3031, R²=0.0081
   Val:   Loss=0.0788, RMSE=0.2808, R²=0.0109
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2484, R²: 0.0015

============================================================
🔄 Round 59 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0918, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0918, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0918, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0918, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0918, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0918, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 59 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0916, RMSE=0.3027, R²=0.0094
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0037
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2484, R²: 0.0015

============================================================
🔄 Round 60 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0898, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0898, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0898, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0898, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0898, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0897, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 60 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0895, RMSE=0.2992, R²=0.0088
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0011
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2484, R²: 0.0015

📊 Round 60 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2484, R²: 0.0015

============================================================
🔄 Round 64 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0927 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0927, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0927, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0927, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0927, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0927)

============================================================
📊 Round 64 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2973, R²=0.0085
   Val:   Loss=0.0927, RMSE=0.3045, R²=0.0090
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2484, R²: 0.0015

📊 Round 64 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2484, R²: 0.0014

📊 Round 64 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2484, R²: 0.0014

📊 Round 64 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2484, R²: 0.0014

============================================================
🔄 Round 72 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0949 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0949, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0949, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0949, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0949, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0949, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0949)

============================================================
📊 Round 72 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2964, R²=0.0092
   Val:   Loss=0.0949, RMSE=0.3081, R²=0.0061
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2484, R²: 0.0015

============================================================
🔄 Round 75 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0932 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0932, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0932, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0932, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0932, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0932, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0932)

============================================================
📊 Round 75 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2971, R²=0.0083
   Val:   Loss=0.0932, RMSE=0.3053, R²=0.0081
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2484, R²: 0.0015

📊 Round 75 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2484, R²: 0.0015

📊 Round 75 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2484, R²: 0.0015

📊 Round 75 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2484, R²: 0.0015

============================================================
🔄 Round 84 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 84 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2979, R²=0.0067
   Val:   Loss=0.0914, RMSE=0.3022, R²=0.0040
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2484, R²: 0.0015

📊 Round 84 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2484, R²: 0.0015

📊 Round 84 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2484, R²: 0.0015

📊 Round 84 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2484, R²: 0.0015

============================================================
🔄 Round 90 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0891, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0891, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0891, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0891, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 90 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0891, RMSE=0.2985, R²=0.0077
   Val:   Loss=0.0899, RMSE=0.2999, R²=0.0105
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2484, R²: 0.0015

============================================================
🔄 Round 93 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0955 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0955, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0954, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0954, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0954, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0954, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0955)

============================================================
📊 Round 93 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=0.0100
   Val:   Loss=0.0955, RMSE=0.3090, R²=0.0034
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2484, R²: 0.0015

============================================================
🔄 Round 96 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0929 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0929, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0929, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0929, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0929, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0929, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 96 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2972, R²=0.0101
   Val:   Loss=0.0929, RMSE=0.3047, R²=0.0022
============================================================


============================================================
🔄 Round 97 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 97 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2979, R²=0.0104
   Val:   Loss=0.0912, RMSE=0.3019, R²=-0.0050
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2484, R²: 0.0015

📊 Round 97 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2484, R²: 0.0015

============================================================
🔄 Round 101 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0890, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 101 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0891, RMSE=0.2984, R²=0.0095
   Val:   Loss=0.0900, RMSE=0.3001, R²=0.0047
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2484, R²: 0.0015

📊 Round 101 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2484, R²: 0.0015

📊 Round 101 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2484, R²: 0.0015

============================================================
🔄 Round 104 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0901, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0901, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0901, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0901, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0901, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0901, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 104 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0900, RMSE=0.3001, R²=0.0082
   Val:   Loss=0.0861, RMSE=0.2934, R²=0.0113
============================================================


============================================================
🔄 Round 106 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0890, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 106 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2981, R²=0.0094
   Val:   Loss=0.0909, RMSE=0.3015, R²=0.0036
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2484, R²: 0.0015

============================================================
🔄 Round 109 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0897, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0897, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0897, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0897, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0897, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 109 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0898, RMSE=0.2997, R²=0.0076
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0103
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2484, R²: 0.0015

📊 Round 109 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2484, R²: 0.0015

📊 Round 109 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2484, R²: 0.0015

📊 Round 109 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2484, R²: 0.0015

📊 Round 109 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2484, R²: 0.0015

📊 Round 109 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2484, R²: 0.0015

📊 Round 109 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2484, R²: 0.0015

📊 Round 109 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2484, R²: 0.0014

============================================================
🔄 Round 118 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.1004 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.1004, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.1004, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.1004, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.1004, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.1005, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1004)

============================================================
📊 Round 118 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=0.0084
   Val:   Loss=0.1004, RMSE=0.3168, R²=-0.0128
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2484, R²: 0.0015

📊 Round 118 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2484, R²: 0.0015

📊 Round 118 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2484, R²: 0.0015

📊 Round 118 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2484, R²: 0.0015

============================================================
🔄 Round 124 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0950 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0950, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0950, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0950, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0950, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0950, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0950)

============================================================
📊 Round 124 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=0.0074
   Val:   Loss=0.0950, RMSE=0.3082, R²=0.0122
============================================================


============================================================
🔄 Round 126 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0907, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0907, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0907, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0907, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0907, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0907, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 126 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0906, RMSE=0.3010, R²=0.0072
   Val:   Loss=0.0839, RMSE=0.2896, R²=0.0123
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2484, R²: 0.0015

============================================================
🔄 Round 127 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0917, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0917, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0917, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0917, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0917, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0917, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 127 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0914, RMSE=0.3023, R²=0.0083
   Val:   Loss=0.0808, RMSE=0.2842, R²=0.0070
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2484, R²: 0.0015

============================================================
🔄 Round 128 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0900, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0900, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0900, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0900, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0900, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0900, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 128 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0899, RMSE=0.2999, R²=0.0064
   Val:   Loss=0.0866, RMSE=0.2942, R²=0.0172
============================================================


============================================================
🔄 Round 129 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0979 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0979, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0979, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0979, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0979, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0979, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0979)

============================================================
📊 Round 129 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=0.0076
   Val:   Loss=0.0979, RMSE=0.3129, R²=0.0059
============================================================


============================================================
🔄 Round 130 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 130 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2981, R²=0.0078
   Val:   Loss=0.0907, RMSE=0.3012, R²=0.0009
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2484, R²: 0.0015

============================================================
🔄 Round 133 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0985 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0985, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0985, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0985, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0985, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0985, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0985)

============================================================
📊 Round 133 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2949, R²=0.0082
   Val:   Loss=0.0985, RMSE=0.3139, R²=0.0088
============================================================


============================================================
🔄 Round 134 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0898, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0898, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0898, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0898, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0898, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0898, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 134 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0899, RMSE=0.2998, R²=0.0088
   Val:   Loss=0.0867, RMSE=0.2944, R²=0.0008
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2484, R²: 0.0015

📊 Round 134 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2484, R²: 0.0015

📊 Round 134 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2484, R²: 0.0015

============================================================
🔄 Round 138 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0891, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0891, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0891, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0891, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 138 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2986, R²=0.0096
   Val:   Loss=0.0895, RMSE=0.2992, R²=-0.0088
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2484, R²: 0.0015

📊 Round 138 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2484, R²: 0.0016

============================================================
🔄 Round 141 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0955 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0955, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0955, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0955, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0955, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0955, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0955)

============================================================
📊 Round 141 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=0.0091
   Val:   Loss=0.0955, RMSE=0.3090, R²=0.0054
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2484, R²: 0.0016

============================================================
🔄 Round 143 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0992 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0992, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0993, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0993, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0993, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0993, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0992)

============================================================
📊 Round 143 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2945, R²=0.0094
   Val:   Loss=0.0992, RMSE=0.3150, R²=-0.0019
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2484, R²: 0.0015

============================================================
🔄 Round 145 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 145 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2981, R²=0.0079
   Val:   Loss=0.0908, RMSE=0.3013, R²=0.0106
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2484, R²: 0.0015

============================================================
🔄 Round 147 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0913, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0913, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0913, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0913, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0913, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0913, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 147 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0913, RMSE=0.3022, R²=0.0089
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0077
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2484, R²: 0.0015

📊 Round 147 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2484, R²: 0.0015

============================================================
🔄 Round 150 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0984 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0985, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0985, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0985, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0985, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0985, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0984)

============================================================
📊 Round 150 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=0.0089
   Val:   Loss=0.0984, RMSE=0.3138, R²=-0.0076
============================================================


============================================================
🔄 Round 154 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0898, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0898, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0898, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0898, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0898, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0898, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 154 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0899, RMSE=0.2999, R²=0.0087
   Val:   Loss=0.0866, RMSE=0.2942, R²=0.0066
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2484, R²: 0.0015

============================================================
🔄 Round 155 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0897, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0897, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0897, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0897, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0897, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 155 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0897, RMSE=0.2995, R²=0.0087
   Val:   Loss=0.0876, RMSE=0.2959, R²=0.0069
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2484, R²: 0.0015

📊 Round 155 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2484, R²: 0.0015

📊 Round 155 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2484, R²: 0.0015

📊 Round 155 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2484, R²: 0.0015

📊 Round 155 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2484, R²: 0.0015

📊 Round 155 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2484, R²: 0.0015

============================================================
🔄 Round 169 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0897, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0897, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0897, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0897, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0897, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 169 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0898, RMSE=0.2996, R²=0.0085
   Val:   Loss=0.0872, RMSE=0.2953, R²=0.0075
============================================================


============================================================
🔄 Round 171 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0891, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0891, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0891, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0891, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 171 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2981, R²=0.0076
   Val:   Loss=0.0908, RMSE=0.3013, R²=-0.0036
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2484, R²: 0.0015

============================================================
🔄 Round 172 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 172 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0891, RMSE=0.2984, R²=0.0080
   Val:   Loss=0.0900, RMSE=0.3001, R²=-0.0090
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2484, R²: 0.0014

============================================================
🔄 Round 173 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0905, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0905, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0905, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0905, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0905, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0905, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 173 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0905, RMSE=0.3008, R²=0.0104
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0090
============================================================


============================================================
🔄 Round 181 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0894, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0894, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0894, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0894, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0894, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0894, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 181 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0895, RMSE=0.2992, R²=0.0074
   Val:   Loss=0.0881, RMSE=0.2968, R²=0.0135
============================================================


============================================================
🔄 Round 182 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0906, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0906, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0906, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0906, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0906, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0906, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 182 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0906, RMSE=0.3009, R²=0.0095
   Val:   Loss=0.0840, RMSE=0.2899, R²=-0.0146
============================================================


============================================================
🔄 Round 184 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0904, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0904, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0904, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0903, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0903, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0903, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 184 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0905, RMSE=0.3009, R²=0.0087
   Val:   Loss=0.0841, RMSE=0.2899, R²=0.0080
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2484, R²: 0.0015

============================================================
🔄 Round 186 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0951 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0951, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0951, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0951, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0951, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0952, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0951)

============================================================
📊 Round 186 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=0.0069
   Val:   Loss=0.0951, RMSE=0.3084, R²=0.0076
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2484, R²: 0.0015

============================================================
🔄 Round 189 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0901, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0901, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0901, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0901, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0901, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0901, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 189 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0900, RMSE=0.3000, R²=0.0094
   Val:   Loss=0.0862, RMSE=0.2935, R²=0.0056
============================================================


============================================================
🔄 Round 190 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 190 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2977, R²=0.0088
   Val:   Loss=0.0918, RMSE=0.3030, R²=0.0086
============================================================


📊 Round 190 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2484, R²: 0.0016

============================================================
🔄 Round 192 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0904, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0903, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0903, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0903, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0903, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0903, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 192 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0905, RMSE=0.3008, R²=0.0077
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0083
============================================================


============================================================
🔄 Round 193 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0898, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0898, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0898, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0898, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0898, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0898, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 193 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0896, RMSE=0.2994, R²=0.0095
   Val:   Loss=0.0877, RMSE=0.2962, R²=0.0018
============================================================


============================================================
🔄 Round 194 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0896, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0896, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0896, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0896, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0896, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0896, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 194 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0895, RMSE=0.2992, R²=0.0097
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0071
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2484, R²: 0.0016

============================================================
🔄 Round 196 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0902, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0902, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0902, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0902, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0902, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0902, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 196 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0900, RMSE=0.3001, R²=0.0069
   Val:   Loss=0.0861, RMSE=0.2934, R²=0.0162
============================================================


📊 Round 196 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2484, R²: 0.0016

============================================================
🔄 Round 198 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0902, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0902, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0902, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0902, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0902, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0902, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 198 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0900, RMSE=0.2999, R²=0.0080
   Val:   Loss=0.0864, RMSE=0.2940, R²=0.0099
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0016

📊 Round 198 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0016

📊 Round 198 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0016

============================================================
🔄 Round 204 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0971 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0971, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0971, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0971, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0971, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0971, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0971)

============================================================
📊 Round 204 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2954, R²=0.0068
   Val:   Loss=0.0971, RMSE=0.3117, R²=0.0130
============================================================


📊 Round 204 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0016

============================================================
🔄 Round 205 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 205 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2978, R²=0.0086
   Val:   Loss=0.0914, RMSE=0.3024, R²=0.0090
============================================================


📊 Round 205 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0016

📊 Round 205 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0016

============================================================
🔄 Round 208 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0906, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0906, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0906, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0906, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0906, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0906, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 208 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0906, RMSE=0.3010, R²=0.0093
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0049
============================================================


============================================================
🔄 Round 209 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0892, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 209 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0891, RMSE=0.2985, R²=0.0079
   Val:   Loss=0.0898, RMSE=0.2997, R²=0.0084
============================================================


📊 Round 209 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0016

============================================================
🔄 Round 210 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0897, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0897, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0897, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0897, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0897, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 210 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0897, RMSE=0.2996, R²=0.0084
   Val:   Loss=0.0872, RMSE=0.2954, R²=0.0035
============================================================


📊 Round 210 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0016

============================================================
🔄 Round 213 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0951 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0951, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0951, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0951, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0951, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0951, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0951)

============================================================
📊 Round 213 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=0.0092
   Val:   Loss=0.0951, RMSE=0.3083, R²=0.0036
============================================================


============================================================
🔄 Round 214 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0896, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0896, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0896, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0896, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0895, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0895, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 214 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0894, RMSE=0.2989, R²=0.0078
   Val:   Loss=0.0888, RMSE=0.2980, R²=0.0114
============================================================


📊 Round 214 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2484, R²: 0.0016

============================================================
🔄 Round 215 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.1007 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.1008, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.1008, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.1008, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.1008, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.1009, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1007)

============================================================
📊 Round 215 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=0.0072
   Val:   Loss=0.1007, RMSE=0.3174, R²=-0.0158
============================================================


📊 Round 215 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2484, R²: 0.0016

📊 Round 215 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0016

============================================================
🔄 Round 218 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0905, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0905, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0905, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0905, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0905, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0905, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 218 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0909, RMSE=0.3015, R²=0.0064
   Val:   Loss=0.0826, RMSE=0.2875, R²=0.0029
============================================================


============================================================
🔄 Round 219 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0891, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0891, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0891, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0891, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 219 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0895, RMSE=0.2991, R²=0.0093
   Val:   Loss=0.0884, RMSE=0.2974, R²=0.0021
============================================================


📊 Round 219 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2484, R²: 0.0016

============================================================
🔄 Round 222 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0948 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0948, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0949, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0949, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0949, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0949, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0948)

============================================================
📊 Round 222 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2964, R²=0.0077
   Val:   Loss=0.0948, RMSE=0.3080, R²=0.0087
============================================================


📊 Round 222 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2484, R²: 0.0016

📊 Round 222 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2484, R²: 0.0016

============================================================
🔄 Round 225 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0908, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0908, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0908, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0908, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0908, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0908, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 225 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0910, RMSE=0.3017, R²=0.0077
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0045
============================================================


============================================================
🔄 Round 226 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0897, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0897, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0897, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0897, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0897, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 226 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0895, RMSE=0.2991, R²=0.0074
   Val:   Loss=0.0883, RMSE=0.2971, R²=-0.0124
============================================================


📊 Round 226 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0016

📊 Round 226 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0016

📊 Round 226 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2484, R²: 0.0016

============================================================
🔄 Round 231 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0923, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 231 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2975, R²=0.0071
   Val:   Loss=0.0923, RMSE=0.3038, R²=0.0125
============================================================


📊 Round 231 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2484, R²: 0.0016

============================================================
🔄 Round 232 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0890, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 232 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2986, R²=0.0092
   Val:   Loss=0.0896, RMSE=0.2993, R²=-0.0111
============================================================


📊 Round 232 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2484, R²: 0.0016

============================================================
🔄 Round 233 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0915, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0915, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0915, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0915, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0915, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0915, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 233 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0916, RMSE=0.3027, R²=0.0087
   Val:   Loss=0.0797, RMSE=0.2824, R²=0.0083
============================================================


📊 Round 233 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0016

============================================================
🔄 Round 234 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0999 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0999, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0999, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0999, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0999, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0999, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0999)

============================================================
📊 Round 234 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=0.0069
   Val:   Loss=0.0999, RMSE=0.3160, R²=0.0088
============================================================


============================================================
🔄 Round 235 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 235 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2979, R²=0.0090
   Val:   Loss=0.0912, RMSE=0.3020, R²=0.0065
============================================================


📊 Round 235 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0016

📊 Round 235 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0016

============================================================
🔄 Round 237 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0908, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0908, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0908, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0907, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0907, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0907, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 237 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0908, RMSE=0.3013, R²=0.0063
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0320
============================================================


============================================================
🔄 Round 238 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 238 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2979, R²=0.0100
   Val:   Loss=0.0914, RMSE=0.3023, R²=0.0031
============================================================


📊 Round 238 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0016

📊 Round 238 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0016

============================================================
🔄 Round 240 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0907, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0907, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0907, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0907, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0907, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0907, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 240 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0908, RMSE=0.3014, R²=0.0086
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0097
============================================================


📊 Round 240 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0016

============================================================
🔄 Round 241 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0932 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0932, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0932, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0932, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0932, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0932, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0932)

============================================================
📊 Round 241 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2971, R²=0.0099
   Val:   Loss=0.0932, RMSE=0.3053, R²=0.0020
============================================================


📊 Round 241 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0016

📊 Round 241 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0017

============================================================
🔄 Round 244 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0908, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0908, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0908, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0908, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0908, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0908, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 244 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0911, RMSE=0.3018, R²=0.0082
   Val:   Loss=0.0820, RMSE=0.2863, R²=0.0065
============================================================


📊 Round 244 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0017

📊 Round 244 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0016

============================================================
🔄 Round 247 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0906, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0906, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0906, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0906, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0906, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0906, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 247 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0906, RMSE=0.3010, R²=0.0077
   Val:   Loss=0.0839, RMSE=0.2897, R²=0.0109
============================================================


📊 Round 247 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0016

============================================================
🔄 Round 250 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0976 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0976, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0976, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0976, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0976, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0976, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0976)

============================================================
📊 Round 250 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=0.0085
   Val:   Loss=0.0976, RMSE=0.3123, R²=0.0090
============================================================


📊 Round 250 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0016

============================================================
🔄 Round 253 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0897, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0897, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0897, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0897, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0897, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 253 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0897, RMSE=0.2996, R²=0.0091
   Val:   Loss=0.0872, RMSE=0.2954, R²=0.0071
============================================================


📊 Round 253 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0017

============================================================
🔄 Round 254 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0932 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0932, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0932, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0932, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0932, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0932, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0932)

============================================================
📊 Round 254 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2971, R²=0.0080
   Val:   Loss=0.0932, RMSE=0.3052, R²=0.0051
============================================================


📊 Round 254 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0016

============================================================
🔄 Round 256 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0902, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0901, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0901, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0901, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0901, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0901, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 256 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0900, RMSE=0.2999, R²=0.0080
   Val:   Loss=0.0864, RMSE=0.2939, R²=0.0120
============================================================


📊 Round 256 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0017

============================================================
🔄 Round 257 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0905, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0905, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0905, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0905, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0905, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0905, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 257 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0906, RMSE=0.3010, R²=0.0077
   Val:   Loss=0.0838, RMSE=0.2895, R²=0.0102
============================================================


📊 Round 257 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0017

============================================================
🔄 Round 259 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0968 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0968, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0968, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0968, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0968, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0968, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0968)

============================================================
📊 Round 259 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=0.0101
   Val:   Loss=0.0968, RMSE=0.3112, R²=0.0038
============================================================


============================================================
🔄 Round 260 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0989 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0989, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0989, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0989, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0989, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0989, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0989)

============================================================
📊 Round 260 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=0.0104
   Val:   Loss=0.0989, RMSE=0.3145, R²=0.0031
============================================================


📊 Round 260 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0016

============================================================
🔄 Round 261 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0984 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0984, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0984, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0984, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0984, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0984, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0984)

============================================================
📊 Round 261 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=0.0082
   Val:   Loss=0.0984, RMSE=0.3137, R²=0.0106
============================================================


📊 Round 261 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0016

============================================================
🔄 Round 265 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0913, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0913, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0913, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0913, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0913, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0913, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 265 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0915, RMSE=0.3024, R²=0.0082
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0051
============================================================


📊 Round 265 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0016

============================================================
🔄 Round 267 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0897, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0897, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0897, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0897, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0897, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 267 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0898, RMSE=0.2996, R²=0.0091
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0160
============================================================


📊 Round 267 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0016

📊 Round 267 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0016

============================================================
🔄 Round 269 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0893, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0893, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0893, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0893, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0893, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 269 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0894, RMSE=0.2990, R²=0.0090
   Val:   Loss=0.0887, RMSE=0.2978, R²=0.0073
============================================================


📊 Round 269 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0016

============================================================
🔄 Round 270 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0922, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0922, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0922, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0922, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0922, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0921, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 270 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0923, RMSE=0.3038, R²=0.0066
   Val:   Loss=0.0771, RMSE=0.2777, R²=0.0137
============================================================


============================================================
🔄 Round 271 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0896, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0896, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0896, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0896, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0896, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0896, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 271 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0895, RMSE=0.2992, R²=0.0084
   Val:   Loss=0.0882, RMSE=0.2970, R²=0.0103
============================================================


📊 Round 271 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0017

============================================================
🔄 Round 276 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0894, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0894, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0894, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0894, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0894, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0894, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 276 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0897, RMSE=0.2995, R²=0.0091
   Val:   Loss=0.0874, RMSE=0.2956, R²=0.0042
============================================================


📊 Round 276 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0017

============================================================
🔄 Round 277 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0938 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0938, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0938, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0938, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0938, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0938, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0938)

============================================================
📊 Round 277 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2968, R²=0.0088
   Val:   Loss=0.0938, RMSE=0.3063, R²=0.0081
============================================================


============================================================
🔄 Round 278 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 278 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2978, R²=0.0081
   Val:   Loss=0.0915, RMSE=0.3025, R²=0.0038
============================================================


📊 Round 278 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0017

📊 Round 278 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0016

============================================================
🔄 Round 280 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0979 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0979, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0979, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0979, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0979, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0979, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0979)

============================================================
📊 Round 280 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=0.0079
   Val:   Loss=0.0979, RMSE=0.3129, R²=0.0093
============================================================


📊 Round 280 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0017

📊 Round 280 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0016

============================================================
🔄 Round 283 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0904, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0904, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0904, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0904, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0904, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0904, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 283 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0907, RMSE=0.3011, R²=0.0087
   Val:   Loss=0.0835, RMSE=0.2890, R²=0.0093
============================================================


📊 Round 283 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0017

📊 Round 283 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0016

============================================================
🔄 Round 287 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0895, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0895, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0895, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0895, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0895, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0895, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 287 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0894, RMSE=0.2990, R²=0.0091
   Val:   Loss=0.0885, RMSE=0.2976, R²=0.0072
============================================================


============================================================
🔄 Round 288 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0946 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0946, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0946, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0946, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0946, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0946, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0946)

============================================================
📊 Round 288 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=0.0089
   Val:   Loss=0.0946, RMSE=0.3076, R²=0.0078
============================================================


📊 Round 288 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0017

============================================================
🔄 Round 290 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0912, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0912, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0912, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0912, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0912, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0912, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 290 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0915, RMSE=0.3025, R²=0.0062
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0050
============================================================


📊 Round 290 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0017

============================================================
🔄 Round 293 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0950 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0950, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0950, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0950, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0950, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0951, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0950)

============================================================
📊 Round 293 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=0.0084
   Val:   Loss=0.0950, RMSE=0.3083, R²=-0.0002
============================================================


============================================================
🔄 Round 294 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0922, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 294 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2975, R²=0.0086
   Val:   Loss=0.0921, RMSE=0.3035, R²=0.0068
============================================================


📊 Round 294 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0017

📊 Round 294 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0017

============================================================
🔄 Round 298 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0898, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0898, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0898, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0898, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0898, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0898, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 298 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0897, RMSE=0.2996, R²=0.0092
   Val:   Loss=0.0873, RMSE=0.2954, R²=0.0068
============================================================


============================================================
🔄 Round 299 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0928 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0928, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0928, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0928, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0928, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0928, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 299 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2973, R²=0.0097
   Val:   Loss=0.0928, RMSE=0.3046, R²=-0.0062
============================================================


📊 Round 299 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0016

============================================================
🔄 Round 300 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0940 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0940, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0940, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0940, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0940, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0940, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0940)

============================================================
📊 Round 300 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2968, R²=0.0084
   Val:   Loss=0.0940, RMSE=0.3066, R²=0.0094
============================================================


============================================================
🔄 Round 301 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0934 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0934, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0934, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0934, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0934, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0934, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0934)

============================================================
📊 Round 301 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=0.0078
   Val:   Loss=0.0934, RMSE=0.3056, R²=0.0105
============================================================


============================================================
🔄 Round 302 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 302 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2980, R²=0.0088
   Val:   Loss=0.0909, RMSE=0.3015, R²=0.0086
============================================================


📊 Round 302 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0017

============================================================
🔄 Round 304 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0894, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0894, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0894, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0894, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0894, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0894, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 304 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0894, RMSE=0.2989, R²=0.0067
   Val:   Loss=0.0888, RMSE=0.2980, R²=0.0042
============================================================


============================================================
🔄 Round 305 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0908, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0908, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0908, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0908, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0908, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0908, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 305 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0907, RMSE=0.3012, R²=0.0092
   Val:   Loss=0.0833, RMSE=0.2886, R²=0.0070
============================================================


📊 Round 305 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0017

============================================================
🔄 Round 307 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0896, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0896, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0896, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0896, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0896, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0896, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 307 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0896, RMSE=0.2993, R²=0.0070
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0009
============================================================


📊 Round 307 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0017

📊 Round 307 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0017

📊 Round 307 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0017

============================================================
🔄 Round 312 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0984 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0984, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0984, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0984, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0984, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0984, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0984)

============================================================
📊 Round 312 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=0.0067
   Val:   Loss=0.0984, RMSE=0.3136, R²=0.0152
============================================================


============================================================
🔄 Round 314 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0901, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0901, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0901, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0901, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0901, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0901, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 314 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0901, RMSE=0.3002, R²=0.0093
   Val:   Loss=0.0859, RMSE=0.2930, R²=0.0031
============================================================


============================================================
🔄 Round 315 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0942 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0942, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0942, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0942, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0942, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0942, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0942)

============================================================
📊 Round 315 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2967, R²=0.0069
   Val:   Loss=0.0942, RMSE=0.3069, R²=0.0146
============================================================


============================================================
🔄 Round 316 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0904, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0904, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0904, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0904, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0904, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0904, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 316 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0903, RMSE=0.3006, R²=0.0089
   Val:   Loss=0.0849, RMSE=0.2914, R²=0.0013
============================================================


============================================================
🔄 Round 318 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0894, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0894, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0894, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0894, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0894, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0894, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 318 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0895, RMSE=0.2991, R²=0.0079
   Val:   Loss=0.0884, RMSE=0.2973, R²=0.0106
============================================================


📊 Round 318 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0017

============================================================
🔄 Round 320 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0922, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0922, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0923, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 320 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2975, R²=0.0069
   Val:   Loss=0.0921, RMSE=0.3035, R²=-0.0068
============================================================


📊 Round 320 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0017

============================================================
🔄 Round 321 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0891, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0891, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0891, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0891, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 321 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0893, RMSE=0.2989, R²=0.0061
   Val:   Loss=0.0889, RMSE=0.2981, R²=-0.0003
============================================================


============================================================
🔄 Round 323 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0910, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0910, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0910, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0910, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0910, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0909, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 323 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0909, RMSE=0.3015, R²=0.0081
   Val:   Loss=0.0825, RMSE=0.2873, R²=-0.0122
============================================================


============================================================
🔄 Round 327 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0908, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0908, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0908, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0908, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0908, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0908, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 327 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0909, RMSE=0.3015, R²=0.0082
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0109
============================================================


📊 Round 327 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0017

============================================================
🔄 Round 330 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 330 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2978, R²=0.0098
   Val:   Loss=0.0914, RMSE=0.3024, R²=0.0039
============================================================


📊 Round 330 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0017

📊 Round 330 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0017

============================================================
🔄 Round 333 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0912, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0912, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0911, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0911, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0911, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0911, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 333 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0911, RMSE=0.3018, R²=0.0091
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0077
============================================================


📊 Round 333 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0017

============================================================
🔄 Round 335 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0896, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0896, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0896, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0896, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0896, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0895, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 335 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0897, RMSE=0.2995, R²=0.0084
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0081
============================================================


📊 Round 335 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0017

📊 Round 335 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0016

📊 Round 335 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0017

============================================================
🔄 Round 344 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0896, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0896, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0896, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0896, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0896, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0896, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 344 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0896, RMSE=0.2994, R²=0.0103
   Val:   Loss=0.0877, RMSE=0.2962, R²=0.0006
============================================================


============================================================
🔄 Round 346 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 346 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2981, R²=0.0051
   Val:   Loss=0.0907, RMSE=0.3012, R²=-0.0198
============================================================


📊 Round 346 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0016

📊 Round 346 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0016

📊 Round 346 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0016

============================================================
🔄 Round 350 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0910, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0910, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0910, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0910, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0909, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0909, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 350 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0912, RMSE=0.3019, R²=0.0065
   Val:   Loss=0.0816, RMSE=0.2856, R²=0.0068
============================================================


📊 Round 350 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0016

============================================================
🔄 Round 352 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0945 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0945, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0945, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0945, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0945, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0945, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0945)

============================================================
📊 Round 352 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=0.0080
   Val:   Loss=0.0945, RMSE=0.3074, R²=0.0018
============================================================


📊 Round 352 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0016

============================================================
🔄 Round 353 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0900, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0900, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0900, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0900, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0900, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0900, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 353 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0899, RMSE=0.2999, R²=0.0065
   Val:   Loss=0.0865, RMSE=0.2942, R²=0.0154
============================================================


============================================================
🔄 Round 354 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0945 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0945, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0945, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0945, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0945, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0944, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0945)

============================================================
📊 Round 354 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2966, R²=0.0083
   Val:   Loss=0.0945, RMSE=0.3073, R²=0.0061
============================================================


📊 Round 354 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0016

📊 Round 354 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0016

============================================================
🔄 Round 357 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0896, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0896, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0896, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0896, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0896, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0896, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 357 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0896, RMSE=0.2993, R²=0.0095
   Val:   Loss=0.0878, RMSE=0.2964, R²=0.0058
============================================================


============================================================
🔄 Round 360 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0905, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0905, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0905, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0905, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0905, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0905, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 360 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0907, RMSE=0.3012, R²=0.0090
   Val:   Loss=0.0834, RMSE=0.2887, R²=0.0035
============================================================


📊 Round 360 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0016

============================================================
🔄 Round 363 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0897, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0897, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0897, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0897, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0897, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 363 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0895, RMSE=0.2991, R²=0.0076
   Val:   Loss=0.0883, RMSE=0.2972, R²=0.0115
============================================================


📊 Round 363 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0016

============================================================
🔄 Round 364 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0891, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0891, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0891, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0891, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0890, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 364 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2986, R²=0.0079
   Val:   Loss=0.0895, RMSE=0.2992, R²=-0.0024
============================================================


============================================================
🔄 Round 370 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0893, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0893, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0893, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0893, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0893, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 370 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2986, R²=0.0066
   Val:   Loss=0.0895, RMSE=0.2992, R²=0.0023
============================================================


📊 Round 370 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0016

============================================================
🔄 Round 371 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0909, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0909, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0909, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0909, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0909, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0909, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 371 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0909, RMSE=0.3015, R²=0.0100
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0030
============================================================


📊 Round 371 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0016

============================================================
🔄 Round 373 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.1023 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.1023, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.1023, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.1023, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.1023, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.1023, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1023)

============================================================
📊 Round 373 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=0.0070
   Val:   Loss=0.1023, RMSE=0.3199, R²=0.0140
============================================================


============================================================
🔄 Round 375 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0905, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0905, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0905, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0905, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0905, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0905, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 375 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0903, RMSE=0.3005, R²=0.0087
   Val:   Loss=0.0850, RMSE=0.2915, R²=0.0093
============================================================


📊 Round 375 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0016

📊 Round 375 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0016

============================================================
🔄 Round 377 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0914, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0914, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0914, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0914, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0914, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0914, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 377 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0914, RMSE=0.3023, R²=0.0081
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0112
============================================================


📊 Round 377 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0016

📊 Round 377 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0016

============================================================
🔄 Round 380 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0971 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0971, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0971, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0971, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0971, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0971, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0971)

============================================================
📊 Round 380 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2954, R²=0.0089
   Val:   Loss=0.0971, RMSE=0.3116, R²=-0.0010
============================================================


📊 Round 380 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0016

============================================================
🔄 Round 381 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0909, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0909, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0909, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0909, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0909, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0909, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 381 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0909, RMSE=0.3015, R²=0.0083
   Val:   Loss=0.0826, RMSE=0.2875, R²=0.0066
============================================================


============================================================
🔄 Round 382 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0906, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0906, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0906, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0906, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0906, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0906, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 382 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0905, RMSE=0.3008, R²=0.0081
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0053
============================================================


📊 Round 382 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0016

============================================================
🔄 Round 383 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0898, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0898, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0898, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0898, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0898, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0897, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 383 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0901, RMSE=0.3001, R²=0.0085
   Val:   Loss=0.0859, RMSE=0.2931, R²=0.0069
============================================================


📊 Round 383 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0016

============================================================
🔄 Round 386 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 386 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2982, R²=0.0099
   Val:   Loss=0.0905, RMSE=0.3009, R²=-0.0036
============================================================


📊 Round 386 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0016

============================================================
🔄 Round 390 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 390 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2974, R²=0.0092
   Val:   Loss=0.0925, RMSE=0.3041, R²=0.0073
============================================================


📊 Round 390 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0016

============================================================
🔄 Round 391 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0914, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0914, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0914, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0914, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0914, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0914, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 391 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0911, RMSE=0.3018, R²=0.0083
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0045
============================================================


📊 Round 391 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0016

============================================================
🔄 Round 394 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0922 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0922, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0922, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0922, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0922, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0922, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0922)

============================================================
📊 Round 394 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2975, R²=0.0094
   Val:   Loss=0.0922, RMSE=0.3037, R²=0.0062
============================================================


============================================================
🔄 Round 395 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0903, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0903, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0903, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0903, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0903, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0903, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 395 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0903, RMSE=0.3005, R²=0.0085
   Val:   Loss=0.0849, RMSE=0.2914, R²=0.0102
============================================================


📊 Round 395 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0016

============================================================
🔄 Round 397 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 397 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2978, R²=0.0098
   Val:   Loss=0.0915, RMSE=0.3025, R²=0.0006
============================================================


📊 Round 397 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0016

============================================================
🔄 Round 398 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0905, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0905, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0905, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0905, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0905, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0905, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 398 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0905, RMSE=0.3009, R²=0.0108
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0006
============================================================


============================================================
🔄 Round 400 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0900, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0900, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0900, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0900, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0900, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0900, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 400 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0898, RMSE=0.2997, R²=0.0088
   Val:   Loss=0.0870, RMSE=0.2950, R²=0.0068
============================================================


============================================================
🔄 Round 401 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0906, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0906, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0906, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0906, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0906, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0906, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 401 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0906, RMSE=0.3011, R²=0.0084
   Val:   Loss=0.0836, RMSE=0.2892, R²=0.0100
============================================================


📊 Round 401 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0017

📊 Round 401 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0017

📊 Round 401 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0017

📊 Round 401 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0016

============================================================
🔄 Round 409 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0893, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0893, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0893, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0893, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0893, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 409 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0893, RMSE=0.2988, R²=0.0087
   Val:   Loss=0.0891, RMSE=0.2985, R²=0.0093
============================================================


📊 Round 409 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0017

📊 Round 409 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0017

============================================================
🔄 Round 416 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0894, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0894, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0894, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0894, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0894, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0894, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 416 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2987, R²=0.0078
   Val:   Loss=0.0892, RMSE=0.2987, R²=0.0096
============================================================


============================================================
🔄 Round 417 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0913, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0913, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0913, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0913, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0913, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0913, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 417 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0912, RMSE=0.3020, R²=0.0102
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0028
============================================================


📊 Round 417 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2483, R²: 0.0017

============================================================
🔄 Round 420 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0891, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0891, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0891, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0891, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 420 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2986, R²=0.0073
   Val:   Loss=0.0895, RMSE=0.2992, R²=0.0029
============================================================


📊 Round 420 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2483, R²: 0.0017

📊 Round 420 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2483, R²: 0.0017

📊 Round 420 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2483, R²: 0.0017

📊 Round 420 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2483, R²: 0.0017

============================================================
🔄 Round 425 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0893, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0893, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0893, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0893, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0893, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 425 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0893, RMSE=0.2989, R²=0.0081
   Val:   Loss=0.0889, RMSE=0.2982, R²=0.0115
============================================================


============================================================
🔄 Round 426 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 426 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2980, R²=0.0082
   Val:   Loss=0.0909, RMSE=0.3016, R²=-0.0023
============================================================


============================================================
🔄 Round 427 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0942 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0942, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0942, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0942, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0942, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0942, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0942)

============================================================
📊 Round 427 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2967, R²=0.0085
   Val:   Loss=0.0942, RMSE=0.3069, R²=0.0096
============================================================


============================================================
🔄 Round 428 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0904, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0904, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0904, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0904, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0904, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0904, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 428 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0904, RMSE=0.3007, R²=0.0097
   Val:   Loss=0.0846, RMSE=0.2909, R²=0.0039
============================================================


📊 Round 428 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2483, R²: 0.0017

============================================================
🔄 Round 429 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0966 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0966, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0966, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0966, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0966, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0965, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0966)

============================================================
📊 Round 429 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2957, R²=0.0076
   Val:   Loss=0.0966, RMSE=0.3107, R²=0.0127
============================================================


📊 Round 429 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2483, R²: 0.0017

============================================================
🔄 Round 432 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0951 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0951, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0951, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0951, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0951, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0952, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0951)

============================================================
📊 Round 432 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=0.0088
   Val:   Loss=0.0951, RMSE=0.3084, R²=-0.0092
============================================================


📊 Round 432 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2483, R²: 0.0018

📊 Round 432 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2483, R²: 0.0018

📊 Round 432 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2483, R²: 0.0018

============================================================
🔄 Round 440 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 440 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2982, R²=0.0077
   Val:   Loss=0.0905, RMSE=0.3008, R²=0.0108
============================================================


📊 Round 440 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2483, R²: 0.0017

📊 Round 440 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2483, R²: 0.0017

============================================================
🔄 Round 443 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0951 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0951, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0951, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0951, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0951, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0951, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0951)

============================================================
📊 Round 443 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=0.0089
   Val:   Loss=0.0951, RMSE=0.3084, R²=0.0085
============================================================


============================================================
🔄 Round 444 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0897, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0897, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0897, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0896, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0896, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 444 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0897, RMSE=0.2995, R²=0.0104
   Val:   Loss=0.0875, RMSE=0.2958, R²=0.0022
============================================================


============================================================
🔄 Round 445 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 445 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2977, R²=0.0099
   Val:   Loss=0.0916, RMSE=0.3027, R²=0.0014
============================================================


📊 Round 445 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2483, R²: 0.0017

============================================================
🔄 Round 447 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0965 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0965, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0965, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0965, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0965, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0965, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0965)

============================================================
📊 Round 447 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2957, R²=0.0094
   Val:   Loss=0.0965, RMSE=0.3107, R²=0.0068
============================================================


📊 Round 447 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2483, R²: 0.0017

============================================================
🔄 Round 448 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0978 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0977, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0977, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0977, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0977, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0977, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0978)

============================================================
📊 Round 448 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2952, R²=0.0078
   Val:   Loss=0.0978, RMSE=0.3127, R²=0.0111
============================================================


📊 Round 448 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2483, R²: 0.0017

============================================================
🔄 Round 449 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0999 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0999, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0999, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0999, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0999, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0999, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0999)

============================================================
📊 Round 449 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=0.0086
   Val:   Loss=0.0999, RMSE=0.3161, R²=0.0090
============================================================


📊 Round 449 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2483, R²: 0.0017

============================================================
🔄 Round 451 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0901, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0901, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0901, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0901, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0901, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0901, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 451 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0899, RMSE=0.2998, R²=0.0098
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0006
============================================================


📊 Round 451 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2483, R²: 0.0017

============================================================
🔄 Round 453 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 453 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0891, RMSE=0.2985, R²=0.0076
   Val:   Loss=0.0899, RMSE=0.2998, R²=0.0127
============================================================


📊 Round 453 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2483, R²: 0.0017

============================================================
🔄 Round 455 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0926, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0926, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0926, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0926, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0926, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0926, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 455 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0927, RMSE=0.3044, R²=0.0091
   Val:   Loss=0.0755, RMSE=0.2748, R²=0.0062
============================================================


============================================================
🔄 Round 456 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0954 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0954, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0954, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0954, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0954, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0954, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0954)

============================================================
📊 Round 456 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2962, R²=0.0110
   Val:   Loss=0.0954, RMSE=0.3089, R²=-0.0010
============================================================


📊 Round 456 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2483, R²: 0.0017

📊 Round 456 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2483, R²: 0.0017

============================================================
🔄 Round 459 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0911, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0911, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0911, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0911, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0911, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0911, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 459 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0910, RMSE=0.3017, R²=0.0094
   Val:   Loss=0.0822, RMSE=0.2866, R²=0.0039
============================================================


📊 Round 459 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2483, R²: 0.0017

============================================================
🔄 Round 460 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0890, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 460 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2986, R²=0.0077
   Val:   Loss=0.0895, RMSE=0.2991, R²=0.0064
============================================================


============================================================
🔄 Round 461 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0933, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0933, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0933, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0933, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0933, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0933, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 461 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0934, RMSE=0.3055, R²=0.0087
   Val:   Loss=0.0728, RMSE=0.2697, R²=0.0079
============================================================


📊 Round 461 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2483, R²: 0.0017

============================================================
🔄 Round 463 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0962 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0962, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0962, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0962, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0962, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0963, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0962)

============================================================
📊 Round 463 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=0.0065
   Val:   Loss=0.0962, RMSE=0.3101, R²=-0.0063
============================================================


📊 Round 463 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2483, R²: 0.0017

📊 Round 463 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0017

============================================================
🔄 Round 470 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0891, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0891, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0891, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0891, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 470 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0891, RMSE=0.2986, R²=0.0074
   Val:   Loss=0.0897, RMSE=0.2995, R²=0.0137
============================================================


============================================================
🔄 Round 471 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0896, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0896, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0896, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0895, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0895, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0895, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 471 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0894, RMSE=0.2991, R²=0.0080
   Val:   Loss=0.0884, RMSE=0.2974, R²=0.0002
============================================================


📊 Round 471 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0017

============================================================
🔄 Round 472 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 472 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2979, R²=0.0083
   Val:   Loss=0.0913, RMSE=0.3022, R²=0.0087
============================================================


📊 Round 472 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0017

📊 Round 472 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0017

📊 Round 472 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0016

============================================================
🔄 Round 478 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0899, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0899, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0899, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0899, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0899, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0899, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 478 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0904, RMSE=0.3007, R²=0.0069
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0029
============================================================


📊 Round 478 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0016

============================================================
🔄 Round 479 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0961 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0961, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0961, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0961, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0961, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0961, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0961)

============================================================
📊 Round 479 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2959, R²=0.0087
   Val:   Loss=0.0961, RMSE=0.3100, R²=0.0054
============================================================


============================================================
🔄 Round 480 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 480 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2980, R²=0.0080
   Val:   Loss=0.0910, RMSE=0.3016, R²=0.0081
============================================================


📊 Round 480 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0017

============================================================
🔄 Round 481 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0912, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0912, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0912, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0912, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0912, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0911, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 481 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0912, RMSE=0.3021, R²=0.0094
   Val:   Loss=0.0812, RMSE=0.2850, R²=0.0026
============================================================


============================================================
🔄 Round 482 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0892, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 482 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0893, RMSE=0.2988, R²=0.0092
   Val:   Loss=0.0890, RMSE=0.2983, R²=-0.0045
============================================================


📊 Round 482 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2483, R²: 0.0017

============================================================
🔄 Round 484 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 484 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2977, R²=0.0094
   Val:   Loss=0.0918, RMSE=0.3030, R²=-0.0024
============================================================


============================================================
🔄 Round 485 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.1023 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.1023, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.1023, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.1023, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.1023, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.1023, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1023)

============================================================
📊 Round 485 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=0.0083
   Val:   Loss=0.1023, RMSE=0.3198, R²=0.0044
============================================================


============================================================
🔄 Round 487 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0961 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0961, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0961, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0961, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0961, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0961, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0961)

============================================================
📊 Round 487 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=0.0088
   Val:   Loss=0.0961, RMSE=0.3101, R²=0.0084
============================================================


📊 Round 487 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2483, R²: 0.0017

============================================================
🔄 Round 489 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0981 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0982, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0982, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0982, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0982, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0982, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0981)

============================================================
📊 Round 489 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=0.0073
   Val:   Loss=0.0981, RMSE=0.3133, R²=0.0124
============================================================


📊 Round 489 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2483, R²: 0.0017

📊 Round 489 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2483, R²: 0.0017

============================================================
🔄 Round 492 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0892, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 492 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0894, RMSE=0.2990, R²=0.0086
   Val:   Loss=0.0887, RMSE=0.2978, R²=0.0085
============================================================


============================================================
🔄 Round 494 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0953 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0953, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0953, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0953, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0953, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0953, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0953)

============================================================
📊 Round 494 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2962, R²=0.0056
   Val:   Loss=0.0953, RMSE=0.3086, R²=0.0125
============================================================


============================================================
🔄 Round 495 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0960 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0960, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0960, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0960, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0960, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0961, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0960)

============================================================
📊 Round 495 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2959, R²=0.0103
   Val:   Loss=0.0960, RMSE=0.3099, R²=-0.0093
============================================================


📊 Round 495 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0017

============================================================
🔄 Round 496 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0896, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0896, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0896, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0896, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0896, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0896, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 496 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0894, RMSE=0.2990, R²=0.0098
   Val:   Loss=0.0887, RMSE=0.2979, R²=-0.0040
============================================================


📊 Round 496 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2483, R²: 0.0017

📊 Round 496 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2483, R²: 0.0017

============================================================
🔄 Round 500 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0951 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0951, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0951, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0951, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0951, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0951, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0951)

============================================================
📊 Round 500 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=0.0081
   Val:   Loss=0.0951, RMSE=0.3083, R²=0.0084
============================================================


============================================================
🔄 Round 501 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0942 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0942, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0942, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0942, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0942, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0942, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0942)

============================================================
📊 Round 501 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2966, R²=0.0099
   Val:   Loss=0.0942, RMSE=0.3070, R²=0.0025
============================================================


📊 Round 501 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2483, R²: 0.0017

📊 Round 501 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2483, R²: 0.0017

============================================================
🔄 Round 504 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0988 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0988, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0988, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0988, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0988, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0988, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0988)

============================================================
📊 Round 504 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2947, R²=0.0112
   Val:   Loss=0.0988, RMSE=0.3143, R²=-0.0037
============================================================


============================================================
🔄 Round 505 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0902, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0902, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0902, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0902, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0902, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0901, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 505 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0899, RMSE=0.2998, R²=0.0103
   Val:   Loss=0.0867, RMSE=0.2945, R²=0.0018
============================================================


📊 Round 505 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2483, R²: 0.0017

============================================================
🔄 Round 506 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0897, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0897, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0897, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0897, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0897, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 506 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0898, RMSE=0.2997, R²=0.0082
   Val:   Loss=0.0870, RMSE=0.2950, R²=0.0097
============================================================


📊 Round 506 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2483, R²: 0.0017

📊 Round 506 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2483, R²: 0.0017

📊 Round 506 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2483, R²: 0.0017

============================================================
🔄 Round 509 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0904, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0904, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0904, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0904, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0904, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0904, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 509 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0904, RMSE=0.3007, R²=0.0100
   Val:   Loss=0.0845, RMSE=0.2908, R²=0.0028
============================================================


📊 Round 509 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2483, R²: 0.0017

============================================================
🔄 Round 512 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0959 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0959, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0959, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0959, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0959, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0959, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0959)

============================================================
📊 Round 512 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2959, R²=0.0090
   Val:   Loss=0.0959, RMSE=0.3097, R²=0.0077
============================================================


============================================================
🔄 Round 514 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0903, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0903, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0903, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0903, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0903, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0903, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 514 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0900, RMSE=0.3000, R²=0.0083
   Val:   Loss=0.0861, RMSE=0.2935, R²=0.0110
============================================================


============================================================
🔄 Round 516 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0890, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 516 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0890, RMSE=0.2983, R²=0.0099
   Val:   Loss=0.0904, RMSE=0.3006, R²=-0.0005
============================================================


============================================================
🔄 Round 517 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0949 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0949, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0949, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0949, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0949, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0949, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0949)

============================================================
📊 Round 517 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2964, R²=0.0092
   Val:   Loss=0.0949, RMSE=0.3080, R²=0.0073
============================================================


📊 Round 517 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2483, R²: 0.0018

📊 Round 517 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2483, R²: 0.0018

============================================================
🔄 Round 519 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0896, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0896, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0896, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0896, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0896, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0895, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 519 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0896, RMSE=0.2993, R²=0.0089
   Val:   Loss=0.0879, RMSE=0.2965, R²=0.0064
============================================================


📊 Round 519 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2483, R²: 0.0017

============================================================
🔄 Round 521 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0949 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0949, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0949, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0949, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0949, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0949, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0949)

============================================================
📊 Round 521 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=0.0088
   Val:   Loss=0.0949, RMSE=0.3081, R²=0.0070
============================================================


============================================================
🔄 Round 522 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0902, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0902, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0902, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0902, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0902, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0902, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 522 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0907, RMSE=0.3011, R²=0.0092
   Val:   Loss=0.0835, RMSE=0.2890, R²=0.0053
============================================================


📊 Round 522 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2483, R²: 0.0017

============================================================
🔄 Round 525 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0894, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0894, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0894, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0894, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0893, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0893, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 525 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0893, RMSE=0.2989, R²=0.0079
   Val:   Loss=0.0889, RMSE=0.2982, R²=0.0121
============================================================


📊 Round 525 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2483, R²: 0.0017

============================================================
🔄 Round 526 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0942 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0942, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0942, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0942, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0942, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0942, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0942)

============================================================
📊 Round 526 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2967, R²=0.0093
   Val:   Loss=0.0942, RMSE=0.3069, R²=0.0056
============================================================


============================================================
🔄 Round 527 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0912, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0912, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0912, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0912, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0912, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0911, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 527 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0914, RMSE=0.3023, R²=0.0094
   Val:   Loss=0.0806, RMSE=0.2838, R²=0.0045
============================================================


📊 Round 527 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2483, R²: 0.0017

📊 Round 527 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2483, R²: 0.0017

📊 Round 527 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2483, R²: 0.0017

📊 Round 527 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2483, R²: 0.0017

📊 Round 527 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2483, R²: 0.0017

============================================================
🔄 Round 535 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0980 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0980, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0980, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0980, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0980, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0981, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0980)

============================================================
📊 Round 535 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2950, R²=0.0085
   Val:   Loss=0.0980, RMSE=0.3131, R²=0.0063
============================================================


============================================================
🔄 Round 536 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0891, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0891, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0891, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0891, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 536 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0890, RMSE=0.2983, R²=0.0086
   Val:   Loss=0.0904, RMSE=0.3007, R²=0.0078
============================================================


============================================================
🔄 Round 537 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0899, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0899, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0899, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0899, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0899, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0899, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 537 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0898, RMSE=0.2997, R²=0.0100
   Val:   Loss=0.0869, RMSE=0.2949, R²=0.0039
============================================================


📊 Round 537 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2483, R²: 0.0017

============================================================
🔄 Round 539 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0904, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0904, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0904, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0904, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0904, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0904, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 539 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0904, RMSE=0.3007, R²=0.0069
   Val:   Loss=0.0845, RMSE=0.2906, R²=0.0116
============================================================


============================================================
🔄 Round 540 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0938 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0938, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0938, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0938, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0938, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0939, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0938)

============================================================
📊 Round 540 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2968, R²=0.0078
   Val:   Loss=0.0938, RMSE=0.3063, R²=0.0020
============================================================


📊 Round 540 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2483, R²: 0.0017

============================================================
🔄 Round 548 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0905, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0905, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0905, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0905, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0905, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0904, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 548 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0906, RMSE=0.3010, R²=0.0070
   Val:   Loss=0.0839, RMSE=0.2896, R²=0.0153
============================================================


📊 Round 548 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2483, R²: 0.0017

============================================================
🔄 Round 551 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 551 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2982, R²=0.0084
   Val:   Loss=0.0905, RMSE=0.3008, R²=0.0080
============================================================


============================================================
🔄 Round 552 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0930 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0930, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0930, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0930, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0930, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0929, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0930)

============================================================
📊 Round 552 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2972, R²=0.0081
   Val:   Loss=0.0930, RMSE=0.3049, R²=0.0116
============================================================


============================================================
🔄 Round 553 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0899, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0899, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0899, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0899, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0899, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0899, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 553 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0898, RMSE=0.2997, R²=0.0078
   Val:   Loss=0.0869, RMSE=0.2948, R²=0.0078
============================================================


============================================================
🔄 Round 554 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0907, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0907, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0907, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0907, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0907, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0907, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 554 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0909, RMSE=0.3016, R²=0.0075
   Val:   Loss=0.0824, RMSE=0.2871, R²=0.0144
============================================================


============================================================
🔄 Round 555 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0987 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0987, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0987, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0987, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0987, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0987, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0987)

============================================================
📊 Round 555 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=0.0068
   Val:   Loss=0.0987, RMSE=0.3141, R²=-0.0019
============================================================


📊 Round 555 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2483, R²: 0.0017

============================================================
🔄 Round 557 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0905, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0905, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0905, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0905, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0905, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0905, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 557 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0908, RMSE=0.3013, R²=0.0093
   Val:   Loss=0.0831, RMSE=0.2883, R²=0.0069
============================================================


📊 Round 557 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2483, R²: 0.0017

============================================================
🔄 Round 558 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0896, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0896, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0896, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0896, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0896, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0895, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 558 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0896, RMSE=0.2994, R²=0.0058
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0058
============================================================


============================================================
🔄 Round 563 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 563 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0890, RMSE=0.2983, R²=0.0098
   Val:   Loss=0.0903, RMSE=0.3005, R²=0.0030
============================================================


📊 Round 563 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2483, R²: 0.0018

📊 Round 563 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2483, R²: 0.0017

============================================================
🔄 Round 570 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 570 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2981, R²=0.0092
   Val:   Loss=0.0908, RMSE=0.3014, R²=-0.0041
============================================================


============================================================
🔄 Round 571 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0960 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0960, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0960, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0960, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0960, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0961, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0960)

============================================================
📊 Round 571 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2959, R²=0.0073
   Val:   Loss=0.0960, RMSE=0.3099, R²=0.0014
============================================================


📊 Round 571 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2483, R²: 0.0017

============================================================
🔄 Round 572 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0900, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0900, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0900, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0900, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0900, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0899, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 572 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0901, RMSE=0.3002, R²=0.0097
   Val:   Loss=0.0856, RMSE=0.2926, R²=0.0034
============================================================


📊 Round 572 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2483, R²: 0.0017

============================================================
🔄 Round 578 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0906, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0906, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0906, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0906, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0906, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0906, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 578 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0907, RMSE=0.3011, R²=0.0078
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0131
============================================================


============================================================
🔄 Round 579 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0964 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0964, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0964, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0964, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0964, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0964, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0964)

============================================================
📊 Round 579 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2957, R²=0.0086
   Val:   Loss=0.0964, RMSE=0.3105, R²=0.0090
============================================================


============================================================
🔄 Round 581 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0905, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0904, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0904, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0904, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0904, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0904, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 581 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0904, RMSE=0.3006, R²=0.0081
   Val:   Loss=0.0847, RMSE=0.2911, R²=0.0120
============================================================


📊 Round 581 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2483, R²: 0.0018

============================================================
🔄 Round 582 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0943 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0943, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0943, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0943, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0943, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0943, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0943)

============================================================
📊 Round 582 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2966, R²=0.0090
   Val:   Loss=0.0943, RMSE=0.3070, R²=-0.0127
============================================================


📊 Round 582 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2483, R²: 0.0018

============================================================
🔄 Round 583 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 583 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2976, R²=0.0103
   Val:   Loss=0.0920, RMSE=0.3033, R²=0.0030
============================================================


============================================================
🔄 Round 585 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0899, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0899, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0899, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0899, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0899, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0899, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 585 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0902, RMSE=0.3004, R²=0.0103
   Val:   Loss=0.0852, RMSE=0.2920, R²=0.0027
============================================================


📊 Round 585 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2483, R²: 0.0017

📊 Round 585 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2483, R²: 0.0017

============================================================
🔄 Round 588 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0893, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0893, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0893, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0893, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0893, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 588 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0894, RMSE=0.2990, R²=0.0092
   Val:   Loss=0.0886, RMSE=0.2977, R²=0.0070
============================================================


============================================================
🔄 Round 590 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0910, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0910, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0910, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0909, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0909, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0909, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 590 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0913, RMSE=0.3021, R²=0.0088
   Val:   Loss=0.0811, RMSE=0.2849, R²=0.0056
============================================================


📊 Round 590 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2483, R²: 0.0017

📊 Round 590 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2483, R²: 0.0017

============================================================
🔄 Round 597 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0903, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0903, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0903, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0903, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0903, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0903, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 597 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0902, RMSE=0.3003, R²=0.0086
   Val:   Loss=0.0855, RMSE=0.2924, R²=0.0093
============================================================


📊 Round 597 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2483, R²: 0.0017

📊 Round 597 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2483, R²: 0.0017

============================================================
🔄 Round 601 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0895, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0895, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0895, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0895, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0895, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0895, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 601 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0897, RMSE=0.2995, R²=0.0082
   Val:   Loss=0.0875, RMSE=0.2958, R²=0.0115
============================================================


📊 Round 601 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2483, R²: 0.0017

📊 Round 601 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2483, R²: 0.0017

============================================================
🔄 Round 605 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0933 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0933, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0933, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0933, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0933, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0933, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0933)

============================================================
📊 Round 605 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=0.0086
   Val:   Loss=0.0933, RMSE=0.3054, R²=0.0096
============================================================


📊 Round 605 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2483, R²: 0.0017

============================================================
🔄 Round 606 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0899, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0899, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0899, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0899, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0899, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0898, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 606 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0899, RMSE=0.2999, R²=0.0086
   Val:   Loss=0.0865, RMSE=0.2940, R²=0.0097
============================================================


============================================================
🔄 Round 608 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0893, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0893, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0893, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0893, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0893, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 608 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0891, RMSE=0.2985, R²=0.0081
   Val:   Loss=0.0898, RMSE=0.2996, R²=-0.0110
============================================================


📊 Round 608 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2483, R²: 0.0017

📊 Round 608 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2483, R²: 0.0017

📊 Round 608 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2483, R²: 0.0017

============================================================
🔄 Round 617 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0890, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 617 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0890, RMSE=0.2984, R²=0.0072
   Val:   Loss=0.0901, RMSE=0.3002, R²=0.0056
============================================================


============================================================
🔄 Round 618 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0951 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0952, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0952, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0952, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0952, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0953, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0951)

============================================================
📊 Round 618 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=0.0079
   Val:   Loss=0.0951, RMSE=0.3085, R²=-0.0161
============================================================


============================================================
🔄 Round 619 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0898, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0898, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0898, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0898, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0898, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0897, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 619 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0899, RMSE=0.2998, R²=0.0064
   Val:   Loss=0.0868, RMSE=0.2945, R²=-0.0050
============================================================


📊 Round 619 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0016

📊 Round 619 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0016

============================================================
🔄 Round 624 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0904, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0904, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0904, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0904, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0904, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0904, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 624 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0900, RMSE=0.3000, R²=0.0087
   Val:   Loss=0.0861, RMSE=0.2935, R²=0.0066
============================================================


============================================================
🔄 Round 625 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0945 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0945, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0945, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0945, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0945, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0945, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0945)

============================================================
📊 Round 625 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2966, R²=0.0105
   Val:   Loss=0.0945, RMSE=0.3074, R²=-0.0137
============================================================


============================================================
🔄 Round 626 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0895, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0895, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0895, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0895, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0895, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0895, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 626 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0898, RMSE=0.2996, R²=0.0081
   Val:   Loss=0.0871, RMSE=0.2951, R²=0.0116
============================================================


📊 Round 626 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0016

📊 Round 626 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0016

============================================================
🔄 Round 629 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 629 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2979, R²=0.0083
   Val:   Loss=0.0913, RMSE=0.3021, R²=0.0051
============================================================


📊 Round 629 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2484, R²: 0.0016

📊 Round 629 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2484, R²: 0.0016

📊 Round 629 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2484, R²: 0.0016

============================================================
🔄 Round 633 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0903, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0903, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0903, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0903, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0903, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0903, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 633 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0904, RMSE=0.3006, R²=0.0071
   Val:   Loss=0.0847, RMSE=0.2910, R²=0.0110
============================================================


📊 Round 633 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2484, R²: 0.0016

============================================================
🔄 Round 636 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0893, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0893, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0893, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0893, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0893, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 636 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2987, R²=0.0076
   Val:   Loss=0.0893, RMSE=0.2988, R²=0.0084
============================================================


📊 Round 636 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0016

============================================================
🔄 Round 638 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0935 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0935, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0935, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0935, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0935, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0936, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0935)

============================================================
📊 Round 638 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=0.0105
   Val:   Loss=0.0935, RMSE=0.3058, R²=-0.0091
============================================================


============================================================
🔄 Round 640 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0893, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0893, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0893, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0893, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0893, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 640 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2987, R²=0.0085
   Val:   Loss=0.0893, RMSE=0.2988, R²=0.0093
============================================================


============================================================
🔄 Round 641 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0999 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0999, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0999, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0999, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0999, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0999, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0999)

============================================================
📊 Round 641 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=0.0091
   Val:   Loss=0.0999, RMSE=0.3161, R²=-0.0090
============================================================


============================================================
🔄 Round 643 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0901, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0901, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0901, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0901, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0901, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0901, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 643 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0901, RMSE=0.3002, R²=0.0076
   Val:   Loss=0.0857, RMSE=0.2927, R²=0.0104
============================================================


📊 Round 643 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0016

============================================================
🔄 Round 644 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0924 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 644 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2974, R²=0.0093
   Val:   Loss=0.0924, RMSE=0.3040, R²=0.0028
============================================================


📊 Round 644 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0016

📊 Round 644 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2483, R²: 0.0017

============================================================
🔄 Round 646 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0933 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0933, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0933, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0933, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0933, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0933, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0933)

============================================================
📊 Round 646 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2971, R²=0.0091
   Val:   Loss=0.0933, RMSE=0.3054, R²=0.0068
============================================================


📊 Round 646 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0016

============================================================
🔄 Round 649 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0908, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0908, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0908, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0908, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0908, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0908, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 649 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0907, RMSE=0.3012, R²=0.0098
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0072
============================================================


📊 Round 649 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0016

============================================================
🔄 Round 650 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 650 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2976, R²=0.0100
   Val:   Loss=0.0920, RMSE=0.3032, R²=0.0040
============================================================


📊 Round 650 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0016

📊 Round 650 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0016

📊 Round 650 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0016

📊 Round 650 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0016

📊 Round 650 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2484, R²: 0.0016

============================================================
🔄 Round 657 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0890, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 657 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0891, RMSE=0.2985, R²=0.0086
   Val:   Loss=0.0899, RMSE=0.2998, R²=0.0096
============================================================


============================================================
🔄 Round 658 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 658 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2979, R²=0.0062
   Val:   Loss=0.0912, RMSE=0.3020, R²=0.0014
============================================================


📊 Round 658 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2483, R²: 0.0017

============================================================
🔄 Round 659 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 659 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2978, R²=0.0095
   Val:   Loss=0.0914, RMSE=0.3024, R²=0.0061
============================================================


📊 Round 659 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2483, R²: 0.0017

============================================================
🔄 Round 661 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0904, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0904, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0904, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0904, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0904, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0904, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 661 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0904, RMSE=0.3006, R²=0.0077
   Val:   Loss=0.0847, RMSE=0.2911, R²=0.0134
============================================================


📊 Round 661 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2483, R²: 0.0017

============================================================
🔄 Round 662 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0896, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0896, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0896, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0896, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0896, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0896, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 662 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2987, R²=0.0082
   Val:   Loss=0.0894, RMSE=0.2990, R²=0.0112
============================================================


📊 Round 662 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2483, R²: 0.0017

❌ Client client_24 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8690 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8690 {grpc_message:"Socket closed", grpc_status:14}"
>
