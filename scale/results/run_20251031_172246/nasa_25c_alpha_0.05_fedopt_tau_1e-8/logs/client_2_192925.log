[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb131eed-0d00-435a-8ff2-6c62fafe09cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d44a88bc-d42e-4de4-9c2f-4cb623f494c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0330c826-4420-4c89-a5de-e6dfb8c6ee35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1a8b4e7-2b24-44e1-a883-3ba0721578d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3f8b7ad-744b-421c-9e49-07ecc067582b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f3ae72d-3d9e-48a6-98a6-558551f32fbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 034b7c75-c162-4d3a-a741-49d5a7c43ff9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6bf7f10-848e-4349-a0f2-2e94c797bd4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af42a883-de51-4738-978c-a6a69d5903a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ac6ce9e-1b64-4edb-ade7-99fdd928bf9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fceac977-1599-4a06-8be3-dd6cbdd00836
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3cffd54-af65-42fb-abed-3daece6d70ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0860fe8a-1662-4842-af6b-8649725c2d90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62f2a8ac-6cf8-453f-86f0-8883c1f572cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e68a102-6450-4a44-a616-1acda9bb29eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ce13211-33d0-47a6-a325-f5a69cc99ea3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05667562-524a-41b5-a065-206311fa4d6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85faed9b-8d3f-4537-80bd-62c5a11ea2ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2997fad-b84c-480a-a273-e0368c0dd0d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4dcb31cd-d087-4bcb-a0ba-3f7f724f5530
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f29ab4fb-c165-4689-a543-2251b85d0c5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 367c111e-45f8-47be-80b8-86cac3d422a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6143b4b-ff50-4124-a149-1ed063c54a7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb60df4c-f222-491c-8760-02f63370196b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4119d196-5a19-4e9b-b0b9-5648d3e23cf2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2e1baff-1c7a-4bdc-a2c7-32a09106506b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42d9f810-b849-41a5-b826-a65b00611b4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cdd0d3e5-5955-469f-bfe9-cacdb142baab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7bc02aa6-5dac-4a5e-ad74-fb7c21cb0510
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7eb6920e-bdc5-4f3b-a748-3b42bc02234b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4cea4221-102f-44f6-b6ee-f08cf3eaf673
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46bc7bd8-3e95-4641-8e66-b384139db7f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04c931df-c5e7-47ba-9ef2-63fb79d6f53c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca044e5e-d6c4-4234-8c64-0168230cfaf5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91540ccb-737f-45df-9fae-73054349dea2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c40dc2d-cd56-480a-9418-9082406cac42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d20892f-3dd4-44f8-bcce-e2893719ebe9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d50c34f-a49f-46b3-bc9e-60f086580a72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3bf5917b-e09b-4701-851f-912bacf9472d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 242ae593-4cb2-4f1e-b470-2cc8136f443f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5cf11044-37cf-4412-ad29-738e545f272c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec9f0fab-f598-4881-aba8-a2d94da41021
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0b2a3d3-549f-402e-b24b-46e2ce54e171
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 198aa4d5-048c-40d8-a64d-252160dd9756
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2b17841-1262-4476-be61-b006a7824691
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de0162f4-4c45-4a40-8daf-80566c4b49c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ecf29aba-896a-4e55-86d2-fd461a77c860
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a24e8b0e-fa24-4876-9484-e72b06874dc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8872c219-c19d-4d46-9882-54f937903619
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ccd7d0f-fc28-4f17-8017-9f9d97e2f52c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf93c97e-f5cd-44db-939b-1d5bc8e4b8ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b9c47ee-38bd-40d3-a346-a3ead09321de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3fda8b9-efe6-4f29-bf37-f264c65933f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4abd5321-a259-4adb-8338-1837de58a62b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 289c37ab-4fd7-4161-b5d0-3250ad30374f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d08cf6f3-b4ef-4f08-b191-01fe7ddb82b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f79cd9c9-d4b6-4182-b796-42a3beaf6943
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8528ced-1b53-4e54-9ac7-4ff5cc885660
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf4997d2-15ae-46e2-9307-5777d419daec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7dcf4b61-f0e6-4963-a907-e9b7e4fedb2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c387fe9-584a-4bfc-a23c-5602f8d3fb83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4990a393-3770-45b0-8b50-53e7d31f996e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94337677-4397-4c8e-81d5-ea7e0bb77ea5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a178aba-76f0-417a-a6dc-4aa3ead6ffa8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7349e1c6-350e-4a83-93e0-837233dfb4d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0e8b23c-15db-427a-b22c-b4f521cba667
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ce60a73-bf0e-4719-b79c-3c8f05e09876
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0422bc26-d390-4496-98b8-5a97113fa138
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef867b05-71ce-438f-b502-94b37022ead0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c290257c-3a0c-479f-8429-ebf757991e53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc9ded8f-3242-4a9c-b759-16d4fe9e5877
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f32d8bc9-4620-4276-a226-0907f2dc182e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6addebfd-bda9-4107-b3fa-2d8a197806e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 100021d9-09b9-4eb6-b032-b91c2490ffc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6623ca43-50d4-4cf4-bb68-39a28ee9f8b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0fbb2d5-26e0-4603-87d7-a84fba837f2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c0e17ab-247c-4518-9df6-32862c1c7a2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 896accdc-1929-46fb-8648-08e028887714
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe09e4a0-4cf6-49a7-b4f7-758dd43ebd26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfc2151a-2a6d-4ab0-92ea-c8a6cf23a77f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25bbd614-819c-426a-8ac4-6c1d6bdb5ecc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4de40fa7-0ddc-4c91-88c4-5b9124137e61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99ff4dd6-1a60-4b0b-a710-ec3b0c9472c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 484d47c6-f21f-494d-86b8-6550370cf525
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b941a4c1-6de7-48c5-9e2c-67be0210432e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 258f571f-11bd-4036-8641-bfeb847ef09b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5674406-8eed-4826-86eb-ca877324df14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96febf37-ec01-4a52-a564-7482389cfda2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09a46c6d-3e83-4a8f-b91c-024bfc11fb20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9983b330-dac1-40d9-963d-0caf5dda4548
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cad48cd9-56ef-4d44-bae8-7fc6ff98439c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39605b7a-b4ea-43bb-89b3-95cdae6667ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4afbc992-d645-4c29-810f-5ef9660b4855
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2da67eb7-d937-434d-a308-e08e20ffb810
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5732949-7ff0-4b0d-a6a0-95e8fdf6f2ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e293ecc-38e0-4533-af73-40f19213080d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94e0b689-e343-45db-b41d-3a2287d6a4f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9f9c18f-4f6c-4cfd-bbf0-30df61420a2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e52f3ce-1f61-4767-bd3e-4257ef575a9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cde91998-2cbc-4ef4-a9e1-f79315820e25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31a57381-14f2-4257-ad36-22043583d34c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4ae35d0-9f14-45ab-b85f-1bc7fe775bfc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5bb8f84-0c9d-4551-bfc2-2cb5f6278845
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da1bae0d-e562-4889-9b5d-a11af9c9ef33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a995c505-89ef-4a0b-a8af-6750ca125691
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0abc079-6388-4c3b-a03a-45382b9af90d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc2a84df-c790-4b40-b847-dc3f7f4c6a32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36e941a0-2b1b-46e8-8259-94aa1ccc5658
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e03a9f1-550c-4ae4-8ebd-e62b525ccf21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd1c3373-d822-4eb7-8722-cd1b1b9b8de1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df8f4828-fa62-418b-aff1-d6d79b7c846b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b81d0f5-9f83-497b-b8fd-d1c03b9834ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40d91511-aaa0-4765-8f18-e8c6e417a4bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 005e1b5c-4590-4c6f-87db-baee05abfaa5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d082a097-5b4e-4222-aeaf-664fc2498226
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b690562-6170-4cc2-a26e-a724837e6e0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ebc69e1c-72f1-4a1f-b037-223869f24f92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9293c8a1-bebb-457a-9dc5-b1878d2c2719
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3861145c-ce75-4199-b594-a8f6882d516e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 405fc08b-5d39-428e-9c16-122d830048ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b36ae04-8b5f-4d00-aa96-9eefe5e85509
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a58e36de-2c0c-4fb4-a472-39e2a531a6e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74c667bc-0c03-43cc-8d06-de79c0706871
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd232c6a-289f-47cf-b111-42ceec131b38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0615f94-7837-4499-889c-1167cbcda02f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1c5896b-c4bb-42df-aee5-014b484c55e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5e93627-8f37-4111-a006-e60930184969
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3e2c983-d9dd-47d5-a5a0-2534763a77b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e754fde-8f2a-43f5-8754-94f7ff324bcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0596c112-f88d-4e13-86ad-ae158eca8510
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d7295fe-7d97-4368-b4da-fd3a86686650
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 618880fc-2518-4704-a801-c96df00e9170
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43b88168-d438-415f-ae71-01c01ef8150b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 397283e8-9de0-47f9-af9a-10a205bcb103
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5494a4da-8ad3-420d-b8d1-1b52f3f2dd8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea102d44-15b9-4789-849c-9ff851553fbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98e5ae84-a4de-4896-9ffb-704ecf4d03c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d50f8c8-2db0-4a95-ab77-e505414d4fb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f264d720-1409-415f-87a3-16576d3f93e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 850463e1-8fbc-4db5-8009-d18deabe94e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7829e709-7c70-4b31-b285-303dd7b4bb27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a71f7c28-408b-4c8f-a299-bea84e92315d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5f431b9-1693-4f6a-8d25-ac81271da905
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48b3ec35-74ca-4fa7-9542-1dbdca0c516e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e409c7c7-9c9c-4551-a650-ad7bd7de5198
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfdfac6b-923d-42db-89e3-a1162c8a3c81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3ca904f-6f32-44c7-8bea-b347bb88f7c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2728783-13cd-44da-9a19-c17c43c8fe32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0244108e-4a26-4525-b14c-c2df0c7ee6b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6112d4f9-5b78-4eb6-bd37-1af735f9d148
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34017a97-ff2a-4847-bdd9-69029396a6f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1c735c9-c81e-4656-ab83-129092337a31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c51ccef-8dde-4f4f-9d99-a3001291bbda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f9790b1-b41a-4b6a-a0b9-116397957187
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b8427bd-de10-4c18-840e-b79151c4ad46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53aebe0b-7ec4-4527-8cfe-e5619dadcf32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 721a2ce0-78a7-41a7-bffe-899f359ca46c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b3b5c16-2a1f-4242-b417-ba8841d2174e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0aef210e-f20a-40b7-8673-0a99a07eaffc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89ebd62c-0e0e-4e2c-9bf6-ed3b3df4cbb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06076d03-1023-4664-8cdb-1481c37d4904
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb7978dd-5ebf-4cce-aaf3-1cf1a6e7b174
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 774e9bd2-40dc-42fc-942f-843f7f6ccb73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0cd0765-7fbe-4e1a-b1ed-132919e33929
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0099d09-8367-406c-b374-4982eea77ae7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fcfa0616-cc31-4076-bbbb-be03bfa9a769
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92c3e21e-ef60-4dd3-bddf-0995d6ad879c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 962f1555-8d39-4d0e-a207-035f2b719626
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa0f267a-4f9e-452f-bce6-eaee0304f059
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 319be85a-dbb9-4303-b497-38f1aa52257e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e90b3802-9f4d-41a8-92bd-14b97ec26dd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4b76763-9553-408d-8c84-4ba5076384a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d4eade2-34b8-4533-997f-6e41077b95b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58fc45fc-375c-4534-bc9e-8f46a72d0a3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14b33f5e-b288-4532-b310-c51743e80824
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc96b06d-5078-42a3-9105-76fe388a2676
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d62b02c-84e7-4cf7-a39f-c766e52c3fd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d980420b-c03c-4c8b-baab-a87255d0a160
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d84a9b8-86df-4cfc-acba-d886032f62c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 913b580e-5c7d-43ab-a36a-45ad14315867
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96771ad8-93cf-4251-8020-56120e9f0268
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a19fa2f-2360-4335-90ae-aa5a06f63988
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56d1903f-8767-4a18-95c0-9f0b48ea1ff7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad9af4aa-215b-4772-a398-1d0103bf25f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b72350d5-0c83-4978-81de-6043400cdc61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cdcea980-b8dc-491f-bda4-5e7ebf904cb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef741888-0d4a-47d5-9042-8c1d7454c4b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78e9ae7c-b7f9-4067-b338-8efdb2012fff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0044d6e-05a4-4010-a0d2-8346254d88f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05872e6a-b636-4e3d-bf1d-15a253ee8571
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9be74c3c-542a-4a80-88e7-f8478be56538
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 456cfb1a-c49c-40cf-ac5f-04a1598c70ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ead1956-455f-491f-8505-87b45aed314d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f3bdc41-c551-4415-b7bc-66132465c5c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0336cabf-16c5-47da-9f8c-cb3cbf920273
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9b3c141-79cf-4f89-9b64-550c3132512a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d8df2e7-3781-439c-8c71-d6bee42dd4ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e063560-0d6e-4037-ba30-c8d3bf2dd93a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1ad7990-bd1e-494a-a757-2d6854805e47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ee77cab-4d3b-4817-b2c9-69db42831938
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c681a358-63f0-4ba7-abb6-020b84de0885
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43969d1c-8cc7-40a0-9579-18b095be0022
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 961fb3e0-6bac-4aac-a251-b184ad39e176
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac77b791-d8e0-448e-986d-a5993943c28d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18602aa4-19ad-4413-a6fd-ab382db67d0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f2c19a0-6eaf-4dfb-bc02-b38816d35599
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f49eec17-1f4f-417f-b6ba-4c73cf0dcdfe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ed0368a-3c94-4b54-8cad-87cf9b5f8d9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7da9415e-f8c1-460f-9e31-4e3833282c34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e45e8d2-b0d6-421c-a663-56313f451bf7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7f9bbea-c1a3-4d68-8272-3f81e9339979
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49256ddc-ee8b-42ca-80ed-4cc3321f8343
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3084b09a-94df-4e95-a2ca-78885fa64e5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d08ea72-4350-4a59-b56f-b6b2230262fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d13275cb-55fc-40ec-96cc-7864474f08db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b88cf3b7-0cdd-473d-a801-c882b346ad34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43520a10-9cc7-461e-a412-95320096b800
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3299ce9a-69ba-45fa-a2c0-1cd48166c555
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 272bdead-1d37-4608-be4b-efea986af3b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04744906-144c-481a-9d62-0fc1374fbb70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9cbec4e3-d4a2-459a-b104-ef3a1662c228
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cff00f76-7773-4aaf-b7c1-c79f53a38eb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f8e8d2d-e622-4256-81b7-7ad0b0418696
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00b271d5-45a7-436f-a31f-8bb0a17ee448
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f1ddedc-ad04-4df0-90f8-85d5b41bd823
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51d4eeda-20b0-4fea-8501-84ac5093c2d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b6cbb01-1aeb-4960-9658-1b7b2363b750
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b12b944-be98-471d-b3bb-9bf8d5a2cf96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21d1c6aa-5278-44f6-a421-3027ae531853
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e22fb4c3-138c-468a-bad6-a20ed2cafc89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 665d9689-4b5b-4b3e-b2de-666ba5a8e437
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b80b1686-194e-42b8-9204-1323266e756b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 809e6572-eaca-44c2-b12b-19502b43bdee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7067014c-8f77-4e87-ab10-ce2d3b23555d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27c1df2d-424f-4f70-9812-7643d434a077
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0eb7924a-88a2-4ba3-b339-f28063cccafa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1f19e2e-442d-40ee-a63e-fddc9906ffb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b45bb3e-35f8-4d66-9af8-50056450b91e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0717c47c-a16e-4a45-9bcb-5c94a2ce6258
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c82d69a-ede8-437f-8ead-5962fdfdacea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 815fa819-8693-47d3-906c-eb2d86ee1584
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d9487c5-e5a5-4874-b8fe-4e9d275c66be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a03b4da3-076b-4b88-9f44-d11a3a418a08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e1335a3-360c-445f-98c0-f9367d53707b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de5fbd22-8909-485d-a3b9-005728dc4727
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64d58d8e-cd0b-49f8-a73e-9b7550efa855
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77755ffd-15bd-4f1b-b929-23dc50507723
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 672a123c-6f3f-4e8f-9a07-dad6640b2b77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9badb2b0-5cc2-4a8c-9702-9b531ed33d3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98a45196-8480-490c-9fd9-3667b68f943d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95c70e44-1a06-41d4-acfe-d9a418a01030
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8145252e-26d5-4833-a6f2-3afa0f7d4c1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67b667d6-b092-4824-b8e4-10c0b01c2bbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 514010c9-c646-4543-8f2d-d5882f015204
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2182d5f-1034-41de-87bf-cc8839a0108d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b6bdd5c-68b6-48d0-b4e2-a3405f080f48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3059b155-8c5d-4961-bf10-e2285f0837ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95153bef-3403-4d98-b16d-ccccb5e12bd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af97aff5-f5a2-4610-b673-d4a18262bc6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f274db8-6671-4799-97af-aa4508cda87e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82dcea34-a3d3-4e53-ab40-736a9f0ff41d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b323003e-bc2c-4aae-9d78-01f8d3a64ef7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ceff081-0368-4afd-afd2-5b4b2832f4fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ef93a33-8e32-4d48-a071-7950541dbbe7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca894695-3cdd-44e0-9c36-08a7b0238322
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 972b05fc-a3a6-48e4-9f36-f2c67e491a79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2d7d221-5258-4ab4-9448-f29888f6913e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62918302-0ed6-4bc0-88c8-be6caa89183f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d71b249f-65ef-4a1d-a9af-80315ad06d83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41bf7a27-e20d-4faf-b327-524558aa6fb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68b00683-fd7c-4291-9ffe-d9a34ce2307a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da7d92d9-fdea-46ef-92c9-47638d402480
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0ff8d6f-84c6-45b0-9fa0-50441648c61c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d8501a1-ef22-4e69-86d2-e793134c34d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7bbb1d1-2f86-4599-b6fa-2039c050fd27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20180338-d7d5-4295-a742-c7194f267ff4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ef9c22a-18d1-467b-9b6f-55bc2251d30d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 751be70b-0a44-48eb-9dfe-5817e6dfba21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8cf1e501-8e61-4686-8f45-0c4ff1bb1855
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6bb9989e-1769-4073-bfff-f2062ba7bfc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33173307-e105-4140-a309-44165ced2857
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6bcfffc2-0e52-4047-81f6-d1995b1fe2d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1be23823-709e-4070-9f16-de4ed39accb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d52676f-8022-4255-81f2-3678a0fcdf31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 994a8b75-a899-4f90-be12-80a6c38f0964
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee298e1c-0479-4217-9cad-b96038e05212
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ecd44490-ba5d-43ff-88aa-a4944a4ae6da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05631415-d87d-4ba5-aac7-b2f5383a4912
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f5b652b-cbcc-4ee5-bdb5-3e4d1019bf54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 194d6afa-40dc-472e-a2bd-c617db846dc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8229f41e-29d6-4eea-b621-a84147ff8238
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e3697ce-eea2-4c89-a50e-b94330a772f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f5f5ebc-c1b7-497f-a050-3ac3b91a1329
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 492a2fb9-45d6-4c41-8694-d911d0830fbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bda13951-ac9b-4c62-8ead-bc6484f79b22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f365e33c-3b5f-4f67-a2f9-050a231445f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02ef334b-c7a5-4e98-b213-656a07100c82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dbe68dec-c9ca-4e6b-a93c-03ea13d27d6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6861e761-32ac-419d-81ee-3decf7b48562
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ff13bb6-a13e-4b07-bb26-205a4b955f26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ef1abab-3433-46e3-9442-19ed2e0bf692
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e36c23d-862c-4c00-b5d3-f99d6f3f44c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56a361b3-5cf6-4c9a-88a4-450067768b07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a111b43f-c8df-4698-9a02-838814668f0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d8d9219-f664-4bab-bb1a-71222a47f6b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b898d276-9592-4f67-9e69-512fec129623
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de44a8ce-3477-451c-9847-6b55e57d3212
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45e45689-e453-46bf-a390-8c95c82d17ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4466c915-a9d1-493a-ba4e-9e325c3c6191
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7e6e75e-9484-4113-a2ac-b599f258b003
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c4d6c00-8ca1-4390-beae-c34e290b8b6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11b95eff-da23-4fa0-866e-a34eb67098a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75dd57b9-e861-43fd-976b-3b1b3c32b604
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c6590c1-5520-4181-922a-d6266c781b93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 137875bc-7d48-4fb8-b27c-7696d48e1077
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e153ff52-3e7a-4aa7-bc71-ad4798d4e968
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9ea4484-fa25-4458-81e6-5cc66e05c05f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e65f6b5-9a3a-40ed-8c63-b3212726ce70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e85a4ba2-46a0-4b83-b51d-171b3c488f8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd2b93b4-2d00-4697-a027-6bccf06340e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96627dad-d4ac-4b22-9b36-1aeaae5a5794
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09f8cc27-ff16-4dfd-a35f-bea2189d9fdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f000dd38-d130-4ba7-af3a-5abcd127dd43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b2d3da5-bb8e-4abf-ae99-953c3fdbb603
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76dd0994-dd6c-49d1-94f6-7ece9a3f6b8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92ad888a-1920-4189-9074-7cdefd6910dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd8ee12a-614f-470a-856f-1f6b24f0b22f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e520bcca-8c08-41b3-865b-e27e217ad69f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b69632ff-7f66-48c7-8ca6-33db1a998d31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a90cce81-65b5-4f87-bafc-b47b806933ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ffa2204-01a8-4235-bb30-c0516aaedbba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6aad09f-78d5-41cf-ad32-ba30848049f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9382a2f6-36f7-4e9d-93bd-9cce323433b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d49a5ce-dc33-4e7c-909f-7fd6b45579ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6d271ef-88fb-43c0-8e4f-5c6d2b611baf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 609065f1-90ff-48d5-86e3-6beab450ca63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 089eae21-28ea-467f-96a2-34881f3dc42c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 822e9bd4-c288-4f93-9018-3f54d74ee100
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25d4e4ee-b473-49d9-9a00-c4be0f1f7986
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36bd1565-b7d6-48d9-93d1-05de3e0db4b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d058c94-9637-43d0-be7f-fad3f954b351
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9549e891-4e70-40c5-9f09-d9515ed53eeb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8f527b7-9f8f-4eb5-bd0d-fa0d5c5f0a79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c4c4189-b44c-4669-8a7f-a061874de6bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab81d6f5-3be2-4912-b215-06b161bfd555
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 309316df-2311-411b-a92b-cf87b1475483
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c73b5a87-c6ca-451a-b3f3-7261e56c2143
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47e88765-6587-4362-aea6-88d896ef17a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1eb154a1-e054-454a-8bbf-0856eb227af8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91f3a8d2-5693-4181-b571-c01d32d39f56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d07ab872-6824-4707-8023-c1a191e5d1d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2ffa38b-9a09-4231-9bd3-3132c9df0285
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90dc2f5d-252a-439b-a0ab-70dff6a2e4c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e0f8e08-719e-4bfd-a240-e12cfc8d3a87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 851988e8-6720-4508-b63f-3a1435302711
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78fb7518-5bf9-44f8-aeb1-9af3d45bf7f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2170e3e6-757a-4773-b96c-614e5a0ff1b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a8c64e1-613b-4dcf-b8bf-3654c9db2060
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af66f530-3fd2-4580-9d35-89327b5c75bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b330221-4139-4d8e-9874-f5be00477161
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ffb2b9b6-db04-4564-b354-960a0661a8c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0cceaefc-c3d1-40b9-be80-ba20a9b7ba99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae6b1550-4e4c-42b0-bdc8-2a43d0edb14d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e361a81d-cd64-4b3f-bcba-29dd9fbe03bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68485128-8e7c-438a-81fc-d14bb6085667
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 074f3e35-722b-4d99-9be9-9de8af29a3c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17d8f27b-8949-4082-b731-39ea3b64301e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 973d4fde-7180-4391-bc3b-54c71d6ba044
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da62e356-edbe-4105-aa44-986cdbbfe6a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9300068-b46c-465c-aa9f-6f0d106ef6c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5dab6816-923a-470a-8608-657f22e36366
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11b2d071-f0f6-4f54-bb5f-f146de871e8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63eea1cc-1c09-4c75-8472-9d5b147bafa7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81726067-0210-4cc8-a1e4-0226cc40c26a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aea62f0a-8002-480e-b564-083357ce0b80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bbfe5c01-6b10-4c00-ab5f-b35cea33a813
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd9da2a9-ff1e-4e8a-b967-2a0f300a91de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5fbf3f65-4e99-49fc-9860-115663696869
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 506a29e2-06ae-4a56-815f-3d42bdab3758
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e62a48e-96bb-4dba-8196-49f30e32d115
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bcecbcdc-65d2-41c5-a574-4a5f13a0c928
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce5dafbf-afd6-4347-be56-44f7628da05a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2eaa308d-b958-405e-b89e-940e63a9010b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 091ce506-48c4-4b0d-a5a7-c6db5f9f0b3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0739bf3-3493-4457-bbbc-bc234d0682fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f757dbef-5c3f-4004-b7fd-a88d54a8ad62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1757bdd2-7e04-4342-9eee-cfb506856029
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fba87e0a-81e7-4820-b882-9fb7433e8134
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7c578ca-7f2b-4e74-b2d2-8e1d3109b6b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da9a512e-1ec5-4c79-b458-542fd0d4cf13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25ea733f-bb13-4e11-81f0-9f07a1ecfd2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2e9a0e6-a65f-42d0-905d-2aa299da97cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e24f9cf-98f1-441b-849f-6398e748667f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f695730-64c5-4131-826a-2e8930fb742e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 842542b9-9847-4136-aa58-73085990cbad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61271053-3617-4dbc-9c7e-a535888bf340
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2efacd80-6f4b-4021-be51-720cd40a2cd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfb7db56-908b-4b52-84ce-dc0c2ee784fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4698c6d-bd41-4c2c-8be2-6b09d032a3a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b464621-eea3-4be6-90c6-527947bc9f96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1ea3041-84d7-4cb0-83e2-d6620bd5436d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e59faaab-d728-41b7-a4fb-06e48be071e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57ed5911-ad4f-4180-b22c-c5c23827bb5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3e1f168-c58e-4ecc-9aa5-92b21d49d0b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6cd66c93-06e2-4922-821f-62d18edf9973
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad150213-ceda-4d6a-9822-674f8c5e80b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 440e5d10-8aaf-4fd7-95f8-68bee5726d85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a702d69e-2b1e-4778-a28b-a985a32e59ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b88f0de-1d56-4a4c-be03-f40e85b54aa7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31a3732d-9f92-43dc-b3a0-646f32385466
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 002cda9d-08b2-4d0e-94e2-66f7e77aca7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2831104-b78f-4f5c-9dce-5776bef8dbe0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 399fa5b5-e79e-4ec9-92e9-73c42261f6f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0df39b88-757c-4bcd-88bb-552c627d8006
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52a24e99-9f4c-478d-84b1-e7c7066104ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d80d5ab1-8557-412d-8be2-a6d39a0091b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e20d34cc-48f9-4357-8b49-112d44d3c55a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message afaa931d-3bb7-4ad5-860f-b61f3151090c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 350c512d-85a4-4842-8493-e3717375a629
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e92cb273-db19-4616-8225-9a345b8aa6f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9eb3a5a-1771-4c2e-ae15-4552b99e293f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c536e01f-4bc6-405b-8594-3c8943455803
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd593b09-ded5-488c-980b-f6bc0e47202f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72d89380-17ef-43d1-95ba-a2a5ea76b93f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a330f410-b75e-4ce4-8412-ab79a7bce552
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ceb46902-424c-4dba-ba49-f6fd8c4a61db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 980c310e-422e-4e7a-a24f-7f5be0b4fdd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f65d5644-e700-4797-a4e1-079336bee3e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25779581-5497-4b23-86b3-b78727557ddf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71f0fdea-3c63-4db9-94ac-5bd505695ece
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80dbb635-66a6-4626-bc77-59e7f67c26d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1c4d5f2-b71c-4200-a160-c2afbd3c7f41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e96987c2-db80-48e0-ac10-c0d9a30012e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 802f06c0-8644-49e0-87c4-281182839977
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4d00ae6-5f46-4255-bf6b-59d63b89f2b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 028b36bf-c670-4a8c-8563-ac8b42b48d8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1da5bcf-2700-40b9-ae54-864ab627c6c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 086134c4-2b4c-4bf7-b657-19a12e86ca6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5af9e1ba-e79b-4f9c-8f18-6a6870f8c3f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea2b63c4-850b-4cc7-ba1b-8a6a7908193f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d464756-b7f5-46a9-b360-64a0b59efc63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8693aa19-3998-4be4-acd4-f0ade2dfcbc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e60e3269-5d04-44ad-94c8-6093dad07f04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4b06f40-4fba-490c-ac69-fb7788dfa377
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03c04bed-84fc-4805-a97c-39c79ba1db81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db891b25-dca4-4404-aa6b-2d629e33f666
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d329eca-d413-4697-8af5-f653240f9985
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c958b2a4-167c-4144-a502-3ed57014bce8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1fc9bf14-ce7f-4eb3-a2dd-2debee67d5e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f928a15e-e78a-40b8-9a62-ee40aadad23b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04ac1f49-142e-408c-ba34-a33bad259083
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ca55da8-1dc7-4c51-b609-2e399902f34a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 542df31e-e5e5-48f8-b90f-9b47b9b98d9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b522f295-cc04-4a4b-ad45-24bcefc04631
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1cd3ccf-b5fa-4d16-b33f-858815a92c1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 351c5712-d667-430e-9cfb-963ab323f7af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16d040a9-1f9c-4b46-b013-d4e75945b1be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1fed2741-5be5-4358-a9e2-8febcda6ba31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8862ac53-b439-41c8-8bc6-a6b4b9efb448
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a1156d1-2268-46cc-9fa0-2b672c5d71a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d95136bc-bd15-45cb-9a05-07054d5d711f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 691e4328-7fe3-4c86-8f20-780e3b6eb414
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f145bb9e-1590-43e3-baf9-07e0c52bc7a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0adbb1a6-f03f-4d01-9ee5-1fe5e5786648
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2d294ed-72af-41fb-809e-ff3e3e92780a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92fe401e-84c2-44dc-a8ed-03430d91d7c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cbd7955c-c9bd-46d7-85d3-f3613bff065a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27187a5b-404f-4db0-86d2-be4f854532b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b395fc2-f14d-463a-a0f4-2abe6cf74b0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4a0a9f2-283b-43fc-a944-6a04b0d4400b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7849167-341b-421b-b596-a61f86c0da01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d0c33ff-20f8-4301-84f4-bc89e97d94e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d972069b-d206-46a4-84ac-5640769582bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21a9a322-192e-4d7b-a505-bee20927236f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c874044-49c3-47da-8987-8cec20c93b34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eec23216-b4dd-44c3-96e5-154d517daba0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82b1c910-8c12-4761-b3b8-4af3f1ec76dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f725cb5-7d75-4554-8ddb-e1cf68ba37fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d3b6668-57e5-44e7-a89a-39a5f530ffc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0ce3a3a-e03c-4470-a18c-7a1376a9acd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1076dd56-be18-423b-be63-3e9772d5190d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message abba2bea-14cb-4a08-bc74-dd697407d78e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2be2fd2-1a03-454f-b8da-7ab1a2d6b345
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2b9655c-7380-4f4a-ad07-07fe496ae94e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5fbf6d66-975b-4c43-b5ea-cadcbcc7cf4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63c2bb3f-2452-48fc-9d9f-be911bb4cbe8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b350cbdc-5985-46f1-8a88-3fce77e05779
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9adfde06-d94c-42e4-8aaf-de731448b891
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10ae866d-fa79-401e-92dd-f2a96b6bf746
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80959638-4097-4b11-9d22-9aa596ea32c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c0af3b8-c06b-4944-837e-8a968d6b11d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9c7a4ba-e126-481d-bea3-946b5b6ae7e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4bd611f9-7fbe-4f58-9d5f-677f89a211c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7074961c-1467-47cb-b5cd-f90259ee2fc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d0027a1-0c27-4112-a858-5d987c570b0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f32f3e4-46bd-4b64-81ec-42b7d3581b47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1908755-f3b2-4e0f-ba08-d3ef4921aa98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26bff9ea-3ccc-489e-9f9f-18bce09c2f22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e47c440-06ab-4f64-835f-55f345c0ea0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4accc74f-5b91-49ad-9806-62ef896fc45c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2dab9dca-3957-4ff0-a2bd-aac6921074d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 769fbf55-dbf0-4a54-a9ee-c091c62e5859
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c47c804e-7e9e-4c94-adc8-b80013c48404
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8214ff2-a047-429d-bdf4-f73bd84805ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3123e8dc-e777-49bc-8c03-1c210dbfb3e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e91cf62b-b8fb-4b58-b961-079e17c7bf32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 579456e2-d5c8-429d-b38b-52ded13df876
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 047cdafe-bfc0-40b5-acc9-69bb1185077d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d53ba20f-3038-49ec-b923-2e213f44b9c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e421407a-2fe3-4a68-b5e9-0688f13c70d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2184d88d-f50f-4073-b3cf-d5d6498db02a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9162d09-dc0a-4d1d-9820-d0467819f89d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c79b858e-b32b-450b-a581-eb5c69f8f5d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cdb63995-ea8b-472e-8143-47b3a86049f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ca97160-4ca2-4daa-83f9-5833e3329afe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fae12765-0503-4278-9810-fc4046513495
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 378e6d18-73e9-44f0-8d7f-738cc7d1c059
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37f8a3f8-f761-484f-bd81-8462fda21bbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd13499d-9438-4f8a-ab5c-8c80b270b7ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90aad3ad-5261-4acd-83c1-02817ba6d71a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5510ef1-b24f-4a5c-aaa0-f5424208f758
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 906f5da8-6bf7-4055-b032-59b91ec24833
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b54c37c3-7aba-4e3e-8122-3cd1402e718f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb78b295-4e3d-496b-a560-84851e17f543
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1cb1b4b9-33cf-4ea9-ba36-97c643f09a1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71a48e05-29af-4434-94ee-63bffd353ac9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03c7cd3e-ea7a-4db3-ac71-f7c7b3d49359
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e48352df-f438-46b1-bdcd-77f33abedd5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d6175e7-117c-477d-9bc5-23e93e4a793f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6df8e78-56e3-4be1-8bcd-2d9bbcbad9c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d80b6ec5-4de0-411f-992a-b32c922f9960
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f5076a0-a3c1-41bf-8cba-9598ecac4a32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6be93fb-818d-445e-a1f5-81b8cc1b7869
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ee0a90f-7106-4b4f-bf3d-eb4151f7ae8c
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8690 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_2
Server: localhost:8690
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_2
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_2/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_2/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_2/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_2/test_labels.txt

📊 Raw data loaded:
   Train: X=(5055, 24), y=(5055,)
   Test:  X=(1264, 24), y=(1264,)

⚠️  Limiting training data: 5055 → 800 samples
⚠️  Limiting test data: 1264 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_2 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 1 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.2827, val=0.1121 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0962, val=0.0842 (↓), lr=0.001000
   ✓ Epoch   3/100: train=0.0815, val=0.0745 (↓), lr=0.001000
   • Epoch   4/100: train=0.0810, val=0.0751, patience=1/15, lr=0.001000
   • Epoch   5/100: train=0.0811, val=0.0755, patience=2/15, lr=0.001000
   📉 Epoch 9: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0795, val=0.0755, patience=8/15, lr=0.000500
   📉 Epoch 17: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 1 Summary - Client client_2
   Epochs: 18/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0031
   Val:   Loss=0.0745, RMSE=0.2730, R²=0.0144
============================================================


📊 Round 1 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2509, R²: 0.0021

============================================================
🔄 Round 2 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0782 (↓), lr=0.000250
   • Epoch   2/100: train=0.0802, val=0.0790, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0800, val=0.0790, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0798, val=0.0791, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0797, val=0.0791, patience=4/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0792, val=0.0791, patience=10/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 2 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0013
   Val:   Loss=0.0782, RMSE=0.2796, R²=-0.0118
============================================================


📊 Round 2 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2510, R²: -0.0027

📊 Round 2 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2511, R²: -0.0021

📊 Round 2 Test Metrics:
   Loss: 0.0840, RMSE: 0.2899, MAE: 0.2509, R²: -0.0005

📊 Round 2 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2509, R²: -0.0004

📊 Round 2 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2510, R²: -0.0014

============================================================
🔄 Round 9 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0823 (↓), lr=0.000063
   • Epoch   2/100: train=0.0794, val=0.0822, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0792, val=0.0823, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0790, val=0.0824, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0789, val=0.0826, patience=4/15, lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0786, val=0.0831, patience=10/15, lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 9 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0007
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0139
============================================================


============================================================
🔄 Round 10 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0786 (↓), lr=0.000016
   • Epoch   2/100: train=0.0810, val=0.0786, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0807, val=0.0787, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0805, val=0.0788, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0804, val=0.0788, patience=4/15, lr=0.000016
   📉 Epoch 7: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0802, val=0.0791, patience=10/15, lr=0.000008
   📉 Epoch 15: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 10 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=-0.0109
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.0007
============================================================


============================================================
🔄 Round 12 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0756 (↓), lr=0.000004
   • Epoch   2/100: train=0.0817, val=0.0755, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0816, val=0.0755, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0816, val=0.0754, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0815, val=0.0753, patience=4/15, lr=0.000004
   📉 Epoch 7: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0814, val=0.0752, patience=10/15, lr=0.000002
   📉 Epoch 15: LR reduced 0.000002 → 0.000001
   • Epoch  21/100: train=0.0813, val=0.0751, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 12 Summary - Client client_2
   Epochs: 30/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=-0.0009
   Val:   Loss=0.0751, RMSE=0.2740, R²=-0.0103
============================================================


============================================================
🔄 Round 13 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 13 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0038
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0221
============================================================


============================================================
🔄 Round 14 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 14 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0085
   Val:   Loss=0.0833, RMSE=0.2887, R²=-0.0188
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2511, R²: -0.0018

============================================================
🔄 Round 16 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 16 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0043
   Val:   Loss=0.0784, RMSE=0.2800, R²=-0.0316
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0019

============================================================
🔄 Round 20 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 20 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0107
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0019
============================================================


============================================================
🔄 Round 21 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 21 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0047
   Val:   Loss=0.0745, RMSE=0.2729, R²=-0.0384
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0019

📊 Round 21 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0019

📊 Round 21 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0019

============================================================
🔄 Round 25 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 25 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=-0.0039
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0409
============================================================


============================================================
🔄 Round 26 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 26 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0020
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.1022
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0019

============================================================
🔄 Round 27 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 27 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=-0.0051
   Val:   Loss=0.0863, RMSE=0.2939, R²=-0.0223
============================================================


============================================================
🔄 Round 31 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 31 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=-0.0125
   Val:   Loss=0.0771, RMSE=0.2777, R²=0.0008
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

📊 Round 31 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0019

============================================================
🔄 Round 35 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 35 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0106
   Val:   Loss=0.0813, RMSE=0.2852, R²=-0.0000
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 37 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0710 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0709, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0709, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0709, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0709, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0708, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0710)

============================================================
📊 Round 37 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0104
   Val:   Loss=0.0710, RMSE=0.2664, R²=-0.0004
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 40 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 40 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=-0.0053
   Val:   Loss=0.0791, RMSE=0.2812, R²=-0.0281
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

📊 Round 40 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 42 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 42 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=-0.0093
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0055
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

📊 Round 42 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

📊 Round 42 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

📊 Round 42 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 46 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 46 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0090
   Val:   Loss=0.0763, RMSE=0.2763, R²=-0.0066
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0019

============================================================
🔄 Round 49 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 49 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0078
   Val:   Loss=0.0734, RMSE=0.2708, R²=-0.0105
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0019

📊 Round 49 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0019

============================================================
🔄 Round 51 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 51 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0058
   Val:   Loss=0.0785, RMSE=0.2801, R²=-0.0198
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0019

📊 Round 51 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0019

============================================================
🔄 Round 53 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 53 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0131
   Val:   Loss=0.0745, RMSE=0.2729, R²=0.0013
============================================================


============================================================
🔄 Round 55 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 55 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0077
   Val:   Loss=0.0753, RMSE=0.2744, R²=-0.0130
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0019

============================================================
🔄 Round 56 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 56 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0057
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0207
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 58 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 58 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0059
   Val:   Loss=0.0735, RMSE=0.2712, R²=-0.0240
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

📊 Round 58 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 61 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 61 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0090
   Val:   Loss=0.0739, RMSE=0.2718, R²=-0.0058
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

📊 Round 61 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 65 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 65 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0075
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0116
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 67 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 67 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=-0.0064
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0174
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

📊 Round 67 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 77 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 77 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0065
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.0188
============================================================


============================================================
🔄 Round 79 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 79 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0071
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0133
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

📊 Round 79 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

📊 Round 79 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 83 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 83 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0143
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0005
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0019

📊 Round 83 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0019

============================================================
🔄 Round 87 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 87 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0089
   Val:   Loss=0.0805, RMSE=0.2838, R²=-0.0063
============================================================


============================================================
🔄 Round 89 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 89 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0022
   Val:   Loss=0.0761, RMSE=0.2758, R²=-0.0655
============================================================


============================================================
🔄 Round 90 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 90 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0073
   Val:   Loss=0.0800, RMSE=0.2829, R²=-0.0149
============================================================


============================================================
🔄 Round 92 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 92 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=-0.0097
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0036
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 97 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 97 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0159
   Val:   Loss=0.0737, RMSE=0.2715, R²=-0.0035
============================================================


============================================================
🔄 Round 99 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 99 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=-0.0063
   Val:   Loss=0.0743, RMSE=0.2726, R²=-0.0235
============================================================


============================================================
🔄 Round 100 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 100 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=-0.0051
   Val:   Loss=0.0883, RMSE=0.2971, R²=-0.0258
============================================================


============================================================
🔄 Round 103 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0725, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 103 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0079
   Val:   Loss=0.0726, RMSE=0.2695, R²=-0.0104
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

📊 Round 103 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

📊 Round 103 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 109 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 109 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0102
   Val:   Loss=0.0790, RMSE=0.2810, R²=-0.0024
============================================================


============================================================
🔄 Round 111 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 111 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0150
   Val:   Loss=0.0728, RMSE=0.2698, R²=0.0022
============================================================


============================================================
🔄 Round 112 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 112 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0078
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0105
============================================================


============================================================
🔄 Round 113 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 113 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=-0.0078
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0115
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 115 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 115 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=-0.0074
   Val:   Loss=0.0772, RMSE=0.2778, R²=-0.0116
============================================================


============================================================
🔄 Round 116 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 116 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=-0.0179
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0095
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 117 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 117 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=-0.0132
   Val:   Loss=0.0893, RMSE=0.2989, R²=-0.0019
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 120 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 120 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=-0.0052
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0241
============================================================


============================================================
🔄 Round 121 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0701 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0701, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0702, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0702, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0702, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0703, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0701)

============================================================
📊 Round 121 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0167
   Val:   Loss=0.0701, RMSE=0.2648, R²=0.0014
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 125 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 125 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0151
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0046
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

📊 Round 125 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

📊 Round 125 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 130 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 130 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0066
   Val:   Loss=0.0837, RMSE=0.2894, R²=-0.0191
============================================================


============================================================
🔄 Round 131 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 131 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2822, R²=-0.0059
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0221
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

📊 Round 131 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 134 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 134 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=-0.0109
   Val:   Loss=0.0857, RMSE=0.2928, R²=-0.0031
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 138 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 138 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=-0.0081
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0109
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

📊 Round 138 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0019

============================================================
🔄 Round 140 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 140 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=-0.0092
   Val:   Loss=0.0861, RMSE=0.2935, R²=-0.0059
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 141 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 141 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=-0.0130
   Val:   Loss=0.0840, RMSE=0.2898, R²=0.0009
============================================================


============================================================
🔄 Round 143 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 143 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=-0.0099
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0030
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 144 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 144 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=-0.0090
   Val:   Loss=0.0899, RMSE=0.2999, R²=-0.0076
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

📊 Round 144 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 146 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 146 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2849, R²=-0.0035
   Val:   Loss=0.0784, RMSE=0.2800, R²=-0.0462
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

📊 Round 146 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 150 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 150 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0061
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0291
============================================================


============================================================
🔄 Round 151 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 151 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=-0.0105
   Val:   Loss=0.0906, RMSE=0.3010, R²=-0.0023
============================================================


============================================================
🔄 Round 154 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 154 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=-0.0085
   Val:   Loss=0.0865, RMSE=0.2940, R²=-0.0075
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 157 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 157 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0170
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0122
============================================================


============================================================
🔄 Round 158 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 158 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0086
   Val:   Loss=0.0833, RMSE=0.2885, R²=-0.0065
============================================================


============================================================
🔄 Round 160 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 160 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=-0.0072
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0128
============================================================


============================================================
🔄 Round 161 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 161 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=-0.0123
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0012
============================================================


============================================================
🔄 Round 162 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 162 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=-0.0049
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0386
============================================================


============================================================
🔄 Round 163 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 163 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0128
   Val:   Loss=0.0792, RMSE=0.2815, R²=0.0010
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 164 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 164 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=-0.0136
   Val:   Loss=0.0864, RMSE=0.2939, R²=0.0052
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 166 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 166 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0118
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0029
============================================================


============================================================
🔄 Round 167 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 167 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0154
   Val:   Loss=0.0746, RMSE=0.2731, R²=-0.0044
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 168 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 168 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0096
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0031
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 169 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 169 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0106
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0007
============================================================


============================================================
🔄 Round 171 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 171 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=-0.0084
   Val:   Loss=0.0848, RMSE=0.2913, R²=-0.0070
============================================================


============================================================
🔄 Round 172 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0717, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0717, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0717, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0716, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 172 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0084
   Val:   Loss=0.0717, RMSE=0.2678, R²=-0.0076
============================================================


============================================================
🔄 Round 173 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 173 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=-0.0106
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0011
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2511, R²: -0.0021

============================================================
🔄 Round 174 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 174 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2863, R²=-0.0046
   Val:   Loss=0.0750, RMSE=0.2739, R²=-0.0301
============================================================


============================================================
🔄 Round 176 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 176 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0049
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0228
============================================================


============================================================
🔄 Round 177 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 177 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0135
   Val:   Loss=0.0776, RMSE=0.2785, R²=-0.0028
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 180 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 180 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0128
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0013
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 182 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 182 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0021
   Val:   Loss=0.0763, RMSE=0.2762, R²=-0.0572
============================================================


============================================================
🔄 Round 183 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 183 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=-0.0056
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0197
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 188 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 188 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0121
   Val:   Loss=0.0806, RMSE=0.2838, R²=0.0000
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 191 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 191 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=-0.0029
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0527
============================================================


============================================================
🔄 Round 193 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 193 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=-0.0026
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0509
============================================================


📊 Round 193 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 194 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 194 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0115
   Val:   Loss=0.0761, RMSE=0.2758, R²=-0.0027
============================================================


============================================================
🔄 Round 195 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 195 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2819, R²=-0.0039
   Val:   Loss=0.0852, RMSE=0.2918, R²=-0.0406
============================================================


📊 Round 195 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

📊 Round 195 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 200 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 200 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0100
   Val:   Loss=0.0789, RMSE=0.2808, R²=-0.0027
============================================================


📊 Round 200 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 202 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 202 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0083
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0085
============================================================


============================================================
🔄 Round 203 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 203 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=-0.0092
   Val:   Loss=0.0869, RMSE=0.2948, R²=-0.0074
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

📊 Round 203 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 206 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 206 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0095
   Val:   Loss=0.0784, RMSE=0.2800, R²=-0.0043
============================================================


📊 Round 206 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 208 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 208 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0034
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0533
============================================================


📊 Round 208 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

📊 Round 208 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 210 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 210 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0112
   Val:   Loss=0.0790, RMSE=0.2810, R²=-0.0030
============================================================


📊 Round 210 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 213 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 213 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0083
   Val:   Loss=0.0769, RMSE=0.2774, R²=-0.0085
============================================================


📊 Round 213 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 214 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 214 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0101
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0065
============================================================


📊 Round 214 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

📊 Round 214 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 217 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 217 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0092
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0054
============================================================


📊 Round 217 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 218 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 218 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=-0.0041
   Val:   Loss=0.0887, RMSE=0.2978, R²=-0.0329
============================================================


📊 Round 218 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

📊 Round 218 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 222 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 222 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0038
   Val:   Loss=0.0758, RMSE=0.2754, R²=-0.0479
============================================================


============================================================
🔄 Round 223 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 223 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0170
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0060
============================================================


📊 Round 223 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 224 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 224 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0072
   Val:   Loss=0.0784, RMSE=0.2800, R²=-0.0147
============================================================


📊 Round 224 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 227 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 227 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0005
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.1515
============================================================


============================================================
🔄 Round 230 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 230 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0169
   Val:   Loss=0.0720, RMSE=0.2683, R²=-0.0044
============================================================


📊 Round 230 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 234 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 234 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=-0.0067
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0159
============================================================


📊 Round 234 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

📊 Round 234 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 236 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 236 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0082
   Val:   Loss=0.0827, RMSE=0.2877, R²=-0.0114
============================================================


📊 Round 236 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

📊 Round 236 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

📊 Round 236 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

📊 Round 236 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 242 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 242 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0104
   Val:   Loss=0.0801, RMSE=0.2831, R²=-0.0031
============================================================


============================================================
🔄 Round 244 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 244 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=-0.0072
   Val:   Loss=0.0880, RMSE=0.2967, R²=-0.0159
============================================================


📊 Round 244 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0019

============================================================
🔄 Round 245 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 245 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=-0.0086
   Val:   Loss=0.0860, RMSE=0.2932, R²=-0.0083
============================================================


============================================================
🔄 Round 246 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 246 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0084
   Val:   Loss=0.0796, RMSE=0.2822, R²=-0.0092
============================================================


📊 Round 246 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 247 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 247 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=-0.0018
   Val:   Loss=0.0840, RMSE=0.2897, R²=-0.0592
============================================================


============================================================
🔄 Round 248 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 248 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0079
   Val:   Loss=0.0778, RMSE=0.2789, R²=-0.0115
============================================================


📊 Round 248 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

📊 Round 248 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

📊 Round 248 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 254 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 254 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0074
   Val:   Loss=0.0731, RMSE=0.2703, R²=-0.0132
============================================================


📊 Round 254 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 258 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 258 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0057
   Val:   Loss=0.0819, RMSE=0.2861, R²=-0.0271
============================================================


============================================================
🔄 Round 259 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0696 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0696, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0696, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0696, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0696, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0695, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0696)

============================================================
📊 Round 259 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0103
   Val:   Loss=0.0696, RMSE=0.2639, R²=-0.0013
============================================================


============================================================
🔄 Round 261 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 261 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=-0.0141
   Val:   Loss=0.0727, RMSE=0.2696, R²=-0.0018
============================================================


📊 Round 261 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 267 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 267 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2812, R²=-0.0017
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0715
============================================================


============================================================
🔄 Round 268 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 268 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=-0.0145
   Val:   Loss=0.0841, RMSE=0.2899, R²=0.0055
============================================================


============================================================
🔄 Round 269 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0716 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0716, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0715, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0715, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0715, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0713, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0716)

============================================================
📊 Round 269 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0024
   Val:   Loss=0.0716, RMSE=0.2676, R²=-0.0777
============================================================


📊 Round 269 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

📊 Round 269 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 273 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 273 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0072
   Val:   Loss=0.0827, RMSE=0.2875, R²=-0.0137
============================================================


============================================================
🔄 Round 274 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 274 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0116
   Val:   Loss=0.0745, RMSE=0.2730, R²=0.0031
============================================================


📊 Round 274 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

📊 Round 274 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 278 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 278 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=-0.0061
   Val:   Loss=0.0805, RMSE=0.2836, R²=-0.0224
============================================================


============================================================
🔄 Round 279 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 279 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0058
   Val:   Loss=0.0807, RMSE=0.2840, R²=-0.0202
============================================================


📊 Round 279 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

📊 Round 279 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 283 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 283 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0097
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0056
============================================================


============================================================
🔄 Round 285 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 285 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=-0.0044
   Val:   Loss=0.0787, RMSE=0.2806, R²=-0.0374
============================================================


📊 Round 285 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

📊 Round 285 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

📊 Round 285 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

📊 Round 285 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

📊 Round 285 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 293 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 293 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0127
   Val:   Loss=0.0790, RMSE=0.2810, R²=-0.0034
============================================================


📊 Round 293 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 295 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 295 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2806, R²=-0.0083
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0102
============================================================


============================================================
🔄 Round 296 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 296 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=-0.0100
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0054
============================================================


============================================================
🔄 Round 297 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 297 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0091
   Val:   Loss=0.0790, RMSE=0.2810, R²=-0.0057
============================================================


📊 Round 297 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

📊 Round 297 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 299 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 299 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0089
   Val:   Loss=0.0752, RMSE=0.2743, R²=-0.0072
============================================================


============================================================
🔄 Round 301 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 301 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=-0.0084
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0091
============================================================


📊 Round 301 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

📊 Round 301 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 306 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 306 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0092
   Val:   Loss=0.0811, RMSE=0.2847, R²=-0.0072
============================================================


📊 Round 306 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 308 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 308 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2799, R²=-0.0129
   Val:   Loss=0.0895, RMSE=0.2992, R²=-0.0002
============================================================


📊 Round 308 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 310 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 310 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0102
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0021
============================================================


============================================================
🔄 Round 311 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 311 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0094
   Val:   Loss=0.0822, RMSE=0.2868, R²=-0.0046
============================================================


📊 Round 311 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 314 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 314 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0104
   Val:   Loss=0.0786, RMSE=0.2803, R²=-0.0042
============================================================


📊 Round 314 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

📊 Round 314 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 318 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0929 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0929, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0929, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0928, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0928, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0927, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 318 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=-0.0062
   Val:   Loss=0.0929, RMSE=0.3048, R²=-0.0165
============================================================


📊 Round 318 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

📊 Round 318 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

📊 Round 318 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 324 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 324 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0097
   Val:   Loss=0.0775, RMSE=0.2783, R²=-0.0041
============================================================


============================================================
🔄 Round 325 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 325 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0110
   Val:   Loss=0.0801, RMSE=0.2831, R²=0.0004
============================================================


============================================================
🔄 Round 326 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 326 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0088
   Val:   Loss=0.0834, RMSE=0.2889, R²=-0.0078
============================================================


📊 Round 326 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 327 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 327 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=-0.0066
   Val:   Loss=0.0760, RMSE=0.2757, R²=-0.0215
============================================================


============================================================
🔄 Round 329 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 329 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0063
   Val:   Loss=0.0826, RMSE=0.2873, R²=-0.0235
============================================================


📊 Round 329 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 332 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 332 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0133
   Val:   Loss=0.0811, RMSE=0.2847, R²=-0.0007
============================================================


📊 Round 332 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 334 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 334 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0130
   Val:   Loss=0.0800, RMSE=0.2829, R²=0.0001
============================================================


📊 Round 334 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

📊 Round 334 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 336 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 336 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0098
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0053
============================================================


📊 Round 336 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

📊 Round 336 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

📊 Round 336 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 342 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 342 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0084
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0082
============================================================


============================================================
🔄 Round 343 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 343 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0041
   Val:   Loss=0.0837, RMSE=0.2894, R²=-0.0376
============================================================


============================================================
🔄 Round 345 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 345 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0098
   Val:   Loss=0.0776, RMSE=0.2785, R²=-0.0027
============================================================


📊 Round 345 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 347 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 347 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=-0.0157
   Val:   Loss=0.0886, RMSE=0.2976, R²=-0.0111
============================================================


============================================================
🔄 Round 348 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 348 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=-0.0073
   Val:   Loss=0.0787, RMSE=0.2806, R²=-0.0134
============================================================


📊 Round 348 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

📊 Round 348 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

📊 Round 348 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 355 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 355 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2826, R²=-0.0131
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0009
============================================================


============================================================
🔄 Round 356 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 356 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0082
   Val:   Loss=0.0737, RMSE=0.2715, R²=-0.0088
============================================================


📊 Round 356 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

📊 Round 356 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 359 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 359 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0070
   Val:   Loss=0.0818, RMSE=0.2861, R²=-0.0163
============================================================


============================================================
🔄 Round 361 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 361 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=-0.0044
   Val:   Loss=0.0844, RMSE=0.2904, R²=-0.0267
============================================================


📊 Round 361 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 362 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 362 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=-0.0035
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0525
============================================================


📊 Round 362 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

📊 Round 362 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 367 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 367 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0189
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0051
============================================================


📊 Round 367 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 369 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 369 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=-0.0065
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0158
============================================================


============================================================
🔄 Round 371 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 371 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0065
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0155
============================================================


============================================================
🔄 Round 372 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 372 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0069
   Val:   Loss=0.0765, RMSE=0.2765, R²=-0.0166
============================================================


============================================================
🔄 Round 373 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 373 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=-0.0126
   Val:   Loss=0.0866, RMSE=0.2943, R²=0.0058
============================================================


📊 Round 373 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 376 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 376 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0098
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0020
============================================================


📊 Round 376 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

📊 Round 376 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 380 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 380 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0061
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0259
============================================================


📊 Round 380 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

📊 Round 380 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

📊 Round 380 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 384 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 384 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=-0.0063
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0186
============================================================


============================================================
🔄 Round 385 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 385 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=-0.0062
   Val:   Loss=0.0839, RMSE=0.2896, R²=-0.0159
============================================================


============================================================
🔄 Round 386 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 386 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0119
   Val:   Loss=0.0758, RMSE=0.2753, R²=0.0002
============================================================


📊 Round 386 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

📊 Round 386 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 390 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 390 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0114
   Val:   Loss=0.0782, RMSE=0.2797, R²=0.0020
============================================================


============================================================
🔄 Round 391 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 391 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=-0.0059
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0272
============================================================


📊 Round 391 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

📊 Round 391 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

📊 Round 391 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 396 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0709 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0709, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0709, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0709, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0709, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0709, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0709)

============================================================
📊 Round 396 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0128
   Val:   Loss=0.0709, RMSE=0.2663, R²=0.0029
============================================================


📊 Round 396 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 402 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 402 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0051
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0258
============================================================


📊 Round 402 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 405 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 405 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=-0.0072
   Val:   Loss=0.0884, RMSE=0.2973, R²=-0.0126
============================================================


📊 Round 405 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 406 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 406 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0052
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0303
============================================================


============================================================
🔄 Round 407 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0717, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0717, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0716, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 407 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0081
   Val:   Loss=0.0718, RMSE=0.2679, R²=-0.0101
============================================================


============================================================
🔄 Round 409 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 409 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0070
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0145
============================================================


📊 Round 409 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

📊 Round 409 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 415 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 415 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0073
   Val:   Loss=0.0777, RMSE=0.2787, R²=-0.0155
============================================================


============================================================
🔄 Round 416 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 416 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0086
   Val:   Loss=0.0784, RMSE=0.2801, R²=-0.0090
============================================================


📊 Round 416 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 421 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 421 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0056
   Val:   Loss=0.0768, RMSE=0.2771, R²=-0.0316
============================================================


============================================================
🔄 Round 422 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 422 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0073
   Val:   Loss=0.0777, RMSE=0.2787, R²=-0.0174
============================================================


📊 Round 422 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 423 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 423 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=-0.0071
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0161
============================================================


============================================================
🔄 Round 425 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 425 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2850, R²=-0.0109
   Val:   Loss=0.0780, RMSE=0.2792, R²=-0.0035
============================================================


============================================================
🔄 Round 427 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 427 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0039
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0358
============================================================


📊 Round 427 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

📊 Round 427 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

📊 Round 427 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 431 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 431 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0089
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0075
============================================================


============================================================
🔄 Round 432 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 432 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0056
   Val:   Loss=0.0807, RMSE=0.2842, R²=-0.0324
============================================================


📊 Round 432 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0019

📊 Round 432 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0019

📊 Round 432 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0019

============================================================
🔄 Round 436 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 436 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0085
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0088
============================================================


📊 Round 436 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 438 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 438 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0042
   Val:   Loss=0.0799, RMSE=0.2826, R²=-0.0385
============================================================


📊 Round 438 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0019

============================================================
🔄 Round 439 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 439 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0073
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0150
============================================================


📊 Round 439 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 440 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 440 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0125
   Val:   Loss=0.0780, RMSE=0.2793, R²=0.0041
============================================================


📊 Round 440 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

📊 Round 440 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 442 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 442 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0102
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0015
============================================================


============================================================
🔄 Round 444 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 444 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2819, R²=-0.0081
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0103
============================================================


📊 Round 444 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

📊 Round 444 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 452 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 452 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=-0.0069
   Val:   Loss=0.0903, RMSE=0.3006, R²=-0.0163
============================================================


============================================================
🔄 Round 453 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 453 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0052
   Val:   Loss=0.0779, RMSE=0.2792, R²=-0.0242
============================================================


📊 Round 453 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 456 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 456 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0108
   Val:   Loss=0.0768, RMSE=0.2772, R²=-0.0009
============================================================


📊 Round 456 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 459 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 459 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0028
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0475
============================================================


📊 Round 459 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 461 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 461 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0158
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0022
============================================================


📊 Round 461 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 462 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 462 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=-0.0112
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0028
============================================================


📊 Round 462 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 466 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 466 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0067
   Val:   Loss=0.0762, RMSE=0.2760, R²=-0.0172
============================================================


============================================================
🔄 Round 467 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 467 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=-0.0081
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0100
============================================================


📊 Round 467 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 472 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 472 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=-0.0059
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0261
============================================================


============================================================
🔄 Round 476 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 476 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0064
   Val:   Loss=0.0777, RMSE=0.2787, R²=-0.0194
============================================================


📊 Round 476 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

📊 Round 476 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 485 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 485 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0053
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0273
============================================================


📊 Round 485 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 486 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 486 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0049
   Val:   Loss=0.0777, RMSE=0.2787, R²=-0.0311
============================================================


📊 Round 486 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 488 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 488 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=-0.0096
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0068
============================================================


============================================================
🔄 Round 489 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 489 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2790, R²=-0.0040
   Val:   Loss=0.0916, RMSE=0.3026, R²=-0.0508
============================================================


📊 Round 489 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

📊 Round 489 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

📊 Round 489 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 493 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 493 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=-0.0106
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0011
============================================================


============================================================
🔄 Round 494 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 494 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=-0.0130
   Val:   Loss=0.0855, RMSE=0.2924, R²=0.0030
============================================================


📊 Round 494 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 497 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 497 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0066
   Val:   Loss=0.0760, RMSE=0.2757, R²=-0.0160
============================================================


📊 Round 497 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

📊 Round 497 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

📊 Round 497 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 501 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 501 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0174
   Val:   Loss=0.0760, RMSE=0.2756, R²=-0.0001
============================================================


============================================================
🔄 Round 502 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 502 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0073
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0122
============================================================


📊 Round 502 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

📊 Round 502 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

📊 Round 502 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

📊 Round 502 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

📊 Round 502 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

📊 Round 502 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 514 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 514 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0066
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0166
============================================================


============================================================
🔄 Round 515 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 515 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0180
   Val:   Loss=0.0775, RMSE=0.2783, R²=0.0010
============================================================


📊 Round 515 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

📊 Round 515 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 518 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 518 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0098
   Val:   Loss=0.0779, RMSE=0.2791, R²=-0.0080
============================================================


============================================================
🔄 Round 519 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 519 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0134
   Val:   Loss=0.0817, RMSE=0.2859, R²=0.0013
============================================================


============================================================
🔄 Round 521 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 521 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0025
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0479
============================================================


📊 Round 521 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

📊 Round 521 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

📊 Round 521 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

📊 Round 521 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 525 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 525 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0104
   Val:   Loss=0.0789, RMSE=0.2809, R²=-0.0049
============================================================


📊 Round 525 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

📊 Round 525 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

📊 Round 525 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 533 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 533 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0110
   Val:   Loss=0.0809, RMSE=0.2845, R²=-0.0018
============================================================


📊 Round 533 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 534 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 534 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0048
   Val:   Loss=0.0762, RMSE=0.2760, R²=-0.0301
============================================================


============================================================
🔄 Round 536 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0958 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0958, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0958, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0957, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0957, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0957, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0958)

============================================================
📊 Round 536 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=-0.0102
   Val:   Loss=0.0958, RMSE=0.3095, R²=-0.0032
============================================================


============================================================
🔄 Round 537 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 537 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0085
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0099
============================================================


📊 Round 537 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 539 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 539 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0125
   Val:   Loss=0.0751, RMSE=0.2741, R²=-0.0003
============================================================


============================================================
🔄 Round 541 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 541 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=-0.0097
   Val:   Loss=0.0775, RMSE=0.2784, R²=-0.0040
============================================================


============================================================
🔄 Round 542 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 542 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0140
   Val:   Loss=0.0746, RMSE=0.2731, R²=0.0049
============================================================


📊 Round 542 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

📊 Round 542 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 546 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 546 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0095
   Val:   Loss=0.0779, RMSE=0.2792, R²=-0.0048
============================================================


📊 Round 546 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

📊 Round 546 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 550 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0714 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0714, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0714, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0714, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0714, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0714, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0714)

============================================================
📊 Round 550 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0143
   Val:   Loss=0.0714, RMSE=0.2672, R²=0.0074
============================================================


📊 Round 550 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

📊 Round 550 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 553 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 553 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0120
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0002
============================================================


📊 Round 553 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 555 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 555 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=-0.0051
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0288
============================================================


📊 Round 555 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 556 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 556 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=-0.0068
   Val:   Loss=0.0862, RMSE=0.2935, R²=-0.0144
============================================================


📊 Round 556 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

📊 Round 556 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 562 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 562 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2835, R²=-0.0077
   Val:   Loss=0.0816, RMSE=0.2856, R²=-0.0121
============================================================


📊 Round 562 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 565 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 565 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=-0.0081
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0105
============================================================


📊 Round 565 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

📊 Round 565 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 569 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 569 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0176
   Val:   Loss=0.0829, RMSE=0.2880, R²=-0.0017
============================================================


📊 Round 569 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

📊 Round 569 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 571 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 571 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=-0.0128
   Val:   Loss=0.0788, RMSE=0.2806, R²=0.0052
============================================================


📊 Round 571 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

📊 Round 571 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

📊 Round 571 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 577 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0705 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0705, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0705, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0705, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0705, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0704, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0705)

============================================================
📊 Round 577 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0111
   Val:   Loss=0.0705, RMSE=0.2656, R²=0.0022
============================================================


📊 Round 577 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 579 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 579 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0050
   Val:   Loss=0.0802, RMSE=0.2831, R²=-0.0264
============================================================


📊 Round 579 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 580 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 580 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=-0.0069
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0178
============================================================


📊 Round 580 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 581 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 581 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0122
   Val:   Loss=0.0755, RMSE=0.2747, R²=0.0042
============================================================


============================================================
🔄 Round 584 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 584 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=-0.0077
   Val:   Loss=0.0867, RMSE=0.2945, R²=-0.0169
============================================================


📊 Round 584 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

📊 Round 584 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 586 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0709 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0708, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0708, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0708, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0708, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0707, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0709)

============================================================
📊 Round 586 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0048
   Val:   Loss=0.0709, RMSE=0.2662, R²=-0.0283
============================================================


📊 Round 586 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

📊 Round 586 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 591 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 591 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0071
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0152
============================================================


============================================================
🔄 Round 592 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 592 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0073
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0133
============================================================


📊 Round 592 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

📊 Round 592 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 594 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 594 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2806, R²=-0.0071
   Val:   Loss=0.0880, RMSE=0.2967, R²=-0.0150
============================================================


📊 Round 594 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 595 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 595 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0030
   Val:   Loss=0.0796, RMSE=0.2822, R²=-0.0528
============================================================


📊 Round 595 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 597 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 597 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0244
   Val:   Loss=0.0770, RMSE=0.2774, R²=-0.0284
============================================================


📊 Round 597 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 599 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 599 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=-0.0109
   Val:   Loss=0.0886, RMSE=0.2976, R²=-0.0015
============================================================


📊 Round 599 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 603 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 603 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0089
   Val:   Loss=0.0744, RMSE=0.2728, R²=-0.0066
============================================================


📊 Round 603 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0020

============================================================
🔄 Round 605 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 605 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=-0.0073
   Val:   Loss=0.0839, RMSE=0.2896, R²=-0.0126
============================================================


============================================================
🔄 Round 607 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 607 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0096
   Val:   Loss=0.0794, RMSE=0.2819, R²=-0.0035
============================================================


============================================================
🔄 Round 608 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 608 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0062
   Val:   Loss=0.0756, RMSE=0.2750, R²=-0.0211
============================================================


📊 Round 608 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2511, R²: -0.0021

============================================================
🔄 Round 610 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 610 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0163
   Val:   Loss=0.0737, RMSE=0.2716, R²=-0.0031
============================================================


📊 Round 610 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0021

============================================================
🔄 Round 611 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 611 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2813, R²=-0.0107
   Val:   Loss=0.0863, RMSE=0.2937, R²=-0.0070
============================================================


📊 Round 611 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2511, R²: -0.0021

============================================================
🔄 Round 612 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 612 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0080
   Val:   Loss=0.0802, RMSE=0.2831, R²=-0.0093
============================================================


============================================================
🔄 Round 613 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 613 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0074
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0126
============================================================


============================================================
🔄 Round 616 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 616 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0042
   Val:   Loss=0.0783, RMSE=0.2798, R²=-0.0371
============================================================


📊 Round 616 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2511, R²: -0.0021

============================================================
🔄 Round 617 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 617 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0078
   Val:   Loss=0.0777, RMSE=0.2788, R²=-0.0107
============================================================


============================================================
🔄 Round 618 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 618 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0073
   Val:   Loss=0.0759, RMSE=0.2756, R²=-0.0168
============================================================


============================================================
🔄 Round 619 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 619 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=-0.0111
   Val:   Loss=0.0906, RMSE=0.3010, R²=0.0008
============================================================


============================================================
🔄 Round 620 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 620 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0139
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0027
============================================================


============================================================
🔄 Round 622 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 622 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=-0.0096
   Val:   Loss=0.0904, RMSE=0.3006, R²=-0.0028
============================================================


📊 Round 622 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2511, R²: -0.0021

============================================================
🔄 Round 623 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 623 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0038
   Val:   Loss=0.0747, RMSE=0.2732, R²=-0.0410
============================================================


============================================================
🔄 Round 624 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 624 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0080
   Val:   Loss=0.0779, RMSE=0.2790, R²=-0.0102
============================================================


📊 Round 624 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2511, R²: -0.0021

📊 Round 624 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2511, R²: -0.0021

📊 Round 624 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2511, R²: -0.0021

============================================================
🔄 Round 629 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 629 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=-0.0078
   Val:   Loss=0.0885, RMSE=0.2976, R²=-0.0113
============================================================


============================================================
🔄 Round 630 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 630 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0092
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0030
============================================================


📊 Round 630 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2511, R²: -0.0021

============================================================
🔄 Round 633 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0922 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0922, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0922, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0922)

============================================================
📊 Round 633 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=-0.0052
   Val:   Loss=0.0922, RMSE=0.3037, R²=-0.0248
============================================================


📊 Round 633 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2511, R²: -0.0021

============================================================
🔄 Round 638 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 638 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=-0.0127
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0073
============================================================


📊 Round 638 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2511, R²: -0.0021

📊 Round 638 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2511, R²: -0.0021

📊 Round 638 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2511, R²: -0.0021

📊 Round 638 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2511, R²: -0.0021

📊 Round 638 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2511, R²: -0.0021

📊 Round 638 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2511, R²: -0.0021

============================================================
🔄 Round 646 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 646 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2849, R²=-0.0149
   Val:   Loss=0.0783, RMSE=0.2798, R²=-0.0018
============================================================


📊 Round 646 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2511, R²: -0.0021

📊 Round 646 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2511, R²: -0.0021

============================================================
🔄 Round 648 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 648 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0071
   Val:   Loss=0.0732, RMSE=0.2705, R²=-0.0120
============================================================


📊 Round 648 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2511, R²: -0.0021

============================================================
🔄 Round 649 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 649 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0096
   Val:   Loss=0.0830, RMSE=0.2880, R²=-0.0027
============================================================


📊 Round 649 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2511, R²: -0.0021

📊 Round 649 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2511, R²: -0.0021

📊 Round 649 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2511, R²: -0.0021

============================================================
🔄 Round 653 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 653 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=-0.0040
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0359
============================================================


============================================================
🔄 Round 655 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 655 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=-0.0087
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0059
============================================================


📊 Round 655 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2511, R²: -0.0021

============================================================
🔄 Round 657 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 657 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=-0.0130
   Val:   Loss=0.0857, RMSE=0.2927, R²=0.0022
============================================================


📊 Round 657 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2511, R²: -0.0021

📊 Round 657 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2511, R²: -0.0021

============================================================
🔄 Round 661 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 661 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0114
   Val:   Loss=0.0791, RMSE=0.2812, R²=-0.0007
============================================================


❌ Client client_2 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8690 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8690 {grpc_message:"Socket closed", grpc_status:14}"
>
