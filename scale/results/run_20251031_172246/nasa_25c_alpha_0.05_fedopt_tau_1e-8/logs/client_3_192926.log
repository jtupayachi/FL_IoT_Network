[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9bff8192-a953-4421-8da8-3c64f2948691
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 819bf80b-071e-4965-b7a8-d4d35123b474
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be796d28-475a-4d53-bb24-35cdac531751
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35603d42-ca19-4e10-afba-7230e07d84c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 867b4585-371a-453c-ac86-3997394fbf32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8640e4c0-b16d-4698-bb6c-b0f5cd8c345c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a637a59-ea07-46ae-8cc2-4860afbbcb38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ec84945-3f08-4723-b1c7-6f13e6cedb69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message caaa553f-45df-4a31-904c-177a561efb1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f6373e7-3b6b-46d7-aa01-d92079ac081f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac59c9d2-f790-404c-8f9d-e82cad0e46c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd28f1eb-64a2-4edb-8e7f-4304149716e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ee5e164-b3d0-480f-a9d5-e31623c96788
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ea812d2-7b50-4666-a1e5-d4f124ee838f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5841b964-d3c4-43e4-9145-c4666858cb0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30ffa4d1-4641-4bfc-8a5a-158b288965c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c4a50c2-0930-40b9-b5b4-ea4e9622268f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message beda7099-2ce2-4a8a-b1b7-b85a8a4fab7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 046d11cf-febe-43f0-b5ff-aaa377114aa4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8f8642a-1fe7-4d90-999c-32b2b76385df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38fa5fce-cfe1-4721-9c74-2f6079ed4f5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc08e4e2-13fc-4bdd-a9c8-5cc9bf17164b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e29bd767-1295-41fd-b677-9476f3c3c2de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a2c71fe-3912-4e51-b849-f1de3b702a87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 434c8844-2a43-4b6d-a3bc-6922057d3cd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49d80eff-2f62-4517-b6f1-e4e308e31751
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b00ea6c-003f-46fc-91b3-8e078648fc6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf5b43a1-1503-4da0-9f4d-a17521723860
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6d7a833-76ca-4f30-9727-0fbc6e895722
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 687f419f-ee3d-48d2-9532-db986773ded1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c432a60-9907-4bef-8df5-a052b72e042e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 426f8097-a214-4e0f-991f-62d50e0ebb59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13397d1c-dac0-4a12-9a28-39f4f67776e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message adeee804-03f6-4052-b457-5b8e67082b6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 490bddf6-1789-429f-8969-8166f3b6b1d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c408e934-95e1-47ca-9f1f-c1381cf5f56b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12d80a3e-ba46-4c7e-bda4-58f66636cbd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76713031-083c-4dcd-ad17-f450bd68806c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8096fc23-5027-40c0-be6f-94a334dd880d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ac8e718-5abb-4086-b6c2-d4ad54767b67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1e9e7e8-9327-40ee-bddf-78d31703d2ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c0eb5c5-8c16-4a33-8451-454635a04b2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7270409d-4bae-4c52-9bae-f2ddbdf9f864
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63227946-afce-4ad4-9552-12de5a8f928e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 481772c7-ae08-4f6a-ba88-4c7bcc6cd6b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96f7da01-f4cd-4f41-a918-657d6f028f53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 883848c0-9548-47b8-b125-e48e8467ea20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00397fa1-d5c4-4f13-bf1b-c49329c8ddf8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1b843ae-d958-457e-9e7e-4a2cc2de6cf7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b076941-d62e-4fc9-9742-322d7d320f65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34fca761-4f0a-45be-8043-3c28e7df5211
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df1f3e8e-f502-40ef-8fbb-3dcc9bacdec5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 033c698e-a82a-4ca1-8717-56e8793abe53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7e45f15-cb5e-4d94-a4fc-9b872017b170
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d07e129-80cc-43e7-be2f-7b7de0aec666
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d1bfcce-fc6a-4930-970e-0a58e245ecd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bafeae3f-ff91-4a7f-a31b-0197e17bad76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40276a19-dbf0-473d-b42f-efed4aaa015b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed4b39ae-154e-4b74-bf89-6a9b0db36db5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 492b777b-d8a3-4890-ae7c-0012ea3ff419
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e2d5464-1c13-44b9-87e7-19e698b1a6d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78239cb0-aa8b-47e7-9121-ab3b92f69069
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 303e3562-b458-4e07-bca4-adccb4675102
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 506ca486-1522-46ce-a952-4520b03aab68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8b5afbc-606d-4626-9e38-ac8c72aad29a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ae35ba0-a95e-40aa-a5ad-79003dcdacb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26a68c4c-aa4e-4db2-b12c-2375a847758c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13e601ad-84db-4c89-8c99-19d4deb60bc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f677566c-2345-42f7-ae24-279da9c6faf1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29fc5ca7-db1d-41db-9796-ab41d142b68b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 111e447e-14af-4529-869f-29a35affdd31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc8f60de-9630-4df3-8a19-894e9449eb9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7ea8de1-8bef-4839-9e9f-1929531ee7dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e24b984a-4800-49ba-869a-6c47fee3e7a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c6def27-17d6-4456-b787-3d8d2c08cae9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b84872a1-f2f2-45d5-9a98-918f51544ac9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc7155cd-8ca7-4305-a665-1abef4fabc93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f60ecb72-c1b0-4d09-b8c0-51c137a181d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db783723-e2b4-4728-8416-7f3e3702a41d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a056393-329d-4446-a3eb-821240ef8389
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04914ce7-550f-4f0d-9a2a-4ba670f345d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a2ef47a-dc4a-4179-9cef-04a60fdae042
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07a90f84-810b-4d13-822c-42a4bd4b3e63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 216e24b7-4723-4ce7-bc55-2bc369114625
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 054d9b56-0390-4ff6-a7d9-538d6c00b632
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d38512cf-60ac-4a91-8c83-3e43333646ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 784427fb-eb01-4e5d-8220-fa3540a3f444
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message baf3c953-b0b2-46c2-b933-08774efa02d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa61686b-8e81-4862-a72d-81b689e3e280
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3ff412e-423a-4b99-9795-4620cd47c7b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f5f9102-dc51-4823-82e1-01934c74be31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b43fb391-0bad-47ed-9b5a-11679818b4db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79f46991-5269-42c2-ae00-3ef43296e6af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21083c80-e9fa-4a41-b342-b293457c404f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5def5789-672f-430c-99f0-56ea4f6f0645
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e89182f4-6446-4aec-b60e-da7e06952705
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 765a9cc2-4d3e-44b8-840a-708a22e3cd58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a0165a8-df1e-489e-b214-47e65c2a9b17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6d56602-f70d-4f53-b369-70a2c44b643f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9cb8724c-0b21-4224-9820-666260c2ab5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5caaa937-d364-43c4-8b60-20ff767d9da1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2098b58c-97d3-492f-a43c-7194e56e9ff9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e96e154-2915-4c36-9e4d-0cfd3a4ca0e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47631473-d718-4817-b820-e9639e3ececb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6ad0a6e-21d2-4c21-8249-3df36aa6c9e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ffcb455b-5494-4b3f-a752-deb95dd4e052
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08c38481-26bd-4e6d-a2a9-a2e72ee8c553
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1519129-7428-4b3b-bf40-4ad565b9d5ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f78924b0-4576-4c5c-a7ce-a95ad9dbf7b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c3b5a15-85c9-4c2f-8485-c0b7ebdfc729
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2382b064-bbbb-4b4b-af9d-8f36f5e2bc62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a413751-26b3-4563-befc-022ed0199ef1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 958a4014-b2e6-49e5-98b7-e68aefddecab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc501341-0d0c-431c-a678-f9693c54fdfc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91951b47-29ff-4e4d-b9d1-2d618400f276
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message faaddbe4-f87b-4905-a2a0-0e423c9f25e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a960867b-0350-4dbb-bf1d-97c68d9ea4c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4af7699-36f6-4dbf-bd18-7d62cfe55db8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b0c7aaa-cfc0-462b-bea0-981ff05e187f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e40cc7ed-2d1a-4818-8398-da5e67e1e737
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de511584-e33a-480e-bd2f-d92af4f44831
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c93355f-9964-404c-883b-48390ae959e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2df5a6bc-5dc7-4498-bdf7-33c2816a14ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a7011fd-29cf-4fee-a6c5-b4e1edd4ed86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15a946e5-ad0f-40cd-8918-a17415d35345
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a8307f2-25f8-4750-99f1-98a970880e2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9f96950-4601-40fd-a46d-51fab1a000c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99cef8dc-34bd-459c-8d97-45038dbb269c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0fd60d1-d4a8-4f63-8d4d-e735874e281d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9391655-dd26-4405-bc95-1ff47458be25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3353bb38-b2b7-42a2-a48a-8891e5379e8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a77c353-76e7-4310-8382-3424bbd4bdf4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64d18841-0b42-438a-83ce-39338d402423
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a62d06f-0a8d-47dd-9b84-3ced3af561e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0dba999-b2e9-4f7d-839d-43b8a40dd002
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 005b47b9-4feb-4465-b686-86f9aab886c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49cb2c99-4206-4735-a0ec-65ec9ca2c144
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e08642ce-6f87-4375-9a31-1f8ae158d7a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 542d82df-a59d-4e02-98ac-cec5e0ce191e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 652ee6b1-3f68-428a-95ac-62738be9792d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61765ece-a444-4229-b4de-2f65b4e6deaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30b1bc49-055a-48b8-b779-12ff68467738
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c36b05bc-8ceb-4d98-b924-a11d7d71f08c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67f89d71-0aaa-4c23-a9ba-e5b0c389bd41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 950f378b-2d6a-4fb2-800d-831a2f7597b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7706696-79eb-4bdc-a0a1-213ad6c594f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f3ad5f1-2a0b-4764-abfd-01072da7b456
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61926bc2-eb7f-49b0-a75c-97df69e16e2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20b1c33a-8ed7-4a89-baa7-95de481b634a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 406fa1ab-0fa0-4ec9-b441-4403f0bdf681
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7349be8-9f1b-486d-838f-6bdbd66a5f4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb0501cd-0be0-404f-9b72-b28f831f8b10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6ea2407-e380-4192-a029-be3f4e8a5479
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9418bc3-52f7-4216-8fae-a68c946c626b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3064767-4da5-4c30-a175-2421fe021a5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d3c42b3-acfc-4799-b9c0-3d672adc97bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1434059-ffae-4c18-ac5a-32430b1f49a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c893bc72-9ffa-4ded-a95c-9bde5d6e363d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63ea4c34-02df-4e30-80f0-2e014567170b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25c57890-d54a-4675-97cc-d0815f5b378c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62c66e13-9e01-4937-a694-faca3068b050
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dee9d2bb-dd80-40b4-abee-5c6eef71d888
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16cfb1e2-c1f4-4840-a2cb-1d6003825eb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67618a96-af97-4002-bde7-41fe7dc2a41c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5229e52-4026-4de3-ab9b-b651c8f540a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c58f1f20-7be0-4099-a1bd-97a9deddc21e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac0d3df9-12f7-4329-aa50-e2ffa77e63c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d3ff31e-dfce-4468-8f0b-a0c6fd5750cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c1aaa36-f322-4540-aa56-41e9fbd0ef71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6be50541-7003-4e4d-b978-e8f60a42f3db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 054177aa-432f-4d7e-8293-681e6a60ed0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71be3638-847a-41b1-9018-dbafddc2ac62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b5d8eb9-8d9a-4048-b221-63d932b8746a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3dd2cda-bd4b-4329-85b2-8f601479060b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35a0abee-dbd0-48ee-8778-354460651b1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67e11c30-d5e9-45c3-8b22-f2a37bdf5145
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e60cccd9-c68e-4975-a8ee-fe09b781da32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4e34c20-fa5f-41fa-ae9e-64a6ff4c5d47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db177aed-612a-4d62-8c4f-ccd82ecd93c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2d78804-a5ab-4f98-b3dc-2a0403b106c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37d8525f-0ea6-47a7-84ba-2bd8083b845e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2513745d-7608-4922-883d-eb0c5d2afa05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32a883ac-3330-49b6-b345-dcaebd79bf16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 432656f5-5772-4a33-87cb-4348d8a817be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a344cc9e-1de6-441c-9185-2c643a63921a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c32f3d41-09be-4a30-a3e5-f9d24254b454
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98431952-dfc1-4d00-9c8b-47a80569be98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ef1fc38-8f7d-4060-8e4c-417a3f22073b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d86c0e84-683f-4fea-a519-9596cac1e058
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1d28cee-21a6-4c87-82c4-7a9833580230
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa02cf1d-391f-4ed0-8985-2b21e08604cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 432a610a-31e5-470c-8672-1008b639df94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82af14c4-c1a6-4636-948d-9e0039e87fac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6495cb7-72b5-4b2a-a6aa-e50cd071e7c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f60f4567-6d86-436e-ad2d-ab99096344f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36ca08ca-5609-44ec-928c-d6387bb53501
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2725c7be-9943-40b1-9e53-72998e21b0ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 693b9005-418a-4888-ba68-5568d7466e45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 359f8d6b-2710-4d0c-b4ab-0388920f1801
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a787f401-62d5-4466-96fc-8b13a07b5ec6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10171c1e-85d3-410d-bced-e9b9ce25d097
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f7ce164-95fc-42fc-9331-d8f870648d87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message def4752d-cd0f-41ad-b24b-18f03c78ee9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3aa866da-87a2-47e9-8d66-3b85ad806d60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c68ed7e2-3458-4b72-ad86-6ecbabc02b33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca46baa5-7956-4864-ad37-c47f4bdddb97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 108c001c-ef54-446d-b525-d04acbb824db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae7bb368-bca6-4933-be05-f2aa8a751a19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e83da449-fa12-43d0-9807-42be08cd4839
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08f19b34-8369-4600-97f8-58c22e558b29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4db70eb-8be7-4f05-a043-9a428ac53344
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3fd25f04-e340-4e32-9b60-fbebdcd5df2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1061ca6c-9e53-4873-8d9a-9e4fe6f75259
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3f8c491-577e-472b-bb78-cae2d0ae510f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35763360-a168-4850-9243-c4907433a830
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1243a862-ca76-4f14-90a5-f72dbab4e303
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85f3a7ce-b5d9-4dce-9c8a-a6e7cb07671f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7be9dc8-6d79-4bec-b1b4-5ca5982fad65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5e30711-4642-4e82-afdc-6faaae42dcf0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05e36cdc-5a3b-49ba-a581-1a8781b67774
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98b392ad-47b3-40fa-9083-2287f4ca2273
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9af8eff5-d908-4b96-9889-2b5dd94e067c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 024f1e43-5a7a-407b-b1df-ae3909ceab04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e92b354-e8da-49c1-bc20-ab12684c5976
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88929ef6-9a9f-470d-85fe-9304e13b649e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message deb30233-a92b-4e97-bd1c-247766bf8989
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10717ad5-0c32-43f1-869b-caea781b31e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb14b008-812f-4a3b-a963-c43e87ca5b48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 131ea807-dd04-40ff-9f3e-a38cf623b00f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46706ce1-6fbe-4df5-8f5b-6b8a7a464874
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b76a5558-7e32-4f3b-995d-cbcecb47b329
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f626092e-67ec-4536-a8f2-2126ec1478f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e09fb65-3307-4599-94b2-19feffb10130
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8655eb40-eb42-495b-8b5d-beebe9b5c2dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ef6a110-05e0-49d6-91d6-8bd65708258a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae7ae459-bcba-4fe9-9136-c825da387e97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2786d669-572d-47c8-a083-14c067c5a962
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97712e78-a634-44da-89e7-fea0026b2569
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8823c0d2-748f-4b20-9346-5766b99fd146
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5531d960-4f4c-4c10-9611-1bff6eae7f98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39978571-4709-42e3-a188-e6a50848cc6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb350366-bebb-4fd5-8473-3ce463133b63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d55de096-1f7e-4a84-9a77-15f5ebdbb781
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e3a9122-222b-4d89-ad49-ccb991abf30a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08a1fb08-ccdb-489b-b338-1acb088ff704
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a29ed59-78d1-4fda-a981-8b79e80ea5cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae040ba1-3d16-4a86-aefc-c4fe5014fe3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90d6a10e-9fdd-4a63-8c75-5cc598b4e3b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8157db35-d067-4cbd-9ff5-d52791033c54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2f31050-87c9-4248-b957-20bbbc660046
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d0a50e2-6512-4a59-8180-2fa974c5ef99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f6ce0d4-9369-45ae-b932-2cff6f497614
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f334bd7-3d2c-4d74-ac1d-22ba4e211e1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 298be061-accd-458c-866e-4c8457d40bc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de489e60-af72-4935-b6bc-1409c0e60f47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c90aee1e-2386-4411-aace-a87f9ef6bdc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b015872-6ce3-4a45-9ee8-a3ef3a7ed694
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bbb15de9-d1db-4484-9ae5-854ceb565420
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a938c2e-8a88-4899-a8e5-419fce3e4c5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd263d7c-a325-428e-ab48-8f82ee1ac540
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46ec2995-03b8-4bf5-9ca2-f6bc7246c71c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e011f56-cab8-4165-9a4a-e598981b932e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6bacda69-3c29-482c-8f69-d203dadc0fcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd24162f-755a-4fda-963b-57cc6b33b6b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62d92c94-6e33-402d-a59a-ce64867bf69e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c618c15-45e2-44de-81fa-1c0f07fc0770
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 728c6662-6342-4aca-96db-eaff57ad78bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0a98ded-6f1b-4d81-95c8-b219d9c8619a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2093531-6948-49ea-8508-1fe798f7843a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad58e8de-5df5-4924-8a52-8d024423f13e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b45cf80-0ac4-4800-bec1-bc2b3724b013
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10eea292-e676-4dce-87e1-f460ff57f4de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea8e34e6-f9b9-43ee-bc93-10006279c84f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b18ddafe-d215-48dc-91bc-35ad63d95289
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6c5ff2a-cc78-40a2-8543-2fa1c051a1aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8152e061-d036-4b5c-acb9-29a4e846a51a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 203e0a2b-5064-4364-96d4-0066f62cba35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f0e7bb5-fef8-4d9c-8fa8-58d17cc8549e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6cf5a8aa-df26-4371-94d4-5452213feb0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d66e6a3b-a19f-4a77-b8ac-8bdb2023d8b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90f113d7-6bba-4039-856c-69be918ce457
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5be2fc8-3197-41fa-9f4f-aaa47ac56e09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05398557-5538-4fcc-8d9b-df6e054b8383
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 567770c2-bfdf-4055-817a-c566d061313d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29c6c1fa-caeb-4360-b76f-bb10b2c24207
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4bd3e9a1-f260-4f4f-a881-f2be429773dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93266240-06f5-410d-9abb-2933dcc67731
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 260ad423-764a-4a89-bcba-9f5839e7a6b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e17a9c5-a858-4854-8f5d-b38f2226a3f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a430ce6-a896-407b-821b-416e3bcc856c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76918a10-c7c2-4907-9597-030b1b271719
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7a42424-e988-48b3-9491-317a6c3ab1eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 160115c8-da3f-409e-a58f-eaf6ed1a3495
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d18cf37-8431-4ca8-accc-e3e75efdbba4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f72a6780-d2b2-4f7b-accb-8359d46ef435
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f51cd384-6021-4263-b623-54018cd22c4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1207f712-06eb-439c-9bc8-52f72fe1f21d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22ca6330-51e3-418f-9daf-8c34aac00130
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ba4b5ab-6e68-4e42-bed5-156637bc6241
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc5a65fd-872e-4e86-bb9d-9664b0110928
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f782e33d-12f0-46db-8846-d42e400cdc1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77a61ab3-bdcd-4e60-acc2-9143f55057a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fed059be-c608-48d8-804b-6a62027cd210
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85a72d3f-da39-406c-9bed-0110c292e2fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d807309-ecc0-4f08-a552-c44d5187476d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4daba93c-f299-4aa2-858b-6045aba7d203
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54f01738-0ee1-4c61-9954-2aaa5209a6e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d887926d-9b14-4ec0-9d8b-2878f0bc8615
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10f5825e-1496-4a5d-bcae-eb5c08c33e74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7b728ac-bcb5-40ee-8f44-e7010e449570
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa4b608b-43b6-4f6e-a1c9-60c061a89075
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb4ea354-1fe2-4a5b-87dd-a3cf9d58d368
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df26beb4-ab79-4d03-b1b4-1f7598fbc297
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f499fb78-8dcf-4c38-a0d3-47a404d830b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0912d9b5-78e7-477d-896f-519f685a359b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3c6bb63-26e2-4e14-ba92-493b2209cf49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ae163a7-70d6-4546-a798-b13b7b0e7d90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c60061b-15d2-4dbc-a125-a036d1a8b176
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b33fc4e-5092-4bc1-97bb-47a5ff9beb9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69c4b63f-9f30-4085-b9f1-edcc8458d05d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73fc6543-de81-4a62-8b24-74f95a4de573
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d95a9b7b-cdde-41cb-b442-c6376110c403
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ba0a844-037c-4655-bf73-69337613d403
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0308aaf3-791b-40fa-9939-b6c22f132c72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 572d2cc2-bb23-493d-b898-4b160dde5d32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7698bb10-4a3b-4b62-8832-443ea2f62d63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b9d7c7b-bef8-405a-a69f-7643a521e7db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f6a38d2-7c0d-43fd-994e-7fcf23a5f4d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08889367-55d6-4abc-8fca-71483553b2c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0f374d2-a85e-4a75-aa00-a97297746d3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c152cf04-f343-435f-b5df-a70b2f96ebcd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5637a2ad-66c5-4c17-b9e7-90e1df35e126
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2536e21-3019-46ba-9a02-30ca0a975493
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d9963c6-8d21-4d6a-ab12-ca2e5fd96e84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2fdf7177-1b9e-4664-b0c5-2426b697fcfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b17d0f69-69df-44cb-919a-a6183ad928c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2155d0ec-2677-499a-b91f-63128915f2c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 361eb01a-a432-424c-8ad8-1156db9606a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa820f3c-72c2-44e6-856b-2f42418c609b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77d65a9b-9784-4f14-b970-9dc11f8cfd7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7de12db4-9342-4406-a534-59bca6cf57a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f4687a4-77cc-4258-bb25-131453dca485
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b645be3-c96e-45a1-85f3-8ce0a9672c1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6dbd5526-1b5a-4513-96d3-10037cc76cd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c220d184-4ae1-4258-b709-4a7f76f1c3b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed1cda1d-07ba-4d24-9be9-f28df6015aae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 997b9339-254b-4a07-b99d-093330472ffd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ce0a516-4484-46c0-9b1d-17367f5be866
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 723d5435-b14f-424f-b151-fad60a0c2633
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3f560c4-a0f5-4a17-8f1a-685c14a83481
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e5b589b-8193-4708-9e95-43a8c7a714b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b602c83-181d-4b69-8397-b0e7f426af83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3e906e0-d225-40c4-9f71-cc153f7363cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cdb9895b-c97e-4b15-9c69-6558abc3898d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af0c5a14-25a6-4f62-b9fe-d91968bd2217
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16237670-ed7b-4f96-b63c-74fcc330b7f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e81e2b60-5b10-4154-b1ae-b4e94ebf4c8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f03ecb4-1cdd-4cef-8e24-5dfb5f7c37b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0cfd0c0-d194-4601-87e5-185b13934d47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79ff4b72-15c9-41da-94f0-d0e156d9cf6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68ddf83e-ec83-437f-9c3f-9f85aa430c9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9cc79c88-dbfa-42ae-bcbe-4604af97fe16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 010ea76f-7129-4867-a872-8f8098a84e52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c995e1d3-9927-45e5-8b98-b8a80d4525b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed1b1ec3-d652-4e91-805e-80e71b53569b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7c84f13-471c-4464-82d0-e453265ea71c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 781e1b9e-d9cb-452c-952f-17e0ed8c5f5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 713c9ee0-edd0-4989-a198-983de9d53dfd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message edc181c7-e7c6-4d32-93c6-9fbbab5545ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b04ca7c9-6c01-438d-83ac-07ab498ea136
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b0d16d7-693a-4541-9447-420d718e2203
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b112bbd0-a823-4820-bc63-ef4379ee6916
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message baa342b6-3b88-4d50-82f0-cda1db54dc32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 093e780b-b10b-4719-828d-b8937988610f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af2c0463-53ce-4316-a1d1-0a5213895376
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6f36639-b938-4352-a404-35e16616be8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1415a39-440e-4787-9ef5-9eced5594246
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aabb9319-3a84-49b2-91f8-ab28e27b4ae6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d3da2aa-b09f-4251-8591-949edff2c796
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb5c4254-b827-4c00-b798-d9f5cbc2b19c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab7a62ee-985a-452e-b18c-e4781c4a424b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db824f57-a5e3-485c-9917-8cd9295c2efa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b87610c0-2d6a-454b-816e-c4b0f39f2320
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32046c83-e251-4d65-85fd-f5eea7bcd42d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5249c7c7-b669-4d3f-9f5c-e8853b6bd874
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4c5888a-9ee0-4d9f-9a70-624bd0737b8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d91a682b-eaa5-4ff5-b29c-b07bcd51220d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7830bfd8-0510-455e-b96a-357c1c8592a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9793dc16-4f33-4b52-83fb-3efdb7db8c97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 059cc9c8-0c24-4777-afa7-f682f00c9f65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e032b0d-e171-41f6-8b1f-017d1eb447ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5fe38b85-f88a-4794-b02a-28ecc8e7ec75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 081fdd97-551f-44ef-ab6b-33d9a47dd02c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3f4ee76-7c89-4220-b30c-99731e270d1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3e2fcc1-d9ef-4d10-8eb9-5215a03dd581
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78a05c1e-ae02-478d-939e-189945881f49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd3393a3-e5a1-4090-9edf-3eca8a09a934
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a42f5c2d-fde2-43c4-aeea-51afae4b7971
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9670f79a-5d90-4a0c-929e-53421b75f918
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41f5783f-6fdc-4db2-8dfe-2da04417cff6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e6defbf-b6a0-4637-82e3-b3c9d6cdcd7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba091b4a-d8d7-4edf-87ea-2867a499e13a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f61fab4f-a417-40f0-9cfe-9690f1843f23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85e1362b-067a-4ebb-a44c-6fb93a1832c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe1169e4-4962-4044-80b3-359aaba4af02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfe2813c-775a-4797-86b3-79d850731a00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9923902f-3f8c-40ad-a85a-c071aa90e7b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e20644c-b574-434d-8280-d43b3a0e12c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ee2d607-f44d-4392-9330-d40c6109b376
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 520995a7-a620-416d-9bd6-e7f1a6c53793
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e0bdfdd-311f-4b21-8a48-23acd8affa3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f22b28d7-e11e-4b27-a5be-bf1a5e46f95e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c027c284-bb5b-41fd-a450-fb74cdeb89a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58e5d0f8-5aeb-44bc-bf14-1178cbf11def
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dbb20c84-42dd-4f12-a0a8-3a8daef59364
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5a3a66f-0c5d-49ce-927b-670d591a3b45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0290324d-65ca-4922-becd-247cb9e51f5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55114703-3619-47a5-9f90-726ff45f463f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da02e4a1-dfc8-45ea-9ef5-2dac235ec765
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be65bf4d-f56e-4af6-8eff-8e6ac011645b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4a463b2-c4bb-423c-a4c7-be27b4174f0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d202e33b-6a3c-47a9-b614-3208a7696226
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 757d240a-ea23-44c3-b642-4d234cf2c359
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d146a84-2821-4dcf-9738-a7b2607cd251
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 454c880f-c58e-44dd-95d6-8fd83749f459
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65dc7aac-4d38-468a-94cb-74301561a68a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39ea0a7c-1b8f-45df-8f15-9eba50e8454d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bca96e06-cb0e-48e3-ab93-1c5e96898b2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 658bf31c-817b-4e49-96b1-2a31dce3071b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4bd6c37c-a4df-43fe-a640-987af784d7bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4467842-a096-4260-a34c-c9a2d275b1d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48c90651-2605-4f38-b5d8-1571e95996ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7440565-6894-4871-9b57-f34950b582c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58221617-8460-4ddf-9f0d-7336f4eb5f19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72ee7c60-8bc6-4aee-bde0-a49e3d127477
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24852c27-e804-451e-a347-1ad01b99d426
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8cbcdc22-d1f2-4be6-964a-39e9d387f57c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 427188c0-116f-4319-8945-6bb3e587d3d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dca3cfcc-dfd7-4f48-ab5a-94f4a1ccc8a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66d1f2d3-dbbd-449c-a7b2-17115f319538
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9890d4c5-fa59-46aa-bf7a-b8ffb69bdbab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95808487-302e-4ea0-a126-5dba25be9e32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1a356e4-e3d0-473b-b96f-e30f07b9dda6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0e5f2df-bfdb-4da8-87cb-2879e7eb393f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 415640f6-91a9-4ee7-9537-f6218d0fcd8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9b085e7-a048-41c3-89f1-41b79a8ad440
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a73d068a-a6be-45f4-b872-130d4f5a5cbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e47816d1-bc6c-47aa-959f-a17727c4e3b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e8e0c01-20f1-4060-8b76-9ef03550d233
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f8c9bbf-2ea8-4a5d-b354-f7af19c49d0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7aa3fa3f-83d0-422d-bfe9-75302b1dacb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 354936c7-866b-425b-8783-3d33d3c00cf2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44ff9647-b459-4698-b45d-a7f702c71518
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8701a5ef-ffca-442b-aea9-365c2b73fcbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9831fef-7f6a-4c2e-ba1d-02b5c786add9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83048b6b-d617-42f1-a85f-266d8a2e761d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5182901d-fe3d-452d-a41f-dd6d60e2f473
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e04aaf5-a79b-4895-a1b0-99460ef65ddd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f49e463a-1cc2-48b8-b9ff-3075ca513efb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb212446-5b8d-46c7-8dc2-df1778cde435
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e49593a7-4f94-42c9-bb68-58dfb2862132
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 389057f7-1bef-473d-8df0-306ecae67a5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 238e1d97-d1e6-492c-96ca-b2c1a130dab5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24033200-e507-49f1-a178-1cda89ba553a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4360b8cc-934a-49d5-8c07-b9add27a5614
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 347d5f32-8612-484c-b52b-d38d9ae52c64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71ed4b5d-3b2b-4cfe-9286-e26cff5ed3f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69bd10c5-8d9b-4184-9703-3217e44caad8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d65b55e6-f4f5-4d3b-9057-afa2b1965f78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message acf22762-5918-49e3-8c2a-14e63daeaa60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ac975fd-6fed-43a4-bb7f-570b84957972
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f2f2ff8-7599-4f48-bd42-4c4dd5fa8a05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8b515c8-dd1d-43f0-83a2-84db06b5ad9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 962c3c73-bf82-4d99-808e-8456121da6ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77355198-ed65-4373-ba16-c507bacb73d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5305bd8c-1c6b-40db-adbc-afb872ec7502
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32732727-57d4-42b4-91ff-10ee802c7d56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e3d6bc2-bb97-4f0f-996e-bce8c19461c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dab14543-b2ff-45a2-ba34-5ca4397d7e66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae91fdbb-df39-41a9-b099-9740a98c2102
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 405c66ac-b5b0-468d-b267-93edd25684d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f9a0083-dafd-4424-977d-2119918ac3f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7f0efbf-867c-49e4-919d-ecccf9387b66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 282303bf-8eb5-4273-a1f0-fc96604b72c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0a7080f-40e8-415b-965d-770f913b2c03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c44a2717-a5bb-435a-933b-1328d5d647b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 917bdff7-7604-4ae9-a27d-cac0057b7150
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03660fd8-77ad-48d5-9030-7a0d8f369f0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73bc506c-b62e-45d1-9570-91368bde7bc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df700865-247d-4211-a34d-312d0c8a2689
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ce7d8c5-1397-41b8-81dc-8f4b939d8bfa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a348572-7c2d-43f0-a97c-168ba5cfb899
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eea5ff34-dcbf-48fa-b58e-aa11a0085063
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 944bc498-5182-4aa9-a1a9-6a808cdc1a60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b64ef040-2b52-4ca4-bf16-81b1455f57ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1cb4cf0-4063-4263-bcfd-8ddc3abdb9df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9629d56d-210d-453c-8729-edd6ae7f9f75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1927bc0-d043-4bf3-be16-9f36baf28ac5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5bb515d-945e-429c-8dc0-cb38b16d7bc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d9000fb-3703-45c5-9b73-cd05317503fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f473a31f-aaf6-418a-9d7a-37954727f4d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee047677-99bb-4d7e-b887-3e6486f8487a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d60840c-794e-42a2-b512-7fd0a90a8ba5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3347ead5-639b-4cbb-a990-c7d7ac234b39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d98e43a7-dddb-4a38-a5fb-101955ef21c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae26a58f-cbe1-4874-b724-4076d443e846
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46cd5142-c342-4844-9d0d-69a2df3c1c79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4388b209-2a08-4a1c-857b-a53b136ddd84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 737a7a40-d2ff-47c6-92b3-f727e5325bb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8bce008-27f5-4fe4-992e-5226e3610420
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8690 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_3
Server: localhost:8690
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_3
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_3/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_3/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_3/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_3/test_labels.txt

📊 Raw data loaded:
   Train: X=(4483, 24), y=(4483,)
   Test:  X=(1121, 24), y=(1121,)

⚠️  Limiting training data: 4483 → 800 samples
⚠️  Limiting test data: 1121 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_3 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 2 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0788 (↓), lr=0.001000
   • Epoch   2/100: train=0.0817, val=0.0792, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0818, val=0.0796, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0817, val=0.0798, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0816, val=0.0800, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0807, val=0.0806, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 2 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=-0.0018
   Val:   Loss=0.0788, RMSE=0.2806, R²=-0.0091
============================================================


============================================================
🔄 Round 3 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0737 (↓), lr=0.000250
   • Epoch   2/100: train=0.0831, val=0.0737, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0830, val=0.0737, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0830, val=0.0738, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0829, val=0.0738, patience=4/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0828, val=0.0737, patience=10/15, lr=0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 3 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000125 (1 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0012
   Val:   Loss=0.0737, RMSE=0.2715, R²=0.0002
============================================================


============================================================
🔄 Round 4 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0798 (↓), lr=0.000125
   • Epoch   2/100: train=0.0813, val=0.0799, patience=1/15, lr=0.000125
   • Epoch   3/100: train=0.0813, val=0.0799, patience=2/15, lr=0.000125
   • Epoch   4/100: train=0.0812, val=0.0799, patience=3/15, lr=0.000125
   • Epoch   5/100: train=0.0812, val=0.0799, patience=4/15, lr=0.000125
   📉 Epoch 6: LR reduced 0.000125 → 0.000063
   • Epoch  11/100: train=0.0811, val=0.0799, patience=10/15, lr=0.000063
   📉 Epoch 14: LR reduced 0.000063 → 0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 4 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000125 → 0.000031 (2 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0001
   Val:   Loss=0.0798, RMSE=0.2826, R²=0.0040
============================================================


📊 Round 4 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2483, R²: 0.0023

============================================================
🔄 Round 5 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0732 (↓), lr=0.000031
   • Epoch   2/100: train=0.0833, val=0.0733, patience=1/15, lr=0.000031
   • Epoch   3/100: train=0.0832, val=0.0734, patience=2/15, lr=0.000031
   • Epoch   4/100: train=0.0832, val=0.0735, patience=3/15, lr=0.000031
   • Epoch   5/100: train=0.0832, val=0.0736, patience=4/15, lr=0.000031
   📉 Epoch 7: LR reduced 0.000031 → 0.000016
   • Epoch  11/100: train=0.0830, val=0.0737, patience=10/15, lr=0.000016
   📉 Epoch 15: LR reduced 0.000016 → 0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 5 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000031 → 0.000008 (2 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0008
   Val:   Loss=0.0732, RMSE=0.2705, R²=0.0008
============================================================


📊 Round 5 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2484, R²: 0.0017

📊 Round 5 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2483, R²: 0.0024

📊 Round 5 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2485, R²: 0.0018

============================================================
🔄 Round 9 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0753 (↓), lr=0.000008
   • Epoch   2/100: train=0.0827, val=0.0753, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0826, val=0.0754, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0826, val=0.0755, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0826, val=0.0756, patience=4/15, lr=0.000008
   📉 Epoch 7: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0825, val=0.0758, patience=10/15, lr=0.000004
   📉 Epoch 15: LR reduced 0.000004 → 0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 9 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0010
   Val:   Loss=0.0753, RMSE=0.2744, R²=-0.0189
============================================================


📊 Round 9 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2484, R²: 0.0026

📊 Round 9 Test Metrics:
   Loss: 0.0826, RMSE: 0.2873, MAE: 0.2485, R²: 0.0025

📊 Round 9 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2485, R²: 0.0022

📊 Round 9 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2482, R²: 0.0035

============================================================
🔄 Round 17 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0902 (↓), lr=0.000002
   • Epoch   2/100: train=0.0787, val=0.0902, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0787, val=0.0902, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0787, val=0.0902, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0787, val=0.0902, patience=4/15, lr=0.000002
   📉 Epoch 7: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0787, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 17 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0020
   Val:   Loss=0.0902, RMSE=0.3003, R²=0.0008
============================================================


============================================================
🔄 Round 19 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 19 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=0.0018
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0010
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0034

📊 Round 19 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0034

============================================================
🔄 Round 22 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 22 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0029
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0063
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0034

============================================================
🔄 Round 24 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 24 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0026
   Val:   Loss=0.0834, RMSE=0.2887, R²=-0.0015
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0034

============================================================
🔄 Round 25 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 25 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0006
   Val:   Loss=0.0840, RMSE=0.2899, R²=-0.0211
============================================================


============================================================
🔄 Round 26 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 26 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0013
   Val:   Loss=0.0784, RMSE=0.2801, R²=0.0038
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0034

============================================================
🔄 Round 29 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 29 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0001
   Val:   Loss=0.0832, RMSE=0.2885, R²=0.0018
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0033

============================================================
🔄 Round 33 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 33 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0008
   Val:   Loss=0.0804, RMSE=0.2835, R²=0.0060
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0033

📊 Round 33 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0033

============================================================
🔄 Round 40 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 40 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0016
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0032
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0033

============================================================
🔄 Round 42 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 42 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=0.0013
   Val:   Loss=0.0732, RMSE=0.2706, R²=-0.0070
============================================================


============================================================
🔄 Round 43 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 43 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2819, R²=0.0028
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0016
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0033

============================================================
🔄 Round 46 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 46 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0013
   Val:   Loss=0.0870, RMSE=0.2949, R²=0.0031
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0033

============================================================
🔄 Round 47 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 47 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0010
   Val:   Loss=0.0782, RMSE=0.2796, R²=-0.0028
============================================================


============================================================
🔄 Round 48 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 48 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0024
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0007
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0033

============================================================
🔄 Round 50 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 50 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0004
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0019
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0034

============================================================
🔄 Round 52 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 52 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0034
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0042
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0034

============================================================
🔄 Round 56 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0700 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0700, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0700, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0700, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0700, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0700, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0700)

============================================================
📊 Round 56 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=0.0014
   Val:   Loss=0.0700, RMSE=0.2646, R²=0.0028
============================================================


============================================================
🔄 Round 57 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 57 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0015
   Val:   Loss=0.0768, RMSE=0.2771, R²=-0.0081
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0034

============================================================
🔄 Round 59 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 59 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=-0.0006
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0009
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0034

============================================================
🔄 Round 60 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 60 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0018
   Val:   Loss=0.0839, RMSE=0.2897, R²=0.0021
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0033

============================================================
🔄 Round 62 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 62 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0027
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0104
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0033

============================================================
🔄 Round 64 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 64 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0022
   Val:   Loss=0.0838, RMSE=0.2894, R²=-0.0016
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0033

============================================================
🔄 Round 68 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 68 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0012
   Val:   Loss=0.0798, RMSE=0.2824, R²=0.0003
============================================================


============================================================
🔄 Round 69 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 69 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0033
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0061
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0033

============================================================
🔄 Round 71 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 71 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0023
   Val:   Loss=0.0736, RMSE=0.2713, R²=-0.0002
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0033

============================================================
🔄 Round 73 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 73 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0013
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0099
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0034

📊 Round 73 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0034

============================================================
🔄 Round 79 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0691 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0691, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0691, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0691, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0691, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0691, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0691)

============================================================
📊 Round 79 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0010
   Val:   Loss=0.0691, RMSE=0.2628, R²=0.0032
============================================================


============================================================
🔄 Round 85 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 85 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0032
   Val:   Loss=0.0827, RMSE=0.2875, R²=-0.0036
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0034

============================================================
🔄 Round 86 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 86 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0019
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0015
============================================================


============================================================
🔄 Round 87 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 87 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0009
   Val:   Loss=0.0836, RMSE=0.2892, R²=0.0009
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0034

============================================================
🔄 Round 91 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 91 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2813, R²=0.0018
   Val:   Loss=0.0885, RMSE=0.2975, R²=-0.0044
============================================================


============================================================
🔄 Round 92 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 92 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0004
   Val:   Loss=0.0876, RMSE=0.2960, R²=0.0063
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0034

============================================================
🔄 Round 96 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 96 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0028
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0071
============================================================


============================================================
🔄 Round 98 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 98 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=0.0027
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0318
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0034

============================================================
🔄 Round 99 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 99 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0005
   Val:   Loss=0.0767, RMSE=0.2770, R²=-0.0004
============================================================


============================================================
🔄 Round 100 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 100 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0003
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0029
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0034

============================================================
🔄 Round 101 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 101 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0027
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0128
============================================================


============================================================
🔄 Round 102 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 102 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0016
   Val:   Loss=0.0762, RMSE=0.2761, R²=0.0029
============================================================


============================================================
🔄 Round 104 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 104 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0018
   Val:   Loss=0.0866, RMSE=0.2943, R²=-0.0041
============================================================


============================================================
🔄 Round 105 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 105 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0024
   Val:   Loss=0.0926, RMSE=0.3044, R²=-0.0036
============================================================


============================================================
🔄 Round 107 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 107 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=-0.0004
   Val:   Loss=0.0845, RMSE=0.2906, R²=0.0018
============================================================


============================================================
🔄 Round 108 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 108 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0016
   Val:   Loss=0.0758, RMSE=0.2752, R²=0.0028
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0034

============================================================
🔄 Round 111 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 111 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0025
   Val:   Loss=0.0769, RMSE=0.2773, R²=-0.0032
============================================================


============================================================
🔄 Round 112 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 112 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0016
   Val:   Loss=0.0853, RMSE=0.2921, R²=0.0000
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0033

============================================================
🔄 Round 113 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 113 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0010
   Val:   Loss=0.0888, RMSE=0.2979, R²=0.0028
============================================================


============================================================
🔄 Round 116 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0715 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0715, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0716, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0716, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0716, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0716, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0715)

============================================================
📊 Round 116 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0010
   Val:   Loss=0.0715, RMSE=0.2675, R²=-0.0121
============================================================


============================================================
🔄 Round 117 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 117 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0003
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0082
============================================================


============================================================
🔄 Round 119 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 119 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0015
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0032
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0033

============================================================
🔄 Round 121 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 121 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0014
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0089
============================================================


============================================================
🔄 Round 123 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 123 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0026
   Val:   Loss=0.0861, RMSE=0.2935, R²=-0.0219
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0034

📊 Round 123 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0033

============================================================
🔄 Round 126 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 126 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0021
   Val:   Loss=0.0838, RMSE=0.2894, R²=0.0001
============================================================


============================================================
🔄 Round 128 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 128 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0028
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0115
============================================================


============================================================
🔄 Round 129 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 129 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0029
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0050
============================================================


============================================================
🔄 Round 130 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 130 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0041
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0080
============================================================


============================================================
🔄 Round 136 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 136 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0016
   Val:   Loss=0.0754, RMSE=0.2747, R²=-0.0027
============================================================


============================================================
🔄 Round 137 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 137 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0002
   Val:   Loss=0.0767, RMSE=0.2770, R²=0.0087
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0034

============================================================
🔄 Round 140 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 140 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0008
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0046
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0034

📊 Round 140 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0034

📊 Round 140 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0034

============================================================
🔄 Round 148 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 148 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0021
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0010
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0034

============================================================
🔄 Round 150 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 150 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=-0.0000
   Val:   Loss=0.0745, RMSE=0.2729, R²=-0.0302
============================================================


============================================================
🔄 Round 152 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 152 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0011
   Val:   Loss=0.0781, RMSE=0.2794, R²=-0.0075
============================================================


============================================================
🔄 Round 153 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 153 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0011
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.0045
============================================================


============================================================
🔄 Round 155 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 155 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0005
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0255
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0034

📊 Round 155 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0034

📊 Round 155 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0033

============================================================
🔄 Round 164 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 164 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0017
   Val:   Loss=0.0806, RMSE=0.2839, R²=0.0006
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0033

📊 Round 164 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0034

============================================================
🔄 Round 167 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 167 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0022
   Val:   Loss=0.0800, RMSE=0.2829, R²=-0.0026
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0034

📊 Round 167 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0034

============================================================
🔄 Round 170 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 170 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0022
   Val:   Loss=0.0840, RMSE=0.2898, R²=0.0008
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0033

============================================================
🔄 Round 172 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 172 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0019
   Val:   Loss=0.0872, RMSE=0.2952, R²=0.0010
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0033

============================================================
🔄 Round 173 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 173 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0023
   Val:   Loss=0.0760, RMSE=0.2756, R²=-0.0028
============================================================


============================================================
🔄 Round 174 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0684 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0684, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0684, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0684, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0684, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0685, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0684)

============================================================
📊 Round 174 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0024
   Val:   Loss=0.0684, RMSE=0.2615, R²=-0.0200
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0033

============================================================
🔄 Round 176 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 176 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0020
   Val:   Loss=0.0727, RMSE=0.2697, R²=-0.0053
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0033

============================================================
🔄 Round 178 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 178 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0014
   Val:   Loss=0.0772, RMSE=0.2778, R²=-0.0166
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0034

📊 Round 178 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0034

============================================================
🔄 Round 183 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 183 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=0.0020
   Val:   Loss=0.0898, RMSE=0.2996, R²=0.0013
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0034

📊 Round 183 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0034

============================================================
🔄 Round 187 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 187 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=-0.0000
   Val:   Loss=0.0829, RMSE=0.2880, R²=-0.0056
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0034

============================================================
🔄 Round 189 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 189 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2857, R²=0.0010
   Val:   Loss=0.0785, RMSE=0.2801, R²=0.0053
============================================================


============================================================
🔄 Round 190 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 190 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=0.0022
   Val:   Loss=0.0761, RMSE=0.2758, R²=-0.0015
============================================================


============================================================
🔄 Round 191 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 191 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0005
   Val:   Loss=0.0800, RMSE=0.2829, R²=0.0066
============================================================


📊 Round 191 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0034

============================================================
🔄 Round 192 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 192 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0013
   Val:   Loss=0.0801, RMSE=0.2831, R²=0.0145
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0034

📊 Round 192 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0034

============================================================
🔄 Round 196 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 196 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0020
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0008
============================================================


============================================================
🔄 Round 197 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 197 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=0.0014
   Val:   Loss=0.0913, RMSE=0.3022, R²=-0.0023
============================================================


============================================================
🔄 Round 198 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 198 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0010
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0040
============================================================


============================================================
🔄 Round 200 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 200 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0007
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0003
============================================================


📊 Round 200 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0034

============================================================
🔄 Round 201 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 201 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0002
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0128
============================================================


📊 Round 201 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0034

📊 Round 201 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0034

============================================================
🔄 Round 204 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 204 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0007
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0149
============================================================


============================================================
🔄 Round 206 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 206 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0022
   Val:   Loss=0.0786, RMSE=0.2803, R²=-0.0002
============================================================


📊 Round 206 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0034

============================================================
🔄 Round 209 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 209 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0007
   Val:   Loss=0.0856, RMSE=0.2926, R²=0.0031
============================================================


📊 Round 209 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0034

============================================================
🔄 Round 215 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 215 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0021
   Val:   Loss=0.0801, RMSE=0.2831, R²=-0.0075
============================================================


📊 Round 215 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0034

============================================================
🔄 Round 216 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 216 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0037
   Val:   Loss=0.0789, RMSE=0.2810, R²=-0.0100
============================================================


📊 Round 216 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0034

============================================================
🔄 Round 217 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 217 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=0.0023
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0005
============================================================


📊 Round 217 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0034

📊 Round 217 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0034

============================================================
🔄 Round 219 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 219 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0027
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0046
============================================================


============================================================
🔄 Round 223 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 223 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0005
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0038
============================================================


📊 Round 223 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0034

============================================================
🔄 Round 225 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 225 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0025
   Val:   Loss=0.0797, RMSE=0.2824, R²=-0.0018
============================================================


============================================================
🔄 Round 226 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 226 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0011
   Val:   Loss=0.0747, RMSE=0.2734, R²=0.0050
============================================================


============================================================
🔄 Round 228 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 228 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0003
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0183
============================================================


============================================================
🔄 Round 230 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 230 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0021
   Val:   Loss=0.0892, RMSE=0.2987, R²=-0.0008
============================================================


============================================================
🔄 Round 232 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 232 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0018
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0021
============================================================


📊 Round 232 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0034

============================================================
🔄 Round 234 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 234 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=0.0029
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0150
============================================================


============================================================
🔄 Round 237 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 237 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0018
   Val:   Loss=0.0871, RMSE=0.2952, R²=0.0005
============================================================


📊 Round 237 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0034

============================================================
🔄 Round 239 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 239 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0008
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0010
============================================================


📊 Round 239 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0034

============================================================
🔄 Round 242 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 242 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=0.0032
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0044
============================================================


📊 Round 242 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

📊 Round 242 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

📊 Round 242 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

============================================================
🔄 Round 247 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 247 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0001
   Val:   Loss=0.0768, RMSE=0.2771, R²=-0.0303
============================================================


📊 Round 247 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0034

============================================================
🔄 Round 249 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 249 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0004
   Val:   Loss=0.0789, RMSE=0.2808, R²=0.0078
============================================================


📊 Round 249 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0034

📊 Round 249 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0034

============================================================
🔄 Round 251 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 251 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0019
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0070
============================================================


📊 Round 251 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

============================================================
🔄 Round 252 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 252 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0010
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0091
============================================================


============================================================
🔄 Round 253 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 253 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0015
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0032
============================================================


============================================================
🔄 Round 254 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 254 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0017
   Val:   Loss=0.0875, RMSE=0.2957, R²=-0.0027
============================================================


📊 Round 254 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

============================================================
🔄 Round 255 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 255 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=-0.0003
   Val:   Loss=0.0876, RMSE=0.2959, R²=0.0095
============================================================


📊 Round 255 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

📊 Round 255 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

============================================================
🔄 Round 257 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 257 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0018
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0019
============================================================


============================================================
🔄 Round 258 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 258 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0011
   Val:   Loss=0.0865, RMSE=0.2941, R²=0.0047
============================================================


📊 Round 258 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0034

📊 Round 258 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0034

============================================================
🔄 Round 264 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 264 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=0.0027
   Val:   Loss=0.0825, RMSE=0.2873, R²=-0.0015
============================================================


📊 Round 264 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0034

============================================================
🔄 Round 265 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 265 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0003
   Val:   Loss=0.0771, RMSE=0.2777, R²=0.0024
============================================================


📊 Round 265 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0034

📊 Round 265 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0034

============================================================
🔄 Round 268 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 268 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0019
   Val:   Loss=0.0840, RMSE=0.2899, R²=-0.0185
============================================================


============================================================
🔄 Round 269 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 269 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0002
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0047
============================================================


📊 Round 269 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

📊 Round 269 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

============================================================
🔄 Round 276 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0954 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0954, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0954, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0954, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0954, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0954, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0954)

============================================================
📊 Round 276 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2783, R²=0.0014
   Val:   Loss=0.0954, RMSE=0.3088, R²=0.0014
============================================================


============================================================
🔄 Round 279 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 279 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0003
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0048
============================================================


📊 Round 279 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

📊 Round 279 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

📊 Round 279 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

============================================================
🔄 Round 283 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 283 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0011
   Val:   Loss=0.0792, RMSE=0.2815, R²=0.0049
============================================================


============================================================
🔄 Round 287 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 287 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0020
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0051
============================================================


📊 Round 287 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

============================================================
🔄 Round 289 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 289 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0005
   Val:   Loss=0.0773, RMSE=0.2781, R²=0.0045
============================================================


📊 Round 289 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

📊 Round 289 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

============================================================
🔄 Round 294 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 294 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0020
   Val:   Loss=0.0818, RMSE=0.2861, R²=0.0004
============================================================


============================================================
🔄 Round 295 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 295 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0034
   Val:   Loss=0.0770, RMSE=0.2774, R²=-0.0065
============================================================


============================================================
🔄 Round 296 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 296 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0032
   Val:   Loss=0.0772, RMSE=0.2779, R²=-0.0071
============================================================


============================================================
🔄 Round 297 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 297 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0004
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0050
============================================================


📊 Round 297 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

📊 Round 297 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

📊 Round 297 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

============================================================
🔄 Round 301 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 301 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0015
   Val:   Loss=0.0843, RMSE=0.2904, R²=0.0032
============================================================


📊 Round 301 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

📊 Round 301 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

============================================================
🔄 Round 303 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0933 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0933, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0933, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0933, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0933, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0933, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0933)

============================================================
📊 Round 303 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2792, R²=0.0020
   Val:   Loss=0.0933, RMSE=0.3054, R²=-0.0022
============================================================


============================================================
🔄 Round 304 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 304 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0017
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0012
============================================================


============================================================
🔄 Round 306 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 306 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0023
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0049
============================================================


============================================================
🔄 Round 307 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 307 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0020
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0007
============================================================


📊 Round 307 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

============================================================
🔄 Round 308 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 308 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0035
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0044
============================================================


📊 Round 308 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

📊 Round 308 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

============================================================
🔄 Round 316 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0694 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0694, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0694, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0694, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0695, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0695, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0694)

============================================================
📊 Round 316 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0005
   Val:   Loss=0.0694, RMSE=0.2635, R²=-0.0162
============================================================


============================================================
🔄 Round 317 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 317 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0033
   Val:   Loss=0.0838, RMSE=0.2896, R²=-0.0049
============================================================


📊 Round 317 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

============================================================
🔄 Round 320 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 320 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0020
   Val:   Loss=0.0803, RMSE=0.2835, R²=-0.0001
============================================================


📊 Round 320 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

============================================================
🔄 Round 321 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 321 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0021
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0009
============================================================


📊 Round 321 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

📊 Round 321 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

📊 Round 321 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

============================================================
🔄 Round 326 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 326 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0014
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0010
============================================================


============================================================
🔄 Round 327 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 327 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0012
   Val:   Loss=0.0891, RMSE=0.2985, R²=0.0030
============================================================


📊 Round 327 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

============================================================
🔄 Round 332 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 332 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0004
   Val:   Loss=0.0835, RMSE=0.2890, R²=0.0051
============================================================


📊 Round 332 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

============================================================
🔄 Round 333 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 333 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0008
   Val:   Loss=0.0742, RMSE=0.2724, R²=-0.0145
============================================================


============================================================
🔄 Round 334 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 334 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0024
   Val:   Loss=0.0769, RMSE=0.2774, R²=-0.0065
============================================================


📊 Round 334 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

📊 Round 334 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

============================================================
🔄 Round 337 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 337 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0011
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0214
============================================================


📊 Round 337 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

============================================================
🔄 Round 338 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 338 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=0.0015
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0022
============================================================


📊 Round 338 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

============================================================
🔄 Round 339 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 339 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0009
   Val:   Loss=0.0851, RMSE=0.2917, R²=0.0051
============================================================


============================================================
🔄 Round 340 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 340 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0015
   Val:   Loss=0.0727, RMSE=0.2696, R²=0.0039
============================================================


📊 Round 340 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

📊 Round 340 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

📊 Round 340 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

📊 Round 340 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

📊 Round 340 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

📊 Round 340 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

============================================================
🔄 Round 350 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 350 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0015
   Val:   Loss=0.0774, RMSE=0.2783, R²=0.0013
============================================================


============================================================
🔄 Round 351 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 351 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0013
   Val:   Loss=0.0838, RMSE=0.2894, R²=-0.0328
============================================================


📊 Round 351 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

============================================================
🔄 Round 353 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 353 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0019
   Val:   Loss=0.0874, RMSE=0.2957, R²=-0.0043
============================================================


============================================================
🔄 Round 355 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 355 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0022
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0038
============================================================


============================================================
🔄 Round 357 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 357 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0005
   Val:   Loss=0.0776, RMSE=0.2785, R²=-0.0088
============================================================


============================================================
🔄 Round 358 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 358 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0024
   Val:   Loss=0.0831, RMSE=0.2882, R²=-0.0001
============================================================


📊 Round 358 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

============================================================
🔄 Round 359 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 359 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0013
   Val:   Loss=0.0751, RMSE=0.2741, R²=-0.0125
============================================================


📊 Round 359 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

============================================================
🔄 Round 361 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 361 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0035
   Val:   Loss=0.0800, RMSE=0.2829, R²=-0.0050
============================================================


============================================================
🔄 Round 362 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 362 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0015
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0042
============================================================


📊 Round 362 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

============================================================
🔄 Round 364 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 364 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0013
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0027
============================================================


📊 Round 364 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

📊 Round 364 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

📊 Round 364 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

============================================================
🔄 Round 370 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 370 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0013
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0065
============================================================


📊 Round 370 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

============================================================
🔄 Round 371 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 371 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0026
   Val:   Loss=0.0800, RMSE=0.2829, R²=-0.0008
============================================================


============================================================
🔄 Round 372 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 372 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0022
   Val:   Loss=0.0747, RMSE=0.2733, R²=0.0007
============================================================


📊 Round 372 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

📊 Round 372 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0034

============================================================
🔄 Round 374 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 374 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0022
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0008
============================================================


📊 Round 374 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

============================================================
🔄 Round 378 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 378 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0007
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0031
============================================================


============================================================
🔄 Round 379 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0709 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0709, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0709, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0709, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0709, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0709, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0709)

============================================================
📊 Round 379 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0025
   Val:   Loss=0.0709, RMSE=0.2664, R²=-0.0009
============================================================


📊 Round 379 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

============================================================
🔄 Round 380 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 380 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0018
   Val:   Loss=0.0758, RMSE=0.2753, R²=-0.0018
============================================================


📊 Round 380 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

============================================================
🔄 Round 382 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 382 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0008
   Val:   Loss=0.0789, RMSE=0.2809, R²=-0.0004
============================================================


📊 Round 382 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

============================================================
🔄 Round 383 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 383 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0019
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0069
============================================================


📊 Round 383 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

============================================================
🔄 Round 388 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0674 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0674, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0674, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0674, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0674, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0674, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0674)

============================================================
📊 Round 388 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0022
   Val:   Loss=0.0674, RMSE=0.2596, R²=-0.0089
============================================================


📊 Round 388 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

============================================================
🔄 Round 390 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 390 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0007
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0111
============================================================


📊 Round 390 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

============================================================
🔄 Round 394 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 394 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0023
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0095
============================================================


📊 Round 394 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

============================================================
🔄 Round 395 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0697 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0697, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0697, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0697, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0697, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0697, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0697)

============================================================
📊 Round 395 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2896, R²=0.0006
   Val:   Loss=0.0697, RMSE=0.2640, R²=0.0046
============================================================


============================================================
🔄 Round 397 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 397 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0017
   Val:   Loss=0.0733, RMSE=0.2708, R²=0.0018
============================================================


📊 Round 397 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

============================================================
🔄 Round 400 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 400 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0028
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0015
============================================================


📊 Round 400 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

============================================================
🔄 Round 401 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 401 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0024
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0085
============================================================


📊 Round 401 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

📊 Round 401 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

📊 Round 401 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

============================================================
🔄 Round 406 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 406 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=0.0017
   Val:   Loss=0.0745, RMSE=0.2729, R²=-0.0126
============================================================


============================================================
🔄 Round 408 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 408 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0016
   Val:   Loss=0.0842, RMSE=0.2902, R²=0.0032
============================================================


📊 Round 408 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

📊 Round 408 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

============================================================
🔄 Round 412 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 412 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0025
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0004
============================================================


============================================================
🔄 Round 414 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 414 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0009
   Val:   Loss=0.0798, RMSE=0.2825, R²=0.0056
============================================================


📊 Round 414 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

============================================================
🔄 Round 417 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 417 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0025
   Val:   Loss=0.0822, RMSE=0.2866, R²=-0.0023
============================================================


📊 Round 417 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

============================================================
🔄 Round 420 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 420 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0025
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0006
============================================================


============================================================
🔄 Round 422 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 422 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0022
   Val:   Loss=0.0827, RMSE=0.2877, R²=0.0005
============================================================


============================================================
🔄 Round 423 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 423 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0035
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0237
============================================================


📊 Round 423 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

============================================================
🔄 Round 424 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 424 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0023
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0014
============================================================


============================================================
🔄 Round 425 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 425 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0019
   Val:   Loss=0.0782, RMSE=0.2796, R²=-0.0125
============================================================


📊 Round 425 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

============================================================
🔄 Round 428 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 428 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0029
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0019
============================================================


📊 Round 428 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

============================================================
🔄 Round 430 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 430 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0006
   Val:   Loss=0.0746, RMSE=0.2732, R²=0.0052
============================================================


📊 Round 430 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0036

📊 Round 430 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0036

============================================================
🔄 Round 433 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 433 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0024
   Val:   Loss=0.0742, RMSE=0.2725, R²=-0.0005
============================================================


📊 Round 433 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0036

============================================================
🔄 Round 435 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 435 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2842, R²=0.0015
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0018
============================================================


============================================================
🔄 Round 437 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 437 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0010
   Val:   Loss=0.0876, RMSE=0.2960, R²=0.0054
============================================================


📊 Round 437 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0036

📊 Round 437 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0036

============================================================
🔄 Round 439 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 439 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0026
   Val:   Loss=0.0834, RMSE=0.2887, R²=-0.0023
============================================================


📊 Round 439 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0036

============================================================
🔄 Round 440 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 440 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=0.0005
   Val:   Loss=0.0825, RMSE=0.2873, R²=-0.0037
============================================================


============================================================
🔄 Round 441 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 441 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0001
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0076
============================================================


============================================================
🔄 Round 443 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 443 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2877, R²=0.0037
   Val:   Loss=0.0741, RMSE=0.2721, R²=-0.0146
============================================================


📊 Round 443 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

📊 Round 443 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

============================================================
🔄 Round 445 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 445 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0020
   Val:   Loss=0.0857, RMSE=0.2928, R²=0.0017
============================================================


📊 Round 445 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

📊 Round 445 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

============================================================
🔄 Round 450 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0941 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0941, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0941, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0941, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0941, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0941, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0941)

============================================================
📊 Round 450 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0018
   Val:   Loss=0.0941, RMSE=0.3068, R²=0.0010
============================================================


📊 Round 450 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

📊 Round 450 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0036

📊 Round 450 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0036

📊 Round 450 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

📊 Round 450 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0036

============================================================
🔄 Round 460 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 460 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0010
   Val:   Loss=0.0812, RMSE=0.2849, R²=0.0057
============================================================


📊 Round 460 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

📊 Round 460 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

📊 Round 460 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

📊 Round 460 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

============================================================
🔄 Round 467 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 467 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2803, R²=0.0031
   Val:   Loss=0.0909, RMSE=0.3015, R²=-0.0027
============================================================


📊 Round 467 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

============================================================
🔄 Round 469 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 469 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0021
   Val:   Loss=0.0777, RMSE=0.2787, R²=-0.0002
============================================================


📊 Round 469 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

============================================================
🔄 Round 470 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 470 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0028
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0057
============================================================


============================================================
🔄 Round 473 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 473 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0019
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0021
============================================================


📊 Round 473 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

============================================================
🔄 Round 476 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 476 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0014
   Val:   Loss=0.0851, RMSE=0.2917, R²=0.0030
============================================================


📊 Round 476 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

📊 Round 476 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

============================================================
🔄 Round 478 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 478 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0033
   Val:   Loss=0.0768, RMSE=0.2772, R²=-0.0076
============================================================


📊 Round 478 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

📊 Round 478 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

📊 Round 478 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

📊 Round 478 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

📊 Round 478 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

============================================================
🔄 Round 488 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 488 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2826, R²=0.0016
   Val:   Loss=0.0857, RMSE=0.2927, R²=0.0022
============================================================


============================================================
🔄 Round 489 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 489 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0041
   Val:   Loss=0.0788, RMSE=0.2808, R²=-0.0077
============================================================


📊 Round 489 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

============================================================
🔄 Round 491 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 491 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0020
   Val:   Loss=0.0825, RMSE=0.2873, R²=-0.0058
============================================================


============================================================
🔄 Round 494 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 494 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0010
   Val:   Loss=0.0799, RMSE=0.2826, R²=0.0022
============================================================


📊 Round 494 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

📊 Round 494 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

============================================================
🔄 Round 498 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 498 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0021
   Val:   Loss=0.0769, RMSE=0.2773, R²=-0.0058
============================================================


============================================================
🔄 Round 500 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 500 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0007
   Val:   Loss=0.0743, RMSE=0.2725, R²=0.0045
============================================================


============================================================
🔄 Round 502 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 502 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0014
   Val:   Loss=0.0832, RMSE=0.2884, R²=0.0039
============================================================


📊 Round 502 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0036

============================================================
🔄 Round 508 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 508 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=0.0011
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0056
============================================================


📊 Round 508 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0036

============================================================
🔄 Round 509 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 509 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0020
   Val:   Loss=0.0879, RMSE=0.2966, R²=-0.0008
============================================================


📊 Round 509 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0036

📊 Round 509 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0036

📊 Round 509 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0036

============================================================
🔄 Round 515 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 515 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0010
   Val:   Loss=0.0816, RMSE=0.2856, R²=0.0044
============================================================


📊 Round 515 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0036

📊 Round 515 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0036

============================================================
🔄 Round 517 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 517 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=0.0019
   Val:   Loss=0.0732, RMSE=0.2705, R²=0.0010
============================================================


📊 Round 517 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0036

============================================================
🔄 Round 519 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 519 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0019
   Val:   Loss=0.0797, RMSE=0.2822, R²=0.0015
============================================================


============================================================
🔄 Round 521 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 521 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0012
   Val:   Loss=0.0775, RMSE=0.2783, R²=0.0042
============================================================


📊 Round 521 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0036

📊 Round 521 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0036

============================================================
🔄 Round 523 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 523 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0009
   Val:   Loss=0.0831, RMSE=0.2882, R²=0.0025
============================================================


📊 Round 523 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0036

============================================================
🔄 Round 528 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 528 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0024
   Val:   Loss=0.0833, RMSE=0.2887, R²=-0.0036
============================================================


============================================================
🔄 Round 529 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 529 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0009
   Val:   Loss=0.0819, RMSE=0.2863, R²=-0.0016
============================================================


📊 Round 529 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0036

============================================================
🔄 Round 531 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 531 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0003
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0127
============================================================


📊 Round 531 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0036

============================================================
🔄 Round 543 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 543 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0014
   Val:   Loss=0.0802, RMSE=0.2833, R²=-0.0056
============================================================


📊 Round 543 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0036

📊 Round 543 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0036

📊 Round 543 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0036

============================================================
🔄 Round 550 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 550 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0008
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0058
============================================================


📊 Round 550 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0036

📊 Round 550 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0036

============================================================
🔄 Round 554 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 554 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0026
   Val:   Loss=0.0869, RMSE=0.2949, R²=-0.0064
============================================================


📊 Round 554 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0036

============================================================
🔄 Round 557 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 557 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0030
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0037
============================================================


📊 Round 557 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0036

============================================================
🔄 Round 558 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 558 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0008
   Val:   Loss=0.0737, RMSE=0.2714, R²=0.0069
============================================================


============================================================
🔄 Round 559 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 559 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=0.0027
   Val:   Loss=0.0825, RMSE=0.2873, R²=-0.0035
============================================================


📊 Round 559 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0036

📊 Round 559 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0036

📊 Round 559 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0036

============================================================
🔄 Round 564 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 564 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=0.0032
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0036
============================================================


📊 Round 564 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0036

============================================================
🔄 Round 569 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 569 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0027
   Val:   Loss=0.0842, RMSE=0.2903, R²=-0.0030
============================================================


============================================================
🔄 Round 570 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 570 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0017
   Val:   Loss=0.0815, RMSE=0.2856, R²=-0.0027
============================================================


============================================================
🔄 Round 573 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 573 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0000
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0050
============================================================


📊 Round 573 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0036

📊 Round 573 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0036

============================================================
🔄 Round 584 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 584 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=0.0012
   Val:   Loss=0.0877, RMSE=0.2961, R²=0.0035
============================================================


📊 Round 584 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0036

============================================================
🔄 Round 585 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 585 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0010
   Val:   Loss=0.0807, RMSE=0.2842, R²=0.0054
============================================================


============================================================
🔄 Round 586 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 586 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2819, R²=0.0003
   Val:   Loss=0.0873, RMSE=0.2954, R²=0.0063
============================================================


============================================================
🔄 Round 587 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0688 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0688, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0688, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0688, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0688, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0688, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0688)

============================================================
📊 Round 587 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=0.0016
   Val:   Loss=0.0688, RMSE=0.2623, R²=0.0028
============================================================


📊 Round 587 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0036

============================================================
🔄 Round 588 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 588 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2878, R²=0.0013
   Val:   Loss=0.0736, RMSE=0.2713, R²=0.0034
============================================================


📊 Round 588 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0036

============================================================
🔄 Round 591 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 591 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0017
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0237
============================================================


📊 Round 591 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0036

📊 Round 591 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0036

📊 Round 591 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0036

============================================================
🔄 Round 595 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0928 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0928, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0928, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0928, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0928, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0928, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 595 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=0.0019
   Val:   Loss=0.0928, RMSE=0.3046, R²=-0.0004
============================================================


============================================================
🔄 Round 596 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 596 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0027
   Val:   Loss=0.0762, RMSE=0.2761, R²=-0.0025
============================================================


============================================================
🔄 Round 598 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 598 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=0.0014
   Val:   Loss=0.0841, RMSE=0.2899, R²=-0.0004
============================================================


📊 Round 598 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0036

============================================================
🔄 Round 599 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 599 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0018
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0160
============================================================


============================================================
🔄 Round 600 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 600 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0021
   Val:   Loss=0.0833, RMSE=0.2887, R²=-0.0003
============================================================


============================================================
🔄 Round 601 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 601 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0010
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0088
============================================================


📊 Round 601 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0036

============================================================
🔄 Round 604 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 604 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0015
   Val:   Loss=0.0875, RMSE=0.2958, R²=0.0033
============================================================


📊 Round 604 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0036

============================================================
🔄 Round 607 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 607 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0021
   Val:   Loss=0.0876, RMSE=0.2960, R²=0.0008
============================================================


============================================================
🔄 Round 609 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 609 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0010
   Val:   Loss=0.0766, RMSE=0.2767, R²=0.0012
============================================================


📊 Round 609 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0036

============================================================
🔄 Round 610 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 610 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0020
   Val:   Loss=0.0866, RMSE=0.2943, R²=0.0010
============================================================


📊 Round 610 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0036

============================================================
🔄 Round 611 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 611 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0003
   Val:   Loss=0.0838, RMSE=0.2895, R²=0.0009
============================================================


============================================================
🔄 Round 614 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 614 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0016
   Val:   Loss=0.0866, RMSE=0.2942, R²=0.0028
============================================================


📊 Round 614 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0036

============================================================
🔄 Round 615 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 615 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0001
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0063
============================================================


============================================================
🔄 Round 616 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0951 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0951, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0951, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0951, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0951, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0952, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0951)

============================================================
📊 Round 616 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0019
   Val:   Loss=0.0951, RMSE=0.3084, R²=-0.0128
============================================================


============================================================
🔄 Round 618 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 618 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0019
   Val:   Loss=0.0909, RMSE=0.3016, R²=0.0024
============================================================


📊 Round 618 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0036

============================================================
🔄 Round 620 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 620 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0017
   Val:   Loss=0.0818, RMSE=0.2861, R²=-0.0145
============================================================


📊 Round 620 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

============================================================
🔄 Round 622 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 622 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=0.0014
   Val:   Loss=0.0796, RMSE=0.2822, R²=0.0008
============================================================


📊 Round 622 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

============================================================
🔄 Round 626 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 626 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0008
   Val:   Loss=0.0776, RMSE=0.2786, R²=0.0050
============================================================


============================================================
🔄 Round 627 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 627 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0005
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0048
============================================================


============================================================
🔄 Round 628 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 628 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0015
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0009
============================================================


============================================================
🔄 Round 629 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 629 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0014
   Val:   Loss=0.0753, RMSE=0.2744, R²=0.0009
============================================================


📊 Round 629 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

📊 Round 629 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

📊 Round 629 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0035

============================================================
🔄 Round 632 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 632 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0017
   Val:   Loss=0.0832, RMSE=0.2884, R²=0.0032
============================================================


📊 Round 632 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0036

============================================================
🔄 Round 634 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 634 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=0.0006
   Val:   Loss=0.0745, RMSE=0.2729, R²=-0.0023
============================================================


📊 Round 634 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0036

============================================================
🔄 Round 636 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 636 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0018
   Val:   Loss=0.0768, RMSE=0.2772, R²=0.0013
============================================================


📊 Round 636 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0036

============================================================
🔄 Round 637 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 637 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0020
   Val:   Loss=0.0838, RMSE=0.2894, R²=-0.0036
============================================================


============================================================
🔄 Round 639 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 639 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0018
   Val:   Loss=0.0855, RMSE=0.2924, R²=0.0022
============================================================


📊 Round 639 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0036

============================================================
🔄 Round 641 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 641 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0025
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0018
============================================================


============================================================
🔄 Round 643 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 643 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0003
   Val:   Loss=0.0805, RMSE=0.2838, R²=-0.0460
============================================================


============================================================
🔄 Round 644 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 644 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0001
   Val:   Loss=0.0738, RMSE=0.2716, R²=-0.0199
============================================================


============================================================
🔄 Round 646 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 646 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=0.0016
   Val:   Loss=0.0744, RMSE=0.2728, R²=-0.0079
============================================================


📊 Round 646 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0036

============================================================
🔄 Round 648 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 648 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0011
   Val:   Loss=0.0775, RMSE=0.2783, R²=0.0054
============================================================


============================================================
🔄 Round 651 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 651 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0019
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0015
============================================================


📊 Round 651 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0036

📊 Round 651 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0036

============================================================
🔄 Round 654 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 654 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2877, R²=0.0020
   Val:   Loss=0.0740, RMSE=0.2721, R²=0.0005
============================================================


============================================================
🔄 Round 657 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 657 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0026
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0007
============================================================


============================================================
🔄 Round 658 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 658 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0017
   Val:   Loss=0.0775, RMSE=0.2783, R²=-0.0125
============================================================


📊 Round 658 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0036

============================================================
🔄 Round 661 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 661 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0012
   Val:   Loss=0.0809, RMSE=0.2845, R²=-0.0133
============================================================


============================================================
🔄 Round 662 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 662 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0018
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0020
============================================================


📊 Round 662 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2483, R²: 0.0036

============================================================
🔄 Round 663 - Client client_3
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 663 Summary - Client client_3
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2810, R²=0.0022
   Val:   Loss=0.0892, RMSE=0.2987, R²=-0.0130
============================================================


❌ Client client_3 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8690 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8690 {grpc_message:"Socket closed", grpc_status:14}"
>
