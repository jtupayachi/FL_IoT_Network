[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 251fcba3-133a-411c-a730-aa0caa759ae5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b59d0ab-0c99-4a2d-845a-f9447639513d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 376106eb-c017-4bc0-bed8-72b52a3aea5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e61230fd-126d-4fa2-827e-8b2b82d7edce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83b8d4eb-13e0-4236-990b-567e7d0db98c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 140d4e1a-c2cc-49dc-9d07-6c450ac2046a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 061e9157-a422-4d9d-9c89-72190a3b79a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aae6fb09-a98e-4f10-8c62-1444b2e80fa7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a47999b6-6153-40cc-831f-1e6762ae862b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ef0bd41-d412-4a95-8b6e-682f26949b4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a90933be-440f-4a42-aaca-61864ca76755
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b05865ac-48d0-44ea-947d-37c391ff9f9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 169a4c00-0049-4e40-b5bd-d18f7a0c79e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5958fe62-d1fe-4793-9179-c05047e0c65c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c04bbf55-ff6f-466f-b4af-c1b13b12ee99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e560b81-2e07-4979-88fa-86f7319427c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83839b71-3632-46da-9232-9c3bc18691e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6797f653-5799-4852-a544-58678bab7fe7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 570f9c18-aaa3-4917-8625-a7e52d035ed9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 599b1f88-0b00-4ddf-8e5b-bd7ba7283be1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ffb4ee3-ecfb-4be1-85d8-38f206551b3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24595aa9-97a4-4131-a949-e145c9b0d313
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ffb4399-343c-4d0b-a561-d7e4c8a4db14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af27e394-55d4-4d50-91ec-bef7f562e024
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25e22a4e-4079-45bc-8ebf-81012e0af973
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 371500a0-8407-4362-82ff-d5012f49d38e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85c2e668-66bf-4aff-aac0-0642fd54703a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7dbfb7b-80e1-485d-9bf1-c194f43302af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de74459e-ab34-4bea-9c8b-7cbb6a70f28f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 177de3a6-af09-4de1-a619-a3380056ffb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5daa58f9-83c5-434a-9ac1-526dbb066592
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b61cbc95-6458-4c82-924d-5c2f78e09555
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfcf1d46-9086-41ee-8867-32487a4b5945
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 792a97d8-6a6f-4277-ba4a-95630eec6b66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 156c2558-9473-4abe-9591-f7ba41a34ebc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5815bc9e-97c6-4b09-ac3c-0ad34acb2c95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13624e5e-e39f-4528-baaf-0dd8c81523c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a71d9ce-2108-4644-882b-d3b41f1bedd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f7c0c79-2c78-4820-a48a-67d4bc3e0ca7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76e21fd0-45b8-42d7-ae0c-6ad4cb44bac6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d09aa3da-76d8-4b37-81dc-018756318539
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 113bf8be-6972-48e5-9697-57859cf30ba0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82600714-253c-4c43-b784-c1782f5dc3e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7bd5199-22ab-4626-ac1c-e5157c2e29c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d81adec9-122b-4769-8d8e-19afe09d7644
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08d3cb38-08d6-4e2e-9b1a-deda1a52bf21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8856dc4b-70fd-4834-bef1-273c83d543bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ecc4db8c-9f0e-4da2-bfdd-6dcb3043fed5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16261d89-ffdb-43be-b8ba-5ec28f0300db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 472b2983-21e7-4ada-818f-ff5cdb423056
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3425a32a-c650-40ef-9009-b05fb9ceedee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6bee6a56-c0c3-4c38-a548-9900073f9d1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc722eb7-1dd0-47e9-bc8d-e4211ba94866
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97ccaf80-4c09-446c-ab75-0d726b9fb5e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6939cd1-9b88-4865-a327-ae22994cd69f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e59264a6-cf5b-488e-95ff-7982e8bed65f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28a60ca0-ae6a-406d-b1c5-c36c7ca978ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94579d99-d4f3-4798-a511-3f66454773b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7df0a7c5-d098-4b1a-9761-157632b160cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63fe7813-ac9d-42dc-931a-b470fc6e3711
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c888142f-0002-47c4-a9a1-24da7a0f463f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 549c5ff6-677a-43c2-bb7e-8bf739a7383a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d791d37-7af3-4ed7-b327-db51211db086
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6b50d87-4b7a-40b8-a03a-72932637d42c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5e5bf4e-9e30-4910-98ee-245489c635c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b33b520-9af9-441f-95df-013b9ab5fbc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e0ee43a-3c6c-4c29-bc63-2e32052d9003
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 057d80f7-0dfb-405d-bb18-0ed3697130ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dae59da9-b8ec-4e6d-b73c-e546230395be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fca0a850-fdb7-4567-bb6e-6eacf4c74239
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30e3cd1b-e730-40f9-bfad-0a006845d4f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2fa8cb3-b101-49fe-b134-6881903bde7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c88b22ac-e94b-49bb-bdd2-621137399ef6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d405544-b1dd-4fd0-858e-c6252d50e23f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55ffbda2-d50f-466d-9b48-76ee653c3b2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d56a4bc2-5eec-477e-91db-438d6ef2e0b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d32b37d-22c2-4157-9434-bd053fefa881
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb982f4e-43dc-4810-aefa-ec3143f320a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a395ebc-c6b1-4cc7-ba6a-2697b7a64df2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc881204-0f15-47a0-8bad-49e9ed2db869
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8ae4a4c-1809-4cc6-be8c-fba445c9b08d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24295f65-9703-4dc3-880c-bf7407999699
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3750a1a4-c986-401c-b086-05c6b982ce01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02d1a04a-1a02-4a93-a4b4-3bb954d201e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b79e4bba-3796-4ee8-a985-7aa183733b89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ffbee4cb-6760-4fea-b661-91c9f96a374e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c568ce19-c7e9-4fe3-8d8b-73c3f0c839b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5cff98c-4d41-49de-9ccc-694007c1b463
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76756ed3-6030-4dfa-90b3-f13a77a63936
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8fc6796-62a4-4ca1-8701-13ed5606eab4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4796fd86-a500-4ac7-8007-1216ec4dd133
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e2b9cfc-3914-40cd-8c37-1e847e9ad138
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7446cc55-71b0-48c9-8a4b-2376e4555b9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d93250e-ee7c-437c-b166-6e5b200c98a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8425e718-5fca-42d5-89c5-70213c1802cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b25c5376-6f34-43e5-99aa-1d5955f960fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6399c290-1d54-478c-9ba6-28363fbf8d59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ac1da4a-fcc4-433f-9126-19f9b8694571
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0169c2d5-dd41-40f9-809f-79bd02449552
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13bf79d6-9633-4cac-95e4-8619e13efaaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7ee9d07-60f5-4a4e-a166-5e5566270757
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 250c4c35-8477-47f2-a64a-5f41dff987d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a4c31e7-e86d-495f-a2b5-29fe585f4781
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da37b257-9aee-4359-9bf6-8b162c9c8825
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 020a4ec2-a85b-4ee3-89bc-bf9e4d95cf9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12034a6c-6a55-4c91-aa15-a78c22440a30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa36a10f-f2b2-4517-958e-5157ec1f73d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53cc82d5-7c79-403e-b080-05f5db243feb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79e2dec8-b6ca-4af0-aa11-ee6ac86f7583
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3db18ed-9c51-44b5-9fab-b33a23c8e260
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3a5bcc7-6ae3-4108-bb18-2001c2a6f57a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7265719-e637-42cf-af31-c1e30965038c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 041a9046-acd3-4440-8902-367d580c7031
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd36cb48-a8cc-44f1-8498-00d241db5cdd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 764574a1-95ce-4944-b618-962921e24afc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75981993-6435-435d-9ac8-2a49cd192df9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 015cef92-1612-44ea-a252-732a3e364bfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56e20b5e-678d-444c-81f3-2f026fe4a86d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85d86459-ce99-4eb8-a3ca-a89fbc5ce4de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9391712c-0e13-46bc-8069-e5d929038c36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1665867-8e08-41ba-83b2-dc43bb5467e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1b804eb-ee0c-494f-8f93-cf7f0801ed9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0bd6fee5-bdba-4878-b987-4637825ab1c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f0818d5-12c7-47e2-9185-c4af0b14c3bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ef2e270-5c2d-4659-9423-412244bb9c8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b48e6081-956d-43b6-9bb1-9886823663b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 548ed6df-a0f1-4f84-bdbc-09c8ae2da8bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9de6c45a-c7c9-4dfe-a7a9-69b94e5aa55c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7981904c-c0ad-4e4c-9ce9-c3a21b13e410
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2dfd0a9e-30b6-490a-8cb9-a40e7c49ee5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7056a843-f3aa-45c8-a3c5-77cd9c713f45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3d96f88-1bd1-4b33-8988-9a85cb0f04fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ca6431c-749c-4ad8-9641-7dddf5b96c79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6c575f7-2bc1-49c8-82d3-7d55a3206153
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60ac9563-0a46-462f-9d97-0a338a9212f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ffdf64b-4838-4571-b034-4fba7a37a383
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9f11c2c-35af-4c28-988a-860451726a9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 864a06c6-d620-43c1-bdce-2ac54ed65996
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message acb91d3b-1af4-440d-bce4-778fb44bcc85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e62e7be6-5d42-4f49-ad71-f8cf6f79dfd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f07c9c2-45d0-4894-8f98-da90aff8f2cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f2410a8-fd11-423f-b564-50f548162882
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e102655-1d08-4765-b3c7-edbdd743bd68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c43d3036-2d2d-4037-97c3-992bb318ebb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8900fa5-a03d-4217-ada6-12c63bec304e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c5def48-6958-4e53-af9b-83e88edf4ff2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35e6cb2c-b2d2-4360-8079-d4325d20dbc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f26d54b-c641-4bad-83a0-d6a4c2e3cf16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88569e95-18ca-427a-b5a7-92df02419d65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26521969-dc2b-4c95-97f9-36d8b9429381
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ed29e45-22c5-49f7-9361-604e284a1741
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 640d93a3-2fd4-4880-8754-94f8be706979
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e834e33c-ed7c-4d46-86bc-c218affafdda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1754105-e52f-4b76-b089-ba3c73f2dd3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78afa98f-e4a2-4353-b932-f69e056e7396
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e50a3894-bdf4-4090-9e85-6519c4e1cd4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 324f5526-df65-4f97-a8de-91f9a97c2911
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ec34359-d896-4afd-b1fa-736afcf95f44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f75a5de3-bded-4fda-9769-ed3e5d08ac68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dea23e90-39aa-4c75-bab9-3c43da3564d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2764a6eb-e561-45b6-94cc-977d35e2e583
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e2a75f6-f815-4fe1-a7dc-9100c694ded4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57f347fc-1c50-462e-b13c-4ceb4a2055ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d45d8ff-272d-4e84-9c90-77ed8b22568d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d52b00e6-7a8c-4f77-8f6e-4f0e717d9ced
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83a87273-daa6-4b02-a8b2-df5039a6a92b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f04741b0-3ee4-452a-90a9-00d98ddfd724
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5810dd3-caf5-4617-a8ee-3b554cbbf72b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e162efd1-0124-4fc1-ab5c-111d0de772c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4506600-1adb-4866-82c1-90a9a339a7b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2e7ce00-ef10-4933-9c0f-5d60be6e0869
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38d170c1-c9dd-4288-b3b2-1c285758477f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a4f52c5-df24-4a57-a45c-cd2f70a7e176
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46203def-1510-4616-97a2-f5094c500c49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6175637-8cdf-43c5-9264-2417f443775b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c55bd28-43e9-4417-a5f8-088ec592109e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32dacc6d-6f3e-4aec-aea9-21e843944e37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41befbad-08cc-4d70-9214-303503cdbcd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8596ed72-d0f6-4aa9-884e-1ee9476bc014
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68580b42-b9c8-4928-8678-10fcc90adc4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 185629e9-e7c4-4749-b85a-3f2f89ab4b84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ff16dd7-3f38-4c35-8c89-766c9ee48308
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4773fbb-2682-428c-9849-568998d0affa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 477a5272-0721-4f86-81df-6c5a1ec277c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6fdcc479-e730-47a0-a079-de2928e69f51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e112a160-9618-4828-9cd8-7e94424f74be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2335dd63-21bc-49a0-b0a2-17c1906391d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e8995cd-f8f2-4a15-9510-90d4a0982df5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 590d85a8-0e83-44e6-8b24-2ea434c32659
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80d6d53e-81d8-46cc-80b5-9ec7698a2865
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 433b16e4-0f43-4d28-8a7a-74403568407d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ddd2bb8-8b7a-498a-baef-44cc8a2fb447
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64d03526-06b6-45f9-a0d8-6b82c01fd965
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2abdd146-3120-492f-8169-b9d734b92e14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4bdca33-0982-4b4e-8daf-a0dbfb144e24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83a4924e-0cb7-441e-ad97-23442232d43b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bbd283e6-61cb-4dad-a8c0-c83ecce6bddb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c6c9536-7949-4ce6-90d3-5ba13894c126
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76400adf-33cd-4874-8a2e-1682871e19ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1000cedb-e86c-46f4-b9ff-79e88aa2a75b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb69ff09-cd8d-47b2-9dc0-3b2a54120d90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2991ba63-0bff-4978-8239-6e7d2a002954
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4a97ace-b7e8-489c-bd34-185f5e062708
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4402e0e0-f2a4-4043-aa40-b6aa605605b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69a107d3-61c0-45ce-a987-c9cb558f14a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8af24d48-6445-4840-9f5e-e17a83ba1293
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a4fd389-4325-4a37-8e4a-1df15d1b2d6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e8da8d9-8473-42e8-bde3-31cdcb8b44ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6bd95e5-30c4-48e6-909d-17a87a59ca1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06295cea-fc40-4097-9670-d4702859bad4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 680dfcec-c724-454e-907c-cc3972065142
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59247a87-eede-4376-987f-24327a0112de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 421ac1ba-23ec-49a5-911f-73e6dc39b797
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ee73096-5db8-4315-9ca1-860abeb89919
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 357de96d-b340-4fa2-8b70-c0a69d04c441
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6bdbfb3c-20e0-4169-baad-c80b2605ced5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e06138f-12b2-4a71-b864-a79e2a3a9c58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a197d3c-3eb7-42f3-be66-6096a17e99cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab881d05-0c0b-429a-9b0b-022da37c9d01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47bb18d6-d0dd-4f8a-bb93-d42907f78408
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0137b8f1-f938-4b93-a757-16379cb24c70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28f8c293-9c4a-42ea-9dc1-43c3b138d0da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b75f52f3-3588-4949-b987-25079d50a525
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90dd54c9-d994-4d76-bed4-b520ca6679fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26a9c576-fa6b-4d2a-9d02-07859abd6352
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05d8b443-0674-4697-a461-de9ca864bba7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a8162ea-80e0-4aa0-9e4c-fb35e4955fcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f47165d-a7d5-43de-869a-346bb51ff3d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb4ddc0e-4bbc-45a1-81c3-f6dba8b92037
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca05d477-3e69-4777-8d9e-40f539fe5d04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eac45bd1-fd62-4925-b939-65c54ee2f063
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82a02a4c-2603-4abb-a70f-7b3cdc8ae90d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66aed84c-e0b6-4d8f-b644-520dd26400a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2729e73e-55b3-404f-bdeb-7b7898f02fed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cefd3f1a-672c-4e1b-900c-84435afae022
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8c8ba42-2208-4f77-a863-113986338d64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b56aa25f-33ee-40a4-9511-ecdaa331f41a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 028457c0-cd47-4886-bee0-0701923b784f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bdce31da-6bc0-4e54-80f2-845b2c1c56df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a95260e-d255-4f46-8f36-ab4ebf5f9098
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78ccdcc0-b415-4527-9428-cf579a558069
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8bce299-f54d-466c-b71a-85c2a8f51adb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c50bed3-6f96-4a1d-aef9-62dd60171042
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de2bc2cd-91a6-493d-b748-2ccc3030dbfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ab4e8d9-7f38-4fc7-be40-898937f41451
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c762065-240b-49f8-82a2-a663e056628d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a68a500-5c13-43ad-a499-3e9e4b1b097d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e403f83-0ce5-4b19-b21a-ec1090614927
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ede4663-7742-474d-a00a-f6a94e0dd658
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92693ed0-b884-4886-80c8-080dc3fec244
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed0d3231-c9a8-44c7-96c0-a5481383a397
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 109fd84b-bb43-4fd4-a0ed-eb4916e6ede6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0bcec83b-8f14-4b62-adf9-2713bcc1d20a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d544d8f-4c6f-44b8-ac56-5d20a6e7520f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67a7a85b-ed38-4f5a-8b08-0e4aadc9e443
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22e955b0-7d55-4ba0-abda-652ba9995ad4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed1b6ea2-9ef7-4a79-b143-38eb78e9f3e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2b160f0-f75b-4b0a-a2c7-f0cabed3f7b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a96c3a3-21ce-475e-add1-258c036348db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52326e35-4ec5-4454-b2f3-5fd288275c02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76b77e99-aa52-451e-9bd0-999e4bfdcc53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bacae252-4ab9-426f-b05c-5471342ecb59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b3f2b03-5792-4bcd-833a-a84f38d9d416
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 828e8ddd-8363-4049-8dcc-f18b393a04b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4d2a388-c5aa-4acb-a02f-ffb6d955aab7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8260b09-925d-449c-a0c1-2b0ab8c5a4cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24d3c66c-3cf5-4a44-bb75-162f6aeb54a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e6a37fa-1625-4afa-a446-4005be66bdd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca47ede3-3a25-42cd-88c0-f061c8a6625c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b61f9c70-0a96-4bf2-a60e-a1a3c477309d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f272132-1e52-41ca-ab27-4d602cdc343b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b42b791d-8386-4259-82b5-268b12d2859e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55fe6be5-93f0-4032-bc8a-2164f9cc8788
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25f4c94d-4636-4616-a737-131fe4e5ce12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f57edfc1-60f8-4ede-99d6-28a8224bbddc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef69cd4c-1e9c-49e1-8183-9483a24c537b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5fb5f28c-4ac6-41e4-976a-36429835ab98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f100335f-782d-4747-b7d2-bad972b32503
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a548468d-d45b-4493-81dd-56a93e7b36e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35340942-6fce-428d-8e27-2bd7b30f7d09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4b08730-3d02-4d10-a4a8-6e03000dfc38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f413286-158f-49dc-92b2-a1a895b2e3e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 537ff77e-f8e3-4488-a33b-3b3b4cc1b512
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f709c7b5-215e-4b5c-aa60-4f02dbd7ffe4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b5a85af-811c-4949-8b28-6c613670f607
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7df782b-4895-4c11-b957-fcc2d2731eea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fab829d3-aa9d-44a9-a9ea-712e471930d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3bf8dfd-b1e6-407c-88bb-2cab3cf84d8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 138677b5-a5cc-45d1-8dc9-e486703f265d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f74d6a1-8a5c-4488-afa0-38df2b2841cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87066cbc-eb51-4ba7-811e-75e58816b836
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92e2ce0b-ce7c-4df1-bfa9-1799c1bd4e36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b99b6d99-a47a-41fe-ad22-724cf508eaf8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63713d80-ec17-49c1-8268-6d26df7ac95d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e01efc1c-ee09-4a08-bfa6-ae552355fdf8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a5d4ceb-2a7d-42cd-a5c7-a9aece8d22e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5da6914-136b-4266-9f32-e60607ae0fd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2905dcda-f35a-444a-b841-e397d89ff968
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message feff5739-e571-49fb-b35f-9cc36fabccff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6f2ddd8-9273-4b11-8ce8-3eb0a4979f26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07698192-f9d0-4d71-bcf1-5c237a7398a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9fa75e2-9a61-4e67-a4ac-3a11e412fd03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93446c38-fd3c-4930-86f5-898b0b1045c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11240fcf-b2ef-4dc9-8c1f-fc1b25e05aac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9fdee1f-bfe2-47d0-9a85-57f1a871e594
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b66279cf-6e06-4db8-9021-a573259fc035
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0d304ac-19ad-4895-b28a-0d1ed0bed2e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46d16be7-8b1e-4042-b3cd-72fbf66cb11a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 462e1a53-4cd1-4397-b5a0-bf38b4598f49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c654233d-95a2-4f4f-b605-5377601fd875
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8b8d37e-54bd-4b44-8513-435dec79da27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4db68b3a-6cb0-408d-bfde-aef4dbba224b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1286ce61-1efe-4b66-bd7f-d35f84077e9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 339d325c-e461-44e8-9685-dc0f763128f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf444674-46e3-4481-b47a-267425ad9aeb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9c6ea40-2a8d-4ee9-8217-7c85f41e59b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cfb2be71-1b77-449b-b9a6-3fd7f2e7d50b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e21dc78-7412-4d4b-9716-cdda1bc8559a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 870e488d-23b9-4459-a76d-b1548b0fec11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b43de5bf-3b11-48bc-b7f4-9777e769a867
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 505fadd4-6dd6-4525-a5e6-79c6f7fd11c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a57be11-0f4a-46e8-a809-b5a93e87fa86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9cd1045d-6f70-4fdf-85a1-2000150d62fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de67a147-ed1c-44d2-8fb0-35bd18e7c10b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76548a8a-22dd-47bb-b4d2-db1bc206c566
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4eebda0e-c8e9-4cff-ba71-50694a9a824b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f5ef749-6854-4c5c-938f-a490bdcf88ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9a68f75-48da-430c-b78e-c60a2e517c8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c02997cc-13a0-4117-9a4f-31785018ad0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a148fc44-e6ff-4afc-ac53-f05460bd8ea6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88724614-b88b-4560-ac4d-37e17294f2dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a3a2682-5b97-4719-990c-8cbec3ea14ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c25defb-316c-4d26-ba05-79628d46c13b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb4eee27-096b-4ae2-8c7f-6d0c11b0fb7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f92cc79-af7c-4fb5-aa00-a296e779c64c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0bd9e585-a5b2-4aaa-8e29-9af70805bd48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27d8e2ff-63f7-4d67-88ab-c22a66da5b4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8210f850-eb84-4dca-9d84-c6730258b24a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8346937f-df89-415c-bc94-5120c64c4d0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 725ce644-967f-441b-ad94-b8b3a4673f34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message beb5a7e6-afd9-49fa-96fa-a78ebde590fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 550849b1-3f2c-467d-ae50-e6e0afa0ac4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7979a2bb-0fa7-43a5-a46f-9c4356d3eca1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3bc5a5a8-7496-400a-8acc-300536273513
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 586e254a-306b-4d29-be8f-07928a4eaa0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32206ce8-28b6-4d72-9826-6711e2818652
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee63fc89-1a2f-42dd-ac03-7d9836b911f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de217924-ecb3-4b40-bb72-ccee7b9cbc30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0ce769e-0872-40cb-b361-6712bac1de24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c0282c4-7b25-41f5-9137-7a92ec4c88d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0f1ae8a-e7e6-492a-9e92-800a5003ec36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b108cb55-1f20-4397-bd5a-5b65ae8dea7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9abbc7a2-4b20-4df2-864f-bbee9a367f91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 975193aa-6be3-4814-aaee-921c8b5ef313
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8010ef37-103f-4cbc-ad21-9a23969fd850
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14d6b818-d060-4dc3-be25-5eb54acfe3e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ccc1abf-f8dc-4742-858f-88d815948b09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29ff982b-5f65-4b49-baa0-367fe1033460
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8bef721-491d-4e7c-9eb9-e01ce9fdb8f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73d77204-2a69-48cb-b303-fceebcd10372
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a27fdf9-f5bc-4b19-8f19-75d8c6da8bbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63034acb-d274-4210-ba27-94c95223696b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c69f080-5ec2-4b79-8ff3-bca6306707f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be0d460c-7f96-406a-8d45-58370c38646a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab9174bd-3806-4ad5-adf4-3bc6d9276960
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed09969e-8ca4-4471-addf-576955472c09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 496e07cd-8e52-42e6-9887-103c18c8a975
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44a1ee49-d746-4ebf-b059-846a730adc8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7bac890b-b333-4ddc-bd7c-5167300251d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5fc58727-8415-49db-82d3-f2d346f1455a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40fdd923-f7ce-4c5f-bb35-e293554e48d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f62b7d5f-a82a-4b97-af56-dbc6bb3e81c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ccdb97b-bffc-40ba-bf5e-223ab5b87f04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6f36c6d-0a12-4cdc-a553-d19cbf9dcbc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a1ec1c9-2c80-46f4-8880-a9163201602d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c087595b-6e4f-42ea-a353-6cd2bd6d71c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53874563-a3c0-4c4b-bb23-dac62fb16839
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2316febc-c17a-4c2e-877b-8e29c71a42b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fcdcb0e0-4124-432e-8a02-b0f8dc3091d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d165759-9280-4edb-af24-a0d71da4a685
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41d52d1c-f358-4bfd-bf23-818c431f67bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b33cf8f-7c07-454b-9287-1769861e6766
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9104e3db-d485-463b-a9d3-84c1468cd569
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89f1f2b9-4305-42a6-aa8f-4ffa98daa084
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d243138-3762-409a-9dc9-2ef1b59a748c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af1e3889-1880-46ae-8dd2-575fcac1b206
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c74295f8-e2cf-44d2-842a-72c51e24e5cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6de4158d-8195-4548-9faf-b705af07357e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 475947ae-5ce7-42f9-8384-6197309021f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1d10e18-108f-4631-b2c3-ce674e531ed6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8da0f17c-7e21-4baf-9673-e3fcef29ff4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb5f2d7f-b0c8-4cc0-afea-c18859ee155f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67071e84-2515-473c-9c0d-8912b6350c3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dfe69873-eb13-4e7c-8353-ea3be9d50c23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ef34184-5ce1-449a-a5de-705b1fbe830c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7265a80-b87d-4e6a-ab12-82518782d636
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0816c0c3-3128-47eb-8623-55afb9995ae1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c60e254e-1724-4035-9e2b-9d19fc0927bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e2f2e4d-b521-4744-9494-f74eea18fa07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3d2370f-c0dd-4c82-bb99-0c87c764a042
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6d7c393-f741-444c-b1c0-00d13545ca47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 705534f6-39fd-4ee4-bffa-0a1079443d00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44d29298-768d-4e3f-86ed-f680f2a835c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 554c6737-f86d-49a4-bf90-6cc0bc70c98f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69939838-6e85-484d-990e-08d89ce832c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a6a2a66-c1a4-4a12-8ea2-f407f6f14fe1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9abe941-f0ee-4829-9892-f4e6ef194edf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33882731-459b-4b2e-a3c4-f1451a935af2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ac24fb0-2456-4506-b4ff-f9576c09d800
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 943ee3c1-fe8b-4c85-b281-5a3341020775
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93454025-52ff-443c-8c55-17ae58c962ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b11d62e-5497-4af2-82c8-afd88d76a135
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c24fc538-b5cf-4951-8336-99ace199d52b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ceb3e97b-6920-48c8-b7b5-77cc325f8769
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11fb00f8-751d-4696-b611-f053f7c24c0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e12ac80-b8ba-4178-8300-5b88f692abf7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91fc4ce6-17ca-4b4c-a48a-7f4b1c6aca8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10b282a7-847b-4d24-9a00-0ca2aa68832b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba826bac-b5c6-4cc1-85fe-11c103fabcf6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4374ada-fd8f-4e6d-9e62-acbf8b5c14d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a978fe29-3524-4251-ba05-5b8489690355
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dbf82b2b-16a6-4066-86f0-07d1eba22e7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 322e52cf-ff76-4825-a6c2-da6a8a1651d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c25aa34c-7d1d-4ed2-8210-0e7784ca498f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08a23d9d-1d5f-4798-887d-808f6fa4c82e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a771a9a7-dbf5-48fb-be28-4ab395feb7d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4e764af-df2e-4069-899e-67b0eedc456f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c8a5f33-af0e-42fd-9a9c-f7b3dbf21ee3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7bad531f-4a94-496f-a247-11c2dce3c932
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c0b5bbc-b476-444f-b504-99e1f02a50c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c7e7c62-c81d-4524-9e03-249d2693bdaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38589e97-0697-4e81-95dc-59ad9cc712b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f253aca9-234e-403c-bcbd-7e5546e35bea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5a3c9c5-8b70-41da-bcb6-fab2abceb3a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message acab23c0-901f-43a9-8b84-3fcaf8425970
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa71861a-dbf9-4ef4-987c-5d062bf8a26b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a602df58-12b7-4538-b3a7-f10293e74324
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5de81f81-5106-4cd7-80cc-43aa4740d5b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5afd7fbc-2852-4138-b7ef-4abf9acbcf5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 045646c3-ec13-4048-b3d1-f6cd392ad898
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46559b42-017f-4d0f-89b0-6922c1a5df72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d086565a-6bb4-4d72-b621-5bbbb59d9da8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f25ee16a-d3e6-45f9-83f4-d91ad0549022
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2ea7c9b-dfeb-4c73-aa8c-22f454255a91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ebc771d0-dc46-4230-a909-7f6cbe16f745
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3df300d0-a436-4868-951b-05026be9e323
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfdad829-c82d-4a80-b8ac-de194941d637
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e7af862-355a-407e-9d27-56195462a7b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0017ca64-c66b-4052-a3b1-3dbc5801632e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 497ffc16-2b15-439a-bba7-30da8ae2754d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2f19304-e802-4f63-9f4a-132b3d4ad694
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47702e7e-1745-41a9-ae1a-12720522dd6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5cec3f15-230f-476e-827e-822373b1a802
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4826fb5-4708-4c27-90d7-74b242baecfd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e04ac866-0869-4148-b7b4-b192b253bc9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 284315e2-f829-4609-aa62-fd5d79e62800
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d2eef73-deb4-4901-b8bf-5a02a9e69ec7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bade089a-5ce9-41ac-9c61-630f78e12cbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9bafc603-fb61-4cae-be62-dd54a8efc7c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b10b132a-0cb5-404e-9d61-1f22ce5bc01b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 359f3bc8-8344-4b67-b10f-09b2bd10c895
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6404fa9d-59df-4f07-b0c1-cfd7048a4c13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae6ae553-543f-4fa3-b98e-9c15b9736cb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a4dc78e-c5b1-4715-b91b-a12ad9a74647
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6fc2553e-3828-4f5a-884f-ce48faaa5574
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4e32eea-fc06-4f75-9640-dfe139cc4bb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25781a07-ccad-4433-a50f-a0608b0926d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 703ff083-2b28-48c1-bd33-2a3508964074
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b92e2e7f-57b9-4fae-a3b2-05fa2eae7112
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3f396be-ce59-47e2-a3fc-0f3281b4b5cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0cce1daf-a989-4ab0-8c3a-3e694a126941
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 733a94c6-1713-4466-a348-98853b7b438a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 538ae4bb-2a69-4b87-aa6d-dfcc89dc8793
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d040877-ca7b-4c23-bd68-9d27442589fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4fa1ba4-cc17-41bc-87d2-90678028f67b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12031299-75c2-4eb9-bd5f-c095f0e88e29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 803d23c1-4b5f-419b-8b46-1109844af9b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2269bb44-902b-4554-bcc6-2b9c87b8140d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 723b2f3e-50a4-4528-a6ca-39c3d9c0a461
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6bef7b39-2381-496a-8c08-ceb646599fda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af070cf3-3f4e-42ca-a566-1b316c00bb64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26f17474-dfbf-4d60-a18d-f11d3bd9ba8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0919f41f-a3bb-47e1-9ca6-5acde92cb0b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c770f870-774a-443a-aea3-459e69320f4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b92ca673-9abe-434f-8862-2a740b494a08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 120cdd4d-7941-4863-b9a9-0cc54d01c671
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16cb03dc-0d76-423e-bc46-6c2c163bda5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b6a6314-7d07-4f4a-a760-02370d30eed2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20907c1b-2055-4e9c-bd36-9a9a59174434
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e20a9b5a-312d-49b5-b324-1b00542c18b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0b5ccba-9ad3-4bba-9d14-5d72f217b79b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 984619d5-e103-479c-a7f3-0e408a819c6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0bcfd2ee-5025-4644-9e0f-ca2fe77b802e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5ed9038-fc3e-4ec4-bff1-5fed0932a74f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 753b40b1-a62d-462e-bbc0-628e82760589
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29371692-c219-4b2a-9e9a-1755d9842941
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6bad553c-bb81-4cc0-b226-977c9cd0af5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab2908cc-a295-473c-a04f-fefc3f4cfba3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 103cd88d-cc06-4b12-8113-046f2f9abdf9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4cfa602d-ebc0-4417-9bee-90c55624ff1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19e0c730-aa73-42b7-847e-164ab5b49da8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32485bd4-b0d4-4e37-8a14-5f3c494c07a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57759e2a-1482-4be4-99dd-108a9196a140
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9417b00-ec38-486e-babc-19ffe8a50055
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70fb9a6d-3cf9-4eb9-b037-29599a780da5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d84de724-5fe8-4043-9077-13b097b909b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a7ca9fa-2096-446e-9094-1a1db1e9c8d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c32df5db-b2d3-4e08-8c74-312f0d7d7c30
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8690 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_4
Server: localhost:8690
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_4
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_4/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_4/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_4/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_4/test_labels.txt

📊 Raw data loaded:
   Train: X=(5467, 24), y=(5467,)
   Test:  X=(1367, 24), y=(1367,)

⚠️  Limiting training data: 5467 → 800 samples
⚠️  Limiting test data: 1367 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_4 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 2 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0865 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0850, val=0.0856 (↓), lr=0.001000
   • Epoch   3/100: train=0.0846, val=0.0853, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0844, val=0.0853, patience=2/15, lr=0.001000
   • Epoch   5/100: train=0.0842, val=0.0852, patience=3/15, lr=0.001000
   • Epoch  11/100: train=0.0827, val=0.0859, patience=9/15, lr=0.001000
   📉 Epoch 12: LR reduced 0.001000 → 0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 2 Summary - Client client_4
   Epochs: 17/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0003
   Val:   Loss=0.0856, RMSE=0.2926, R²=0.0024
============================================================


============================================================
🔄 Round 4 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0922 (↓), lr=0.000500
   • Epoch   2/100: train=0.0827, val=0.0920, patience=1/15, lr=0.000500
   📉 Epoch 3: LR reduced 0.000500 → 0.000250
   • Epoch   3/100: train=0.0825, val=0.0920, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0823, val=0.0918, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0821, val=0.0919, patience=4/15, lr=0.000250
   📉 Epoch 11: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0818, val=0.0921, patience=10/15, lr=0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0922)

============================================================
📊 Round 4 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000500 → 0.000125 (2 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0005
   Val:   Loss=0.0922, RMSE=0.3037, R²=-0.0020
============================================================


📊 Round 4 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2526, R²: 0.0022

📊 Round 4 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2527, R²: 0.0018

============================================================
🔄 Round 7 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0977 (↓), lr=0.000125
   • Epoch   2/100: train=0.0812, val=0.0976, patience=1/15, lr=0.000125
   📉 Epoch 3: LR reduced 0.000125 → 0.000063
   • Epoch   3/100: train=0.0811, val=0.0974, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0811, val=0.0974, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0811, val=0.0974, patience=4/15, lr=0.000063
   📉 Epoch 11: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0810, val=0.0973, patience=10/15, lr=0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0977)

============================================================
📊 Round 7 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000125 → 0.000031 (2 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0015
   Val:   Loss=0.0977, RMSE=0.3126, R²=-0.0056
============================================================


📊 Round 7 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2527, R²: 0.0019

============================================================
🔄 Round 8 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0735 (↓), lr=0.000031
   • Epoch   2/100: train=0.0872, val=0.0736, patience=1/15, lr=0.000031
   • Epoch   3/100: train=0.0871, val=0.0737, patience=2/15, lr=0.000031
   • Epoch   4/100: train=0.0871, val=0.0737, patience=3/15, lr=0.000031
   • Epoch   5/100: train=0.0871, val=0.0737, patience=4/15, lr=0.000031
   📉 Epoch 7: LR reduced 0.000031 → 0.000016
   • Epoch  11/100: train=0.0869, val=0.0738, patience=10/15, lr=0.000016
   📉 Epoch 15: LR reduced 0.000016 → 0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 8 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000031 → 0.000008 (2 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=-0.0005
   Val:   Loss=0.0735, RMSE=0.2711, R²=-0.0511
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2526, R²: 0.0023

📊 Round 8 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2526, R²: 0.0019

============================================================
🔄 Round 11 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0887 (↓), lr=0.000008
   • Epoch   2/100: train=0.0835, val=0.0887, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0834, val=0.0888, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0834, val=0.0889, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0834, val=0.0890, patience=4/15, lr=0.000008
   📉 Epoch 7: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0833, val=0.0892, patience=10/15, lr=0.000004
   📉 Epoch 15: LR reduced 0.000004 → 0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 11 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0015
   Val:   Loss=0.0887, RMSE=0.2978, R²=-0.0063
============================================================


============================================================
🔄 Round 13 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0818 (↓), lr=0.000002
   • Epoch   2/100: train=0.0853, val=0.0818, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0853, val=0.0819, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0853, val=0.0819, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0853, val=0.0819, patience=4/15, lr=0.000002
   📉 Epoch 7: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0853, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 13 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0020
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0123
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2525, R²: 0.0032

============================================================
🔄 Round 18 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 18 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2947, R²=0.0018
   Val:   Loss=0.0749, RMSE=0.2737, R²=-0.0065
============================================================


============================================================
🔄 Round 19 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 19 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0025
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0108
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2525, R²: 0.0031

📊 Round 19 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2525, R²: 0.0031

============================================================
🔄 Round 24 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 24 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2904, R²=0.0013
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0048
============================================================


============================================================
🔄 Round 25 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 25 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0003
   Val:   Loss=0.0882, RMSE=0.2969, R²=0.0007
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2525, R²: 0.0031

============================================================
🔄 Round 28 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 28 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0007
   Val:   Loss=0.0783, RMSE=0.2798, R²=0.0051
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2525, R²: 0.0031

📊 Round 28 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2525, R²: 0.0031

============================================================
🔄 Round 30 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0944 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0944, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0944, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0944, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0944, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0945, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0944)

============================================================
📊 Round 30 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0001
   Val:   Loss=0.0944, RMSE=0.3073, R²=0.0001
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2525, R²: 0.0031

📊 Round 30 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2525, R²: 0.0031

============================================================
🔄 Round 32 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 32 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0019
   Val:   Loss=0.0783, RMSE=0.2798, R²=-0.0190
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2525, R²: 0.0031

============================================================
🔄 Round 34 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 34 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=0.0016
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0044
============================================================


============================================================
🔄 Round 36 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 36 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2944, R²=0.0022
   Val:   Loss=0.0757, RMSE=0.2752, R²=-0.0079
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2525, R²: 0.0031

============================================================
🔄 Round 38 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 38 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2904, R²=0.0003
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0076
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2525, R²: 0.0031

============================================================
🔄 Round 39 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 39 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=-0.0004
   Val:   Loss=0.0755, RMSE=0.2747, R²=-0.0020
============================================================


============================================================
🔄 Round 42 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 42 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2923, R²=-0.0003
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0033
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2525, R²: 0.0031

📊 Round 42 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2525, R²: 0.0031

============================================================
🔄 Round 46 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 46 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=0.0009
   Val:   Loss=0.0801, RMSE=0.2829, R²=-0.0061
============================================================


============================================================
🔄 Round 47 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 47 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0010
   Val:   Loss=0.0841, RMSE=0.2901, R²=-0.0044
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2525, R²: 0.0031

============================================================
🔄 Round 51 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 51 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0002
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0107
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2525, R²: 0.0031

📊 Round 51 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2525, R²: 0.0031

📊 Round 51 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2525, R²: 0.0031

============================================================
🔄 Round 56 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 56 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0014
   Val:   Loss=0.0903, RMSE=0.3005, R²=0.0041
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2525, R²: 0.0031

============================================================
🔄 Round 57 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 57 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0008
   Val:   Loss=0.0903, RMSE=0.3006, R²=-0.0019
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2525, R²: 0.0031

============================================================
🔄 Round 62 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 62 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=0.0005
   Val:   Loss=0.0775, RMSE=0.2785, R²=-0.0059
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2525, R²: 0.0031

📊 Round 62 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2525, R²: 0.0032

============================================================
🔄 Round 69 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 69 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0004
   Val:   Loss=0.0809, RMSE=0.2843, R²=0.0006
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2525, R²: 0.0032

============================================================
🔄 Round 70 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0715 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0715, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0715, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0715, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0716, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0716, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0715)

============================================================
📊 Round 70 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=-0.0004
   Val:   Loss=0.0715, RMSE=0.2674, R²=-0.0022
============================================================


============================================================
🔄 Round 72 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 72 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0022
   Val:   Loss=0.0880, RMSE=0.2966, R²=0.0046
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2525, R²: 0.0031

============================================================
🔄 Round 74 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 74 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0002
   Val:   Loss=0.0852, RMSE=0.2920, R²=0.0014
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2525, R²: 0.0031

============================================================
🔄 Round 76 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 76 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0030
   Val:   Loss=0.0847, RMSE=0.2911, R²=-0.0001
============================================================


============================================================
🔄 Round 77 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 77 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0007
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0026
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2525, R²: 0.0031

📊 Round 77 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2525, R²: 0.0031

============================================================
🔄 Round 87 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 87 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0010
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0286
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2525, R²: 0.0032

============================================================
🔄 Round 88 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 88 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=0.0003
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0006
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2525, R²: 0.0032

============================================================
🔄 Round 89 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 89 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=-0.0012
   Val:   Loss=0.0830, RMSE=0.2880, R²=-0.0163
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2525, R²: 0.0032

============================================================
🔄 Round 90 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 90 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0017
   Val:   Loss=0.0780, RMSE=0.2794, R²=0.0098
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2525, R²: 0.0032

============================================================
🔄 Round 91 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 91 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0001
   Val:   Loss=0.0809, RMSE=0.2845, R²=-0.0002
============================================================


============================================================
🔄 Round 92 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 92 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0007
   Val:   Loss=0.0820, RMSE=0.2863, R²=0.0038
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2525, R²: 0.0032

============================================================
🔄 Round 93 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 93 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0019
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0076
============================================================


============================================================
🔄 Round 94 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 94 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=-0.0020
   Val:   Loss=0.0761, RMSE=0.2759, R²=0.0004
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2525, R²: 0.0032

📊 Round 94 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2525, R²: 0.0032

📊 Round 94 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2525, R²: 0.0032

============================================================
🔄 Round 102 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 102 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=0.0005
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0006
============================================================


============================================================
🔄 Round 105 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 105 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0006
   Val:   Loss=0.0885, RMSE=0.2975, R²=-0.0135
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2525, R²: 0.0032

============================================================
🔄 Round 110 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 110 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0008
   Val:   Loss=0.0776, RMSE=0.2786, R²=0.0057
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2525, R²: 0.0032

📊 Round 110 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2525, R²: 0.0032

============================================================
🔄 Round 113 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 113 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0006
   Val:   Loss=0.0853, RMSE=0.2920, R²=-0.0024
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0032

============================================================
🔄 Round 114 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 114 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0012
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0083
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0032

============================================================
🔄 Round 116 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 116 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0010
   Val:   Loss=0.0879, RMSE=0.2965, R²=-0.0017
============================================================


============================================================
🔄 Round 119 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0996 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0996, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0996, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0996, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0996, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0996, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0996)

============================================================
📊 Round 119 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0014
   Val:   Loss=0.0996, RMSE=0.3155, R²=0.0061
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0032

============================================================
🔄 Round 121 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 121 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0006
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0008
============================================================


============================================================
🔄 Round 122 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 122 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0012
   Val:   Loss=0.0861, RMSE=0.2935, R²=0.0066
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0032

============================================================
🔄 Round 125 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 125 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0004
   Val:   Loss=0.0831, RMSE=0.2882, R²=-0.0019
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0032

============================================================
🔄 Round 126 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 126 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0017
   Val:   Loss=0.0875, RMSE=0.2957, R²=-0.0045
============================================================


============================================================
🔄 Round 128 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 128 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0022
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0075
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0032

📊 Round 128 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0032

📊 Round 128 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0032

============================================================
🔄 Round 131 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 131 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0002
   Val:   Loss=0.0822, RMSE=0.2867, R²=0.0023
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0032

============================================================
🔄 Round 133 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0945 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0945, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0945, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0945, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0945, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0945, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0945)

============================================================
📊 Round 133 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0005
   Val:   Loss=0.0945, RMSE=0.3074, R²=-0.0005
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0032

📊 Round 133 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0032

============================================================
🔄 Round 137 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 137 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0012
   Val:   Loss=0.0883, RMSE=0.2971, R²=0.0011
============================================================


============================================================
🔄 Round 139 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 139 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0000
   Val:   Loss=0.0846, RMSE=0.2909, R²=0.0021
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0032

============================================================
🔄 Round 141 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 141 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=0.0001
   Val:   Loss=0.0768, RMSE=0.2771, R²=-0.0152
============================================================


============================================================
🔄 Round 142 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 142 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0011
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0022
============================================================


============================================================
🔄 Round 143 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0943 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0943, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0943, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0943, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0944, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0944, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0943)

============================================================
📊 Round 143 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0001
   Val:   Loss=0.0943, RMSE=0.3071, R²=-0.0155
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0032

📊 Round 143 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0032

============================================================
🔄 Round 148 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 148 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0010
   Val:   Loss=0.0858, RMSE=0.2930, R²=0.0062
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0032

============================================================
🔄 Round 149 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 149 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=0.0004
   Val:   Loss=0.0860, RMSE=0.2933, R²=0.0005
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0032

📊 Round 149 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0032

============================================================
🔄 Round 152 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 152 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0011
   Val:   Loss=0.0907, RMSE=0.3011, R²=-0.0061
============================================================


============================================================
🔄 Round 153 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 153 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0016
   Val:   Loss=0.0915, RMSE=0.3025, R²=-0.0036
============================================================


============================================================
🔄 Round 154 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 154 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=-0.0001
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0031
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0032

============================================================
🔄 Round 155 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 155 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0034
   Val:   Loss=0.0845, RMSE=0.2906, R²=-0.0040
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0032

📊 Round 155 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0032

📊 Round 155 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0032

============================================================
🔄 Round 161 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 161 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0004
   Val:   Loss=0.0889, RMSE=0.2982, R²=0.0036
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0032

📊 Round 161 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0032

============================================================
🔄 Round 163 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 163 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=-0.0016
   Val:   Loss=0.0885, RMSE=0.2975, R²=0.0027
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0032

============================================================
🔄 Round 166 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 166 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0001
   Val:   Loss=0.0740, RMSE=0.2720, R²=-0.0107
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0032

📊 Round 166 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0032

📊 Round 166 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0032

============================================================
🔄 Round 173 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 173 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0016
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0049
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0032

============================================================
🔄 Round 177 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 177 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0000
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0010
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0032

============================================================
🔄 Round 178 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 178 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0009
   Val:   Loss=0.0904, RMSE=0.3006, R²=-0.0011
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0032

📊 Round 178 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0032

============================================================
🔄 Round 183 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 183 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0009
   Val:   Loss=0.0911, RMSE=0.3019, R²=0.0049
============================================================


============================================================
🔄 Round 185 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 185 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0019
   Val:   Loss=0.0842, RMSE=0.2901, R²=-0.0053
============================================================


============================================================
🔄 Round 186 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 186 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=-0.0013
   Val:   Loss=0.0741, RMSE=0.2722, R²=0.0056
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0032

============================================================
🔄 Round 187 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0943 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0943, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0943, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0943, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0944, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0944, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0943)

============================================================
📊 Round 187 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0017
   Val:   Loss=0.0943, RMSE=0.3071, R²=-0.0092
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0032

📊 Round 187 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0032

📊 Round 187 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0032

============================================================
🔄 Round 190 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 190 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0004
   Val:   Loss=0.0916, RMSE=0.3027, R²=-0.0064
============================================================


📊 Round 190 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0032

📊 Round 190 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0032

📊 Round 190 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0032

📊 Round 190 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0032

============================================================
🔄 Round 196 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 196 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0002
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0033
============================================================


📊 Round 196 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0032

📊 Round 196 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0032

============================================================
🔄 Round 199 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 199 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0027
   Val:   Loss=0.0768, RMSE=0.2771, R²=-0.0045
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0032

============================================================
🔄 Round 202 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 202 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0022
   Val:   Loss=0.0896, RMSE=0.2993, R²=-0.0085
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0032

📊 Round 202 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0032

📊 Round 202 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0032

============================================================
🔄 Round 205 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 205 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0011
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0074
============================================================


📊 Round 205 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0032

============================================================
🔄 Round 206 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0927 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0927, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0927, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0927, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0927, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0927)

============================================================
📊 Round 206 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0001
   Val:   Loss=0.0927, RMSE=0.3045, R²=0.0023
============================================================


📊 Round 206 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0032

📊 Round 206 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0032

📊 Round 206 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0032

============================================================
🔄 Round 211 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 211 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=0.0002
   Val:   Loss=0.0798, RMSE=0.2824, R²=-0.0027
============================================================


📊 Round 211 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0032

============================================================
🔄 Round 213 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0934 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0934, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0934, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0933, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0933, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0933, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0934)

============================================================
📊 Round 213 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=0.0002
   Val:   Loss=0.0934, RMSE=0.3055, R²=-0.0019
============================================================


============================================================
🔄 Round 214 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 214 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0005
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0031
============================================================


📊 Round 214 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0032

📊 Round 214 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0032

📊 Round 214 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0032

============================================================
🔄 Round 229 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0958 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0958, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0958, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0958, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0958, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0958, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0958)

============================================================
📊 Round 229 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0017
   Val:   Loss=0.0958, RMSE=0.3095, R²=-0.0041
============================================================


📊 Round 229 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0032

============================================================
🔄 Round 230 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 230 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0006
   Val:   Loss=0.0855, RMSE=0.2923, R²=-0.0051
============================================================


============================================================
🔄 Round 231 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 231 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=0.0015
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0041
============================================================


============================================================
🔄 Round 233 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0979 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0979, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0979, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0979, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0979, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0979, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0979)

============================================================
📊 Round 233 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0012
   Val:   Loss=0.0979, RMSE=0.3129, R²=-0.0033
============================================================


📊 Round 233 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0032

📊 Round 233 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0032

📊 Round 233 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0032

============================================================
🔄 Round 237 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 237 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0018
   Val:   Loss=0.0895, RMSE=0.2991, R²=0.0042
============================================================


📊 Round 237 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0032

============================================================
🔄 Round 238 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0934 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0934, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0934, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0934, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0934, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0935, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0934)

============================================================
📊 Round 238 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=-0.0007
   Val:   Loss=0.0934, RMSE=0.3056, R²=-0.0029
============================================================


============================================================
🔄 Round 240 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 240 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=0.0010
   Val:   Loss=0.0749, RMSE=0.2737, R²=-0.0026
============================================================


============================================================
🔄 Round 241 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 241 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=-0.0008
   Val:   Loss=0.0789, RMSE=0.2808, R²=0.0054
============================================================


📊 Round 241 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0032

📊 Round 241 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0032

📊 Round 241 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0032

============================================================
🔄 Round 245 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 245 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=-0.0009
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0066
============================================================


📊 Round 245 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0032

📊 Round 245 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0032

============================================================
🔄 Round 249 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 249 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=0.0004
   Val:   Loss=0.0872, RMSE=0.2953, R²=0.0010
============================================================


📊 Round 249 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0032

📊 Round 249 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0032

============================================================
🔄 Round 257 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 257 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=-0.0001
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0025
============================================================


📊 Round 257 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0032

📊 Round 257 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0032

📊 Round 257 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0032

============================================================
🔄 Round 261 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 261 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0021
   Val:   Loss=0.0849, RMSE=0.2913, R²=-0.0085
============================================================


============================================================
🔄 Round 262 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 262 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0001
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0023
============================================================


📊 Round 262 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0033

============================================================
🔄 Round 264 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 264 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0002
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0019
============================================================


📊 Round 264 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0033

============================================================
🔄 Round 266 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 266 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0001
   Val:   Loss=0.0822, RMSE=0.2866, R²=-0.0037
============================================================


📊 Round 266 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0032

============================================================
🔄 Round 268 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 268 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0001
   Val:   Loss=0.0867, RMSE=0.2945, R²=0.0027
============================================================


📊 Round 268 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0032

📊 Round 268 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0032

📊 Round 268 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0032

============================================================
🔄 Round 275 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 275 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0008
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0034
============================================================


📊 Round 275 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0032

============================================================
🔄 Round 278 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.1002 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.1002, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.1002, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.1002, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.1002, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.1001, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1002)

============================================================
📊 Round 278 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0007
   Val:   Loss=0.1002, RMSE=0.3165, R²=-0.0004
============================================================


============================================================
🔄 Round 279 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 279 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=-0.0011
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0012
============================================================


============================================================
🔄 Round 280 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 280 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0009
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0049
============================================================


📊 Round 280 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0033

============================================================
🔄 Round 281 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 281 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0015
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0039
============================================================


📊 Round 281 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0033

============================================================
🔄 Round 283 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 283 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0009
   Val:   Loss=0.0830, RMSE=0.2882, R²=-0.0012
============================================================


📊 Round 283 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0033

============================================================
🔄 Round 286 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 286 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0027
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0097
============================================================


📊 Round 286 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0033

📊 Round 286 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0033

============================================================
🔄 Round 288 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 288 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=0.0002
   Val:   Loss=0.0845, RMSE=0.2906, R²=0.0005
============================================================


📊 Round 288 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0033

📊 Round 288 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0033

============================================================
🔄 Round 290 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 290 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=0.0021
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0066
============================================================


============================================================
🔄 Round 291 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 291 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0000
   Val:   Loss=0.0917, RMSE=0.3028, R²=-0.0021
============================================================


============================================================
🔄 Round 294 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 294 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0009
   Val:   Loss=0.0909, RMSE=0.3015, R²=-0.0010
============================================================


📊 Round 294 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0033

📊 Round 294 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0033

============================================================
🔄 Round 302 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 302 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=0.0017
   Val:   Loss=0.0797, RMSE=0.2824, R²=-0.0285
============================================================


============================================================
🔄 Round 303 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 303 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=0.0016
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0059
============================================================


📊 Round 303 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0033

📊 Round 303 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0033

📊 Round 303 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0033

============================================================
🔄 Round 308 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 308 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0003
   Val:   Loss=0.0889, RMSE=0.2981, R²=0.0035
============================================================


📊 Round 308 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0033

============================================================
🔄 Round 310 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 310 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0001
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0035
============================================================


============================================================
🔄 Round 313 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 313 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=0.0012
   Val:   Loss=0.0841, RMSE=0.2901, R²=-0.0048
============================================================


============================================================
🔄 Round 314 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 314 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0014
   Val:   Loss=0.0895, RMSE=0.2991, R²=-0.0191
============================================================


📊 Round 314 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0033

============================================================
🔄 Round 315 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 315 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0007
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0063
============================================================


============================================================
🔄 Round 316 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 316 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0002
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0112
============================================================


============================================================
🔄 Round 317 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 317 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0003
   Val:   Loss=0.0892, RMSE=0.2986, R²=0.0013
============================================================


📊 Round 317 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0033

============================================================
🔄 Round 319 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 319 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=-0.0001
   Val:   Loss=0.0784, RMSE=0.2800, R²=-0.0024
============================================================


============================================================
🔄 Round 320 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 320 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0018
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0018
============================================================


============================================================
🔄 Round 322 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 322 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0016
   Val:   Loss=0.0859, RMSE=0.2932, R²=-0.0040
============================================================


📊 Round 322 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0033

📊 Round 322 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0033

📊 Round 322 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0033

============================================================
🔄 Round 328 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 328 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0001
   Val:   Loss=0.0893, RMSE=0.2988, R²=0.0026
============================================================


📊 Round 328 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0033

📊 Round 328 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0033

📊 Round 328 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0033

📊 Round 328 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0033

📊 Round 328 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0033

📊 Round 328 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0033

============================================================
🔄 Round 338 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0946 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0946, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0946, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0946, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0946, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0946, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0946)

============================================================
📊 Round 338 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0003
   Val:   Loss=0.0946, RMSE=0.3075, R²=-0.0017
============================================================


============================================================
🔄 Round 339 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0974 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0974, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0974, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0974, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0974, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0974, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0974)

============================================================
📊 Round 339 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0005
   Val:   Loss=0.0974, RMSE=0.3121, R²=0.0007
============================================================


============================================================
🔄 Round 340 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 340 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0002
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0006
============================================================


============================================================
🔄 Round 341 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 341 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0009
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0046
============================================================


📊 Round 341 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0033

============================================================
🔄 Round 342 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 342 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0010
   Val:   Loss=0.0853, RMSE=0.2920, R²=0.0034
============================================================


📊 Round 342 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0033

============================================================
🔄 Round 343 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 343 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0017
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0051
============================================================


📊 Round 343 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0033

============================================================
🔄 Round 345 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 345 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0021
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0111
============================================================


📊 Round 345 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0033

============================================================
🔄 Round 346 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 346 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0002
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0227
============================================================


============================================================
🔄 Round 347 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 347 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0006
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0016
============================================================


============================================================
🔄 Round 348 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0934 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0934, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0934, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0934, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0935, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0936, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0934)

============================================================
📊 Round 348 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=-0.0019
   Val:   Loss=0.0934, RMSE=0.3056, R²=-0.0188
============================================================


============================================================
🔄 Round 349 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 349 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0011
   Val:   Loss=0.0821, RMSE=0.2866, R²=0.0031
============================================================


📊 Round 349 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0033

============================================================
🔄 Round 350 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 350 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=0.0022
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0150
============================================================


============================================================
🔄 Round 351 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 351 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=0.0002
   Val:   Loss=0.0751, RMSE=0.2740, R²=-0.0008
============================================================


📊 Round 351 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0033

📊 Round 351 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0033

============================================================
🔄 Round 355 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 355 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0002
   Val:   Loss=0.0899, RMSE=0.2998, R²=0.0017
============================================================


============================================================
🔄 Round 356 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 356 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=0.0008
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0033
============================================================


📊 Round 356 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0033

============================================================
🔄 Round 360 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 360 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2957, R²=-0.0006
   Val:   Loss=0.0724, RMSE=0.2691, R²=0.0027
============================================================


============================================================
🔄 Round 361 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 361 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2896, R²=-0.0001
   Val:   Loss=0.0869, RMSE=0.2948, R²=-0.0025
============================================================


============================================================
🔄 Round 362 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 362 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0012
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0021
============================================================


============================================================
🔄 Round 363 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 363 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0009
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0010
============================================================


============================================================
🔄 Round 365 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 365 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=-0.0006
   Val:   Loss=0.0772, RMSE=0.2778, R²=0.0061
============================================================


============================================================
🔄 Round 368 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 368 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0002
   Val:   Loss=0.0828, RMSE=0.2878, R²=0.0005
============================================================


============================================================
🔄 Round 370 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 370 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=0.0021
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0057
============================================================


📊 Round 370 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0033

============================================================
🔄 Round 373 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 373 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0001
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0026
============================================================


📊 Round 373 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0033

📊 Round 373 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0033

============================================================
🔄 Round 376 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 376 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=0.0015
   Val:   Loss=0.0750, RMSE=0.2738, R²=-0.0058
============================================================


============================================================
🔄 Round 377 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 377 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0006
   Val:   Loss=0.0877, RMSE=0.2962, R²=-0.0011
============================================================


============================================================
🔄 Round 380 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 380 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0002
   Val:   Loss=0.0875, RMSE=0.2959, R²=-0.0026
============================================================


📊 Round 380 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0033

📊 Round 380 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0033

📊 Round 380 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0033

============================================================
🔄 Round 391 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 391 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0011
   Val:   Loss=0.0826, RMSE=0.2874, R²=0.0033
============================================================


📊 Round 391 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0033

📊 Round 391 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0033

============================================================
🔄 Round 395 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 395 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=-0.0003
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0036
============================================================


============================================================
🔄 Round 397 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 397 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0007
   Val:   Loss=0.0887, RMSE=0.2978, R²=0.0038
============================================================


📊 Round 397 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0033

============================================================
🔄 Round 400 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 400 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=0.0014
   Val:   Loss=0.0801, RMSE=0.2831, R²=-0.0211
============================================================


📊 Round 400 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0033

============================================================
🔄 Round 404 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 404 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0035
   Val:   Loss=0.0865, RMSE=0.2940, R²=-0.0068
============================================================


📊 Round 404 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0033

============================================================
🔄 Round 406 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 406 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=0.0005
   Val:   Loss=0.0795, RMSE=0.2819, R²=-0.0011
============================================================


📊 Round 406 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0033

📊 Round 406 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0033

📊 Round 406 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0033

📊 Round 406 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0033

============================================================
🔄 Round 411 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 411 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=0.0004
   Val:   Loss=0.0845, RMSE=0.2906, R²=0.0009
============================================================


📊 Round 411 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0033

📊 Round 411 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0033

============================================================
🔄 Round 413 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 413 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=0.0011
   Val:   Loss=0.0784, RMSE=0.2799, R²=-0.0159
============================================================


📊 Round 413 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0033

============================================================
🔄 Round 415 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 415 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=0.0002
   Val:   Loss=0.0812, RMSE=0.2850, R²=0.0019
============================================================


📊 Round 415 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0033

============================================================
🔄 Round 418 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 418 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2937, R²=0.0002
   Val:   Loss=0.0773, RMSE=0.2781, R²=0.0018
============================================================


============================================================
🔄 Round 419 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 419 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0009
   Val:   Loss=0.0836, RMSE=0.2892, R²=-0.0042
============================================================


📊 Round 419 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0033

📊 Round 419 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0033

============================================================
🔄 Round 425 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 425 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0022
   Val:   Loss=0.0852, RMSE=0.2918, R²=-0.0087
============================================================


📊 Round 425 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0033

📊 Round 425 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0033

============================================================
🔄 Round 430 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 430 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0013
   Val:   Loss=0.0880, RMSE=0.2967, R²=-0.0027
============================================================


============================================================
🔄 Round 432 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0706 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0706, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0706, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0706, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0706, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0706, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0706)

============================================================
📊 Round 432 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=0.0001
   Val:   Loss=0.0706, RMSE=0.2658, R²=0.0025
============================================================


📊 Round 432 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0033

📊 Round 432 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0033

📊 Round 432 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0033

📊 Round 432 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0033

============================================================
🔄 Round 437 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 437 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0031
   Val:   Loss=0.0879, RMSE=0.2964, R²=-0.0175
============================================================


📊 Round 437 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0033

============================================================
🔄 Round 438 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 438 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0012
   Val:   Loss=0.0862, RMSE=0.2935, R²=-0.0104
============================================================


📊 Round 438 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0033

============================================================
🔄 Round 441 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 441 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=0.0002
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0001
============================================================


============================================================
🔄 Round 444 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 444 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0015
   Val:   Loss=0.0892, RMSE=0.2987, R²=-0.0118
============================================================


📊 Round 444 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0033

============================================================
🔄 Round 446 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0946 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0946, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0946, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0946, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0946, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0946, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0946)

============================================================
📊 Round 446 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0005
   Val:   Loss=0.0946, RMSE=0.3076, R²=0.0012
============================================================


📊 Round 446 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0033

📊 Round 446 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0033

============================================================
🔄 Round 449 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 449 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0023
   Val:   Loss=0.0909, RMSE=0.3015, R²=-0.0077
============================================================


============================================================
🔄 Round 457 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 457 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0024
   Val:   Loss=0.0774, RMSE=0.2782, R²=0.0019
============================================================


📊 Round 457 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0034

============================================================
🔄 Round 458 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 458 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0035
   Val:   Loss=0.0896, RMSE=0.2992, R²=-0.0212
============================================================


📊 Round 458 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0033

============================================================
🔄 Round 460 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 460 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0006
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0098
============================================================


📊 Round 460 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0033

📊 Round 460 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0034

============================================================
🔄 Round 462 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 462 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0013
   Val:   Loss=0.0843, RMSE=0.2903, R²=0.0047
============================================================


============================================================
🔄 Round 464 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 464 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0013
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0020
============================================================


============================================================
🔄 Round 465 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 465 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=0.0006
   Val:   Loss=0.0783, RMSE=0.2798, R²=-0.0033
============================================================


============================================================
🔄 Round 468 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 468 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0002
   Val:   Loss=0.0781, RMSE=0.2794, R²=-0.0037
============================================================


📊 Round 468 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0034

📊 Round 468 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0034

📊 Round 468 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0034

📊 Round 468 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0034

============================================================
🔄 Round 475 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 475 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=0.0002
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0023
============================================================


📊 Round 475 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0034

============================================================
🔄 Round 477 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 477 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0013
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0090
============================================================


📊 Round 477 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0034

============================================================
🔄 Round 479 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 479 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0020
   Val:   Loss=0.0861, RMSE=0.2935, R²=-0.0057
============================================================


📊 Round 479 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0034

============================================================
🔄 Round 480 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 480 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0011
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0064
============================================================


============================================================
🔄 Round 482 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 482 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=0.0001
   Val:   Loss=0.0796, RMSE=0.2822, R²=-0.0011
============================================================


📊 Round 482 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0034

📊 Round 482 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0034

============================================================
🔄 Round 488 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 488 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0007
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0002
============================================================


📊 Round 488 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0034

============================================================
🔄 Round 491 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 491 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0004
   Val:   Loss=0.0846, RMSE=0.2908, R²=-0.0008
============================================================


📊 Round 491 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0034

============================================================
🔄 Round 492 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 492 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0010
   Val:   Loss=0.0880, RMSE=0.2967, R²=-0.0037
============================================================


📊 Round 492 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0034

============================================================
🔄 Round 496 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 496 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0006
   Val:   Loss=0.0809, RMSE=0.2845, R²=0.0006
============================================================


============================================================
🔄 Round 498 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 498 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2915, R²=0.0004
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0001
============================================================


📊 Round 498 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0034

📊 Round 498 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0034

============================================================
🔄 Round 501 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 501 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0026
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0204
============================================================


============================================================
🔄 Round 502 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0928 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0928, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0928, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0928, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0928, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0928, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 502 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0001
   Val:   Loss=0.0928, RMSE=0.3046, R²=0.0032
============================================================


📊 Round 502 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0034

📊 Round 502 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0034

📊 Round 502 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0034

============================================================
🔄 Round 508 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 508 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=0.0030
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0199
============================================================


============================================================
🔄 Round 509 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0958 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0958, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0958, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0958, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0958, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0958, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0958)

============================================================
📊 Round 509 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0001
   Val:   Loss=0.0958, RMSE=0.3095, R²=0.0017
============================================================


📊 Round 509 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0034

============================================================
🔄 Round 511 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 511 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0004
   Val:   Loss=0.0902, RMSE=0.3003, R²=0.0003
============================================================


📊 Round 511 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0034

📊 Round 511 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0034

📊 Round 511 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0034

============================================================
🔄 Round 516 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 516 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=-0.0005
   Val:   Loss=0.0741, RMSE=0.2723, R²=0.0026
============================================================


============================================================
🔄 Round 518 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 518 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0000
   Val:   Loss=0.0899, RMSE=0.2999, R²=0.0022
============================================================


📊 Round 518 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0034

📊 Round 518 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0034

📊 Round 518 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0034

============================================================
🔄 Round 522 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 522 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0014
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0039
============================================================


============================================================
🔄 Round 523 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 523 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0005
   Val:   Loss=0.0765, RMSE=0.2766, R²=0.0056
============================================================


📊 Round 523 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0034

============================================================
🔄 Round 524 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 524 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0002
   Val:   Loss=0.0898, RMSE=0.2997, R²=-0.0010
============================================================


============================================================
🔄 Round 525 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 525 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=0.0008
   Val:   Loss=0.0793, RMSE=0.2817, R²=-0.0022
============================================================


📊 Round 525 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0034

============================================================
🔄 Round 528 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 528 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0005
   Val:   Loss=0.0852, RMSE=0.2920, R²=0.0011
============================================================


============================================================
🔄 Round 529 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 529 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0008
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0022
============================================================


📊 Round 529 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0034

📊 Round 529 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0034

📊 Round 529 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0034

============================================================
🔄 Round 533 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 533 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0004
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0022
============================================================


📊 Round 533 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0034

============================================================
🔄 Round 534 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 534 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0002
   Val:   Loss=0.0859, RMSE=0.2930, R²=0.0028
============================================================


============================================================
🔄 Round 536 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 536 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0007
   Val:   Loss=0.0814, RMSE=0.2854, R²=-0.0020
============================================================


📊 Round 536 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0034

📊 Round 536 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0034

📊 Round 536 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0034

============================================================
🔄 Round 540 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 540 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0002
   Val:   Loss=0.0840, RMSE=0.2899, R²=-0.0008
============================================================


📊 Round 540 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0034

📊 Round 540 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0034

============================================================
🔄 Round 544 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0717, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0717, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0717, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0717, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 544 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=0.0005
   Val:   Loss=0.0717, RMSE=0.2678, R²=-0.0013
============================================================


📊 Round 544 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2524, R²: 0.0034

📊 Round 544 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2524, R²: 0.0034

============================================================
🔄 Round 549 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0963 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0963, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0963, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0963, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0963, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0963, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0963)

============================================================
📊 Round 549 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0026
   Val:   Loss=0.0963, RMSE=0.3104, R²=-0.0063
============================================================


============================================================
🔄 Round 550 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 550 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0002
   Val:   Loss=0.0921, RMSE=0.3035, R²=-0.0016
============================================================


📊 Round 550 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0034

============================================================
🔄 Round 555 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 555 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0002
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0013
============================================================


📊 Round 555 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2524, R²: 0.0034

📊 Round 555 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0034

============================================================
🔄 Round 560 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 560 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0002
   Val:   Loss=0.0787, RMSE=0.2806, R²=0.0044
============================================================


📊 Round 560 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2524, R²: 0.0034

============================================================
🔄 Round 563 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 563 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0005
   Val:   Loss=0.0851, RMSE=0.2918, R²=-0.0095
============================================================


============================================================
🔄 Round 564 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0948 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0948, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0948, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0948, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0948, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0948, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0948)

============================================================
📊 Round 564 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0003
   Val:   Loss=0.0948, RMSE=0.3079, R²=0.0014
============================================================


📊 Round 564 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2524, R²: 0.0034

============================================================
🔄 Round 566 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0996 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0996, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0996, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0996, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0996, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0996, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0996)

============================================================
📊 Round 566 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0016
   Val:   Loss=0.0996, RMSE=0.3155, R²=0.0053
============================================================


📊 Round 566 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2524, R²: 0.0034

============================================================
🔄 Round 567 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 567 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0014
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0054
============================================================


📊 Round 567 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0034

============================================================
🔄 Round 568 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 568 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0022
   Val:   Loss=0.0900, RMSE=0.3001, R²=-0.0170
============================================================


📊 Round 568 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2524, R²: 0.0034

📊 Round 568 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2524, R²: 0.0034

============================================================
🔄 Round 574 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 574 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0000
   Val:   Loss=0.0835, RMSE=0.2890, R²=0.0030
============================================================


📊 Round 574 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2524, R²: 0.0034

============================================================
🔄 Round 578 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 578 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0012
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0014
============================================================


============================================================
🔄 Round 580 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 580 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2885, R²=0.0005
   Val:   Loss=0.0892, RMSE=0.2987, R²=0.0015
============================================================


📊 Round 580 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2524, R²: 0.0034

============================================================
🔄 Round 581 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 581 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0003
   Val:   Loss=0.0871, RMSE=0.2951, R²=0.0018
============================================================


📊 Round 581 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0034

📊 Round 581 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0034

============================================================
🔄 Round 583 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 583 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0005
   Val:   Loss=0.0838, RMSE=0.2895, R²=0.0048
============================================================


📊 Round 583 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0034

📊 Round 583 Test Metrics:
   Loss: 0.0841, RMSE: 0.2901, MAE: 0.2525, R²: 0.0034

============================================================
🔄 Round 589 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 589 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0013
   Val:   Loss=0.0867, RMSE=0.2945, R²=-0.0027
============================================================


📊 Round 589 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2524, R²: 0.0034

============================================================
🔄 Round 592 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 592 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0008
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0012
============================================================


📊 Round 592 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2524, R²: 0.0034

============================================================
🔄 Round 596 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 596 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=0.0007
   Val:   Loss=0.0798, RMSE=0.2824, R²=0.0002
============================================================


📊 Round 596 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2524, R²: 0.0034

📊 Round 596 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2524, R²: 0.0034

============================================================
🔄 Round 598 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 598 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0011
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0011
============================================================


============================================================
🔄 Round 601 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 601 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0003
   Val:   Loss=0.0806, RMSE=0.2840, R²=0.0022
============================================================


============================================================
🔄 Round 603 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 603 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0012
   Val:   Loss=0.0798, RMSE=0.2826, R²=-0.0010
============================================================


📊 Round 603 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2524, R²: 0.0034

============================================================
🔄 Round 605 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 605 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=0.0021
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0279
============================================================


📊 Round 605 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2524, R²: 0.0034

📊 Round 605 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2524, R²: 0.0035

============================================================
🔄 Round 608 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 608 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0002
   Val:   Loss=0.0842, RMSE=0.2902, R²=0.0045
============================================================


📊 Round 608 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2524, R²: 0.0035

============================================================
🔄 Round 610 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 610 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0013
   Val:   Loss=0.0874, RMSE=0.2957, R²=-0.0260
============================================================


============================================================
🔄 Round 611 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 611 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=0.0002
   Val:   Loss=0.0794, RMSE=0.2817, R²=0.0028
============================================================


============================================================
🔄 Round 612 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 612 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2897, R²=-0.0003
   Val:   Loss=0.0864, RMSE=0.2940, R²=-0.0012
============================================================


============================================================
🔄 Round 618 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 618 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0020
   Val:   Loss=0.0856, RMSE=0.2925, R²=0.0106
============================================================


============================================================
🔄 Round 619 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 619 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0018
   Val:   Loss=0.0895, RMSE=0.2992, R²=-0.0036
============================================================


📊 Round 619 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2524, R²: 0.0035

============================================================
🔄 Round 622 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 622 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0001
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0035
============================================================


============================================================
🔄 Round 624 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0922, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 624 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0005
   Val:   Loss=0.0921, RMSE=0.3034, R²=-0.0084
============================================================


📊 Round 624 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2524, R²: 0.0035

============================================================
🔄 Round 625 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 625 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0024
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0197
============================================================


📊 Round 625 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2524, R²: 0.0035

============================================================
🔄 Round 626 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 626 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0004
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0023
============================================================


============================================================
🔄 Round 628 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 628 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0014
   Val:   Loss=0.0855, RMSE=0.2923, R²=-0.0020
============================================================


============================================================
🔄 Round 629 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 629 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=0.0009
   Val:   Loss=0.0884, RMSE=0.2974, R²=0.0001
============================================================


📊 Round 629 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2524, R²: 0.0035

============================================================
🔄 Round 630 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 630 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=0.0006
   Val:   Loss=0.0816, RMSE=0.2856, R²=0.0010
============================================================


📊 Round 630 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2524, R²: 0.0035

============================================================
🔄 Round 631 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 631 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0002
   Val:   Loss=0.0819, RMSE=0.2861, R²=-0.0020
============================================================


============================================================
🔄 Round 639 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 639 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0008
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0001
============================================================


============================================================
🔄 Round 640 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 640 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=0.0006
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0001
============================================================


============================================================
🔄 Round 641 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 641 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0004
   Val:   Loss=0.0841, RMSE=0.2901, R²=0.0030
============================================================


📊 Round 641 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2524, R²: 0.0035

📊 Round 641 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2524, R²: 0.0035

📊 Round 641 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2524, R²: 0.0035

📊 Round 641 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2524, R²: 0.0035

============================================================
🔄 Round 646 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 646 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0017
   Val:   Loss=0.0888, RMSE=0.2979, R²=-0.0057
============================================================


============================================================
🔄 Round 647 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 647 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0003
   Val:   Loss=0.0853, RMSE=0.2920, R²=0.0019
============================================================


📊 Round 647 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2524, R²: 0.0035

============================================================
🔄 Round 650 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 650 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0006
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0063
============================================================


📊 Round 650 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2524, R²: 0.0035

============================================================
🔄 Round 652 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 652 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0016
   Val:   Loss=0.0911, RMSE=0.3019, R²=-0.0053
============================================================


📊 Round 652 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2524, R²: 0.0035

============================================================
🔄 Round 655 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 655 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0010
   Val:   Loss=0.0864, RMSE=0.2940, R²=-0.0002
============================================================


📊 Round 655 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2524, R²: 0.0035

📊 Round 655 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2524, R²: 0.0035

📊 Round 655 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2524, R²: 0.0035

📊 Round 655 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2524, R²: 0.0035

============================================================
🔄 Round 663 - Client client_4
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 663 Summary - Client client_4
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0008
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0067
============================================================


❌ Client client_4 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8690 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8690 {grpc_message:"Socket closed", grpc_status:14}"
>
