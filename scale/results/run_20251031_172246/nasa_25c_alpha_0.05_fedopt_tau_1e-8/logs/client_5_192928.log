[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e4b47b7-ed4e-4a2d-a477-a97ddf17ee84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7751d32d-113e-4dc6-a484-459caa231433
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1c55d24-660c-4c76-a7b1-623c3c094701
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e836b989-fd07-4de6-bebe-65892bc729a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4055b0e-41d3-417e-a208-46ea8aba37b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63efe73b-fe01-4c1a-982f-34c76e255e09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b66afaec-42b1-40fd-bfed-e0a0ffe80d33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3cf28116-3eb9-4218-a85e-287cc21a6a07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f63b700e-42f6-422d-891a-affef4c74be7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b2496cf-83ba-4657-a3ae-e233d628b1ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5448d50-41e1-4cce-aa55-b02b37f9e1b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 694e8528-cda3-4874-9e4c-27bbfc76a4b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5fe2202-dd7a-4b44-bfe5-330df0a18c24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23e0ed0b-274d-46d1-9ac5-0f2e2253e9ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c23c958-dee7-467d-a382-ecbcd9910461
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d86d1c7-f2bb-4f28-b416-4e8aedee5eeb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d404ef3-f2e1-4d50-9150-72b2a3f1e1ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6ba66d9-216c-45c0-a74e-9f45e6eb6ab5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5c9ecd7-4abe-4b2e-b791-f9c43f5768e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a7b0d01-02b0-430f-89fe-2e0bb68ec013
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21631a79-3d05-4331-a245-11afd5f41108
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61a83b00-d39b-4a02-a645-1e71ed723f8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1cb2c693-6665-4e46-8989-c975661a3f1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f1dffff-d45e-4aec-8093-d8d83e404fe5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85cadf49-b7cf-45fa-9091-d8239890f4a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41109e4b-ef89-49f9-8de1-b250632df91c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c23ca42b-208c-4159-8a19-b7b970369bb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ffa0ee5-7ea3-49b7-87a2-d864d79a0a2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8c02454-bed0-4d5c-ad51-a2ced9522fbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4f6bc59-715b-479a-9361-db6ea2a484e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00c3fdda-1915-4f0b-9b5f-fad65ac59c99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9a4334e-1de3-4885-823e-036f2c3d0882
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00964fa6-e32f-47fc-b02a-89625c333828
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03a11e27-dbb1-4d02-94b3-960a1b95acf8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8f746b8-fb92-4eef-bab9-2dfa2a277ebc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d8aaa24-d3db-4e1e-a927-323f678a8e13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a7e53d9-4ed8-4fea-a66f-74f5db69d7f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93b537bd-f17b-4274-90ce-cf342357dad6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16c4ac6d-7d35-49a9-a8af-483eb78a6bc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b90277b-d0a9-45d1-a80b-d3cbe0495400
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 443567d6-7ca8-4a01-8e22-91c2f8ac2dc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49b79cc1-a1d6-43e9-b47e-a46cb7472f1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04b23732-b343-4d1b-90fb-0cf72dac6b15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aefcae35-4167-4cfc-ba77-92fad0395f9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message afd38082-67c7-400f-8eb4-f53f9b271255
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b8e8ef4-4965-452e-946d-f9f5672df79a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c696abe2-b811-4e1d-ba2d-c7d3c96033f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56b44a23-e8b4-4963-bec6-05fb495d2d5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c9e7442-14a7-4801-954d-236317754230
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 547854c5-bdd0-497c-ba42-2653ae952646
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 006d7ed3-0c43-4125-b0b6-e98b861ca2ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69747c72-29b3-424c-a722-f27ef00aabd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b391f5bf-dfce-45fb-b14f-4355f0866674
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2fc40816-2666-4043-a171-dbd7f76deae6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55178466-06af-4454-a65c-11946eb5c7e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89cc7e94-a632-446d-9b4d-138721351b12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e0652a3-d4c6-4447-9b0e-bc8be02cf51b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77279bd0-f581-49a4-9d21-a2ac8e51c7a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 704ef1c6-9405-4682-8f03-9fee4921218a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03c97e54-cf6c-44bb-a1d6-c8f6d002e8d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1c55def-d4c7-42c4-b55f-b7ea3cb079f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0169b89a-3a2b-4767-989c-ff6b5ac92d33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6257caca-2322-4e7c-a6eb-1c5c79153982
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64a93145-3f82-4ab6-bdf8-25d1a2862273
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9692288c-a916-4021-9991-68e7387d7d79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 814045c5-4b81-496d-8799-d55bd8c64fb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6ed68e2-2651-49d4-bde9-796adfb19e7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a795715-cd98-42bd-8a56-0493c6ac7b48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d315fe33-55c0-4d7e-95a9-3e9e6da6a257
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15e8ec79-eb08-4299-a4c4-a81a5be16266
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1dddc53-3185-4a36-8dce-1801fd40d187
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b122440-e1db-4b9b-b151-659b31c4dd84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42b2a41a-850b-48d6-83e3-ccdc30971094
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0da9e67-0350-40b8-a8c2-484eab17517a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b20a19a2-4fef-42ce-86bd-89a37a1c0624
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c691a99c-bedf-45ab-bbfb-4ba9c34db0f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5dda0196-d28e-423d-a720-82eb9906734c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2477347f-9bf8-46c1-8a3e-1ea523559024
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ca5abf9-b59d-40cf-8a83-2933cc869e06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43dd6eb0-56a9-4135-acae-0c4e18c4ab35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39c64023-8b3c-4d0c-8383-0d6ed309fd88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc01e81e-1123-4c17-adac-3bd0dc7cae0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8eb87967-c69c-4668-af5f-2b8c78e37372
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c935c393-9fa1-412d-a8ee-18b8fb378733
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b060e12-af25-40ba-bbb0-a30788c80a60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9662c3f0-f260-4c76-8687-554e0bb4bbcd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc98fbb8-0e4b-4c0f-8658-56f2273d74cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d955518-fc57-4008-8b37-78c460010fd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d474ce1-0a42-4872-a093-ba566bd55aed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0dcd0a7e-b1e8-4953-b960-ef4f5a329549
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5941209-6836-4e09-9bbd-64c06a0c6725
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e5627ef-ede8-44ca-936c-c63777287fa9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b8a118f-a20a-42a2-ae61-ca6311fae90a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00c09125-2999-420d-b794-cc930ef19856
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec66cf58-fac4-4df0-bb3f-463326a287d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58be2053-386c-46c6-9441-2e818c4ac1d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b5a2992-960b-4b08-9dc8-e446f78ee404
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa1d2aa5-81f4-4b46-b127-3ab34e7e4e45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 991af2da-1d46-4d49-9df6-991f11abbc47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50b9c15b-5fa6-4f7e-8a11-b7b51c951406
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d50e07af-cd25-49a4-9f1a-4bd5232470f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9b7a934-cd8a-4e9b-a33d-3c23dfdc3a91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a530107d-4527-45ef-8bc4-674f117f9443
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5fa9282-3d4f-4fb8-bc2f-f5d4f5724bcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 437c733c-8381-4c30-87ea-5cae3c7f8f47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4fcbf895-5cab-4119-ab0c-ab629b46551f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 147b5493-270d-438d-bcf5-6657729299a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 505ec949-84bd-4bba-9d9c-d109bf76d6ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7a87814-8b37-42e0-a12f-981cb0891aba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb193d93-30ab-4b07-8419-b0003dfd5322
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5cf23a4f-0c3f-4da5-b346-4d19f7cdb6d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d62e041-3db5-4c66-a344-f0a96129755c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6df1308d-5c10-47be-9931-549cd2ca4b22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 570926b0-698a-4127-aeba-0af2cdbfced1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ce902b3-2a56-4be3-a0d5-1fb697daf0dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 133c2928-a2c6-4cc1-9368-a4769413d401
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message efe46f7a-63a9-45d6-a625-d8c48d751c1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14003d2f-db25-4cab-bc4b-924b61596f9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df01c13d-98f5-4e62-93b2-d6a10aa68255
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91ccf081-85c2-40ac-9017-46455fe04aba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c95b0fca-d66a-4a54-86aa-9e031d0c708f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c097ed2b-b19e-4bcc-bd91-2cdbb802e4aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb6c31d6-7e61-433e-a88a-e464351d1b90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07f45b05-f06d-47b0-8b07-2b61e7805bc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c6b6e18-154e-4fd0-948e-07b2c79c3532
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f6a4d07-610b-403f-9e72-1b00fc0ccd6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2618d117-380b-49f8-bc28-a6afb659ed52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89863835-31bf-4f43-8bd9-eaae78356457
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31e07cca-fffa-40ac-9b64-070b0cb22a8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ada358f-cd2b-4931-8bb6-f409faaafd2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a83882f2-a1c3-4c7e-a914-7c5a5ee49215
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8cb6f844-6f9e-44c6-9790-2f88a7fc4ece
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6e7f129-9cff-47dc-86ac-34f2d9b446bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3bafdb90-2a5a-42b5-9870-c726d3a0f662
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4de48d2a-719e-41ed-94e3-0d7eee0db3e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 913191e9-42ff-4340-85a6-1dc10ae12ba4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aab3ca41-d994-4f30-8b06-2be018f4e1df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5d0e028-9142-491d-940d-54adc31484ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae3e559d-62d4-4f14-a1c8-1f97d756ce58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ac8a4f9-dc33-4bd0-bef8-4780be61e21d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89da8670-a804-406a-add0-6e0db13827a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5f3e511-71e7-4151-bef4-11c8cd2c1dfc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45529eb5-3e9b-4d6a-8c43-b1610147361e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7943a9e3-1eac-4288-bd08-bf8a7d83de56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5536b753-d9df-4d7b-a594-b9873e1a479d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c9d792c-9c74-4134-86fd-2f81ebadfa5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ab7d789-1923-4728-a184-c9a236cac0fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5ab0a42-6c8d-4467-ad69-eaca53040342
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39493bd2-cf46-4e2b-a62f-0872205f8189
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90ca9f56-766a-4b56-9ccf-04fce3b27b89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d445a372-0682-450e-8b7f-69bb2b69a802
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3baaa51-46c1-4da6-8369-5dce5e71ade8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 660b0055-f059-4091-895c-dca123f2d7a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63d9bf99-4f05-43c4-bd26-68119f8af181
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9fa200cb-09b5-4352-a63a-0b43a13ed135
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50f3c151-045c-49ed-a742-2cb4e4b864ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3074fc9-1f04-44ef-bd49-a1a66d58225b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f390b6b1-58fd-4e2e-ac16-cd6b162a49e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58c72315-bde7-4073-9ad0-3cb496c87634
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bafdb127-d668-4918-9c24-38bf76399808
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e49946b4-0614-4ff1-b7f3-15179707ffcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5856e61a-6f2c-453d-9b0f-d652cb83d703
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9d7c861-3af1-45fe-8a3c-0b5bab477fe4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63e036b5-8e0e-4bf8-8ef0-6232d3166960
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe286647-6569-4659-b65a-b745598b77da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5cd3135-09f5-4358-8621-e4c73d097cc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48e5e739-9c24-40b5-9965-06d05358cb3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a80fc5a-1ddf-491f-abeb-702275e4b75e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f28bfc1b-c720-4ffb-946c-9faba6fb96d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6a8563b-bb5f-4f89-92f9-75eb8ae931b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71aa4fa8-53b1-4f40-ba27-322418ad08aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 982f8c2e-0250-4dc7-9922-cb829b5b35c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b5345eb-0abc-466c-8443-531195375fc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76923e45-7a6e-4587-9c29-746ead75ac2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 795860ed-4d84-4bee-9eec-0253d78a0c04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 242ba87b-0f6b-46f2-b140-93fd5606c839
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1184f354-36e5-45d3-94a2-26494ccad20e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a14e27ca-b9fa-452c-badf-0363ed9ce875
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8a07b77-e82e-4296-bbec-fc72ce6f06ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35555cdb-386d-4c31-856a-bf90a0c69fbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d9859b7-f228-429a-bd13-af4a42e8da02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd65bc09-fbfe-4ba7-a33e-ab63d8bfc6f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b799c051-e3ac-49c6-b178-cab6fee4fa0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 191f612c-a509-45e6-abdc-ccda04d16cfa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f32c8496-c973-4578-a590-4989c4d5915e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b4f1be8-bb36-48e9-b537-b7e13328ee93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74c2802e-623c-49da-867a-71b5f6cdb080
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3160ae77-fb74-48e4-bd23-ad5445652924
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46c9a30b-76ca-4cc5-899f-850a46ad28d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed5d9c6c-5965-47b3-848f-46194de80f90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44caf14d-0525-44a8-9c4d-aea4d2dc85c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86ab8296-77ed-45ba-8396-8306429ea9bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84712cd4-1e43-4369-b6ae-cd3dffea195e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d1432e8-0e27-4b7d-a419-268c59af4b3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67d21ffc-8f43-44f8-b583-01537976a18a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cef697fb-c4d9-4da8-aa63-39bd0aadeadc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dcf2b4a7-e145-4766-81cf-7a50ba2cf7dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6e09450-236c-4bf4-a34c-1be5888e07b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5219e04c-8427-4b88-801b-5bdc3bc48613
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d003de4-e3fe-4560-af8e-15fab267b682
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message afcbf6a5-266a-45df-8e96-f3cc39fd692e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d9db306-9200-48d5-b408-253c18fecde3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c46b506-b1cc-44a2-bc9b-665d5287e832
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a33f52cc-b8e5-47d8-8417-8f39df593c79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3190ed91-19cf-455c-84f4-4731d6fb7600
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90935f2a-acda-4d28-9918-bbe0ebca5c10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfd2b575-b6fb-47bd-8395-cde89f3c4034
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6f0f019-c040-45d1-b5a3-50ee396b6dda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d99515f1-7ad0-46f8-814f-4f875f5faa65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60f1b36c-e12c-4530-8a05-2aea853ecb75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af2018e8-b931-4310-8ace-15ec1712be14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13d4bfc1-e00d-449b-b387-95ef189afecf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 302aca4b-5834-48e7-89d6-c298da0fc99b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 221298d1-45d5-4086-97ff-54baf29883ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2801b14-eb05-4a8c-b2d6-20ff4322195a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a397ebc7-cd6c-487e-b10f-905f62e1be13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc73afb1-aa0a-4b2b-af80-a7d542006704
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2bd0f4c-c5bc-4306-ae76-04b449c41f3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd4ef8fe-32c0-415f-9b6a-e2c71ce31848
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ac5f5f6-42fc-4208-8baa-e0e7579c24ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b23e433-fb44-44bb-947c-b6d5bbd083be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d01ab98a-3b4c-449a-bd7d-dec18b2b6b2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38b115e5-8c0b-4903-b127-2f5e478c7ef6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c162c681-5750-460e-9200-47b34da70bff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 750ace28-c2e0-417b-a0d4-f6aa67eb9797
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10712e6d-9293-437e-a708-ecd50736cfa1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64637a8c-df09-476f-9358-55ba52f01c9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e92ee088-6af9-4cf9-a50e-a24f556e9a32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad9e87c3-220c-4c61-a133-f859325549ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea615ea2-6924-416d-a233-f34becb4c08d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 543e06a9-7d7e-4ff4-b8fe-28805c6cc998
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09330849-6658-412b-82b2-87daa5fa10b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2bd5fbb-5c4f-41a3-ae5c-71d68103f318
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6477dd9-75e2-42e2-866d-9beb966e1295
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a9b54f5-2ebb-43b2-9a6e-2321bdec16d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5616f99f-344b-4898-98c3-400778982a5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b676d32-6238-4c05-97a6-53ff4ef541fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95a0641e-3330-4727-948b-44cd81f29fbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 712e82d5-5b56-4343-93d3-e57896e99791
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0e04685-e529-4cb7-8ac8-36a0aae0dc36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c1eddbc-108b-498c-84c5-24e63f0da92e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bdd001dc-caad-46a3-ad9b-0e26c46c3959
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a770b18-1017-4e4f-8021-b320ee60047f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d79db1f6-128b-4db7-a25c-9773d26cc445
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c2064f4-962c-495e-904a-fb3566a732cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4ea3b84-f00e-4873-b1d2-d958bd5048c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 022beedd-9da6-4cbf-8db7-67dfc403c1a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9680e6ea-770d-4c2a-aa1a-e57c73a60d15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06c2bb50-00bf-4ac8-bf41-504b8e3a9e8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfcdfaab-9b52-41b6-be05-ce8aa890736d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51428da4-6bc7-4864-bde4-758932a184be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20be67b1-4ec9-4aba-b013-ace5c06e7c5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd7c08fa-0f52-48cf-a7a5-6a08fa24c438
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ed489b5-85a9-4754-a037-c43148bcd7f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 819f4b64-0519-459b-920c-69bbb8a87645
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4559c8d-0601-49e2-9430-31fcae8733b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9127704d-af9d-4cca-876d-0e357e889a32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 844f1240-cd47-4040-94e7-ce8643cd7dea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 899f6157-613e-45b5-99ba-4832bd8b2f7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9cc134e1-6385-42fe-87c5-d30db1e7d724
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3e57767-3922-4f79-b7a8-a36340c501a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d264d67-23e9-42e0-b77b-39d8a3ac013d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01cda2f8-453e-4211-af47-1c10005a8843
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f8ad4b7-275f-4e76-8993-d51352883e15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 835b58ad-bd12-4f6f-a416-fbb58881ebca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b6342fe-098d-49de-a97f-dc43795c258f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e395af2c-ca49-42cf-8226-44cb4cd7a70e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31d79cdc-a296-4428-8175-a3c7e3a8bece
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e0c5f06-31da-4361-9a6f-c360573e7832
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35745b07-eecc-457d-95a0-67dd3013e49d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 207056b9-f02c-47ac-8b09-8fc0dac8bfde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0dcf9834-29b9-4a06-be82-20324ffb22b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 139a8f1f-3a50-47c5-80c8-ab307a601b9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7bdcc94-7822-4992-90f3-7ead34d08a3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 896b46a6-98b5-44d6-bd65-b3545317be31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3872cfc4-ec11-4149-bc8e-74234849d881
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f827b2eb-fc4a-4767-8f07-9d5c14e1ee6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de98c565-1964-4e71-ad99-620ad5c33943
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 682bc481-a269-4810-8af0-2162f41a5dc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32300a3e-4fa8-424f-ac92-1371f96ae5d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8a2369f-47bd-4205-8ce0-0ea55d1a325e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ebec21f-3384-415f-8c69-d93885681165
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3a7cc41-a955-4549-8de3-9d30cfb7a2e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab6bdb14-81b0-43e3-a0e1-092751230f41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ce82824-c537-4ec2-9215-10cd4284f045
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2c75000-8690-494d-ae3f-7cbb4f704bcd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd817a2a-6d8a-41b3-91e3-164e8a250e1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5648b78f-6705-4d38-b3d5-0922cdab6987
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42217436-387d-4faf-8832-c6f019218708
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1016b6e9-9a83-4a37-b5c1-c95f67b4c83e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aec692ae-e4c6-4569-997b-bdfbe54982fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 247590bf-dabe-4378-8144-35b8bd445b08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f31b667-26be-4e39-9b65-fb4361da78c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b117b258-5bf9-4c6b-9d06-b0fd44e68ffe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cefc3b58-b588-4f1e-a67a-5673a0eef204
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d74bdc4-5490-4307-ab40-043817d6b0aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 799a88fe-98bb-4ed6-80af-3c4100d1d003
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 729fc308-53e6-4e8d-ad78-0732d9aafe54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c73d5ce-2e26-42df-a3eb-b63ed12f8a2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3056a0e2-7129-4260-9c23-7046544810bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85c48bc5-df75-43a1-994a-ce53a28005ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d138470e-c0e8-45fc-95e9-ab3255f42340
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52419357-2ea3-475d-84e5-b9398d383676
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1d60176-dea2-40cb-a6c7-f039da573e49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7cfdb3d5-86d4-4700-8c89-900131a9df94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44cb5004-b5f3-4c08-9474-9a1d20af1a48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ac9e9a5-3686-467b-9aa8-9283c4df84ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 645aea12-4c16-4a96-9f49-15405271b12e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b503181f-d689-4c80-9628-0cd9b1dec96e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message abcc47a7-4836-492b-a59b-a385bac00a09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8e195ca-36c8-4a66-902c-658183be0ca9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c7343cf-3fc2-497f-91b4-9e30632e0109
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eed62623-b967-44b0-8423-1eae89ba6d3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1abe67a-ce72-4fc7-8cd8-dcb16cde733e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bef211e1-3955-42f9-9715-75f118c73f06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0740dbb5-2092-4deb-81a9-db5278a86e16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7f09352-6c44-439e-8e69-6348191da467
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b743a063-c505-4dfb-b7d7-eaaedf3d2e30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ee3d18a-9104-4fc4-9aa6-5506854a2e91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d8cde96-ff3d-4265-a4c8-c316c0acc038
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2bf69b5-6978-4708-88aa-72d712127fe8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c6d3ad8-63c3-4ff1-b29b-652c2392ca36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 654143b0-7550-4223-a183-15a6217342ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b30ed7cf-7fee-483a-828b-3be0b8d7beff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc2f2654-3212-4651-83b6-332c3c5f9f41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4420bd1-c227-4742-bee1-98f3c4591698
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be167e1f-af23-4e34-bae3-727335d27d5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf01b132-00f4-4a44-8b53-7699623586ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e93af192-b602-40a3-a601-c0aa3e088ed5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e419765a-90c2-47ca-aab0-64ec9c30b4be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f63e67c-eff4-41e0-a09d-449b3de11591
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f72973f1-b692-4591-a9cc-d3ffa1658082
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03338f0a-4bf3-4aec-8c8b-a10740b9e4cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca90cbb7-f3c9-41e4-90bf-3b2250bd93ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfc00f3e-c6eb-440d-afa8-3acf3c79b1c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4243b8b1-a253-493f-830b-559fe2bfcc2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6c0f57a-3feb-4a28-91e2-f65b35d87571
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4356628f-7f0e-4955-8f3d-3768f437928f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27680d90-13ed-4952-9363-3fd8bddb6553
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 495e44d8-f6a5-49cb-b057-1b9249ed1f82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d02b5d6-cfbc-4660-8a97-fb9cb9b62564
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c5d651f-e589-4cb0-b4be-73a357239ab5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4bcfa12c-ca8e-4e55-ac63-21082392cbfe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d5f848b-59aa-4d47-8fb3-49d981ac35ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13d02820-a443-4aa8-ad51-8a1c129861ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03544140-c5f9-492e-a426-c54303e0da27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message daa40e44-ed65-4188-a3d5-6c229f4c87c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ace2e3b-2af2-4d9a-ba72-713d2db87ffd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0624625b-55cf-4529-a23f-0e1e5d41ee1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 529b1201-b325-4b68-9cc5-217aa3de0a29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a89fe3e-ea88-4980-8a1a-ddd75061fcbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8649b1b-9f29-40ec-a92f-6ea1fe030069
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9fdf14e-9d88-4a29-9915-0b7aebb9bb21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eac5611c-d4b2-4df4-abeb-bfc213bc2433
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 817d56f3-bf6a-4ab9-9866-5685568c3f35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e151c035-660a-4c66-ae6d-e9c784184f44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b11fcd8-19cf-4fd5-b1a3-f8708cde4beb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4e19e08-8e42-4027-9607-ce70c7e973c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb097088-21cd-4ca5-ab77-7722d45e4e1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 777cbedc-1018-466b-aec6-89816bd50fa9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14c8981e-bd51-4282-beb4-bb304288c3d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57d7196c-af39-4a4a-a32c-cca94dc23695
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 132ddf67-86ef-466b-9dd1-e5c54728c310
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0fad0d2-9e4f-456f-ab2c-1c2360c73aa5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55a3179a-91bb-4a61-aca7-b177e7e0c0c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a836b326-7a5a-4890-bb8a-33e9efcaab3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8fc9c63-a1c2-41f7-b4ee-f3f065b1a00d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2453905d-0f2b-421c-a42b-49c7db92d6ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a424430f-5abb-40b7-bb40-589536c96e30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 200968c9-47ad-4600-ab4c-c9a28b563892
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59eaab2e-2934-4f52-93f7-f454cdeb9a43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b33c394-02e9-4496-9d8d-0bd752f13fcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9972ce6-2817-4f3b-9dd6-f7d966264a7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64773b9b-166a-43c5-87ff-b60896d05c07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46dc8fbd-84f3-499a-84b7-8f3bef81eee8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 939a0915-d7f0-4bb3-9b9f-39c1e115fcfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23208861-f2ea-4cff-b62e-fb1cac38a1c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce4c880b-a32f-4ff5-8f53-f6398fac9ed5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6760977-12d7-490c-be30-7b53b8f4008a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab44818d-6eaf-4ee1-97f9-9fd215e27fce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ad03573-07ea-4b05-8c02-62b3f0c7959a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ce21ad3-7324-4362-af0b-427a85797eb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b3a138b-3f4d-4844-885b-a923b9413a89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fbe0c5fd-da24-4aa6-8096-5209022aee12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db3210f5-c613-4703-80aa-906d948c415c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8935c5f2-4232-46ae-ba7c-17bbee98739b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0950a3d5-d819-4c1a-a661-b54ecad5be6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2927e1e8-6401-4afd-9a0f-a2b5a4e651db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17002e19-2bc3-4930-8ba8-9cfb9abc9003
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9f6c9f0-c183-451e-9340-a96c9df65889
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd19022c-5169-4723-9c9b-758753a3fdf8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7cef623-54ec-4973-abfa-d31d3901b8e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 314874ea-1907-4254-a60c-7c4a72f9fdf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65bd05d7-271d-4f89-bb80-d1371679ec45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b06e84cf-b9f8-4deb-b173-e5d8efb832b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3fb7893-212b-4486-8deb-8e6d5ff008ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 086adb1b-52dc-4038-88de-b96e73dac1fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95ff541f-c9e4-4c90-8104-9ff9c05e9c19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c6f2e49-66b0-4ffc-bb3f-001dcfe8d10b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35e63924-babc-47f6-af98-ab141ca190e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f37169ba-af3c-4f35-a91e-576ecb9006c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4bdec41a-4570-4f13-8b36-a95bd065f31d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a919e50c-78e6-4b52-b8bd-05e97d8e6eb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b256481-dfa3-45a1-8516-9cdb8a24c91a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d55ee4d-a42a-4847-b089-51ddf2d16faf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32c53dad-ac10-4b1a-aa23-d1ea89f8e239
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2880460d-6275-481a-a264-24263c2d6f28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f4480b7-de16-4995-b1a7-67e56e10bdeb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ba9364d-4a1d-4c35-8ccd-714a97383ce7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1cded42-982d-42e3-b939-e0780d83efec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6f64c77-e840-4354-9c10-2d6a00f3846e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5be9e0ba-52e7-4eda-b533-bc48cf3dd1d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1d90e46-83d8-47d7-95ee-7109b41c84e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d016b58-3c54-444b-870f-2ed30377b757
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 984fc3d4-f14b-4979-b5f6-0a0eeaaa66df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7671d611-22a1-4c5a-b77e-e06dd834498d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed297845-b3c0-4585-9591-0b8e2a0eb335
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e51effe3-3ac7-42c7-a5c1-50cec6371b2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e6a20e7-e7f6-4aed-9df8-527d102c2fca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ec83068-fc62-4f37-84e3-1773313c1f13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eeac1c15-c9b1-48f0-bf04-8da9250378e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c1bc20d-d202-4b7e-8d65-3abaee096c0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f273a66-51ba-4b24-babc-c54b0d7bb6ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 436c712c-ab45-4d98-ae74-e98a0c5e1edd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0889cbe-f553-48ef-8740-bd1c740156de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75713f23-4781-4e42-8a8c-0d0cc78a2739
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 775fc6f9-c59a-452b-bba0-f97b48c18e5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17077b95-c4ca-49d0-aee5-80139727746c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad2d4f63-a87c-4a18-b1d0-bf0f3a4cda7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23fc8a3d-3a2c-42c2-82ca-afee098f8ebd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb7585ea-161c-437a-84eb-f322dcc609f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 654c9a36-fd28-408f-bd53-24b6f0257027
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73b42505-3de1-4104-ae69-bec62e4b2843
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d411a88f-c6e1-43bf-9022-475d98721800
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4886307e-29bb-4a3e-b264-a968c515fe14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a480342-cd4a-4e69-8640-c4466327f8cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43e38658-1b2f-49eb-8db1-86b6f0985051
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73f82a85-94ed-47b4-b3b9-11f2bf3e5cda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83a7e6c1-2fc5-4ee1-aad2-5abad38b7730
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7866eed-7759-4394-823e-eafe5b4e9da9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab144d15-3b6a-47de-8e94-c11a9d198981
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9be6e858-fb6c-4034-b8bf-4a5ca34848de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32d343b8-0f38-456a-89f0-95029d86a95d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb4f91c9-5b71-461f-bfec-d6a3757a8d63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11f5b5ca-fba8-428c-9a0c-40a3796a416c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6452906-9223-4774-ae25-fa9667d802bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e6cbe27-e3fd-4b55-840d-7d1b5c7c922d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73c5e6b9-3019-4826-b352-17bfe56665c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 814f1aa1-8195-43b8-b501-7ade46363b9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 576e139b-da00-4256-84f8-0086dd38cdff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e50c9c71-c748-4e02-9997-b7123715f0ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74ad157d-5dec-4252-ac7a-7b01b600e3af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e21a1c3-452e-491e-9db7-c30584380da7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4da0a0d2-9f17-4cf5-beb8-9d6548248d2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4c5ce32-6d57-4f11-acc8-085430840636
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2cebb997-0db2-488f-ba63-f1782b75827f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8502c638-c38e-4d54-971b-408973b910ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8cd34805-0b4c-4e03-be0a-b0e6837ff6f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b42b6988-932f-483b-8374-f490fc66bbcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90ff1b83-2b2a-431e-93cd-cc20c2bd7e7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70fcb049-b920-4391-a04a-63e76a4dfa73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1b87e44-4210-4e7b-8abe-97b97d48dc8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5819a304-99c9-4e4f-8a40-0d2440b03064
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25bc5252-661f-4d71-a8de-084ef1d04136
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39cf2a11-0d19-480b-b4aa-1bf092dcbac3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e878c376-a307-4f5a-b12a-cc5261f9a9de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f854d670-ddcd-42bb-bda0-3114682bebca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cec87720-f60b-4063-8b5e-f221d0a8861f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9da10840-6dc4-464d-b086-94935a92f792
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec9660a8-8091-46d7-a706-fc7eda247371
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12e6045d-bcaf-415c-86c8-b3c90a4b3e25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e131369d-75ba-4fe6-9197-e3ab270ab569
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2401d1ad-5a5e-4bcc-a6fe-3c5790b8f2e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c12e49c5-558a-4d63-839b-16f93b40c5d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d38bfdbc-fbab-4c81-b546-6792aba7ba67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8324c833-a1b3-4699-8898-3fdbe0cec299
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 927824b1-0300-4616-8bc9-8d2f12dd93b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf418abc-a651-470c-b6a0-dd0400146a21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46dc51a5-120b-4044-b73b-0e2bb4158549
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62befb2a-2f22-4fb2-948f-1127678a3b1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b42348e1-154a-4e54-bba1-4ea36196cba0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 470a9309-578f-4f21-95a2-a3bcbce59441
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c864b74f-a98b-402f-8fa9-7ea59f7d4fc1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b518e413-64c9-4588-9723-2fbf115acc48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 635e0e1f-f8d5-4101-ad0f-e77711eb0576
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8d11eaa-4d6b-45b4-982b-73dff649e8df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3cb26ef8-e8b8-415a-a177-3d75dfb5bc64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b1f87b9-8bf9-4ec2-94b9-1e7a4d3ee0fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cdc81955-5d81-462e-8ce8-dd43e4b62edf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d50c220-c8d1-4ad5-a9dd-334b787be429
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ffdfd26-4aa5-4828-ba24-d0abb02912b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3034266-50a4-4866-b7bd-3bc4f332fede
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0308fb1-6482-4711-81ca-cea78878bb02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99e14d5b-30d4-4480-887f-6eb4bf981de3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4be2d26f-a45c-473b-b747-da785e030f95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a6d5e34-d7dd-45f1-afc8-1cff5dc2ba42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c514ef0-90a4-47a9-840b-18e7045f14f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7369130-3b20-4849-af73-b19a98fa5768
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1cd15bcf-ae40-4b9e-912c-9deec60b28d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba48fb19-957f-4a71-b918-7cdff6a29577
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 136c4f7f-d456-47ee-849e-b41e8b1f96f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f315b0a4-d2e2-4fb1-8356-8caac9c929af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5dbb6dc4-2f2b-4554-b07d-e85714550624
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e430967-fd9f-4dd5-b891-89b68eaa852b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 972e7e58-1271-4bcf-88fb-8f1fe39a6296
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8d61b25-59c7-4693-bda9-980c7d403503
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7097d70-3690-49a8-976f-cbf036fc5950
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28960b52-cc75-40fa-9e2c-f89e33a92c9f
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8690 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_5
Server: localhost:8690
Algorithm: FEDOPT
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_5
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_5/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_5/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_5/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.05/client_5/test_labels.txt

📊 Raw data loaded:
   Train: X=(5354, 24), y=(5354,)
   Test:  X=(1339, 24), y=(1339,)

⚠️  Limiting training data: 5354 → 800 samples
⚠️  Limiting test data: 1339 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  791 samples, 5 features
✅ Client client_5 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0904, RMSE: 0.3006, MAE: 0.2612, R²: -0.0029

📊 Round 0 Test Metrics:
   Loss: 0.0899, RMSE: 0.2999, MAE: 0.2607, R²: 0.0018

📊 Round 0 Test Metrics:
   Loss: 0.0899, RMSE: 0.2999, MAE: 0.2608, R²: 0.0018

============================================================
🔄 Round 7 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0830 (↓), lr=0.001000
   • Epoch   2/100: train=0.0815, val=0.0833, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0812, val=0.0835, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0811, val=0.0837, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0810, val=0.0837, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0800, val=0.0836, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 7 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0049
   Val:   Loss=0.0830, RMSE=0.2880, R²=0.0032
============================================================


📊 Round 7 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2608, R²: 0.0014

============================================================
🔄 Round 9 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0784 (↓), lr=0.000250
   • Epoch   2/100: train=0.0824, val=0.0782, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0823, val=0.0783, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0822, val=0.0782, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0822, val=0.0782, patience=4/15, lr=0.000250
   📉 Epoch 8: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0817, val=0.0782, patience=10/15, lr=0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 9 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000125 (1 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0016
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0108
============================================================


📊 Round 9 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2607, R²: 0.0001

📊 Round 9 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2607, R²: 0.0001

📊 Round 9 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0010

📊 Round 9 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0009

============================================================
🔄 Round 16 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0782 (↓), lr=0.000125
   • Epoch   2/100: train=0.0823, val=0.0784, patience=1/15, lr=0.000125
   • Epoch   3/100: train=0.0823, val=0.0783, patience=2/15, lr=0.000125
   • Epoch   4/100: train=0.0822, val=0.0783, patience=3/15, lr=0.000125
   📉 Epoch 5: LR reduced 0.000125 → 0.000063
   • Epoch   5/100: train=0.0822, val=0.0783, patience=4/15, lr=0.000063
   • Epoch  11/100: train=0.0820, val=0.0782, patience=10/15, lr=0.000063
   📉 Epoch 13: LR reduced 0.000063 → 0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 16 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000125 → 0.000031 (2 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0041
   Val:   Loss=0.0782, RMSE=0.2796, R²=-0.0068
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0006

============================================================
🔄 Round 19 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0852 (↓), lr=0.000031
   • Epoch   2/100: train=0.0804, val=0.0852, patience=1/15, lr=0.000031
   • Epoch   3/100: train=0.0804, val=0.0853, patience=2/15, lr=0.000031
   • Epoch   4/100: train=0.0804, val=0.0853, patience=3/15, lr=0.000031
   📉 Epoch 5: LR reduced 0.000031 → 0.000016
   • Epoch   5/100: train=0.0803, val=0.0854, patience=4/15, lr=0.000016
   • Epoch  11/100: train=0.0803, val=0.0855, patience=10/15, lr=0.000016
   📉 Epoch 13: LR reduced 0.000016 → 0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 19 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000031 → 0.000008 (2 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0053
   Val:   Loss=0.0852, RMSE=0.2918, R²=-0.0195
============================================================


============================================================
🔄 Round 20 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0841 (↓), lr=0.000008
   • Epoch   2/100: train=0.0805, val=0.0843, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0804, val=0.0845, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0803, val=0.0847, patience=3/15, lr=0.000008
   📉 Epoch 5: LR reduced 0.000008 → 0.000004
   • Epoch   5/100: train=0.0803, val=0.0849, patience=4/15, lr=0.000004
   • Epoch  11/100: train=0.0802, val=0.0854, patience=10/15, lr=0.000004
   📉 Epoch 13: LR reduced 0.000004 → 0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 20 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0003
   Val:   Loss=0.0841, RMSE=0.2899, R²=-0.0351
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0006

============================================================
🔄 Round 22 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0805 (↓), lr=0.000002
   • Epoch   2/100: train=0.0813, val=0.0805, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0813, val=0.0805, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0813, val=0.0805, patience=3/15, lr=0.000002
   📉 Epoch 5: LR reduced 0.000002 → 0.000001
   • Epoch   5/100: train=0.0812, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 22 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0813, RMSE=0.2850, R²=0.0034
   Val:   Loss=0.0805, RMSE=0.2838, R²=0.0005
============================================================


============================================================
🔄 Round 23 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 23 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0030
   Val:   Loss=0.0854, RMSE=0.2923, R²=0.0021
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0006

============================================================
🔄 Round 24 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 24 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=0.0034
   Val:   Loss=0.0830, RMSE=0.2880, R²=0.0021
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0006

============================================================
🔄 Round 26 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0708 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0708, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0708, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0708, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0708, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0709, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0708)

============================================================
📊 Round 26 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0006
   Val:   Loss=0.0708, RMSE=0.2660, R²=-0.0130
============================================================


============================================================
🔄 Round 27 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 27 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0033
   Val:   Loss=0.0866, RMSE=0.2943, R²=0.0024
============================================================


============================================================
🔄 Round 29 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 29 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2836, R²=0.0020
   Val:   Loss=0.0838, RMSE=0.2894, R²=0.0071
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0006

============================================================
🔄 Round 31 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 31 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0028
   Val:   Loss=0.0776, RMSE=0.2786, R²=-0.0029
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0006

============================================================
🔄 Round 32 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 32 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0022
   Val:   Loss=0.0860, RMSE=0.2932, R²=0.0018
============================================================


============================================================
🔄 Round 33 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 33 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2835, R²=0.0020
   Val:   Loss=0.0842, RMSE=0.2901, R²=-0.0107
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0006

============================================================
🔄 Round 34 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 34 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0030
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0008
============================================================


============================================================
🔄 Round 36 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 36 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0055
   Val:   Loss=0.0815, RMSE=0.2854, R²=-0.0277
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0006

============================================================
🔄 Round 37 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 37 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0045
   Val:   Loss=0.0747, RMSE=0.2733, R²=-0.0048
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0006

📊 Round 37 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0006

============================================================
🔄 Round 41 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 41 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=0.0025
   Val:   Loss=0.0750, RMSE=0.2739, R²=-0.0031
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0006

============================================================
🔄 Round 44 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0712 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0712, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0712, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0712, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0712, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0712, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0712)

============================================================
📊 Round 44 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0027
   Val:   Loss=0.0712, RMSE=0.2668, R²=0.0051
============================================================


============================================================
🔄 Round 45 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 45 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0049
   Val:   Loss=0.0844, RMSE=0.2906, R²=-0.0051
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0006

============================================================
🔄 Round 46 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 46 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0042
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0153
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0006

📊 Round 46 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0006

📊 Round 46 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0006

============================================================
🔄 Round 50 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 50 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0063
   Val:   Loss=0.0903, RMSE=0.3006, R²=-0.0105
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0006

📊 Round 50 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0006

📊 Round 50 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0006

============================================================
🔄 Round 54 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 54 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0039
   Val:   Loss=0.0779, RMSE=0.2791, R²=-0.0079
============================================================


============================================================
🔄 Round 58 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 58 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0032
   Val:   Loss=0.0862, RMSE=0.2935, R²=0.0030
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0006

📊 Round 58 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0006

============================================================
🔄 Round 61 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0710 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0710, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0710, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0710, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0710, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0710, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0710)

============================================================
📊 Round 61 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0038
   Val:   Loss=0.0710, RMSE=0.2664, R²=-0.0116
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0006

============================================================
🔄 Round 62 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 62 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0031
   Val:   Loss=0.0770, RMSE=0.2775, R²=0.0030
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0006

============================================================
🔄 Round 63 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 63 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0027
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0008
============================================================


============================================================
🔄 Round 66 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 66 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0026
   Val:   Loss=0.0767, RMSE=0.2769, R²=0.0052
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0006

📊 Round 66 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0006

📊 Round 66 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0006

============================================================
🔄 Round 70 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 70 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0027
   Val:   Loss=0.0768, RMSE=0.2771, R²=0.0043
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0006

📊 Round 70 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0006

============================================================
🔄 Round 73 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 73 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0022
   Val:   Loss=0.0749, RMSE=0.2737, R²=0.0064
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0006

============================================================
🔄 Round 74 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 74 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2822, R²=0.0012
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0003
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0006

📊 Round 74 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0006

============================================================
🔄 Round 78 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 78 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0025
   Val:   Loss=0.0821, RMSE=0.2866, R²=-0.0096
============================================================


============================================================
🔄 Round 79 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 79 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0041
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0011
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0006

📊 Round 79 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0006

============================================================
🔄 Round 81 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 81 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0033
   Val:   Loss=0.0728, RMSE=0.2698, R²=-0.0078
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0006

📊 Round 81 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0006

============================================================
🔄 Round 85 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 85 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0025
   Val:   Loss=0.0784, RMSE=0.2799, R²=0.0058
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0006

============================================================
🔄 Round 86 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0955 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0955, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0955, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0955, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0955, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0956, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0955)

============================================================
📊 Round 86 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0032
   Val:   Loss=0.0955, RMSE=0.3091, R²=-0.0026
============================================================


============================================================
🔄 Round 89 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 89 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=0.0022
   Val:   Loss=0.0802, RMSE=0.2831, R²=0.0066
============================================================


============================================================
🔄 Round 90 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 90 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2878, R²=0.0008
   Val:   Loss=0.0741, RMSE=0.2723, R²=-0.0022
============================================================


============================================================
🔄 Round 92 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 92 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0024
   Val:   Loss=0.0829, RMSE=0.2880, R²=0.0056
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0006

============================================================
🔄 Round 94 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 94 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0002
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0035
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0006

============================================================
🔄 Round 98 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 98 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=0.0005
   Val:   Loss=0.0769, RMSE=0.2774, R²=0.0044
============================================================


============================================================
🔄 Round 99 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 99 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0045
   Val:   Loss=0.0785, RMSE=0.2801, R²=-0.0138
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0006

📊 Round 99 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0006

============================================================
🔄 Round 103 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 103 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0022
   Val:   Loss=0.0784, RMSE=0.2801, R²=0.0066
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0006

============================================================
🔄 Round 104 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 104 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0053
   Val:   Loss=0.0866, RMSE=0.2943, R²=-0.0052
============================================================


============================================================
🔄 Round 105 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 105 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0030
   Val:   Loss=0.0760, RMSE=0.2756, R²=-0.0067
============================================================


============================================================
🔄 Round 108 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 108 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0030
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0004
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0006

📊 Round 108 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0006

============================================================
🔄 Round 110 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 110 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0021
   Val:   Loss=0.0754, RMSE=0.2746, R²=0.0075
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0006

============================================================
🔄 Round 112 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 112 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=0.0011
   Val:   Loss=0.0817, RMSE=0.2859, R²=0.0112
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0006

📊 Round 112 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0006

============================================================
🔄 Round 116 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 116 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0032
   Val:   Loss=0.0757, RMSE=0.2752, R²=-0.0036
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0006

============================================================
🔄 Round 118 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 118 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0043
   Val:   Loss=0.0886, RMSE=0.2977, R²=-0.0053
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0006

📊 Round 118 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0006

============================================================
🔄 Round 120 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 120 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0023
   Val:   Loss=0.0796, RMSE=0.2822, R²=-0.0045
============================================================


============================================================
🔄 Round 121 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 121 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0037
   Val:   Loss=0.0772, RMSE=0.2779, R²=0.0004
============================================================


============================================================
🔄 Round 122 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 122 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0041
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0012
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0006

============================================================
🔄 Round 123 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 123 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0021
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0090
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0006

📊 Round 123 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0006

============================================================
🔄 Round 125 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 125 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0021
   Val:   Loss=0.0879, RMSE=0.2964, R²=0.0059
============================================================


============================================================
🔄 Round 126 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 126 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2842, R²=0.0035
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0051
============================================================


============================================================
🔄 Round 127 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 127 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0018
   Val:   Loss=0.0763, RMSE=0.2761, R²=-0.0022
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0006

============================================================
🔄 Round 130 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 130 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0001
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0014
============================================================


============================================================
🔄 Round 132 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 132 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2799, R²=0.0054
   Val:   Loss=0.0921, RMSE=0.3035, R²=-0.0064
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0006

============================================================
🔄 Round 139 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 139 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0027
   Val:   Loss=0.0889, RMSE=0.2982, R²=0.0038
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0006

============================================================
🔄 Round 141 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 141 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0051
   Val:   Loss=0.0768, RMSE=0.2771, R²=-0.0178
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0006

📊 Round 141 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0006

============================================================
🔄 Round 145 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 145 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=0.0038
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.0006
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0006

============================================================
🔄 Round 147 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 147 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0045
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0023
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0006

============================================================
🔄 Round 149 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 149 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=0.0038
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0044
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0006

============================================================
🔄 Round 150 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 150 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=-0.0000
   Val:   Loss=0.0798, RMSE=0.2825, R²=0.0121
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0006

📊 Round 150 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0006

============================================================
🔄 Round 153 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 153 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0045
   Val:   Loss=0.0773, RMSE=0.2780, R²=-0.0043
============================================================


============================================================
🔄 Round 154 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 154 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0043
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0043
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0006

============================================================
🔄 Round 156 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 156 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0045
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0024
============================================================


============================================================
🔄 Round 158 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 158 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0041
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0018
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0006

📊 Round 158 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0006

============================================================
🔄 Round 163 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 163 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0055
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0076
============================================================


============================================================
🔄 Round 164 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 164 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=-0.0019
   Val:   Loss=0.0861, RMSE=0.2935, R²=0.0038
============================================================


============================================================
🔄 Round 165 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 165 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0019
   Val:   Loss=0.0835, RMSE=0.2889, R²=0.0076
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0006

============================================================
🔄 Round 170 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 170 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0027
   Val:   Loss=0.0834, RMSE=0.2888, R²=0.0029
============================================================


============================================================
🔄 Round 172 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 172 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0054
   Val:   Loss=0.0790, RMSE=0.2810, R²=-0.0071
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0006

📊 Round 172 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0006

📊 Round 172 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0006

📊 Round 172 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0006

📊 Round 172 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0006

============================================================
🔄 Round 180 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 180 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0015
   Val:   Loss=0.0774, RMSE=0.2781, R²=0.0097
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0006

============================================================
🔄 Round 183 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 183 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0006
   Val:   Loss=0.0891, RMSE=0.2985, R²=0.0117
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0006

============================================================
🔄 Round 185 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0924 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 185 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0033
   Val:   Loss=0.0924, RMSE=0.3039, R²=-0.0037
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0006

============================================================
🔄 Round 186 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 186 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0001
   Val:   Loss=0.0765, RMSE=0.2765, R²=0.0005
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0006

📊 Round 186 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0006

============================================================
🔄 Round 190 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 190 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0021
   Val:   Loss=0.0878, RMSE=0.2963, R²=0.0037
============================================================


📊 Round 190 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0006

============================================================
🔄 Round 192 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 192 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2856, R²=0.0013
   Val:   Loss=0.0794, RMSE=0.2817, R²=0.0079
============================================================


============================================================
🔄 Round 195 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 195 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0020
   Val:   Loss=0.0871, RMSE=0.2950, R²=0.0061
============================================================


📊 Round 195 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0007

📊 Round 195 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0007

============================================================
🔄 Round 199 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 199 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0074
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0147
============================================================


============================================================
🔄 Round 200 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 200 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0050
   Val:   Loss=0.0779, RMSE=0.2792, R²=-0.0059
============================================================


📊 Round 200 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0007

============================================================
🔄 Round 203 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 203 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0011
   Val:   Loss=0.0837, RMSE=0.2894, R²=-0.0176
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0006

📊 Round 203 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0007

============================================================
🔄 Round 205 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 205 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=0.0044
   Val:   Loss=0.0750, RMSE=0.2739, R²=-0.0024
============================================================


============================================================
🔄 Round 206 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 206 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0029
   Val:   Loss=0.0871, RMSE=0.2951, R²=0.0037
============================================================


📊 Round 206 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0007

============================================================
🔄 Round 207 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 207 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0033
   Val:   Loss=0.0775, RMSE=0.2784, R²=-0.0104
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0007

📊 Round 207 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0007

📊 Round 207 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0007

============================================================
🔄 Round 213 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 213 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0026
   Val:   Loss=0.0887, RMSE=0.2978, R²=0.0045
============================================================


📊 Round 213 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0007

📊 Round 213 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0006

============================================================
🔄 Round 215 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 215 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=0.0018
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0072
============================================================


============================================================
🔄 Round 217 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 217 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0034
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0056
============================================================


📊 Round 217 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0007

============================================================
🔄 Round 219 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 219 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=0.0030
   Val:   Loss=0.0737, RMSE=0.2715, R²=0.0036
============================================================


============================================================
🔄 Round 222 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 222 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0049
   Val:   Loss=0.0893, RMSE=0.2989, R²=-0.0033
============================================================


📊 Round 222 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0007

============================================================
🔄 Round 223 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0708 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0708, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0708, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0708, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0708, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0708, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0708)

============================================================
📊 Round 223 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0015
   Val:   Loss=0.0708, RMSE=0.2660, R²=0.0008
============================================================


📊 Round 223 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0007

============================================================
🔄 Round 224 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 224 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0023
   Val:   Loss=0.0865, RMSE=0.2942, R²=0.0019
============================================================


📊 Round 224 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0007

📊 Round 224 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0007

============================================================
🔄 Round 230 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 230 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0033
   Val:   Loss=0.0782, RMSE=0.2797, R²=0.0020
============================================================


============================================================
🔄 Round 231 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 231 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0012
   Val:   Loss=0.0748, RMSE=0.2736, R²=-0.0275
============================================================


============================================================
🔄 Round 232 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 232 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0038
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0003
============================================================


============================================================
🔄 Round 233 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 233 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0025
   Val:   Loss=0.0851, RMSE=0.2917, R²=0.0000
============================================================


📊 Round 233 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0007

📊 Round 233 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0007

============================================================
🔄 Round 238 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 238 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0016
   Val:   Loss=0.0808, RMSE=0.2842, R²=0.0002
============================================================


📊 Round 238 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0007

📊 Round 238 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0007

============================================================
🔄 Round 245 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 245 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2819, R²=0.0037
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0124
============================================================


📊 Round 245 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0007

📊 Round 245 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0007

============================================================
🔄 Round 250 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 250 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0034
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0025
============================================================


============================================================
🔄 Round 251 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 251 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0022
   Val:   Loss=0.0732, RMSE=0.2706, R²=0.0005
============================================================


📊 Round 251 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0007

📊 Round 251 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0007

📊 Round 251 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0007

============================================================
🔄 Round 254 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0716 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0716, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0716, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0716, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0716, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0716, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0716)

============================================================
📊 Round 254 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0025
   Val:   Loss=0.0716, RMSE=0.2675, R²=0.0040
============================================================


============================================================
🔄 Round 255 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 255 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0050
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0185
============================================================


📊 Round 255 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0007

📊 Round 255 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0007

============================================================
🔄 Round 258 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 258 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0030
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0037
============================================================


📊 Round 258 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0007

📊 Round 258 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0007

============================================================
🔄 Round 262 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0705 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0705, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0705, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0705, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0705, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0705, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0705)

============================================================
📊 Round 262 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=0.0030
   Val:   Loss=0.0705, RMSE=0.2655, R²=0.0029
============================================================


📊 Round 262 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0007

📊 Round 262 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0007

============================================================
🔄 Round 264 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 264 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0021
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0048
============================================================


📊 Round 264 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0007

============================================================
🔄 Round 265 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 265 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0017
   Val:   Loss=0.0806, RMSE=0.2839, R²=0.0086
============================================================


============================================================
🔄 Round 266 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 266 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0027
   Val:   Loss=0.0784, RMSE=0.2801, R²=-0.0198
============================================================


============================================================
🔄 Round 267 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 267 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=0.0013
   Val:   Loss=0.0750, RMSE=0.2739, R²=0.0043
============================================================


📊 Round 267 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0007

📊 Round 267 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0007

============================================================
🔄 Round 272 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 272 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0028
   Val:   Loss=0.0916, RMSE=0.3026, R²=0.0041
============================================================


============================================================
🔄 Round 274 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 274 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0008
   Val:   Loss=0.0768, RMSE=0.2772, R²=-0.0039
============================================================


📊 Round 274 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0007

============================================================
🔄 Round 277 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 277 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0042
   Val:   Loss=0.0904, RMSE=0.3006, R²=-0.0014
============================================================


============================================================
🔄 Round 279 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 279 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0020
   Val:   Loss=0.0758, RMSE=0.2754, R²=0.0051
============================================================


📊 Round 279 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0007

📊 Round 279 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0007

============================================================
🔄 Round 285 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 285 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2819, R²=0.0021
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0008
============================================================


📊 Round 285 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0007

============================================================
🔄 Round 286 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 286 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0026
   Val:   Loss=0.0761, RMSE=0.2758, R²=0.0015
============================================================


📊 Round 286 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0007

============================================================
🔄 Round 287 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 287 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0015
   Val:   Loss=0.0864, RMSE=0.2940, R²=0.0064
============================================================


📊 Round 287 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0007

📊 Round 287 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0007

📊 Round 287 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0007

============================================================
🔄 Round 293 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 293 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0047
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0051
============================================================


📊 Round 293 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0007

============================================================
🔄 Round 295 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 295 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0016
   Val:   Loss=0.0738, RMSE=0.2716, R²=0.0077
============================================================


📊 Round 295 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0007

============================================================
🔄 Round 297 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 297 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0045
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0078
============================================================


📊 Round 297 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0007

============================================================
🔄 Round 299 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 299 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0017
   Val:   Loss=0.0793, RMSE=0.2817, R²=-0.0169
============================================================


📊 Round 299 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0007

============================================================
🔄 Round 303 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 303 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0015
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0084
============================================================


📊 Round 303 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0007

============================================================
🔄 Round 305 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 305 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0014
   Val:   Loss=0.0721, RMSE=0.2685, R²=0.0010
============================================================


============================================================
🔄 Round 306 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 306 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0027
   Val:   Loss=0.0760, RMSE=0.2756, R²=0.0042
============================================================


📊 Round 306 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0007

============================================================
🔄 Round 309 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 309 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0009
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0119
============================================================


📊 Round 309 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0007

📊 Round 309 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0007

============================================================
🔄 Round 314 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 314 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=0.0003
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0020
============================================================


============================================================
🔄 Round 315 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 315 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0004
   Val:   Loss=0.0877, RMSE=0.2961, R²=0.0014
============================================================


============================================================
🔄 Round 318 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 318 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0043
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0052
============================================================


============================================================
🔄 Round 321 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 321 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0043
   Val:   Loss=0.0764, RMSE=0.2764, R²=-0.0059
============================================================


📊 Round 321 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0007

📊 Round 321 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0007

📊 Round 321 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0007

📊 Round 321 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0007

📊 Round 321 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0007

============================================================
🔄 Round 332 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 332 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0034
   Val:   Loss=0.0855, RMSE=0.2923, R²=0.0023
============================================================


📊 Round 332 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0007

📊 Round 332 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0007

============================================================
🔄 Round 339 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 339 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0026
   Val:   Loss=0.0787, RMSE=0.2806, R²=-0.0047
============================================================


📊 Round 339 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0007

📊 Round 339 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0007

============================================================
🔄 Round 344 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 344 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0034
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0012
============================================================


📊 Round 344 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0007

============================================================
🔄 Round 345 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 345 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0033
   Val:   Loss=0.0813, RMSE=0.2852, R²=0.0004
============================================================


============================================================
🔄 Round 346 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 346 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0021
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0080
============================================================


============================================================
🔄 Round 347 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 347 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0025
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0046
============================================================


============================================================
🔄 Round 348 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 348 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0033
   Val:   Loss=0.0794, RMSE=0.2817, R²=0.0019
============================================================


📊 Round 348 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0007

============================================================
🔄 Round 353 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 353 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0015
   Val:   Loss=0.0775, RMSE=0.2783, R²=0.0051
============================================================


📊 Round 353 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0007

📊 Round 353 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0007

📊 Round 353 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0007

📊 Round 353 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0007

📊 Round 353 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0007

📊 Round 353 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0007

📊 Round 353 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0007

📊 Round 353 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0007

📊 Round 353 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0007

============================================================
🔄 Round 372 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 372 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0006
   Val:   Loss=0.0843, RMSE=0.2904, R²=0.0023
============================================================


============================================================
🔄 Round 373 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 373 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0049
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0048
============================================================


============================================================
🔄 Round 374 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 374 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0039
   Val:   Loss=0.0800, RMSE=0.2829, R²=-0.0032
============================================================


============================================================
🔄 Round 376 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 376 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2797, R²=0.0047
   Val:   Loss=0.0926, RMSE=0.3043, R²=-0.0023
============================================================


📊 Round 376 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0007

📊 Round 376 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2607, R²: 0.0007

============================================================
🔄 Round 378 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 378 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0019
   Val:   Loss=0.0729, RMSE=0.2699, R²=0.0080
============================================================


📊 Round 378 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0007

📊 Round 378 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0007

============================================================
🔄 Round 384 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 384 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0039
   Val:   Loss=0.0727, RMSE=0.2696, R²=-0.0040
============================================================


============================================================
🔄 Round 385 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 385 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0026
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0177
============================================================


============================================================
🔄 Round 386 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 386 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0001
   Val:   Loss=0.0857, RMSE=0.2928, R²=-0.0100
============================================================


============================================================
🔄 Round 388 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 388 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0032
   Val:   Loss=0.0732, RMSE=0.2706, R²=0.0017
============================================================


📊 Round 388 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0007

============================================================
🔄 Round 390 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 390 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0028
   Val:   Loss=0.0895, RMSE=0.2992, R²=0.0039
============================================================


📊 Round 390 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0007

📊 Round 390 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0007

============================================================
🔄 Round 395 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 395 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0036
   Val:   Loss=0.0784, RMSE=0.2800, R²=-0.0068
============================================================


📊 Round 395 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0007

📊 Round 395 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0007

============================================================
🔄 Round 398 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 398 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0024
   Val:   Loss=0.0856, RMSE=0.2926, R²=0.0053
============================================================


📊 Round 398 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0007

📊 Round 398 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0007

📊 Round 398 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0007

📊 Round 398 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0007

📊 Round 398 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0007

============================================================
🔄 Round 406 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 406 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0024
   Val:   Loss=0.0779, RMSE=0.2790, R²=0.0050
============================================================


============================================================
🔄 Round 407 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 407 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0029
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0020
============================================================


📊 Round 407 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0007

============================================================
🔄 Round 408 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0693 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0693, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0693, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0693, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0693, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0693, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0693)

============================================================
📊 Round 408 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=0.0015
   Val:   Loss=0.0693, RMSE=0.2632, R²=0.0019
============================================================


============================================================
🔄 Round 409 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 409 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0038
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0021
============================================================


📊 Round 409 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0007

============================================================
🔄 Round 410 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 410 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0018
   Val:   Loss=0.0832, RMSE=0.2885, R²=0.0016
============================================================


============================================================
🔄 Round 413 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 413 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0020
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0060
============================================================


📊 Round 413 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0008

============================================================
🔄 Round 414 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 414 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0030
   Val:   Loss=0.0785, RMSE=0.2801, R²=0.0025
============================================================


📊 Round 414 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0008

============================================================
🔄 Round 417 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 417 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=0.0034
   Val:   Loss=0.0833, RMSE=0.2887, R²=-0.0161
============================================================


📊 Round 417 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0008

📊 Round 417 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0008

============================================================
🔄 Round 420 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 420 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0027
   Val:   Loss=0.0782, RMSE=0.2797, R²=-0.0007
============================================================


============================================================
🔄 Round 421 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 421 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0032
   Val:   Loss=0.0856, RMSE=0.2925, R²=0.0018
============================================================


============================================================
🔄 Round 422 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 422 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0032
   Val:   Loss=0.0795, RMSE=0.2819, R²=0.0027
============================================================


============================================================
🔄 Round 426 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 426 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0015
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0018
============================================================


📊 Round 426 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0008

============================================================
🔄 Round 428 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 428 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0028
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0001
============================================================


📊 Round 428 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0008

📊 Round 428 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0008

📊 Round 428 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0008

============================================================
🔄 Round 436 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 436 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0027
   Val:   Loss=0.0755, RMSE=0.2748, R²=-0.0006
============================================================


📊 Round 436 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0008

📊 Round 436 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0008

📊 Round 436 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0008

============================================================
🔄 Round 442 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 442 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0024
   Val:   Loss=0.0753, RMSE=0.2743, R²=-0.0008
============================================================


============================================================
🔄 Round 443 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 443 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0020
   Val:   Loss=0.0749, RMSE=0.2737, R²=-0.0025
============================================================


============================================================
🔄 Round 445 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 445 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0025
   Val:   Loss=0.0764, RMSE=0.2764, R²=0.0049
============================================================


📊 Round 445 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0008

============================================================
🔄 Round 454 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 454 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0046
   Val:   Loss=0.0788, RMSE=0.2808, R²=-0.0212
============================================================


============================================================
🔄 Round 457 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 457 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0022
   Val:   Loss=0.0797, RMSE=0.2822, R²=0.0053
============================================================


============================================================
🔄 Round 458 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 458 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0027
   Val:   Loss=0.0769, RMSE=0.2773, R²=-0.0079
============================================================


📊 Round 458 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0008

============================================================
🔄 Round 460 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 460 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0025
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0050
============================================================


📊 Round 460 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0008

📊 Round 460 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0008

📊 Round 460 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0008

📊 Round 460 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0008

============================================================
🔄 Round 467 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 467 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0046
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0029
============================================================


📊 Round 467 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0008

📊 Round 467 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0008

📊 Round 467 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0008

📊 Round 467 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0008

============================================================
🔄 Round 473 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 473 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0034
   Val:   Loss=0.0845, RMSE=0.2906, R²=-0.0010
============================================================


============================================================
🔄 Round 474 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 474 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0015
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.0059
============================================================


📊 Round 474 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0008

📊 Round 474 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0008

============================================================
🔄 Round 478 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 478 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0033
   Val:   Loss=0.0814, RMSE=0.2852, R²=-0.0016
============================================================


============================================================
🔄 Round 479 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0725, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 479 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0034
   Val:   Loss=0.0725, RMSE=0.2693, R²=0.0014
============================================================


📊 Round 479 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0008

============================================================
🔄 Round 482 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 482 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0043
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0045
============================================================


📊 Round 482 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0008

============================================================
🔄 Round 483 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 483 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0036
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0015
============================================================


============================================================
🔄 Round 485 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 485 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0026
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0027
============================================================


📊 Round 485 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0008

📊 Round 485 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0008

📊 Round 485 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0008

============================================================
🔄 Round 491 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 491 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0023
   Val:   Loss=0.0758, RMSE=0.2753, R²=0.0054
============================================================


============================================================
🔄 Round 496 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 496 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0011
   Val:   Loss=0.0762, RMSE=0.2761, R²=0.0021
============================================================


============================================================
🔄 Round 498 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 498 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0044
   Val:   Loss=0.0720, RMSE=0.2684, R²=-0.0130
============================================================


📊 Round 498 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0008

============================================================
🔄 Round 499 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 499 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0014
   Val:   Loss=0.0781, RMSE=0.2794, R²=0.0088
============================================================


📊 Round 499 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0008

============================================================
🔄 Round 502 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 502 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0014
   Val:   Loss=0.0843, RMSE=0.2904, R²=0.0048
============================================================


============================================================
🔄 Round 503 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 503 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0003
   Val:   Loss=0.0824, RMSE=0.2871, R²=0.0131
============================================================


📊 Round 503 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0008

============================================================
🔄 Round 505 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 505 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0042
   Val:   Loss=0.0881, RMSE=0.2969, R²=-0.0018
============================================================


📊 Round 505 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0008

============================================================
🔄 Round 507 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 507 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2843, R²=0.0017
   Val:   Loss=0.0822, RMSE=0.2866, R²=0.0073
============================================================


📊 Round 507 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0008

📊 Round 507 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0008

============================================================
🔄 Round 509 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 509 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0010
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0038
============================================================


============================================================
🔄 Round 510 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 510 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0023
   Val:   Loss=0.0810, RMSE=0.2845, R²=-0.0050
============================================================


📊 Round 510 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0008

============================================================
🔄 Round 511 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 511 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0012
   Val:   Loss=0.0771, RMSE=0.2777, R²=0.0089
============================================================


============================================================
🔄 Round 514 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 514 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0027
   Val:   Loss=0.0760, RMSE=0.2757, R²=-0.0069
============================================================


📊 Round 514 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0008

============================================================
🔄 Round 518 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 518 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0033
   Val:   Loss=0.0813, RMSE=0.2852, R²=0.0024
============================================================


📊 Round 518 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0008

============================================================
🔄 Round 520 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 520 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0009
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0070
============================================================


📊 Round 520 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0008

============================================================
🔄 Round 521 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 521 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2826, R²=0.0032
   Val:   Loss=0.0862, RMSE=0.2937, R²=0.0028
============================================================


============================================================
🔄 Round 522 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 522 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0037
   Val:   Loss=0.0783, RMSE=0.2798, R²=-0.0092
============================================================


📊 Round 522 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0008

📊 Round 522 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0008

============================================================
🔄 Round 526 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 526 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=0.0020
   Val:   Loss=0.0883, RMSE=0.2971, R²=0.0046
============================================================


============================================================
🔄 Round 527 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0700 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0700, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0701, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0701, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0701, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0701, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0700)

============================================================
📊 Round 527 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0031
   Val:   Loss=0.0700, RMSE=0.2646, R²=-0.0281
============================================================


📊 Round 527 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0008

📊 Round 527 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0008

============================================================
🔄 Round 529 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 529 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0046
   Val:   Loss=0.0801, RMSE=0.2829, R²=-0.0090
============================================================


============================================================
🔄 Round 532 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0702 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0702, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0702, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0702, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0702, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0702, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0702)

============================================================
📊 Round 532 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0015
   Val:   Loss=0.0702, RMSE=0.2650, R²=0.0067
============================================================


============================================================
🔄 Round 533 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 533 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0020
   Val:   Loss=0.0746, RMSE=0.2731, R²=0.0021
============================================================


📊 Round 533 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0008

📊 Round 533 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0008

============================================================
🔄 Round 537 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 537 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0025
   Val:   Loss=0.0756, RMSE=0.2750, R²=0.0056
============================================================


============================================================
🔄 Round 538 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 538 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0028
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0007
============================================================


📊 Round 538 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0008

📊 Round 538 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0008

📊 Round 538 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0008

============================================================
🔄 Round 543 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 543 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0014
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0049
============================================================


📊 Round 543 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0008

============================================================
🔄 Round 546 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 546 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2885, R²=0.0030
   Val:   Loss=0.0726, RMSE=0.2694, R²=-0.0002
============================================================


📊 Round 546 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0008

📊 Round 546 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0008

============================================================
🔄 Round 554 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 554 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0029
   Val:   Loss=0.0768, RMSE=0.2771, R²=-0.0036
============================================================


📊 Round 554 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0008

============================================================
🔄 Round 555 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 555 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0031
   Val:   Loss=0.0887, RMSE=0.2979, R²=-0.0080
============================================================


📊 Round 555 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0008

============================================================
🔄 Round 556 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 556 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0034
   Val:   Loss=0.0782, RMSE=0.2797, R²=0.0016
============================================================


📊 Round 556 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0008

============================================================
🔄 Round 559 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 559 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0025
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0199
============================================================


📊 Round 559 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0008

📊 Round 559 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0008

============================================================
🔄 Round 566 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 566 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0026
   Val:   Loss=0.0840, RMSE=0.2899, R²=0.0039
============================================================


📊 Round 566 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0008

============================================================
🔄 Round 569 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 569 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0032
   Val:   Loss=0.0759, RMSE=0.2755, R²=0.0026
============================================================


📊 Round 569 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0008

============================================================
🔄 Round 574 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 574 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0016
   Val:   Loss=0.0815, RMSE=0.2854, R²=-0.0074
============================================================


============================================================
🔄 Round 576 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 576 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0035
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0112
============================================================


📊 Round 576 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0008

============================================================
🔄 Round 577 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 577 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0035
   Val:   Loss=0.0895, RMSE=0.2992, R²=0.0013
============================================================


📊 Round 577 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0008

============================================================
🔄 Round 579 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0715 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0715, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0715, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0715, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0716, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0716, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0715)

============================================================
📊 Round 579 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0045
   Val:   Loss=0.0715, RMSE=0.2674, R²=-0.0078
============================================================


📊 Round 579 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0008

============================================================
🔄 Round 580 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 580 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0027
   Val:   Loss=0.0789, RMSE=0.2810, R²=0.0043
============================================================


📊 Round 580 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0008

============================================================
🔄 Round 582 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 582 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0033
   Val:   Loss=0.0907, RMSE=0.3011, R²=0.0010
============================================================


📊 Round 582 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0008

📊 Round 582 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0008

============================================================
🔄 Round 585 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 585 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0061
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0105
============================================================


📊 Round 585 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0008

============================================================
🔄 Round 587 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 587 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=0.0034
   Val:   Loss=0.0801, RMSE=0.2831, R²=-0.0134
============================================================


📊 Round 587 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0008

📊 Round 587 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0008

============================================================
🔄 Round 591 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 591 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0030
   Val:   Loss=0.0872, RMSE=0.2954, R²=-0.0171
============================================================


📊 Round 591 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0008

============================================================
🔄 Round 592 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 592 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0021
   Val:   Loss=0.0769, RMSE=0.2773, R²=0.0067
============================================================


📊 Round 592 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0008

============================================================
🔄 Round 594 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 594 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0016
   Val:   Loss=0.0877, RMSE=0.2961, R²=0.0079
============================================================


📊 Round 594 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0008

📊 Round 594 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0008

📊 Round 594 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0008

============================================================
🔄 Round 598 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 598 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2856, R²=0.0028
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0063
============================================================


============================================================
🔄 Round 601 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 601 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2863, R²=0.0020
   Val:   Loss=0.0778, RMSE=0.2789, R²=0.0031
============================================================


============================================================
🔄 Round 602 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 602 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0013
   Val:   Loss=0.0793, RMSE=0.2817, R²=-0.0088
============================================================


============================================================
🔄 Round 604 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 604 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0036
   Val:   Loss=0.0774, RMSE=0.2782, R²=0.0007
============================================================


============================================================
🔄 Round 605 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 605 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0038
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0026
============================================================


📊 Round 605 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0008

📊 Round 605 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0008

============================================================
🔄 Round 609 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 609 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0011
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0096
============================================================


============================================================
🔄 Round 611 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 611 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0047
   Val:   Loss=0.0783, RMSE=0.2798, R²=-0.0089
============================================================


📊 Round 611 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0008

============================================================
🔄 Round 613 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0689 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0689, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0689, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0689, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0689, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0689, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0689)

============================================================
📊 Round 613 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0029
   Val:   Loss=0.0689, RMSE=0.2626, R²=0.0037
============================================================


============================================================
🔄 Round 614 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 614 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0020
   Val:   Loss=0.0888, RMSE=0.2980, R²=0.0021
============================================================


📊 Round 614 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0008

============================================================
🔄 Round 616 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 616 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=0.0023
   Val:   Loss=0.0883, RMSE=0.2971, R²=0.0057
============================================================


============================================================
🔄 Round 617 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 617 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0037
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0056
============================================================


============================================================
🔄 Round 618 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 618 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0040
   Val:   Loss=0.0779, RMSE=0.2792, R²=-0.0076
============================================================


============================================================
🔄 Round 621 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0701 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0701, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0701, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0701, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0701, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0701, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0701)

============================================================
📊 Round 621 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0009
   Val:   Loss=0.0701, RMSE=0.2647, R²=0.0018
============================================================


📊 Round 621 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0007

📊 Round 621 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0007

📊 Round 621 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0007

📊 Round 621 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0007

📊 Round 621 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0008

============================================================
🔄 Round 631 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 631 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0049
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0048
============================================================


📊 Round 631 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0007

📊 Round 631 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0008

============================================================
🔄 Round 634 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 634 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0017
   Val:   Loss=0.0894, RMSE=0.2990, R²=0.0070
============================================================


📊 Round 634 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0008

============================================================
🔄 Round 636 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0697 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0697, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0696, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0696, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0696, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0696, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0697)

============================================================
📊 Round 636 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0031
   Val:   Loss=0.0697, RMSE=0.2639, R²=0.0019
============================================================


============================================================
🔄 Round 638 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 638 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=0.0023
   Val:   Loss=0.0902, RMSE=0.3003, R²=-0.0112
============================================================


📊 Round 638 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0008

============================================================
🔄 Round 641 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 641 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0028
   Val:   Loss=0.0912, RMSE=0.3020, R²=0.0038
============================================================


📊 Round 641 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0008

📊 Round 641 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0008

============================================================
🔄 Round 643 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 643 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0034
   Val:   Loss=0.0795, RMSE=0.2819, R²=0.0004
============================================================


📊 Round 643 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0008

============================================================
🔄 Round 644 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 644 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0029
   Val:   Loss=0.0757, RMSE=0.2752, R²=0.0021
============================================================


============================================================
🔄 Round 647 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 647 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0019
   Val:   Loss=0.0739, RMSE=0.2719, R²=0.0006
============================================================


============================================================
🔄 Round 651 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 651 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0011
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0009
============================================================


📊 Round 651 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0008

📊 Round 651 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0008

📊 Round 651 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0008

============================================================
🔄 Round 656 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 656 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0009
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0030
============================================================


============================================================
🔄 Round 658 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 658 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0029
   Val:   Loss=0.0912, RMSE=0.3019, R²=0.0023
============================================================


============================================================
🔄 Round 660 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 660 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0030
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0000
============================================================


📊 Round 660 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0008

============================================================
🔄 Round 661 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 661 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0047
   Val:   Loss=0.0788, RMSE=0.2806, R²=-0.0040
============================================================


📊 Round 661 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2607, R²: 0.0008

❌ Client client_5 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8690 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8690 {grpc_message:"Socket closed", grpc_status:14}"
>
